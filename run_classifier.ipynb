{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dbffc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3==1.26.55\n",
      "  Downloading boto3-1.26.55-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore==1.29.55\n",
      "  Downloading botocore-1.29.55-py3-none-any.whl (10.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.3 MB 46.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting build==0.10.0\n",
      "  Downloading build-0.10.0-py3-none-any.whl (17 kB)\n",
      "Collecting certifi==2022.12.7\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 60.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer==3.0.1\n",
      "  Downloading charset_normalizer-3.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
      "\u001b[K     |████████████████████████████████| 195 kB 51.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click==8.1.3\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 18.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna==3.4\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 348 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath==1.0.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting numpy==1.24.1\n",
      "  Downloading numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 71.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 317.1 MB 30 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 29.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[K     |████████████████████████████████| 849 kB 64.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 557.1 MB 10.0 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging==23.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 41)) (23.0)\n",
      "Collecting pandas==1.5.3\n",
      "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2 MB 29.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pip-tools==6.12.1\n",
      "  Downloading pip_tools-6.12.1-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 4.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pyproject-hooks==1.0.0\n",
      "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 49)) (2.8.2)\n",
      "Collecting pytz==2022.7.1\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "\u001b[K     |████████████████████████████████| 499 kB 70.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex==2022.10.31\n",
      "  Downloading regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "\u001b[K     |████████████████████████████████| 772 kB 44.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests==2.28.2\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 5.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer==0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 61)) (1.16.0)\n",
      "Collecting tomli==2.0.1\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting torch==1.13.1\n",
      "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 887.4 MB 1.3 kB/s  eta 0:00:011    |██████▏                         | 170.3 MB 53.5 MB/s eta 0:00:14     |███████████████▌                | 430.2 MB 72.6 MB/s eta 0:00:07     |██████████████████████████████▊ | 851.3 MB 60.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm==4.64.1\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 17.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions==4.4.0\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting urllib3==1.26.14\n",
      "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 61.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel==0.38.4\n",
      "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->-r requirements.txt (line 31)) (58.0.4)\n",
      "Collecting pip>=22.2\n",
      "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 33.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: wheel, urllib3, tomli, jmespath, pyproject-hooks, nvidia-cublas-cu11, botocore, typing-extensions, s3transfer, pytz, pip, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, numpy, idna, click, charset-normalizer, certifi, build, tqdm, torch, requests, regex, pip-tools, pandas, boto3\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.37.1\n",
      "    Uninstalling wheel-0.37.1:\n",
      "      Successfully uninstalled wheel-0.37.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.7\n",
      "    Uninstalling urllib3-1.26.7:\n",
      "      Successfully uninstalled urllib3-1.26.7\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2021.3\n",
      "    Uninstalling pytz-2021.3:\n",
      "      Successfully uninstalled pytz-2021.3\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.2\n",
      "    Uninstalling numpy-1.21.2:\n",
      "      Successfully uninstalled numpy-1.21.2\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Uninstalling charset-normalizer-2.0.4:\n",
      "      Successfully uninstalled charset-normalizer-2.0.4\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2021.10.8\n",
      "    Uninstalling certifi-2021.10.8:\n",
      "      Successfully uninstalled certifi-2021.10.8\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.62.3\n",
      "    Uninstalling tqdm-4.62.3:\n",
      "      Successfully uninstalled tqdm-4.62.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.27.1\n",
      "    Uninstalling requests-2.27.1:\n",
      "      Successfully uninstalled requests-2.27.1\n",
      "Successfully installed boto3-1.26.55 botocore-1.29.55 build-0.10.0 certifi-2022.12.7 charset-normalizer-3.0.1 click-8.1.3 idna-3.4 jmespath-1.0.1 numpy-1.24.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pandas-1.5.3 pip-22.3.1 pip-tools-6.12.1 pyproject-hooks-1.0.0 pytz-2022.7.1 regex-2022.10.31 requests-2.28.2 s3transfer-0.6.0 tomli-2.0.1 torch-1.13.1 tqdm-4.64.1 typing-extensions-4.4.0 urllib3-1.26.14 wheel-0.38.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cde111c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "01/25/2023 12:54:22 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "01/25/2023 12:54:24 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpmivi82rz\n",
      "100%|████████████████████████████████| 231508/231508 [00:00<00:00, 995938.29B/s]\n",
      "01/25/2023 12:54:24 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpmivi82rz to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "01/25/2023 12:54:24 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "01/25/2023 12:54:24 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpmivi82rz\n",
      "01/25/2023 12:54:24 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "01/25/2023 12:54:24 - INFO - __main__ -   Looking at data/yelp/bert_classifier_training\n",
      "01/25/2023 12:54:27 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpqlou1086\n",
      "100%|█████████████████████████| 407873900/407873900 [03:44<00:00, 1817243.61B/s]\n",
      "01/25/2023 12:58:12 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpqlou1086 to cache at /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "01/25/2023 12:58:12 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "01/25/2023 12:58:12 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpqlou1086\n",
      "01/25/2023 12:58:12 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "01/25/2023 12:58:12 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpof4ygdew\n",
      "01/25/2023 12:58:16 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "01/25/2023 12:58:18 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "01/25/2023 12:58:18 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   *** Example ***\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   guid: train-0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   tokens: [CLS] i was sadly mistaken . [SEP]\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   input_ids: 101 1045 2001 13718 13534 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   label: 0 (id = 0)\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   *** Example ***\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   guid: train-1\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   tokens: [CLS] so on to the ho ##agi ##es , the italian is general run of the mill . [SEP]\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   input_ids: 101 2061 2006 2000 1996 7570 22974 2229 1010 1996 3059 2003 2236 2448 1997 1996 4971 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   label: 0 (id = 0)\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   *** Example ***\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   guid: train-2\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   tokens: [CLS] minimal meat and a ton of shredded let ##tu ##ce . [SEP]\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   input_ids: 101 10124 6240 1998 1037 10228 1997 29022 2292 8525 3401 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   label: 0 (id = 0)\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   *** Example ***\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   guid: train-3\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   tokens: [CLS] nothing really special & not worthy of the $ _ nu ##m _ price tag . [SEP]\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   input_ids: 101 2498 2428 2569 1004 2025 11007 1997 1996 1002 1035 16371 2213 1035 3976 6415 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   label: 0 (id = 0)\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   *** Example ***\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   guid: train-4\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   tokens: [CLS] second , the steak ho ##agi ##e , it is at ##ro ##cious . [SEP]\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   input_ids: 101 2117 1010 1996 21475 7570 22974 2063 1010 2009 2003 2012 3217 18436 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "01/25/2023 12:58:20 - INFO - __main__ -   label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/25/2023 12:59:27 - INFO - __main__ -   ***** Running training *****\n",
      "01/25/2023 12:59:27 - INFO - __main__ -     Num examples = 443259\n",
      "01/25/2023 12:59:27 - INFO - __main__ -     Batch size = 32\n",
      "01/25/2023 12:59:27 - INFO - __main__ -     Num steps = 13851\n",
      "Epoch:   0%|                                              | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                      | 0/13852 [00:00<?, ?it/s]\u001b[A/workspace/transformer-drg-style-transfer/pytorch_pretrained_bert/optimization.py:132: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1420.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "\n",
      "Training loss: 8.18e-01 lr: 0.00e+00:   0%| | 1/13852 [00:00<3:33:53,  1.08it/s]\u001b[A\n",
      "Training loss: 8.00e-01 lr: 3.61e-08:   0%| | 2/13852 [00:01<1:56:44,  1.98it/s]\u001b[A\n",
      "Training loss: 7.71e-01 lr: 7.22e-08:   0%| | 3/13852 [00:01<1:25:24,  2.70it/s]\u001b[A\n",
      "Training loss: 7.97e-01 lr: 1.08e-07:   0%| | 4/13852 [00:01<1:10:33,  3.27it/s]\u001b[A\n",
      "Training loss: 8.09e-01 lr: 1.44e-07:   0%| | 5/13852 [00:01<1:02:28,  3.69it/s]\u001b[A\n",
      "Training loss: 8.24e-01 lr: 1.80e-07:   0%|   | 6/13852 [00:01<57:30,  4.01it/s]\u001b[A\n",
      "Training loss: 8.03e-01 lr: 2.17e-07:   0%|   | 7/13852 [00:02<54:30,  4.23it/s]\u001b[A\n",
      "Training loss: 8.09e-01 lr: 2.53e-07:   0%|   | 8/13852 [00:02<52:27,  4.40it/s]\u001b[A\n",
      "Training loss: 8.05e-01 lr: 2.89e-07:   0%|   | 9/13852 [00:02<51:18,  4.50it/s]\u001b[A\n",
      "Training loss: 7.91e-01 lr: 3.25e-07:   0%|  | 10/13852 [00:02<50:12,  4.59it/s]\u001b[A\n",
      "Training loss: 7.78e-01 lr: 3.61e-07:   0%|  | 11/13852 [00:03<49:25,  4.67it/s]\u001b[A\n",
      "Training loss: 7.65e-01 lr: 3.97e-07:   0%|  | 12/13852 [00:03<48:54,  4.72it/s]\u001b[A\n",
      "Training loss: 7.95e-01 lr: 4.33e-07:   0%|  | 13/13852 [00:03<48:33,  4.75it/s]\u001b[A\n",
      "Training loss: 7.84e-01 lr: 4.69e-07:   0%|  | 14/13852 [00:03<48:23,  4.77it/s]\u001b[A\n",
      "Training loss: 7.74e-01 lr: 5.05e-07:   0%|  | 15/13852 [00:03<48:09,  4.79it/s]\u001b[A\n",
      "Training loss: 7.57e-01 lr: 5.41e-07:   0%|  | 16/13852 [00:04<48:02,  4.80it/s]\u001b[A\n",
      "Training loss: 7.36e-01 lr: 5.78e-07:   0%|  | 17/13852 [00:04<47:56,  4.81it/s]\u001b[A\n",
      "Training loss: 7.40e-01 lr: 6.14e-07:   0%|  | 18/13852 [00:04<47:53,  4.81it/s]\u001b[A\n",
      "Training loss: 7.48e-01 lr: 6.50e-07:   0%|  | 19/13852 [00:04<47:57,  4.81it/s]\u001b[A\n",
      "Training loss: 7.47e-01 lr: 6.86e-07:   0%|  | 20/13852 [00:04<47:52,  4.82it/s]\u001b[A\n",
      "Training loss: 7.38e-01 lr: 7.22e-07:   0%|  | 21/13852 [00:05<47:51,  4.82it/s]\u001b[A\n",
      "Training loss: 7.19e-01 lr: 7.58e-07:   0%|  | 22/13852 [00:05<47:53,  4.81it/s]\u001b[A\n",
      "Training loss: 7.13e-01 lr: 7.94e-07:   0%|  | 23/13852 [00:05<47:54,  4.81it/s]\u001b[A\n",
      "Training loss: 7.00e-01 lr: 8.30e-07:   0%|  | 24/13852 [00:05<47:56,  4.81it/s]\u001b[A\n",
      "Training loss: 7.00e-01 lr: 8.66e-07:   0%|  | 25/13852 [00:05<47:53,  4.81it/s]\u001b[A\n",
      "Training loss: 6.93e-01 lr: 9.02e-07:   0%|  | 26/13852 [00:06<47:50,  4.82it/s]\u001b[A\n",
      "Training loss: 6.88e-01 lr: 9.39e-07:   0%|  | 27/13852 [00:06<47:51,  4.81it/s]\u001b[A\n",
      "Training loss: 6.76e-01 lr: 9.75e-07:   0%|  | 28/13852 [00:06<47:55,  4.81it/s]\u001b[A\n",
      "Training loss: 6.67e-01 lr: 1.01e-06:   0%|  | 29/13852 [00:06<49:16,  4.67it/s]\u001b[A\n",
      "Training loss: 6.62e-01 lr: 1.05e-06:   0%|  | 30/13852 [00:06<48:51,  4.72it/s]\u001b[A\n",
      "Training loss: 6.64e-01 lr: 1.08e-06:   0%|  | 31/13852 [00:07<48:53,  4.71it/s]\u001b[A\n",
      "Training loss: 6.66e-01 lr: 1.12e-06:   0%|  | 32/13852 [00:07<48:52,  4.71it/s]\u001b[A\n",
      "Training loss: 6.55e-01 lr: 1.16e-06:   0%|  | 33/13852 [00:07<48:43,  4.73it/s]\u001b[A\n",
      "Training loss: 6.52e-01 lr: 1.19e-06:   0%|  | 34/13852 [00:07<48:41,  4.73it/s]\u001b[A\n",
      "Training loss: 6.35e-01 lr: 1.23e-06:   0%|  | 35/13852 [00:08<48:31,  4.75it/s]\u001b[A\n",
      "Training loss: 6.21e-01 lr: 1.26e-06:   0%|  | 36/13852 [00:08<48:17,  4.77it/s]\u001b[A\n",
      "Training loss: 5.93e-01 lr: 1.30e-06:   0%|  | 37/13852 [00:08<48:08,  4.78it/s]\u001b[A\n",
      "Training loss: 6.00e-01 lr: 1.34e-06:   0%|  | 38/13852 [00:08<48:02,  4.79it/s]\u001b[A\n",
      "Training loss: 6.21e-01 lr: 1.37e-06:   0%|  | 39/13852 [00:08<47:53,  4.81it/s]\u001b[A\n",
      "Training loss: 5.93e-01 lr: 1.41e-06:   0%|  | 40/13852 [00:09<47:47,  4.82it/s]\u001b[A\n",
      "Training loss: 5.96e-01 lr: 1.44e-06:   0%|  | 41/13852 [00:09<47:46,  4.82it/s]\u001b[A\n",
      "Training loss: 5.70e-01 lr: 1.48e-06:   0%|  | 42/13852 [00:09<47:46,  4.82it/s]\u001b[A\n",
      "Training loss: 5.97e-01 lr: 1.52e-06:   0%|  | 43/13852 [00:09<47:47,  4.82it/s]\u001b[A\n",
      "Training loss: 6.37e-01 lr: 1.55e-06:   0%|  | 44/13852 [00:09<47:48,  4.81it/s]\u001b[A\n",
      "Training loss: 5.99e-01 lr: 1.59e-06:   0%|  | 45/13852 [00:10<47:45,  4.82it/s]\u001b[A\n",
      "Training loss: 5.71e-01 lr: 1.62e-06:   0%|  | 46/13852 [00:10<47:44,  4.82it/s]\u001b[A\n",
      "Training loss: 5.65e-01 lr: 1.66e-06:   0%|  | 47/13852 [00:10<47:44,  4.82it/s]\u001b[A\n",
      "Training loss: 5.68e-01 lr: 1.70e-06:   0%|  | 48/13852 [00:10<47:46,  4.82it/s]\u001b[A\n",
      "Training loss: 5.48e-01 lr: 1.73e-06:   0%|  | 49/13852 [00:10<48:07,  4.78it/s]\u001b[A\n",
      "Training loss: 5.35e-01 lr: 1.77e-06:   0%|  | 50/13852 [00:11<48:01,  4.79it/s]\u001b[A\n",
      "Training loss: 5.28e-01 lr: 1.80e-06:   0%|  | 51/13852 [00:11<48:27,  4.75it/s]\u001b[A\n",
      "Training loss: 5.33e-01 lr: 1.84e-06:   0%|  | 52/13852 [00:11<48:16,  4.76it/s]\u001b[A\n",
      "Training loss: 5.24e-01 lr: 1.88e-06:   0%|  | 53/13852 [00:11<48:13,  4.77it/s]\u001b[A\n",
      "Training loss: 5.12e-01 lr: 1.91e-06:   0%|  | 54/13852 [00:11<48:06,  4.78it/s]\u001b[A\n",
      "Training loss: 4.80e-01 lr: 1.95e-06:   0%|  | 55/13852 [00:12<48:04,  4.78it/s]\u001b[A\n",
      "Training loss: 4.61e-01 lr: 1.99e-06:   0%|  | 56/13852 [00:12<48:02,  4.79it/s]\u001b[A\n",
      "Training loss: 4.49e-01 lr: 2.02e-06:   0%|  | 57/13852 [00:12<47:57,  4.79it/s]\u001b[A\n",
      "Training loss: 4.29e-01 lr: 2.06e-06:   0%|  | 58/13852 [00:12<48:08,  4.78it/s]\u001b[A\n",
      "Training loss: 4.37e-01 lr: 2.09e-06:   0%|  | 59/13852 [00:13<47:58,  4.79it/s]\u001b[A\n",
      "Training loss: 4.31e-01 lr: 2.13e-06:   0%|  | 60/13852 [00:13<47:54,  4.80it/s]\u001b[A\n",
      "Training loss: 4.21e-01 lr: 2.17e-06:   0%|  | 61/13852 [00:13<47:52,  4.80it/s]\u001b[A\n",
      "Training loss: 3.83e-01 lr: 2.20e-06:   0%|  | 62/13852 [00:13<47:52,  4.80it/s]\u001b[A\n",
      "Training loss: 3.91e-01 lr: 2.24e-06:   0%|  | 63/13852 [00:13<47:52,  4.80it/s]\u001b[A\n",
      "Training loss: 4.04e-01 lr: 2.27e-06:   0%|  | 64/13852 [00:14<47:50,  4.80it/s]\u001b[A\n",
      "Training loss: 3.55e-01 lr: 2.31e-06:   0%|  | 65/13852 [00:14<47:47,  4.81it/s]\u001b[A\n",
      "Training loss: 3.28e-01 lr: 2.35e-06:   0%|  | 66/13852 [00:14<47:48,  4.81it/s]\u001b[A\n",
      "Training loss: 3.24e-01 lr: 2.38e-06:   0%|  | 67/13852 [00:14<47:44,  4.81it/s]\u001b[A\n",
      "Training loss: 2.87e-01 lr: 2.42e-06:   0%|  | 68/13852 [00:14<47:44,  4.81it/s]\u001b[A\n",
      "Training loss: 2.66e-01 lr: 2.45e-06:   0%|  | 69/13852 [00:15<47:43,  4.81it/s]\u001b[A\n",
      "Training loss: 2.95e-01 lr: 2.49e-06:   1%|  | 70/13852 [00:15<47:44,  4.81it/s]\u001b[A\n",
      "Training loss: 3.02e-01 lr: 2.53e-06:   1%|  | 71/13852 [00:15<47:44,  4.81it/s]\u001b[A\n",
      "Training loss: 2.86e-01 lr: 2.56e-06:   1%|  | 72/13852 [00:15<47:41,  4.82it/s]\u001b[A\n",
      "Training loss: 2.76e-01 lr: 2.60e-06:   1%|  | 73/13852 [00:15<47:39,  4.82it/s]\u001b[A\n",
      "Training loss: 2.84e-01 lr: 2.64e-06:   1%|  | 74/13852 [00:16<47:54,  4.79it/s]\u001b[A\n",
      "Training loss: 2.94e-01 lr: 2.67e-06:   1%|  | 75/13852 [00:16<48:03,  4.78it/s]\u001b[A\n",
      "Training loss: 2.99e-01 lr: 2.71e-06:   1%|  | 76/13852 [00:16<47:53,  4.79it/s]\u001b[A\n",
      "Training loss: 2.79e-01 lr: 2.74e-06:   1%|  | 77/13852 [00:16<47:52,  4.80it/s]\u001b[A\n",
      "Training loss: 2.39e-01 lr: 2.78e-06:   1%|  | 78/13852 [00:16<47:52,  4.79it/s]\u001b[A\n",
      "Training loss: 2.40e-01 lr: 2.82e-06:   1%|  | 79/13852 [00:17<47:52,  4.80it/s]\u001b[A\n",
      "Training loss: 2.42e-01 lr: 2.85e-06:   1%|  | 80/13852 [00:17<48:00,  4.78it/s]\u001b[A\n",
      "Training loss: 2.14e-01 lr: 2.89e-06:   1%|  | 81/13852 [00:17<47:58,  4.78it/s]\u001b[A\n",
      "Training loss: 2.45e-01 lr: 2.92e-06:   1%|  | 82/13852 [00:17<47:57,  4.78it/s]\u001b[A\n",
      "Training loss: 2.18e-01 lr: 2.96e-06:   1%|  | 83/13852 [00:18<47:55,  4.79it/s]\u001b[A\n",
      "Training loss: 1.93e-01 lr: 3.00e-06:   1%|  | 84/13852 [00:18<47:52,  4.79it/s]\u001b[A\n",
      "Training loss: 1.84e-01 lr: 3.03e-06:   1%|  | 85/13852 [00:18<47:53,  4.79it/s]\u001b[A\n",
      "Training loss: 2.29e-01 lr: 3.07e-06:   1%|  | 86/13852 [00:18<47:53,  4.79it/s]\u001b[A\n",
      "Training loss: 2.72e-01 lr: 3.10e-06:   1%|  | 87/13852 [00:18<47:50,  4.79it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.27e-01 lr: 3.14e-06:   1%|  | 88/13852 [00:19<47:46,  4.80it/s]\u001b[A\n",
      "Training loss: 2.22e-01 lr: 3.18e-06:   1%|  | 89/13852 [00:19<47:45,  4.80it/s]\u001b[A\n",
      "Training loss: 2.16e-01 lr: 3.21e-06:   1%|  | 90/13852 [00:19<47:49,  4.80it/s]\u001b[A\n",
      "Training loss: 2.09e-01 lr: 3.25e-06:   1%|  | 91/13852 [00:19<47:48,  4.80it/s]\u001b[A\n",
      "Training loss: 2.14e-01 lr: 3.28e-06:   1%|  | 92/13852 [00:19<47:47,  4.80it/s]\u001b[A\n",
      "Training loss: 2.25e-01 lr: 3.32e-06:   1%|  | 93/13852 [00:20<47:50,  4.79it/s]\u001b[A\n",
      "Training loss: 2.56e-01 lr: 3.36e-06:   1%|  | 94/13852 [00:20<47:49,  4.80it/s]\u001b[A\n",
      "Training loss: 2.55e-01 lr: 3.39e-06:   1%|  | 95/13852 [00:20<47:46,  4.80it/s]\u001b[A\n",
      "Training loss: 2.51e-01 lr: 3.43e-06:   1%|  | 96/13852 [00:20<47:45,  4.80it/s]\u001b[A\n",
      "Training loss: 2.25e-01 lr: 3.47e-06:   1%|  | 97/13852 [00:20<47:47,  4.80it/s]\u001b[A\n",
      "Training loss: 2.08e-01 lr: 3.50e-06:   1%|  | 98/13852 [00:21<47:51,  4.79it/s]\u001b[A\n",
      "Training loss: 1.94e-01 lr: 3.54e-06:   1%|  | 99/13852 [00:21<48:09,  4.76it/s]\u001b[A\n",
      "Training loss: 2.22e-01 lr: 3.57e-06:   1%| | 100/13852 [00:21<48:07,  4.76it/s]\u001b[A\n",
      "Training loss: 1.79e-01 lr: 3.61e-06:   1%| | 101/13852 [00:21<48:05,  4.77it/s]\u001b[A\n",
      "Training loss: 1.69e-01 lr: 3.65e-06:   1%| | 102/13852 [00:22<47:58,  4.78it/s]\u001b[A\n",
      "Training loss: 1.79e-01 lr: 3.68e-06:   1%| | 103/13852 [00:22<48:10,  4.76it/s]\u001b[A\n",
      "Training loss: 1.72e-01 lr: 3.72e-06:   1%| | 104/13852 [00:22<48:09,  4.76it/s]\u001b[A\n",
      "Training loss: 1.70e-01 lr: 3.75e-06:   1%| | 105/13852 [00:22<48:04,  4.77it/s]\u001b[A\n",
      "Training loss: 2.43e-01 lr: 3.79e-06:   1%| | 106/13852 [00:22<48:01,  4.77it/s]\u001b[A\n",
      "Training loss: 2.49e-01 lr: 3.83e-06:   1%| | 107/13852 [00:23<48:03,  4.77it/s]\u001b[A\n",
      "Training loss: 2.24e-01 lr: 3.86e-06:   1%| | 108/13852 [00:23<48:01,  4.77it/s]\u001b[A\n",
      "Training loss: 1.90e-01 lr: 3.90e-06:   1%| | 109/13852 [00:23<47:56,  4.78it/s]\u001b[A\n",
      "Training loss: 2.28e-01 lr: 3.93e-06:   1%| | 110/13852 [00:23<47:55,  4.78it/s]\u001b[A\n",
      "Training loss: 2.27e-01 lr: 3.97e-06:   1%| | 111/13852 [00:23<47:56,  4.78it/s]\u001b[A\n",
      "Training loss: 2.07e-01 lr: 4.01e-06:   1%| | 112/13852 [00:24<47:52,  4.78it/s]\u001b[A\n",
      "Training loss: 2.04e-01 lr: 4.04e-06:   1%| | 113/13852 [00:24<47:53,  4.78it/s]\u001b[A\n",
      "Training loss: 2.11e-01 lr: 4.08e-06:   1%| | 114/13852 [00:24<47:54,  4.78it/s]\u001b[A\n",
      "Training loss: 1.77e-01 lr: 4.12e-06:   1%| | 115/13852 [00:24<47:54,  4.78it/s]\u001b[A\n",
      "Training loss: 1.54e-01 lr: 4.15e-06:   1%| | 116/13852 [00:24<47:52,  4.78it/s]\u001b[A\n",
      "Training loss: 1.63e-01 lr: 4.19e-06:   1%| | 117/13852 [00:25<47:50,  4.78it/s]\u001b[A\n",
      "Training loss: 1.67e-01 lr: 4.22e-06:   1%| | 118/13852 [00:25<47:52,  4.78it/s]\u001b[A\n",
      "Training loss: 2.22e-01 lr: 4.26e-06:   1%| | 119/13852 [00:25<47:51,  4.78it/s]\u001b[A\n",
      "Training loss: 2.12e-01 lr: 4.30e-06:   1%| | 120/13852 [00:25<47:51,  4.78it/s]\u001b[A\n",
      "Training loss: 1.79e-01 lr: 4.33e-06:   1%| | 121/13852 [00:25<47:50,  4.78it/s]\u001b[A\n",
      "Training loss: 1.78e-01 lr: 4.37e-06:   1%| | 122/13852 [00:26<47:52,  4.78it/s]\u001b[A\n",
      "Training loss: 1.54e-01 lr: 4.40e-06:   1%| | 123/13852 [00:26<47:49,  4.78it/s]\u001b[A\n",
      "Training loss: 1.54e-01 lr: 4.44e-06:   1%| | 124/13852 [00:26<47:48,  4.79it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 4.48e-06:   1%| | 125/13852 [00:26<47:49,  4.78it/s]\u001b[A\n",
      "Training loss: 1.67e-01 lr: 4.51e-06:   1%| | 126/13852 [00:27<47:50,  4.78it/s]\u001b[A\n",
      "Training loss: 1.64e-01 lr: 4.55e-06:   1%| | 127/13852 [00:27<48:02,  4.76it/s]\u001b[A\n",
      "Training loss: 1.67e-01 lr: 4.58e-06:   1%| | 128/13852 [00:27<48:06,  4.76it/s]\u001b[A\n",
      "Training loss: 1.59e-01 lr: 4.62e-06:   1%| | 129/13852 [00:27<48:01,  4.76it/s]\u001b[A\n",
      "Training loss: 1.63e-01 lr: 4.66e-06:   1%| | 130/13852 [00:27<47:59,  4.77it/s]\u001b[A\n",
      "Training loss: 1.43e-01 lr: 4.69e-06:   1%| | 131/13852 [00:28<48:02,  4.76it/s]\u001b[A\n",
      "Training loss: 1.69e-01 lr: 4.73e-06:   1%| | 132/13852 [00:28<47:59,  4.76it/s]\u001b[A\n",
      "Training loss: 1.39e-01 lr: 4.76e-06:   1%| | 133/13852 [00:28<47:54,  4.77it/s]\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.80e-06:   1%| | 134/13852 [00:28<47:54,  4.77it/s]\u001b[A\n",
      "Training loss: 1.32e-01 lr: 4.84e-06:   1%| | 135/13852 [00:28<49:16,  4.64it/s]\u001b[A\n",
      "Training loss: 1.88e-01 lr: 4.87e-06:   1%| | 136/13852 [00:29<50:10,  4.56it/s]\u001b[A\n",
      "Training loss: 1.81e-01 lr: 4.91e-06:   1%| | 137/13852 [00:29<50:14,  4.55it/s]\u001b[A\n",
      "Training loss: 2.28e-01 lr: 4.95e-06:   1%| | 138/13852 [00:29<49:34,  4.61it/s]\u001b[A\n",
      "Training loss: 2.70e-01 lr: 4.98e-06:   1%| | 139/13852 [00:29<49:09,  4.65it/s]\u001b[A\n",
      "Training loss: 2.75e-01 lr: 5.02e-06:   1%| | 140/13852 [00:30<48:50,  4.68it/s]\u001b[A\n",
      "Training loss: 2.45e-01 lr: 5.05e-06:   1%| | 141/13852 [00:30<48:31,  4.71it/s]\u001b[A\n",
      "Training loss: 2.03e-01 lr: 5.09e-06:   1%| | 142/13852 [00:30<48:25,  4.72it/s]\u001b[A\n",
      "Training loss: 2.52e-01 lr: 5.13e-06:   1%| | 143/13852 [00:30<48:19,  4.73it/s]\u001b[A\n",
      "Training loss: 2.62e-01 lr: 5.16e-06:   1%| | 144/13852 [00:30<48:13,  4.74it/s]\u001b[A\n",
      "Training loss: 2.97e-01 lr: 5.20e-06:   1%| | 145/13852 [00:31<48:32,  4.71it/s]\u001b[A\n",
      "Training loss: 2.50e-01 lr: 5.23e-06:   1%| | 146/13852 [00:31<48:35,  4.70it/s]\u001b[A\n",
      "Training loss: 1.95e-01 lr: 5.27e-06:   1%| | 147/13852 [00:31<48:34,  4.70it/s]\u001b[A\n",
      "Training loss: 1.84e-01 lr: 5.31e-06:   1%| | 148/13852 [00:31<48:33,  4.70it/s]\u001b[A\n",
      "Training loss: 1.45e-01 lr: 5.34e-06:   1%| | 149/13852 [00:31<48:23,  4.72it/s]\u001b[A\n",
      "Training loss: 1.20e-01 lr: 5.38e-06:   1%| | 150/13852 [00:32<48:28,  4.71it/s]\u001b[A\n",
      "Training loss: 1.27e-01 lr: 5.41e-06:   1%| | 151/13852 [00:32<48:25,  4.72it/s]\u001b[A\n",
      "Training loss: 1.91e-01 lr: 5.45e-06:   1%| | 152/13852 [00:32<48:23,  4.72it/s]\u001b[A\n",
      "Training loss: 2.00e-01 lr: 5.49e-06:   1%| | 153/13852 [00:32<48:19,  4.73it/s]\u001b[A\n",
      "Training loss: 2.07e-01 lr: 5.52e-06:   1%| | 154/13852 [00:32<48:14,  4.73it/s]\u001b[A\n",
      "Training loss: 2.31e-01 lr: 5.56e-06:   1%| | 155/13852 [00:33<48:13,  4.73it/s]\u001b[A\n",
      "Training loss: 2.32e-01 lr: 5.60e-06:   1%| | 156/13852 [00:33<48:12,  4.73it/s]\u001b[A\n",
      "Training loss: 1.84e-01 lr: 5.63e-06:   1%| | 157/13852 [00:33<48:18,  4.72it/s]\u001b[A\n",
      "Training loss: 1.60e-01 lr: 5.67e-06:   1%| | 158/13852 [00:33<48:15,  4.73it/s]\u001b[A\n",
      "Training loss: 1.38e-01 lr: 5.70e-06:   1%| | 159/13852 [00:34<48:12,  4.73it/s]\u001b[A\n",
      "Training loss: 1.48e-01 lr: 5.74e-06:   1%| | 160/13852 [00:34<48:13,  4.73it/s]\u001b[A\n",
      "Training loss: 1.44e-01 lr: 5.78e-06:   1%| | 161/13852 [00:34<48:06,  4.74it/s]\u001b[A\n",
      "Training loss: 1.36e-01 lr: 5.81e-06:   1%| | 162/13852 [00:34<48:07,  4.74it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 5.85e-06:   1%| | 163/13852 [00:34<48:07,  4.74it/s]\u001b[A\n",
      "Training loss: 1.83e-01 lr: 5.88e-06:   1%| | 164/13852 [00:35<48:04,  4.74it/s]\u001b[A\n",
      "Training loss: 1.69e-01 lr: 5.92e-06:   1%| | 165/13852 [00:35<48:06,  4.74it/s]\u001b[A\n",
      "Training loss: 1.68e-01 lr: 5.96e-06:   1%| | 166/13852 [00:35<48:07,  4.74it/s]\u001b[A\n",
      "Training loss: 1.63e-01 lr: 5.99e-06:   1%| | 167/13852 [00:35<48:03,  4.75it/s]\u001b[A\n",
      "Training loss: 2.34e-01 lr: 6.03e-06:   1%| | 168/13852 [00:35<48:07,  4.74it/s]\u001b[A\n",
      "Training loss: 2.53e-01 lr: 6.06e-06:   1%| | 169/13852 [00:36<48:05,  4.74it/s]\u001b[A\n",
      "Training loss: 2.21e-01 lr: 6.10e-06:   1%| | 170/13852 [00:36<48:03,  4.74it/s]\u001b[A\n",
      "Training loss: 1.88e-01 lr: 6.14e-06:   1%| | 171/13852 [00:36<48:07,  4.74it/s]\u001b[A\n",
      "Training loss: 1.89e-01 lr: 6.17e-06:   1%| | 172/13852 [00:36<49:05,  4.64it/s]\u001b[A\n",
      "Training loss: 1.65e-01 lr: 6.21e-06:   1%| | 173/13852 [00:37<50:18,  4.53it/s]\u001b[A\n",
      "Training loss: 1.53e-01 lr: 6.25e-06:   1%| | 174/13852 [00:37<52:23,  4.35it/s]\u001b[A\n",
      "Training loss: 2.15e-01 lr: 6.28e-06:   1%| | 175/13852 [00:37<51:40,  4.41it/s]\u001b[A\n",
      "Training loss: 2.16e-01 lr: 6.32e-06:   1%| | 176/13852 [00:37<52:19,  4.36it/s]\u001b[A\n",
      "Training loss: 1.74e-01 lr: 6.35e-06:   1%| | 177/13852 [00:37<52:36,  4.33it/s]\u001b[A\n",
      "Training loss: 1.95e-01 lr: 6.39e-06:   1%| | 178/13852 [00:38<52:53,  4.31it/s]\u001b[A\n",
      "Training loss: 1.85e-01 lr: 6.43e-06:   1%| | 179/13852 [00:38<53:09,  4.29it/s]\u001b[A\n",
      "Training loss: 2.31e-01 lr: 6.46e-06:   1%| | 180/13852 [00:38<51:34,  4.42it/s]\u001b[A\n",
      "Training loss: 2.30e-01 lr: 6.50e-06:   1%| | 181/13852 [00:38<50:30,  4.51it/s]\u001b[A\n",
      "Training loss: 1.89e-01 lr: 6.53e-06:   1%| | 182/13852 [00:39<49:57,  4.56it/s]\u001b[A\n",
      "Training loss: 1.73e-01 lr: 6.57e-06:   1%| | 183/13852 [00:39<49:22,  4.61it/s]\u001b[A\n",
      "Training loss: 1.60e-01 lr: 6.61e-06:   1%| | 184/13852 [00:39<48:55,  4.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.47e-01 lr: 6.64e-06:   1%| | 185/13852 [00:39<48:43,  4.68it/s]\u001b[A\n",
      "Training loss: 1.39e-01 lr: 6.68e-06:   1%| | 186/13852 [00:39<48:31,  4.69it/s]\u001b[A\n",
      "Training loss: 1.22e-01 lr: 6.71e-06:   1%| | 187/13852 [00:40<48:19,  4.71it/s]\u001b[A\n",
      "Training loss: 1.37e-01 lr: 6.75e-06:   1%| | 188/13852 [00:40<48:12,  4.72it/s]\u001b[A\n",
      "Training loss: 1.18e-01 lr: 6.79e-06:   1%| | 189/13852 [00:40<48:15,  4.72it/s]\u001b[A\n",
      "Training loss: 1.28e-01 lr: 6.82e-06:   1%| | 190/13852 [00:40<48:07,  4.73it/s]\u001b[A\n",
      "Training loss: 1.12e-01 lr: 6.86e-06:   1%| | 191/13852 [00:40<48:05,  4.74it/s]\u001b[A\n",
      "Training loss: 1.20e-01 lr: 6.89e-06:   1%| | 192/13852 [00:41<48:24,  4.70it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 6.93e-06:   1%| | 193/13852 [00:41<48:40,  4.68it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 6.97e-06:   1%| | 194/13852 [00:41<48:34,  4.69it/s]\u001b[A\n",
      "Training loss: 1.26e-01 lr: 7.00e-06:   1%| | 195/13852 [00:41<48:42,  4.67it/s]\u001b[A\n",
      "Training loss: 9.78e-02 lr: 7.04e-06:   1%| | 196/13852 [00:42<48:29,  4.69it/s]\u001b[A\n",
      "Training loss: 9.19e-02 lr: 7.08e-06:   1%| | 197/13852 [00:42<48:40,  4.68it/s]\u001b[A\n",
      "Training loss: 1.31e-01 lr: 7.11e-06:   1%| | 198/13852 [00:42<48:31,  4.69it/s]\u001b[A\n",
      "Training loss: 1.42e-01 lr: 7.15e-06:   1%| | 199/13852 [00:42<48:20,  4.71it/s]\u001b[A\n",
      "Training loss: 1.28e-01 lr: 7.18e-06:   1%| | 200/13852 [00:42<48:12,  4.72it/s]\u001b[A\n",
      "Training loss: 9.72e-02 lr: 7.22e-06:   1%| | 201/13852 [00:43<48:05,  4.73it/s]\u001b[A\n",
      "Training loss: 1.11e-01 lr: 7.26e-06:   1%| | 202/13852 [00:43<48:07,  4.73it/s]\u001b[A\n",
      "Training loss: 8.82e-02 lr: 7.29e-06:   1%| | 203/13852 [00:43<48:10,  4.72it/s]\u001b[A\n",
      "Training loss: 1.20e-01 lr: 7.33e-06:   1%| | 204/13852 [00:43<48:22,  4.70it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 7.36e-06:   1%| | 205/13852 [00:43<48:14,  4.71it/s]\u001b[A\n",
      "Training loss: 1.62e-01 lr: 7.40e-06:   1%| | 206/13852 [00:44<48:20,  4.70it/s]\u001b[A\n",
      "Training loss: 1.41e-01 lr: 7.44e-06:   1%| | 207/13852 [00:44<48:14,  4.71it/s]\u001b[A\n",
      "Training loss: 2.08e-01 lr: 7.47e-06:   2%| | 208/13852 [00:44<48:09,  4.72it/s]\u001b[A\n",
      "Training loss: 1.78e-01 lr: 7.51e-06:   2%| | 209/13852 [00:44<48:07,  4.72it/s]\u001b[A\n",
      "Training loss: 1.59e-01 lr: 7.54e-06:   2%| | 210/13852 [00:45<48:01,  4.73it/s]\u001b[A\n",
      "Training loss: 1.46e-01 lr: 7.58e-06:   2%| | 211/13852 [00:45<47:59,  4.74it/s]\u001b[A\n",
      "Training loss: 1.48e-01 lr: 7.62e-06:   2%| | 212/13852 [00:45<48:02,  4.73it/s]\u001b[A\n",
      "Training loss: 1.18e-01 lr: 7.65e-06:   2%| | 213/13852 [00:45<47:57,  4.74it/s]\u001b[A\n",
      "Training loss: 1.42e-01 lr: 7.69e-06:   2%| | 214/13852 [00:45<48:05,  4.73it/s]\u001b[A\n",
      "Training loss: 1.24e-01 lr: 7.73e-06:   2%| | 215/13852 [00:46<48:03,  4.73it/s]\u001b[A\n",
      "Training loss: 1.47e-01 lr: 7.76e-06:   2%| | 216/13852 [00:46<48:04,  4.73it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 7.80e-06:   2%| | 217/13852 [00:46<48:10,  4.72it/s]\u001b[A\n",
      "Training loss: 1.07e-01 lr: 7.83e-06:   2%| | 218/13852 [00:46<48:30,  4.68it/s]\u001b[A\n",
      "Training loss: 8.74e-02 lr: 7.87e-06:   2%| | 219/13852 [00:46<50:00,  4.54it/s]\u001b[A\n",
      "Training loss: 7.09e-02 lr: 7.91e-06:   2%| | 220/13852 [00:47<51:45,  4.39it/s]\u001b[A\n",
      "Training loss: 1.10e-01 lr: 7.94e-06:   2%| | 221/13852 [00:47<52:20,  4.34it/s]\u001b[A\n",
      "Training loss: 1.40e-01 lr: 7.98e-06:   2%| | 222/13852 [00:47<51:35,  4.40it/s]\u001b[A\n",
      "Training loss: 1.32e-01 lr: 8.01e-06:   2%| | 223/13852 [00:47<51:07,  4.44it/s]\u001b[A\n",
      "Training loss: 1.28e-01 lr: 8.05e-06:   2%| | 224/13852 [00:48<50:24,  4.51it/s]\u001b[A\n",
      "Training loss: 1.22e-01 lr: 8.09e-06:   2%| | 225/13852 [00:48<50:03,  4.54it/s]\u001b[A\n",
      "Training loss: 1.45e-01 lr: 8.12e-06:   2%| | 226/13852 [00:48<51:13,  4.43it/s]\u001b[A\n",
      "Training loss: 1.87e-01 lr: 8.16e-06:   2%| | 227/13852 [00:48<51:58,  4.37it/s]\u001b[A\n",
      "Training loss: 1.75e-01 lr: 8.19e-06:   2%| | 228/13852 [00:48<50:56,  4.46it/s]\u001b[A\n",
      "Training loss: 2.13e-01 lr: 8.23e-06:   2%| | 229/13852 [00:49<50:02,  4.54it/s]\u001b[A\n",
      "Training loss: 2.09e-01 lr: 8.27e-06:   2%| | 230/13852 [00:49<49:27,  4.59it/s]\u001b[A\n",
      "Training loss: 1.83e-01 lr: 8.30e-06:   2%| | 231/13852 [00:49<49:09,  4.62it/s]\u001b[A\n",
      "Training loss: 1.68e-01 lr: 8.34e-06:   2%| | 232/13852 [00:49<48:51,  4.65it/s]\u001b[A\n",
      "Training loss: 1.58e-01 lr: 8.37e-06:   2%| | 233/13852 [00:50<48:35,  4.67it/s]\u001b[A\n",
      "Training loss: 1.36e-01 lr: 8.41e-06:   2%| | 234/13852 [00:50<48:34,  4.67it/s]\u001b[A\n",
      "Training loss: 1.06e-01 lr: 8.45e-06:   2%| | 235/13852 [00:50<48:27,  4.68it/s]\u001b[A\n",
      "Training loss: 9.53e-02 lr: 8.48e-06:   2%| | 236/13852 [00:50<48:18,  4.70it/s]\u001b[A\n",
      "Training loss: 9.12e-02 lr: 8.52e-06:   2%| | 237/13852 [00:50<48:14,  4.70it/s]\u001b[A\n",
      "Training loss: 7.01e-02 lr: 8.56e-06:   2%| | 238/13852 [00:51<48:22,  4.69it/s]\u001b[A\n",
      "Training loss: 9.37e-02 lr: 8.59e-06:   2%| | 239/13852 [00:51<48:41,  4.66it/s]\u001b[A\n",
      "Training loss: 9.72e-02 lr: 8.63e-06:   2%| | 240/13852 [00:51<48:40,  4.66it/s]\u001b[A\n",
      "Training loss: 1.34e-01 lr: 8.66e-06:   2%| | 241/13852 [00:51<48:26,  4.68it/s]\u001b[A\n",
      "Training loss: 1.16e-01 lr: 8.70e-06:   2%| | 242/13852 [00:51<48:34,  4.67it/s]\u001b[A\n",
      "Training loss: 1.41e-01 lr: 8.74e-06:   2%| | 243/13852 [00:52<48:45,  4.65it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 8.77e-06:   2%| | 244/13852 [00:52<48:45,  4.65it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 8.81e-06:   2%| | 245/13852 [00:52<48:37,  4.66it/s]\u001b[A\n",
      "Training loss: 1.20e-01 lr: 8.84e-06:   2%| | 246/13852 [00:52<48:26,  4.68it/s]\u001b[A\n",
      "Training loss: 1.28e-01 lr: 8.88e-06:   2%| | 247/13852 [00:53<48:17,  4.70it/s]\u001b[A\n",
      "Training loss: 1.52e-01 lr: 8.92e-06:   2%| | 248/13852 [00:53<48:13,  4.70it/s]\u001b[A\n",
      "Training loss: 1.56e-01 lr: 8.95e-06:   2%| | 249/13852 [00:53<48:09,  4.71it/s]\u001b[A\n",
      "Training loss: 1.22e-01 lr: 8.99e-06:   2%| | 250/13852 [00:53<48:07,  4.71it/s]\u001b[A\n",
      "Training loss: 1.26e-01 lr: 9.02e-06:   2%| | 251/13852 [00:53<48:09,  4.71it/s]\u001b[A\n",
      "Training loss: 1.75e-01 lr: 9.06e-06:   2%| | 252/13852 [00:54<48:07,  4.71it/s]\u001b[A\n",
      "Training loss: 1.67e-01 lr: 9.10e-06:   2%| | 253/13852 [00:54<48:07,  4.71it/s]\u001b[A\n",
      "Training loss: 1.74e-01 lr: 9.13e-06:   2%| | 254/13852 [00:54<48:03,  4.72it/s]\u001b[A\n",
      "Training loss: 1.47e-01 lr: 9.17e-06:   2%| | 255/13852 [00:54<48:04,  4.71it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 9.21e-06:   2%| | 256/13852 [00:54<48:00,  4.72it/s]\u001b[A\n",
      "Training loss: 1.04e-01 lr: 9.24e-06:   2%| | 257/13852 [00:55<48:02,  4.72it/s]\u001b[A\n",
      "Training loss: 1.59e-01 lr: 9.28e-06:   2%| | 258/13852 [00:55<48:08,  4.71it/s]\u001b[A\n",
      "Training loss: 1.39e-01 lr: 9.31e-06:   2%| | 259/13852 [00:55<48:07,  4.71it/s]\u001b[A\n",
      "Training loss: 1.19e-01 lr: 9.35e-06:   2%| | 260/13852 [00:55<48:04,  4.71it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 9.39e-06:   2%| | 261/13852 [00:56<48:10,  4.70it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 9.42e-06:   2%| | 262/13852 [00:56<48:11,  4.70it/s]\u001b[A\n",
      "Training loss: 1.51e-01 lr: 9.46e-06:   2%| | 263/13852 [00:56<48:05,  4.71it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 9.49e-06:   2%| | 264/13852 [00:56<48:08,  4.70it/s]\u001b[A\n",
      "Training loss: 1.82e-01 lr: 9.53e-06:   2%| | 265/13852 [00:56<49:16,  4.60it/s]\u001b[A\n",
      "Training loss: 1.58e-01 lr: 9.57e-06:   2%| | 266/13852 [00:57<48:53,  4.63it/s]\u001b[A\n",
      "Training loss: 1.40e-01 lr: 9.60e-06:   2%| | 267/13852 [00:57<49:01,  4.62it/s]\u001b[A\n",
      "Training loss: 1.81e-01 lr: 9.64e-06:   2%| | 268/13852 [00:57<49:00,  4.62it/s]\u001b[A\n",
      "Training loss: 1.50e-01 lr: 9.67e-06:   2%| | 269/13852 [00:57<48:51,  4.63it/s]\u001b[A\n",
      "Training loss: 1.34e-01 lr: 9.71e-06:   2%| | 270/13852 [00:57<48:48,  4.64it/s]\u001b[A\n",
      "Training loss: 1.73e-01 lr: 9.75e-06:   2%| | 271/13852 [00:58<48:44,  4.64it/s]\u001b[A\n",
      "Training loss: 1.52e-01 lr: 9.78e-06:   2%| | 272/13852 [00:58<48:37,  4.66it/s]\u001b[A\n",
      "Training loss: 1.52e-01 lr: 9.82e-06:   2%| | 273/13852 [00:58<48:36,  4.66it/s]\u001b[A\n",
      "Training loss: 1.21e-01 lr: 9.85e-06:   2%| | 274/13852 [00:58<48:24,  4.67it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 9.89e-06:   2%| | 275/13852 [00:59<48:22,  4.68it/s]\u001b[A\n",
      "Training loss: 8.82e-02 lr: 9.93e-06:   2%| | 276/13852 [00:59<48:19,  4.68it/s]\u001b[A\n",
      "Training loss: 8.56e-02 lr: 9.96e-06:   2%| | 277/13852 [00:59<48:16,  4.69it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 1.00e-05:   2%| | 278/13852 [00:59<48:17,  4.69it/s]\u001b[A\n",
      "Training loss: 1.32e-01 lr: 1.00e-05:   2%| | 279/13852 [00:59<48:15,  4.69it/s]\u001b[A\n",
      "Training loss: 9.92e-02 lr: 1.01e-05:   2%| | 280/13852 [01:00<48:24,  4.67it/s]\u001b[A\n",
      "Training loss: 8.13e-02 lr: 1.01e-05:   2%| | 281/13852 [01:00<48:17,  4.68it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.45e-02 lr: 1.01e-05:   2%| | 282/13852 [01:00<48:15,  4.69it/s]\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.02e-05:   2%| | 283/13852 [01:00<48:11,  4.69it/s]\u001b[A\n",
      "Training loss: 1.07e-01 lr: 1.02e-05:   2%| | 284/13852 [01:00<48:13,  4.69it/s]\u001b[A\n",
      "Training loss: 7.93e-02 lr: 1.03e-05:   2%| | 285/13852 [01:01<48:10,  4.69it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 1.03e-05:   2%| | 286/13852 [01:01<48:48,  4.63it/s]\u001b[A\n",
      "Training loss: 1.32e-01 lr: 1.03e-05:   2%| | 287/13852 [01:01<48:39,  4.65it/s]\u001b[A\n",
      "Training loss: 1.10e-01 lr: 1.04e-05:   2%| | 288/13852 [01:01<50:00,  4.52it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 1.04e-05:   2%| | 289/13852 [01:02<50:48,  4.45it/s]\u001b[A\n",
      "Training loss: 1.72e-01 lr: 1.04e-05:   2%| | 290/13852 [01:02<51:20,  4.40it/s]\u001b[A\n",
      "Training loss: 1.42e-01 lr: 1.05e-05:   2%| | 291/13852 [01:02<50:24,  4.48it/s]\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.05e-05:   2%| | 292/13852 [01:02<49:44,  4.54it/s]\u001b[A\n",
      "Training loss: 1.26e-01 lr: 1.05e-05:   2%| | 293/13852 [01:02<49:16,  4.59it/s]\u001b[A\n",
      "Training loss: 1.37e-01 lr: 1.06e-05:   2%| | 294/13852 [01:03<48:55,  4.62it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.06e-05:   2%| | 295/13852 [01:03<48:39,  4.64it/s]\u001b[A\n",
      "Training loss: 1.87e-01 lr: 1.06e-05:   2%| | 296/13852 [01:03<48:36,  4.65it/s]\u001b[A\n",
      "Training loss: 1.37e-01 lr: 1.07e-05:   2%| | 297/13852 [01:03<48:35,  4.65it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.07e-05:   2%| | 298/13852 [01:03<48:22,  4.67it/s]\u001b[A\n",
      "Training loss: 8.59e-02 lr: 1.08e-05:   2%| | 299/13852 [01:04<48:28,  4.66it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.08e-05:   2%| | 300/13852 [01:04<48:19,  4.67it/s]\u001b[A\n",
      "Training loss: 8.31e-02 lr: 1.08e-05:   2%| | 301/13852 [01:04<48:15,  4.68it/s]\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.09e-05:   2%| | 302/13852 [01:04<48:16,  4.68it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 1.09e-05:   2%| | 303/13852 [01:05<48:12,  4.68it/s]\u001b[A\n",
      "Training loss: 9.87e-02 lr: 1.09e-05:   2%| | 304/13852 [01:05<48:09,  4.69it/s]\u001b[A\n",
      "Training loss: 9.21e-02 lr: 1.10e-05:   2%| | 305/13852 [01:05<48:06,  4.69it/s]\u001b[A\n",
      "Training loss: 1.00e-01 lr: 1.10e-05:   2%| | 306/13852 [01:05<48:12,  4.68it/s]\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.10e-05:   2%| | 307/13852 [01:05<48:11,  4.68it/s]\u001b[A\n",
      "Training loss: 8.78e-02 lr: 1.11e-05:   2%| | 308/13852 [01:06<48:07,  4.69it/s]\u001b[A\n",
      "Training loss: 9.99e-02 lr: 1.11e-05:   2%| | 309/13852 [01:06<48:16,  4.68it/s]\u001b[A\n",
      "Training loss: 7.61e-02 lr: 1.12e-05:   2%| | 310/13852 [01:06<48:10,  4.69it/s]\u001b[A\n",
      "Training loss: 1.56e-01 lr: 1.12e-05:   2%| | 311/13852 [01:06<48:13,  4.68it/s]\u001b[A\n",
      "Training loss: 2.10e-01 lr: 1.12e-05:   2%| | 312/13852 [01:06<48:09,  4.69it/s]\u001b[A\n",
      "Training loss: 1.76e-01 lr: 1.13e-05:   2%| | 313/13852 [01:07<48:15,  4.68it/s]\u001b[A\n",
      "Training loss: 1.76e-01 lr: 1.13e-05:   2%| | 314/13852 [01:07<48:28,  4.65it/s]\u001b[A\n",
      "Training loss: 1.51e-01 lr: 1.13e-05:   2%| | 315/13852 [01:07<48:28,  4.65it/s]\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.14e-05:   2%| | 316/13852 [01:07<48:38,  4.64it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 1.14e-05:   2%| | 317/13852 [01:08<48:30,  4.65it/s]\u001b[A\n",
      "Training loss: 8.51e-02 lr: 1.14e-05:   2%| | 318/13852 [01:08<48:29,  4.65it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 1.15e-05:   2%| | 319/13852 [01:08<48:18,  4.67it/s]\u001b[A\n",
      "Training loss: 1.47e-01 lr: 1.15e-05:   2%| | 320/13852 [01:08<48:27,  4.65it/s]\u001b[A\n",
      "Training loss: 1.48e-01 lr: 1.16e-05:   2%| | 321/13852 [01:08<48:20,  4.67it/s]\u001b[A\n",
      "Training loss: 1.16e-01 lr: 1.16e-05:   2%| | 322/13852 [01:09<48:16,  4.67it/s]\u001b[A\n",
      "Training loss: 1.10e-01 lr: 1.16e-05:   2%| | 323/13852 [01:09<48:20,  4.66it/s]\u001b[A\n",
      "Training loss: 1.10e-01 lr: 1.17e-05:   2%| | 324/13852 [01:09<48:12,  4.68it/s]\u001b[A\n",
      "Training loss: 1.78e-01 lr: 1.17e-05:   2%| | 325/13852 [01:09<48:10,  4.68it/s]\u001b[A\n",
      "Training loss: 2.00e-01 lr: 1.17e-05:   2%| | 326/13852 [01:09<48:06,  4.69it/s]\u001b[A\n",
      "Training loss: 1.87e-01 lr: 1.18e-05:   2%| | 327/13852 [01:10<48:03,  4.69it/s]\u001b[A\n",
      "Training loss: 1.58e-01 lr: 1.18e-05:   2%| | 328/13852 [01:10<48:02,  4.69it/s]\u001b[A\n",
      "Training loss: 1.39e-01 lr: 1.18e-05:   2%| | 329/13852 [01:10<48:04,  4.69it/s]\u001b[A\n",
      "Training loss: 1.28e-01 lr: 1.19e-05:   2%| | 330/13852 [01:10<48:09,  4.68it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.19e-05:   2%| | 331/13852 [01:11<48:07,  4.68it/s]\u001b[A\n",
      "Training loss: 1.04e-01 lr: 1.19e-05:   2%| | 332/13852 [01:11<48:24,  4.65it/s]\u001b[A\n",
      "Training loss: 1.38e-01 lr: 1.20e-05:   2%| | 333/13852 [01:11<48:24,  4.65it/s]\u001b[A\n",
      "Training loss: 1.34e-01 lr: 1.20e-05:   2%| | 334/13852 [01:11<48:36,  4.63it/s]\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.21e-05:   2%| | 335/13852 [01:11<48:32,  4.64it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 1.21e-05:   2%| | 336/13852 [01:12<48:27,  4.65it/s]\u001b[A\n",
      "Training loss: 1.46e-01 lr: 1.21e-05:   2%| | 337/13852 [01:12<48:19,  4.66it/s]\u001b[A\n",
      "Training loss: 1.19e-01 lr: 1.22e-05:   2%| | 338/13852 [01:12<48:15,  4.67it/s]\u001b[A\n",
      "Training loss: 1.20e-01 lr: 1.22e-05:   2%| | 339/13852 [01:12<48:20,  4.66it/s]\u001b[A\n",
      "Training loss: 1.29e-01 lr: 1.22e-05:   2%| | 340/13852 [01:12<48:17,  4.66it/s]\u001b[A\n",
      "Training loss: 1.31e-01 lr: 1.23e-05:   2%| | 341/13852 [01:13<48:11,  4.67it/s]\u001b[A\n",
      "Training loss: 1.00e-01 lr: 1.23e-05:   2%| | 342/13852 [01:13<48:19,  4.66it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.23e-05:   2%| | 343/13852 [01:13<48:12,  4.67it/s]\u001b[A\n",
      "Training loss: 1.50e-01 lr: 1.24e-05:   2%| | 344/13852 [01:13<48:11,  4.67it/s]\u001b[A\n",
      "Training loss: 1.39e-01 lr: 1.24e-05:   2%| | 345/13852 [01:14<48:20,  4.66it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.25e-05:   2%| | 346/13852 [01:14<48:18,  4.66it/s]\u001b[A\n",
      "Training loss: 9.30e-02 lr: 1.25e-05:   3%| | 347/13852 [01:14<47:53,  4.70it/s]\u001b[A\n",
      "Training loss: 1.61e-01 lr: 1.25e-05:   3%| | 348/13852 [01:14<47:57,  4.69it/s]\u001b[A\n",
      "Training loss: 1.61e-01 lr: 1.26e-05:   3%| | 349/13852 [01:14<47:56,  4.69it/s]\u001b[A\n",
      "Training loss: 1.43e-01 lr: 1.26e-05:   3%| | 350/13852 [01:15<48:02,  4.68it/s]\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.26e-05:   3%| | 351/13852 [01:15<48:05,  4.68it/s]\u001b[A\n",
      "Training loss: 8.28e-02 lr: 1.27e-05:   3%| | 352/13852 [01:15<48:04,  4.68it/s]\u001b[A\n",
      "Training loss: 8.25e-02 lr: 1.27e-05:   3%| | 353/13852 [01:15<48:00,  4.69it/s]\u001b[A\n",
      "Training loss: 8.16e-02 lr: 1.27e-05:   3%| | 354/13852 [01:15<48:05,  4.68it/s]\u001b[A\n",
      "Training loss: 6.55e-02 lr: 1.28e-05:   3%| | 355/13852 [01:16<48:04,  4.68it/s]\u001b[A\n",
      "Training loss: 6.98e-02 lr: 1.28e-05:   3%| | 356/13852 [01:16<48:06,  4.68it/s]\u001b[A\n",
      "Training loss: 7.69e-02 lr: 1.29e-05:   3%| | 357/13852 [01:16<48:03,  4.68it/s]\u001b[A\n",
      "Training loss: 5.70e-02 lr: 1.29e-05:   3%| | 358/13852 [01:16<48:05,  4.68it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 1.29e-05:   3%| | 359/13852 [01:17<48:01,  4.68it/s]\u001b[A\n",
      "Training loss: 9.89e-02 lr: 1.30e-05:   3%| | 360/13852 [01:17<48:30,  4.64it/s]\u001b[A\n",
      "Training loss: 7.97e-02 lr: 1.30e-05:   3%| | 361/13852 [01:17<48:28,  4.64it/s]\u001b[A\n",
      "Training loss: 7.11e-02 lr: 1.30e-05:   3%| | 362/13852 [01:17<48:18,  4.65it/s]\u001b[A\n",
      "Training loss: 6.29e-02 lr: 1.31e-05:   3%| | 363/13852 [01:17<48:18,  4.65it/s]\u001b[A\n",
      "Training loss: 5.14e-02 lr: 1.31e-05:   3%| | 364/13852 [01:18<48:17,  4.65it/s]\u001b[A\n",
      "Training loss: 8.06e-02 lr: 1.31e-05:   3%| | 365/13852 [01:18<48:18,  4.65it/s]\u001b[A\n",
      "Training loss: 6.30e-02 lr: 1.32e-05:   3%| | 366/13852 [01:18<48:19,  4.65it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 1.32e-05:   3%| | 367/13852 [01:18<48:28,  4.64it/s]\u001b[A\n",
      "Training loss: 1.04e-01 lr: 1.32e-05:   3%| | 368/13852 [01:18<48:27,  4.64it/s]\u001b[A\n",
      "Training loss: 2.05e-01 lr: 1.33e-05:   3%| | 369/13852 [01:19<48:17,  4.65it/s]\u001b[A\n",
      "Training loss: 1.88e-01 lr: 1.33e-05:   3%| | 370/13852 [01:19<48:17,  4.65it/s]\u001b[A\n",
      "Training loss: 2.03e-01 lr: 1.34e-05:   3%| | 371/13852 [01:19<48:09,  4.67it/s]\u001b[A\n",
      "Training loss: 1.78e-01 lr: 1.34e-05:   3%| | 372/13852 [01:19<48:09,  4.66it/s]\u001b[A\n",
      "Training loss: 1.69e-01 lr: 1.34e-05:   3%| | 373/13852 [01:20<48:06,  4.67it/s]\u001b[A\n",
      "Training loss: 2.30e-01 lr: 1.35e-05:   3%| | 374/13852 [01:20<48:14,  4.66it/s]\u001b[A\n",
      "Training loss: 1.64e-01 lr: 1.35e-05:   3%| | 375/13852 [01:20<48:11,  4.66it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 1.35e-05:   3%| | 376/13852 [01:20<48:07,  4.67it/s]\u001b[A\n",
      "Training loss: 2.29e-01 lr: 1.36e-05:   3%| | 377/13852 [01:20<48:05,  4.67it/s]\u001b[A\n",
      "Training loss: 2.15e-01 lr: 1.36e-05:   3%| | 378/13852 [01:21<48:15,  4.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.81e-01 lr: 1.36e-05:   3%| | 379/13852 [01:21<48:46,  4.60it/s]\u001b[A\n",
      "Training loss: 1.48e-01 lr: 1.37e-05:   3%| | 380/13852 [01:21<48:39,  4.61it/s]\u001b[A\n",
      "Training loss: 1.44e-01 lr: 1.37e-05:   3%| | 381/13852 [01:21<48:25,  4.64it/s]\u001b[A\n",
      "Training loss: 1.78e-01 lr: 1.38e-05:   3%| | 382/13852 [01:21<48:21,  4.64it/s]\u001b[A\n",
      "Training loss: 1.70e-01 lr: 1.38e-05:   3%| | 383/13852 [01:22<48:31,  4.63it/s]\u001b[A\n",
      "Training loss: 1.36e-01 lr: 1.38e-05:   3%| | 384/13852 [01:22<48:23,  4.64it/s]\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.39e-05:   3%| | 385/13852 [01:22<48:27,  4.63it/s]\u001b[A\n",
      "Training loss: 8.13e-02 lr: 1.39e-05:   3%| | 386/13852 [01:22<48:19,  4.64it/s]\u001b[A\n",
      "Training loss: 6.48e-02 lr: 1.39e-05:   3%| | 387/13852 [01:23<48:33,  4.62it/s]\u001b[A\n",
      "Training loss: 1.04e-01 lr: 1.40e-05:   3%| | 388/13852 [01:23<48:27,  4.63it/s]\u001b[A\n",
      "Training loss: 1.47e-01 lr: 1.40e-05:   3%| | 389/13852 [01:23<48:17,  4.65it/s]\u001b[A\n",
      "Training loss: 1.36e-01 lr: 1.40e-05:   3%| | 390/13852 [01:23<48:14,  4.65it/s]\u001b[A\n",
      "Training loss: 1.75e-01 lr: 1.41e-05:   3%| | 391/13852 [01:23<48:09,  4.66it/s]\u001b[A\n",
      "Training loss: 1.74e-01 lr: 1.41e-05:   3%| | 392/13852 [01:24<48:10,  4.66it/s]\u001b[A\n",
      "Training loss: 1.48e-01 lr: 1.42e-05:   3%| | 393/13852 [01:24<48:04,  4.67it/s]\u001b[A\n",
      "Training loss: 1.75e-01 lr: 1.42e-05:   3%| | 394/13852 [01:24<48:08,  4.66it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 1.42e-05:   3%| | 395/13852 [01:24<48:05,  4.66it/s]\u001b[A\n",
      "Training loss: 1.28e-01 lr: 1.43e-05:   3%| | 396/13852 [01:25<48:03,  4.67it/s]\u001b[A\n",
      "Training loss: 1.07e-01 lr: 1.43e-05:   3%| | 397/13852 [01:25<47:59,  4.67it/s]\u001b[A\n",
      "Training loss: 1.16e-01 lr: 1.43e-05:   3%| | 398/13852 [01:25<48:00,  4.67it/s]\u001b[A\n",
      "Training loss: 1.90e-01 lr: 1.44e-05:   3%| | 399/13852 [01:25<48:03,  4.67it/s]\u001b[A\n",
      "Training loss: 1.84e-01 lr: 1.44e-05:   3%| | 400/13852 [01:25<48:05,  4.66it/s]\u001b[A\n",
      "Training loss: 1.82e-01 lr: 1.44e-05:   3%| | 401/13852 [01:26<48:13,  4.65it/s]\u001b[A\n",
      "Training loss: 1.40e-01 lr: 1.45e-05:   3%| | 402/13852 [01:26<48:34,  4.62it/s]\u001b[A\n",
      "Training loss: 2.04e-01 lr: 1.45e-05:   3%| | 403/13852 [01:26<48:19,  4.64it/s]\u001b[A\n",
      "Training loss: 2.61e-01 lr: 1.45e-05:   3%| | 404/13852 [01:26<48:21,  4.63it/s]\u001b[A\n",
      "Training loss: 2.18e-01 lr: 1.46e-05:   3%| | 405/13852 [01:26<48:22,  4.63it/s]\u001b[A\n",
      "Training loss: 1.72e-01 lr: 1.46e-05:   3%| | 406/13852 [01:27<48:20,  4.64it/s]\u001b[A\n",
      "Training loss: 1.54e-01 lr: 1.47e-05:   3%| | 407/13852 [01:27<48:20,  4.64it/s]\u001b[A\n",
      "Training loss: 1.16e-01 lr: 1.47e-05:   3%| | 408/13852 [01:27<48:13,  4.65it/s]\u001b[A\n",
      "Training loss: 1.28e-01 lr: 1.47e-05:   3%| | 409/13852 [01:27<48:11,  4.65it/s]\u001b[A\n",
      "Training loss: 1.27e-01 lr: 1.48e-05:   3%| | 410/13852 [01:28<48:05,  4.66it/s]\u001b[A\n",
      "Training loss: 1.03e-01 lr: 1.48e-05:   3%| | 411/13852 [01:28<48:05,  4.66it/s]\u001b[A\n",
      "Training loss: 9.93e-02 lr: 1.48e-05:   3%| | 412/13852 [01:28<48:04,  4.66it/s]\u001b[A\n",
      "Training loss: 9.61e-02 lr: 1.49e-05:   3%| | 413/13852 [01:28<48:02,  4.66it/s]\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.49e-05:   3%| | 414/13852 [01:28<48:07,  4.65it/s]\u001b[A\n",
      "Training loss: 1.30e-01 lr: 1.49e-05:   3%| | 415/13852 [01:29<47:59,  4.67it/s]\u001b[A\n",
      "Training loss: 1.18e-01 lr: 1.50e-05:   3%| | 416/13852 [01:29<48:13,  4.64it/s]\u001b[A\n",
      "Training loss: 9.38e-02 lr: 1.50e-05:   3%| | 417/13852 [01:29<48:06,  4.66it/s]\u001b[A\n",
      "Training loss: 1.28e-01 lr: 1.51e-05:   3%| | 418/13852 [01:29<48:09,  4.65it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 1.51e-05:   3%| | 419/13852 [01:29<48:06,  4.65it/s]\u001b[A\n",
      "Training loss: 9.72e-02 lr: 1.51e-05:   3%| | 420/13852 [01:30<48:02,  4.66it/s]\u001b[A\n",
      "Training loss: 7.60e-02 lr: 1.52e-05:   3%| | 421/13852 [01:30<47:57,  4.67it/s]\u001b[A\n",
      "Training loss: 5.93e-02 lr: 1.52e-05:   3%| | 422/13852 [01:30<48:01,  4.66it/s]\u001b[A\n",
      "Training loss: 1.05e-01 lr: 1.52e-05:   3%| | 423/13852 [01:30<48:14,  4.64it/s]\u001b[A\n",
      "Training loss: 9.79e-02 lr: 1.53e-05:   3%| | 424/13852 [01:31<48:09,  4.65it/s]\u001b[A\n",
      "Training loss: 1.09e-01 lr: 1.53e-05:   3%| | 425/13852 [01:31<48:26,  4.62it/s]\u001b[A\n",
      "Training loss: 8.34e-02 lr: 1.53e-05:   3%| | 426/13852 [01:31<48:38,  4.60it/s]\u001b[A\n",
      "Training loss: 1.43e-01 lr: 1.54e-05:   3%| | 427/13852 [01:31<48:31,  4.61it/s]\u001b[A\n",
      "Training loss: 1.80e-01 lr: 1.54e-05:   3%| | 428/13852 [01:31<48:18,  4.63it/s]\u001b[A\n",
      "Training loss: 1.49e-01 lr: 1.55e-05:   3%| | 429/13852 [01:32<48:11,  4.64it/s]\u001b[A\n",
      "Training loss: 1.25e-01 lr: 1.55e-05:   3%| | 430/13852 [01:32<48:09,  4.65it/s]\u001b[A\n",
      "Training loss: 1.38e-01 lr: 1.55e-05:   3%| | 431/13852 [01:32<48:05,  4.65it/s]\u001b[A\n",
      "Training loss: 1.18e-01 lr: 1.56e-05:   3%| | 432/13852 [01:32<47:58,  4.66it/s]\u001b[A\n",
      "Training loss: 8.70e-02 lr: 1.56e-05:   3%| | 433/13852 [01:32<47:56,  4.66it/s]\u001b[A\n",
      "Training loss: 7.57e-02 lr: 1.56e-05:   3%| | 434/13852 [01:33<47:52,  4.67it/s]\u001b[A\n",
      "Training loss: 6.53e-02 lr: 1.57e-05:   3%| | 435/13852 [01:33<47:51,  4.67it/s]\u001b[A\n",
      "Training loss: 8.67e-02 lr: 1.57e-05:   3%| | 436/13852 [01:33<47:52,  4.67it/s]\u001b[A\n",
      "Training loss: 9.08e-02 lr: 1.57e-05:   3%| | 437/13852 [01:33<47:51,  4.67it/s]\u001b[A\n",
      "Training loss: 1.32e-01 lr: 1.58e-05:   3%| | 438/13852 [01:34<47:48,  4.68it/s]\u001b[A\n",
      "Training loss: 1.25e-01 lr: 1.58e-05:   3%| | 439/13852 [01:34<47:52,  4.67it/s]\u001b[A\n",
      "Training loss: 1.29e-01 lr: 1.58e-05:   3%| | 440/13852 [01:34<47:50,  4.67it/s]\u001b[A\n",
      "Training loss: 9.46e-02 lr: 1.59e-05:   3%| | 441/13852 [01:34<47:51,  4.67it/s]\u001b[A\n",
      "Training loss: 9.86e-02 lr: 1.59e-05:   3%| | 442/13852 [01:34<47:50,  4.67it/s]\u001b[A\n",
      "Training loss: 8.64e-02 lr: 1.60e-05:   3%| | 443/13852 [01:35<47:50,  4.67it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.60e-05:   3%| | 444/13852 [01:35<47:51,  4.67it/s]\u001b[A\n",
      "Training loss: 8.91e-02 lr: 1.60e-05:   3%| | 445/13852 [01:35<47:48,  4.67it/s]\u001b[A\n",
      "Training loss: 6.61e-02 lr: 1.61e-05:   3%| | 446/13852 [01:35<47:49,  4.67it/s]\u001b[A\n",
      "Training loss: 8.61e-02 lr: 1.61e-05:   3%| | 447/13852 [01:35<47:45,  4.68it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 1.61e-05:   3%| | 448/13852 [01:36<47:49,  4.67it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 1.62e-05:   3%| | 449/13852 [01:36<47:45,  4.68it/s]\u001b[A\n",
      "Training loss: 9.77e-02 lr: 1.62e-05:   3%| | 450/13852 [01:36<47:56,  4.66it/s]\u001b[A\n",
      "Training loss: 8.33e-02 lr: 1.62e-05:   3%| | 451/13852 [01:36<48:47,  4.58it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 1.63e-05:   3%| | 452/13852 [01:37<48:29,  4.60it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.63e-05:   3%| | 453/13852 [01:37<48:50,  4.57it/s]\u001b[A\n",
      "Training loss: 7.99e-02 lr: 1.64e-05:   3%| | 454/13852 [01:37<48:57,  4.56it/s]\u001b[A\n",
      "Training loss: 9.61e-02 lr: 1.64e-05:   3%| | 455/13852 [01:37<48:58,  4.56it/s]\u001b[A\n",
      "Training loss: 7.98e-02 lr: 1.64e-05:   3%| | 456/13852 [01:37<49:09,  4.54it/s]\u001b[A\n",
      "Training loss: 7.68e-02 lr: 1.65e-05:   3%| | 457/13852 [01:38<48:47,  4.58it/s]\u001b[A\n",
      "Training loss: 7.56e-02 lr: 1.65e-05:   3%| | 458/13852 [01:38<48:26,  4.61it/s]\u001b[A\n",
      "Training loss: 9.14e-02 lr: 1.65e-05:   3%| | 459/13852 [01:38<48:17,  4.62it/s]\u001b[A\n",
      "Training loss: 7.70e-02 lr: 1.66e-05:   3%| | 460/13852 [01:38<48:11,  4.63it/s]\u001b[A\n",
      "Training loss: 7.83e-02 lr: 1.66e-05:   3%| | 461/13852 [01:39<48:12,  4.63it/s]\u001b[A\n",
      "Training loss: 1.27e-01 lr: 1.66e-05:   3%| | 462/13852 [01:39<48:04,  4.64it/s]\u001b[A\n",
      "Training loss: 1.04e-01 lr: 1.67e-05:   3%| | 463/13852 [01:39<48:00,  4.65it/s]\u001b[A\n",
      "Training loss: 1.29e-01 lr: 1.67e-05:   3%| | 464/13852 [01:39<47:56,  4.65it/s]\u001b[A\n",
      "Training loss: 1.98e-01 lr: 1.67e-05:   3%| | 465/13852 [01:39<47:52,  4.66it/s]\u001b[A\n",
      "Training loss: 1.61e-01 lr: 1.68e-05:   3%| | 466/13852 [01:40<47:51,  4.66it/s]\u001b[A\n",
      "Training loss: 1.25e-01 lr: 1.68e-05:   3%| | 467/13852 [01:40<47:46,  4.67it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 1.69e-05:   3%| | 468/13852 [01:40<47:46,  4.67it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.69e-05:   3%| | 469/13852 [01:40<47:45,  4.67it/s]\u001b[A\n",
      "Training loss: 9.81e-02 lr: 1.69e-05:   3%| | 470/13852 [01:40<47:49,  4.66it/s]\u001b[A\n",
      "Training loss: 8.52e-02 lr: 1.70e-05:   3%| | 471/13852 [01:41<47:43,  4.67it/s]\u001b[A\n",
      "Training loss: 8.30e-02 lr: 1.70e-05:   3%| | 472/13852 [01:41<48:07,  4.63it/s]\u001b[A\n",
      "Training loss: 1.54e-01 lr: 1.70e-05:   3%| | 473/13852 [01:41<48:12,  4.63it/s]\u001b[A\n",
      "Training loss: 1.98e-01 lr: 1.71e-05:   3%| | 474/13852 [01:41<48:05,  4.64it/s]\u001b[A\n",
      "Training loss: 1.50e-01 lr: 1.71e-05:   3%| | 475/13852 [01:42<48:03,  4.64it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.34e-01 lr: 1.71e-05:   3%| | 476/13852 [01:42<48:12,  4.62it/s]\u001b[A\n",
      "Training loss: 1.03e-01 lr: 1.72e-05:   3%| | 477/13852 [01:42<48:03,  4.64it/s]\u001b[A\n",
      "Training loss: 7.73e-02 lr: 1.72e-05:   3%| | 478/13852 [01:42<47:58,  4.65it/s]\u001b[A\n",
      "Training loss: 1.24e-01 lr: 1.73e-05:   3%| | 479/13852 [01:42<47:52,  4.66it/s]\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.73e-05:   3%| | 480/13852 [01:43<47:54,  4.65it/s]\u001b[A\n",
      "Training loss: 8.56e-02 lr: 1.73e-05:   3%| | 481/13852 [01:43<47:53,  4.65it/s]\u001b[A\n",
      "Training loss: 6.39e-02 lr: 1.74e-05:   3%| | 482/13852 [01:43<47:53,  4.65it/s]\u001b[A\n",
      "Training loss: 7.08e-02 lr: 1.74e-05:   3%| | 483/13852 [01:43<47:52,  4.65it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.74e-05:   3%| | 484/13852 [01:43<47:50,  4.66it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.75e-05:   4%| | 485/13852 [01:44<47:51,  4.65it/s]\u001b[A\n",
      "Training loss: 1.39e-01 lr: 1.75e-05:   4%| | 486/13852 [01:44<47:44,  4.67it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 1.75e-05:   4%| | 487/13852 [01:44<47:48,  4.66it/s]\u001b[A\n",
      "Training loss: 1.94e-01 lr: 1.76e-05:   4%| | 488/13852 [01:44<47:47,  4.66it/s]\u001b[A\n",
      "Training loss: 1.43e-01 lr: 1.76e-05:   4%| | 489/13852 [01:45<47:45,  4.66it/s]\u001b[A\n",
      "Training loss: 1.27e-01 lr: 1.77e-05:   4%| | 490/13852 [01:45<47:43,  4.67it/s]\u001b[A\n",
      "Training loss: 1.00e-01 lr: 1.77e-05:   4%| | 491/13852 [01:45<47:42,  4.67it/s]\u001b[A\n",
      "Training loss: 8.59e-02 lr: 1.77e-05:   4%| | 492/13852 [01:45<47:40,  4.67it/s]\u001b[A\n",
      "Training loss: 1.47e-01 lr: 1.78e-05:   4%| | 493/13852 [01:45<47:40,  4.67it/s]\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.78e-05:   4%| | 494/13852 [01:46<47:40,  4.67it/s]\u001b[A\n",
      "Training loss: 1.34e-01 lr: 1.78e-05:   4%| | 495/13852 [01:46<47:39,  4.67it/s]\u001b[A\n",
      "Training loss: 9.92e-02 lr: 1.79e-05:   4%| | 496/13852 [01:46<47:40,  4.67it/s]\u001b[A\n",
      "Training loss: 1.30e-01 lr: 1.79e-05:   4%| | 497/13852 [01:46<47:47,  4.66it/s]\u001b[A\n",
      "Training loss: 1.44e-01 lr: 1.79e-05:   4%| | 498/13852 [01:46<47:46,  4.66it/s]\u001b[A\n",
      "Training loss: 1.24e-01 lr: 1.80e-05:   4%| | 499/13852 [01:47<47:56,  4.64it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.80e-05:   4%| | 500/13852 [01:47<48:11,  4.62it/s]\u001b[A\n",
      "Training loss: 1.22e-01 lr: 1.80e-05:   4%| | 501/13852 [01:47<48:02,  4.63it/s]\u001b[A\n",
      "Training loss: 1.57e-01 lr: 1.81e-05:   4%| | 502/13852 [01:47<47:59,  4.64it/s]\u001b[A\n",
      "Training loss: 1.93e-01 lr: 1.81e-05:   4%| | 503/13852 [01:48<47:54,  4.64it/s]\u001b[A\n",
      "Training loss: 1.41e-01 lr: 1.82e-05:   4%| | 504/13852 [01:48<47:51,  4.65it/s]\u001b[A\n",
      "Training loss: 1.45e-01 lr: 1.82e-05:   4%| | 505/13852 [01:48<47:51,  4.65it/s]\u001b[A\n",
      "Training loss: 1.19e-01 lr: 1.82e-05:   4%| | 506/13852 [01:48<47:49,  4.65it/s]\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.83e-05:   4%| | 507/13852 [01:48<47:45,  4.66it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 1.83e-05:   4%| | 508/13852 [01:49<47:45,  4.66it/s]\u001b[A\n",
      "Training loss: 1.93e-01 lr: 1.83e-05:   4%| | 509/13852 [01:49<47:44,  4.66it/s]\u001b[A\n",
      "Training loss: 1.61e-01 lr: 1.84e-05:   4%| | 510/13852 [01:49<47:44,  4.66it/s]\u001b[A\n",
      "Training loss: 1.85e-01 lr: 1.84e-05:   4%| | 511/13852 [01:49<47:41,  4.66it/s]\u001b[A\n",
      "Training loss: 1.66e-01 lr: 1.84e-05:   4%| | 512/13852 [01:49<47:42,  4.66it/s]\u001b[A\n",
      "Training loss: 1.47e-01 lr: 1.85e-05:   4%| | 513/13852 [01:50<47:39,  4.66it/s]\u001b[A\n",
      "Training loss: 1.95e-01 lr: 1.85e-05:   4%| | 514/13852 [01:50<47:38,  4.67it/s]\u001b[A\n",
      "Training loss: 1.80e-01 lr: 1.86e-05:   4%| | 515/13852 [01:50<47:42,  4.66it/s]\u001b[A\n",
      "Training loss: 1.42e-01 lr: 1.86e-05:   4%| | 516/13852 [01:50<47:50,  4.65it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.86e-05:   4%| | 517/13852 [01:51<47:46,  4.65it/s]\u001b[A\n",
      "Training loss: 9.57e-02 lr: 1.87e-05:   4%| | 518/13852 [01:51<48:02,  4.63it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.87e-05:   4%| | 519/13852 [01:51<48:04,  4.62it/s]\u001b[A\n",
      "Training loss: 8.69e-02 lr: 1.87e-05:   4%| | 520/13852 [01:51<48:08,  4.62it/s]\u001b[A\n",
      "Training loss: 7.36e-02 lr: 1.88e-05:   4%| | 521/13852 [01:51<48:04,  4.62it/s]\u001b[A\n",
      "Training loss: 9.34e-02 lr: 1.88e-05:   4%| | 522/13852 [01:52<47:58,  4.63it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 1.88e-05:   4%| | 523/13852 [01:52<48:01,  4.63it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.89e-05:   4%| | 524/13852 [01:52<47:55,  4.64it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.89e-05:   4%| | 525/13852 [01:52<47:59,  4.63it/s]\u001b[A\n",
      "Training loss: 1.05e-01 lr: 1.90e-05:   4%| | 526/13852 [01:52<48:04,  4.62it/s]\u001b[A\n",
      "Training loss: 9.42e-02 lr: 1.90e-05:   4%| | 527/13852 [01:53<47:58,  4.63it/s]\u001b[A\n",
      "Training loss: 7.52e-02 lr: 1.90e-05:   4%| | 528/13852 [01:53<47:59,  4.63it/s]\u001b[A\n",
      "Training loss: 1.41e-01 lr: 1.91e-05:   4%| | 529/13852 [01:53<47:52,  4.64it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 1.91e-05:   4%| | 530/13852 [01:53<47:51,  4.64it/s]\u001b[A\n",
      "Training loss: 1.61e-01 lr: 1.91e-05:   4%| | 531/13852 [01:54<47:49,  4.64it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 1.92e-05:   4%| | 532/13852 [01:54<47:45,  4.65it/s]\u001b[A\n",
      "Training loss: 1.04e-01 lr: 1.92e-05:   4%| | 533/13852 [01:54<47:44,  4.65it/s]\u001b[A\n",
      "Training loss: 8.82e-02 lr: 1.92e-05:   4%| | 534/13852 [01:54<47:41,  4.65it/s]\u001b[A\n",
      "Training loss: 8.47e-02 lr: 1.93e-05:   4%| | 535/13852 [01:54<47:45,  4.65it/s]\u001b[A\n",
      "Training loss: 8.91e-02 lr: 1.93e-05:   4%| | 536/13852 [01:55<47:45,  4.65it/s]\u001b[A\n",
      "Training loss: 8.63e-02 lr: 1.93e-05:   4%| | 537/13852 [01:55<47:53,  4.63it/s]\u001b[A\n",
      "Training loss: 7.30e-02 lr: 1.94e-05:   4%| | 538/13852 [01:55<47:50,  4.64it/s]\u001b[A\n",
      "Training loss: 9.34e-02 lr: 1.94e-05:   4%| | 539/13852 [01:55<47:50,  4.64it/s]\u001b[A\n",
      "Training loss: 7.99e-02 lr: 1.95e-05:   4%| | 540/13852 [01:56<47:50,  4.64it/s]\u001b[A\n",
      "Training loss: 6.04e-02 lr: 1.95e-05:   4%| | 541/13852 [01:56<47:47,  4.64it/s]\u001b[A\n",
      "Training loss: 4.71e-02 lr: 1.95e-05:   4%| | 542/13852 [01:56<47:41,  4.65it/s]\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.96e-05:   4%| | 543/13852 [01:56<47:41,  4.65it/s]\u001b[A\n",
      "Training loss: 7.23e-02 lr: 1.96e-05:   4%| | 544/13852 [01:56<47:41,  4.65it/s]\u001b[A\n",
      "Training loss: 6.39e-02 lr: 1.96e-05:   4%| | 545/13852 [01:57<47:48,  4.64it/s]\u001b[A\n",
      "Training loss: 1.38e-01 lr: 1.97e-05:   4%| | 546/13852 [01:57<48:15,  4.60it/s]\u001b[A\n",
      "Training loss: 1.55e-01 lr: 1.97e-05:   4%| | 547/13852 [01:57<48:06,  4.61it/s]\u001b[A\n",
      "Training loss: 1.24e-01 lr: 1.97e-05:   4%| | 548/13852 [01:57<47:58,  4.62it/s]\u001b[A\n",
      "Training loss: 9.99e-02 lr: 1.98e-05:   4%| | 549/13852 [01:57<47:58,  4.62it/s]\u001b[A\n",
      "Training loss: 8.06e-02 lr: 1.98e-05:   4%| | 550/13852 [01:58<48:01,  4.62it/s]\u001b[A\n",
      "Training loss: 6.04e-02 lr: 1.99e-05:   4%| | 551/13852 [01:58<48:10,  4.60it/s]\u001b[A\n",
      "Training loss: 5.54e-02 lr: 1.99e-05:   4%| | 552/13852 [01:58<48:05,  4.61it/s]\u001b[A\n",
      "Training loss: 4.31e-02 lr: 1.99e-05:   4%| | 553/13852 [01:58<47:56,  4.62it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.00e-05:   4%| | 554/13852 [01:59<47:56,  4.62it/s]\u001b[A\n",
      "Training loss: 9.67e-02 lr: 2.00e-05:   4%| | 555/13852 [01:59<47:53,  4.63it/s]\u001b[A\n",
      "Training loss: 7.20e-02 lr: 2.00e-05:   4%| | 556/13852 [01:59<47:50,  4.63it/s]\u001b[A\n",
      "Training loss: 6.10e-02 lr: 2.01e-05:   4%| | 557/13852 [01:59<47:58,  4.62it/s]\u001b[A\n",
      "Training loss: 9.84e-02 lr: 2.01e-05:   4%| | 558/13852 [01:59<47:57,  4.62it/s]\u001b[A\n",
      "Training loss: 7.87e-02 lr: 2.01e-05:   4%| | 559/13852 [02:00<47:52,  4.63it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 2.02e-05:   4%| | 560/13852 [02:00<47:55,  4.62it/s]\u001b[A\n",
      "Training loss: 1.56e-01 lr: 2.02e-05:   4%| | 561/13852 [02:00<47:50,  4.63it/s]\u001b[A\n",
      "Training loss: 1.15e-01 lr: 2.03e-05:   4%| | 562/13852 [02:00<47:47,  4.63it/s]\u001b[A\n",
      "Training loss: 1.56e-01 lr: 2.03e-05:   4%| | 563/13852 [02:00<47:47,  4.63it/s]\u001b[A\n",
      "Training loss: 1.67e-01 lr: 2.03e-05:   4%| | 564/13852 [02:01<47:46,  4.64it/s]\u001b[A\n",
      "Training loss: 1.56e-01 lr: 2.04e-05:   4%| | 565/13852 [02:01<48:05,  4.61it/s]\u001b[A\n",
      "Training loss: 1.26e-01 lr: 2.04e-05:   4%| | 566/13852 [02:01<48:00,  4.61it/s]\u001b[A\n",
      "Training loss: 9.40e-02 lr: 2.04e-05:   4%| | 567/13852 [02:01<47:52,  4.62it/s]\u001b[A\n",
      "Training loss: 1.24e-01 lr: 2.05e-05:   4%| | 568/13852 [02:02<47:51,  4.63it/s]\u001b[A\n",
      "Training loss: 9.32e-02 lr: 2.05e-05:   4%| | 569/13852 [02:02<47:59,  4.61it/s]\u001b[A\n",
      "Training loss: 8.24e-02 lr: 2.05e-05:   4%| | 570/13852 [02:02<47:51,  4.63it/s]\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.06e-05:   4%| | 571/13852 [02:02<47:49,  4.63it/s]\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.06e-05:   4%| | 572/13852 [02:02<47:48,  4.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.68e-02 lr: 2.06e-05:   4%| | 573/13852 [02:03<47:45,  4.63it/s]\u001b[A\n",
      "Training loss: 6.83e-02 lr: 2.07e-05:   4%| | 574/13852 [02:03<47:44,  4.64it/s]\u001b[A\n",
      "Training loss: 7.21e-02 lr: 2.07e-05:   4%| | 575/13852 [02:03<47:52,  4.62it/s]\u001b[A\n",
      "Training loss: 9.24e-02 lr: 2.08e-05:   4%| | 576/13852 [02:03<47:46,  4.63it/s]\u001b[A\n",
      "Training loss: 8.06e-02 lr: 2.08e-05:   4%| | 577/13852 [02:04<47:45,  4.63it/s]\u001b[A\n",
      "Training loss: 9.88e-02 lr: 2.08e-05:   4%| | 578/13852 [02:04<47:41,  4.64it/s]\u001b[A\n",
      "Training loss: 9.11e-02 lr: 2.09e-05:   4%| | 579/13852 [02:04<47:42,  4.64it/s]\u001b[A\n",
      "Training loss: 7.42e-02 lr: 2.09e-05:   4%| | 580/13852 [02:04<47:36,  4.65it/s]\u001b[A\n",
      "Training loss: 7.51e-02 lr: 2.09e-05:   4%| | 581/13852 [02:04<47:35,  4.65it/s]\u001b[A\n",
      "Training loss: 9.82e-02 lr: 2.10e-05:   4%| | 582/13852 [02:05<47:36,  4.65it/s]\u001b[A\n",
      "Training loss: 9.66e-02 lr: 2.10e-05:   4%| | 583/13852 [02:05<47:34,  4.65it/s]\u001b[A\n",
      "Training loss: 1.00e-01 lr: 2.10e-05:   4%| | 584/13852 [02:05<47:37,  4.64it/s]\u001b[A\n",
      "Training loss: 8.60e-02 lr: 2.11e-05:   4%| | 585/13852 [02:05<47:31,  4.65it/s]\u001b[A\n",
      "Training loss: 6.88e-02 lr: 2.11e-05:   4%| | 586/13852 [02:05<47:36,  4.64it/s]\u001b[A\n",
      "Training loss: 6.53e-02 lr: 2.12e-05:   4%| | 587/13852 [02:06<47:35,  4.65it/s]\u001b[A\n",
      "Training loss: 5.13e-02 lr: 2.12e-05:   4%| | 588/13852 [02:06<47:35,  4.64it/s]\u001b[A\n",
      "Training loss: 8.02e-02 lr: 2.12e-05:   4%| | 589/13852 [02:06<47:37,  4.64it/s]\u001b[A\n",
      "Training loss: 8.10e-02 lr: 2.13e-05:   4%| | 590/13852 [02:06<47:42,  4.63it/s]\u001b[A\n",
      "Training loss: 1.38e-01 lr: 2.13e-05:   4%| | 591/13852 [02:07<47:41,  4.63it/s]\u001b[A\n",
      "Training loss: 1.32e-01 lr: 2.13e-05:   4%| | 592/13852 [02:07<48:06,  4.59it/s]\u001b[A\n",
      "Training loss: 1.06e-01 lr: 2.14e-05:   4%| | 593/13852 [02:07<48:22,  4.57it/s]\u001b[A\n",
      "Training loss: 9.68e-02 lr: 2.14e-05:   4%| | 594/13852 [02:07<48:21,  4.57it/s]\u001b[A\n",
      "Training loss: 1.41e-01 lr: 2.14e-05:   4%| | 595/13852 [02:07<48:41,  4.54it/s]\u001b[A\n",
      "Training loss: 1.56e-01 lr: 2.15e-05:   4%| | 596/13852 [02:08<48:21,  4.57it/s]\u001b[A\n",
      "Training loss: 1.42e-01 lr: 2.15e-05:   4%| | 597/13852 [02:08<48:09,  4.59it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 2.16e-05:   4%| | 598/13852 [02:08<47:55,  4.61it/s]\u001b[A\n",
      "Training loss: 9.19e-02 lr: 2.16e-05:   4%| | 599/13852 [02:08<47:47,  4.62it/s]\u001b[A\n",
      "Training loss: 7.05e-02 lr: 2.16e-05:   4%| | 600/13852 [02:08<47:44,  4.63it/s]\u001b[A\n",
      "Training loss: 9.02e-02 lr: 2.17e-05:   4%| | 601/13852 [02:09<47:42,  4.63it/s]\u001b[A\n",
      "Training loss: 9.56e-02 lr: 2.17e-05:   4%| | 602/13852 [02:09<47:43,  4.63it/s]\u001b[A\n",
      "Training loss: 9.40e-02 lr: 2.17e-05:   4%| | 603/13852 [02:09<47:37,  4.64it/s]\u001b[A\n",
      "Training loss: 8.96e-02 lr: 2.18e-05:   4%| | 604/13852 [02:09<47:38,  4.63it/s]\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.18e-05:   4%| | 605/13852 [02:10<47:38,  4.63it/s]\u001b[A\n",
      "Training loss: 7.43e-02 lr: 2.18e-05:   4%| | 606/13852 [02:10<47:35,  4.64it/s]\u001b[A\n",
      "Training loss: 8.50e-02 lr: 2.19e-05:   4%| | 607/13852 [02:10<47:36,  4.64it/s]\u001b[A\n",
      "Training loss: 7.48e-02 lr: 2.19e-05:   4%| | 608/13852 [02:10<47:35,  4.64it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.19e-05:   4%| | 609/13852 [02:10<47:36,  4.64it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 2.20e-05:   4%| | 610/13852 [02:11<47:36,  4.64it/s]\u001b[A\n",
      "Training loss: 1.00e-01 lr: 2.20e-05:   4%| | 611/13852 [02:11<48:03,  4.59it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 2.21e-05:   4%| | 612/13852 [02:11<47:53,  4.61it/s]\u001b[A\n",
      "Training loss: 1.47e-01 lr: 2.21e-05:   4%| | 613/13852 [02:11<48:26,  4.55it/s]\u001b[A\n",
      "Training loss: 1.27e-01 lr: 2.21e-05:   4%| | 614/13852 [02:12<48:17,  4.57it/s]\u001b[A\n",
      "Training loss: 9.35e-02 lr: 2.22e-05:   4%| | 615/13852 [02:12<48:30,  4.55it/s]\u001b[A\n",
      "Training loss: 9.11e-02 lr: 2.22e-05:   4%| | 616/13852 [02:12<48:17,  4.57it/s]\u001b[A\n",
      "Training loss: 7.49e-02 lr: 2.22e-05:   4%| | 617/13852 [02:12<48:00,  4.60it/s]\u001b[A\n",
      "Training loss: 5.74e-02 lr: 2.23e-05:   4%| | 618/13852 [02:12<47:52,  4.61it/s]\u001b[A\n",
      "Training loss: 4.40e-02 lr: 2.23e-05:   4%| | 619/13852 [02:13<47:48,  4.61it/s]\u001b[A\n",
      "Training loss: 6.74e-02 lr: 2.23e-05:   4%| | 620/13852 [02:13<47:44,  4.62it/s]\u001b[A\n",
      "Training loss: 7.12e-02 lr: 2.24e-05:   4%| | 621/13852 [02:13<47:46,  4.62it/s]\u001b[A\n",
      "Training loss: 9.35e-02 lr: 2.24e-05:   4%| | 622/13852 [02:13<47:42,  4.62it/s]\u001b[A\n",
      "Training loss: 9.07e-02 lr: 2.25e-05:   4%| | 623/13852 [02:13<47:38,  4.63it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 2.25e-05:   5%| | 624/13852 [02:14<47:35,  4.63it/s]\u001b[A\n",
      "Training loss: 1.19e-01 lr: 2.25e-05:   5%| | 625/13852 [02:14<47:29,  4.64it/s]\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.26e-05:   5%| | 626/13852 [02:14<47:31,  4.64it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 2.26e-05:   5%| | 627/13852 [02:14<47:25,  4.65it/s]\u001b[A\n",
      "Training loss: 9.77e-02 lr: 2.26e-05:   5%| | 628/13852 [02:15<47:28,  4.64it/s]\u001b[A\n",
      "Training loss: 1.51e-01 lr: 2.27e-05:   5%| | 629/13852 [02:15<47:27,  4.64it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 2.27e-05:   5%| | 630/13852 [02:15<47:26,  4.65it/s]\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.27e-05:   5%| | 631/13852 [02:15<47:27,  4.64it/s]\u001b[A\n",
      "Training loss: 9.17e-02 lr: 2.28e-05:   5%| | 632/13852 [02:15<47:23,  4.65it/s]\u001b[A\n",
      "Training loss: 7.73e-02 lr: 2.28e-05:   5%| | 633/13852 [02:16<47:30,  4.64it/s]\u001b[A\n",
      "Training loss: 8.32e-02 lr: 2.29e-05:   5%| | 634/13852 [02:16<47:32,  4.63it/s]\u001b[A\n",
      "Training loss: 8.18e-02 lr: 2.29e-05:   5%| | 635/13852 [02:16<47:28,  4.64it/s]\u001b[A\n",
      "Training loss: 6.75e-02 lr: 2.29e-05:   5%| | 636/13852 [02:16<47:38,  4.62it/s]\u001b[A\n",
      "Training loss: 7.88e-02 lr: 2.30e-05:   5%| | 637/13852 [02:16<47:31,  4.63it/s]\u001b[A\n",
      "Training loss: 1.31e-01 lr: 2.30e-05:   5%| | 638/13852 [02:17<47:43,  4.62it/s]\u001b[A\n",
      "Training loss: 1.24e-01 lr: 2.30e-05:   5%| | 639/13852 [02:17<47:46,  4.61it/s]\u001b[A\n",
      "Training loss: 1.22e-01 lr: 2.31e-05:   5%| | 640/13852 [02:17<47:39,  4.62it/s]\u001b[A\n",
      "Training loss: 1.92e-01 lr: 2.31e-05:   5%| | 641/13852 [02:17<47:34,  4.63it/s]\u001b[A\n",
      "Training loss: 1.43e-01 lr: 2.31e-05:   5%| | 642/13852 [02:18<47:35,  4.63it/s]\u001b[A\n",
      "Training loss: 1.80e-01 lr: 2.32e-05:   5%| | 643/13852 [02:18<47:31,  4.63it/s]\u001b[A\n",
      "Training loss: 1.44e-01 lr: 2.32e-05:   5%| | 644/13852 [02:18<47:53,  4.60it/s]\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.32e-05:   5%| | 645/13852 [02:18<47:45,  4.61it/s]\u001b[A\n",
      "Training loss: 7.69e-02 lr: 2.33e-05:   5%| | 646/13852 [02:18<47:39,  4.62it/s]\u001b[A\n",
      "Training loss: 7.35e-02 lr: 2.33e-05:   5%| | 647/13852 [02:19<47:31,  4.63it/s]\u001b[A\n",
      "Training loss: 7.07e-02 lr: 2.34e-05:   5%| | 648/13852 [02:19<47:30,  4.63it/s]\u001b[A\n",
      "Training loss: 9.54e-02 lr: 2.34e-05:   5%| | 649/13852 [02:19<47:26,  4.64it/s]\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.34e-05:   5%| | 650/13852 [02:19<47:27,  4.64it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 2.35e-05:   5%| | 651/13852 [02:20<47:25,  4.64it/s]\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.35e-05:   5%| | 652/13852 [02:20<47:25,  4.64it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.35e-05:   5%| | 653/13852 [02:20<47:29,  4.63it/s]\u001b[A\n",
      "Training loss: 1.52e-01 lr: 2.36e-05:   5%| | 654/13852 [02:20<47:25,  4.64it/s]\u001b[A\n",
      "Training loss: 1.65e-01 lr: 2.36e-05:   5%| | 655/13852 [02:20<47:28,  4.63it/s]\u001b[A\n",
      "Training loss: 1.53e-01 lr: 2.36e-05:   5%| | 656/13852 [02:21<47:29,  4.63it/s]\u001b[A\n",
      "Training loss: 1.27e-01 lr: 2.37e-05:   5%| | 657/13852 [02:21<47:41,  4.61it/s]\u001b[A\n",
      "Training loss: 1.18e-01 lr: 2.37e-05:   5%| | 658/13852 [02:21<47:43,  4.61it/s]\u001b[A\n",
      "Training loss: 1.76e-01 lr: 2.38e-05:   5%| | 659/13852 [02:21<47:39,  4.61it/s]\u001b[A\n",
      "Training loss: 1.97e-01 lr: 2.38e-05:   5%| | 660/13852 [02:21<49:04,  4.48it/s]\u001b[A\n",
      "Training loss: 1.66e-01 lr: 2.38e-05:   5%| | 661/13852 [02:22<50:04,  4.39it/s]\u001b[A\n",
      "Training loss: 1.38e-01 lr: 2.39e-05:   5%| | 662/13852 [02:22<49:26,  4.45it/s]\u001b[A\n",
      "Training loss: 1.57e-01 lr: 2.39e-05:   5%| | 663/13852 [02:22<48:56,  4.49it/s]\u001b[A\n",
      "Training loss: 1.31e-01 lr: 2.39e-05:   5%| | 664/13852 [02:22<48:28,  4.53it/s]\u001b[A\n",
      "Training loss: 1.00e-01 lr: 2.40e-05:   5%| | 665/13852 [02:23<48:11,  4.56it/s]\u001b[A\n",
      "Training loss: 9.06e-02 lr: 2.40e-05:   5%| | 666/13852 [02:23<47:57,  4.58it/s]\u001b[A\n",
      "Training loss: 6.73e-02 lr: 2.40e-05:   5%| | 667/13852 [02:23<47:47,  4.60it/s]\u001b[A\n",
      "Training loss: 1.38e-01 lr: 2.41e-05:   5%| | 668/13852 [02:23<47:43,  4.60it/s]\u001b[A\n",
      "Training loss: 1.19e-01 lr: 2.41e-05:   5%| | 669/13852 [02:23<47:36,  4.62it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.07e-01 lr: 2.41e-05:   5%| | 670/13852 [02:24<47:36,  4.61it/s]\u001b[A\n",
      "Training loss: 1.18e-01 lr: 2.42e-05:   5%| | 671/13852 [02:24<47:31,  4.62it/s]\u001b[A\n",
      "Training loss: 9.62e-02 lr: 2.42e-05:   5%| | 672/13852 [02:24<47:31,  4.62it/s]\u001b[A\n",
      "Training loss: 1.16e-01 lr: 2.43e-05:   5%| | 673/13852 [02:24<47:28,  4.63it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 2.43e-05:   5%| | 674/13852 [02:25<47:25,  4.63it/s]\u001b[A\n",
      "Training loss: 7.92e-02 lr: 2.43e-05:   5%| | 675/13852 [02:25<47:26,  4.63it/s]\u001b[A\n",
      "Training loss: 7.81e-02 lr: 2.44e-05:   5%| | 676/13852 [02:25<47:28,  4.63it/s]\u001b[A\n",
      "Training loss: 6.14e-02 lr: 2.44e-05:   5%| | 677/13852 [02:25<47:24,  4.63it/s]\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.44e-05:   5%| | 678/13852 [02:25<47:28,  4.62it/s]\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.45e-05:   5%| | 679/13852 [02:26<47:31,  4.62it/s]\u001b[A\n",
      "Training loss: 1.06e-01 lr: 2.45e-05:   5%| | 680/13852 [02:26<47:29,  4.62it/s]\u001b[A\n",
      "Training loss: 9.15e-02 lr: 2.45e-05:   5%| | 681/13852 [02:26<47:29,  4.62it/s]\u001b[A\n",
      "Training loss: 8.35e-02 lr: 2.46e-05:   5%| | 682/13852 [02:26<47:30,  4.62it/s]\u001b[A\n",
      "Training loss: 1.24e-01 lr: 2.46e-05:   5%| | 683/13852 [02:26<47:26,  4.63it/s]\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.47e-05:   5%| | 684/13852 [02:27<47:43,  4.60it/s]\u001b[A\n",
      "Training loss: 9.40e-02 lr: 2.47e-05:   5%| | 685/13852 [02:27<47:46,  4.59it/s]\u001b[A\n",
      "Training loss: 8.83e-02 lr: 2.47e-05:   5%| | 686/13852 [02:27<47:40,  4.60it/s]\u001b[A\n",
      "Training loss: 8.85e-02 lr: 2.48e-05:   5%| | 687/13852 [02:27<47:36,  4.61it/s]\u001b[A\n",
      "Training loss: 1.16e-01 lr: 2.48e-05:   5%| | 688/13852 [02:28<47:34,  4.61it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.48e-05:   5%| | 689/13852 [02:28<47:32,  4.61it/s]\u001b[A\n",
      "Training loss: 8.29e-02 lr: 2.49e-05:   5%| | 690/13852 [02:28<47:31,  4.62it/s]\u001b[A\n",
      "Training loss: 7.74e-02 lr: 2.49e-05:   5%| | 691/13852 [02:28<47:32,  4.61it/s]\u001b[A\n",
      "Training loss: 6.72e-02 lr: 2.49e-05:   5%| | 692/13852 [02:28<47:47,  4.59it/s]\u001b[A\n",
      "Training loss: 8.59e-02 lr: 2.50e-05:   5%| | 693/13852 [02:29<47:41,  4.60it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 2.50e-05:   5%| | 694/13852 [02:29<47:39,  4.60it/s]\u001b[A\n",
      "Training loss: 9.43e-02 lr: 2.51e-05:   5%| | 695/13852 [02:29<47:39,  4.60it/s]\u001b[A\n",
      "Training loss: 6.89e-02 lr: 2.51e-05:   5%| | 696/13852 [02:29<47:38,  4.60it/s]\u001b[A\n",
      "Training loss: 9.45e-02 lr: 2.51e-05:   5%| | 697/13852 [02:30<47:38,  4.60it/s]\u001b[A\n",
      "Training loss: 7.30e-02 lr: 2.52e-05:   5%| | 698/13852 [02:30<47:36,  4.61it/s]\u001b[A\n",
      "Training loss: 7.38e-02 lr: 2.52e-05:   5%| | 699/13852 [02:30<47:31,  4.61it/s]\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.52e-05:   5%| | 700/13852 [02:30<47:31,  4.61it/s]\u001b[A\n",
      "Training loss: 7.58e-02 lr: 2.53e-05:   5%| | 701/13852 [02:30<47:31,  4.61it/s]\u001b[A\n",
      "Training loss: 6.16e-02 lr: 2.53e-05:   5%| | 702/13852 [02:31<47:28,  4.62it/s]\u001b[A\n",
      "Training loss: 4.54e-02 lr: 2.53e-05:   5%| | 703/13852 [02:31<47:42,  4.59it/s]\u001b[A\n",
      "Training loss: 9.25e-02 lr: 2.54e-05:   5%| | 704/13852 [02:31<47:44,  4.59it/s]\u001b[A\n",
      "Training loss: 7.54e-02 lr: 2.54e-05:   5%| | 705/13852 [02:31<47:43,  4.59it/s]\u001b[A\n",
      "Training loss: 1.63e-01 lr: 2.54e-05:   5%| | 706/13852 [02:31<47:41,  4.59it/s]\u001b[A\n",
      "Training loss: 1.69e-01 lr: 2.55e-05:   5%| | 707/13852 [02:32<47:58,  4.57it/s]\u001b[A\n",
      "Training loss: 2.33e-01 lr: 2.55e-05:   5%| | 708/13852 [02:32<47:52,  4.58it/s]\u001b[A\n",
      "Training loss: 1.95e-01 lr: 2.56e-05:   5%| | 709/13852 [02:32<47:40,  4.59it/s]\u001b[A\n",
      "Training loss: 1.50e-01 lr: 2.56e-05:   5%| | 710/13852 [02:32<47:36,  4.60it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 2.56e-05:   5%| | 711/13852 [02:33<47:39,  4.60it/s]\u001b[A\n",
      "Training loss: 1.00e-01 lr: 2.57e-05:   5%| | 712/13852 [02:33<47:36,  4.60it/s]\u001b[A\n",
      "Training loss: 8.45e-02 lr: 2.57e-05:   5%| | 713/13852 [02:33<47:52,  4.57it/s]\u001b[A\n",
      "Training loss: 7.76e-02 lr: 2.57e-05:   5%| | 714/13852 [02:33<47:44,  4.59it/s]\u001b[A\n",
      "Training loss: 9.57e-02 lr: 2.58e-05:   5%| | 715/13852 [02:33<47:39,  4.59it/s]\u001b[A\n",
      "Training loss: 1.15e-01 lr: 2.58e-05:   5%| | 716/13852 [02:34<47:31,  4.61it/s]\u001b[A\n",
      "Training loss: 1.26e-01 lr: 2.58e-05:   5%| | 717/13852 [02:34<47:28,  4.61it/s]\u001b[A\n",
      "Training loss: 9.61e-02 lr: 2.59e-05:   5%| | 718/13852 [02:34<47:31,  4.61it/s]\u001b[A\n",
      "Training loss: 1.57e-01 lr: 2.59e-05:   5%| | 719/13852 [02:34<47:30,  4.61it/s]\u001b[A\n",
      "Training loss: 1.42e-01 lr: 2.60e-05:   5%| | 720/13852 [02:35<47:34,  4.60it/s]\u001b[A\n",
      "Training loss: 1.40e-01 lr: 2.60e-05:   5%| | 721/13852 [02:35<47:42,  4.59it/s]\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.60e-05:   5%| | 722/13852 [02:35<47:37,  4.59it/s]\u001b[A\n",
      "Training loss: 1.26e-01 lr: 2.61e-05:   5%| | 723/13852 [02:35<47:30,  4.61it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 2.61e-05:   5%| | 724/13852 [02:35<47:31,  4.60it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.61e-05:   5%| | 725/13852 [02:36<47:28,  4.61it/s]\u001b[A\n",
      "Training loss: 9.63e-02 lr: 2.62e-05:   5%| | 726/13852 [02:36<47:26,  4.61it/s]\u001b[A\n",
      "Training loss: 9.01e-02 lr: 2.62e-05:   5%| | 727/13852 [02:36<47:26,  4.61it/s]\u001b[A\n",
      "Training loss: 8.49e-02 lr: 2.62e-05:   5%| | 728/13852 [02:36<47:24,  4.61it/s]\u001b[A\n",
      "Training loss: 7.65e-02 lr: 2.63e-05:   5%| | 729/13852 [02:36<47:33,  4.60it/s]\u001b[A\n",
      "Training loss: 1.74e-01 lr: 2.63e-05:   5%| | 730/13852 [02:37<47:38,  4.59it/s]\u001b[A\n",
      "Training loss: 1.61e-01 lr: 2.64e-05:   5%| | 731/13852 [02:37<48:55,  4.47it/s]\u001b[A\n",
      "Training loss: 1.29e-01 lr: 2.64e-05:   5%| | 732/13852 [02:37<50:00,  4.37it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.64e-05:   5%| | 733/13852 [02:37<49:54,  4.38it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.65e-05:   5%| | 734/13852 [02:38<49:04,  4.46it/s]\u001b[A\n",
      "Training loss: 1.24e-01 lr: 2.65e-05:   5%| | 735/13852 [02:38<48:33,  4.50it/s]\u001b[A\n",
      "Training loss: 1.31e-01 lr: 2.65e-05:   5%| | 736/13852 [02:38<48:07,  4.54it/s]\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.66e-05:   5%| | 737/13852 [02:38<47:49,  4.57it/s]\u001b[A\n",
      "Training loss: 1.62e-01 lr: 2.66e-05:   5%| | 738/13852 [02:38<47:39,  4.59it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 2.66e-05:   5%| | 739/13852 [02:39<47:27,  4.61it/s]\u001b[A\n",
      "Training loss: 9.30e-02 lr: 2.67e-05:   5%| | 740/13852 [02:39<47:28,  4.60it/s]\u001b[A\n",
      "Training loss: 8.51e-02 lr: 2.67e-05:   5%| | 741/13852 [02:39<47:23,  4.61it/s]\u001b[A\n",
      "Training loss: 8.55e-02 lr: 2.67e-05:   5%| | 742/13852 [02:39<47:21,  4.61it/s]\u001b[A\n",
      "Training loss: 8.36e-02 lr: 2.68e-05:   5%| | 743/13852 [02:40<47:18,  4.62it/s]\u001b[A\n",
      "Training loss: 1.18e-01 lr: 2.68e-05:   5%| | 744/13852 [02:40<47:17,  4.62it/s]\u001b[A\n",
      "Training loss: 9.58e-02 lr: 2.69e-05:   5%| | 745/13852 [02:40<47:20,  4.61it/s]\u001b[A\n",
      "Training loss: 1.04e-01 lr: 2.69e-05:   5%| | 746/13852 [02:40<47:22,  4.61it/s]\u001b[A\n",
      "Training loss: 1.32e-01 lr: 2.69e-05:   5%| | 747/13852 [02:40<47:29,  4.60it/s]\u001b[A\n",
      "Training loss: 1.25e-01 lr: 2.70e-05:   5%| | 748/13852 [02:41<47:29,  4.60it/s]\u001b[A\n",
      "Training loss: 1.80e-01 lr: 2.70e-05:   5%| | 749/13852 [02:41<47:37,  4.59it/s]\u001b[A\n",
      "Training loss: 1.34e-01 lr: 2.70e-05:   5%| | 750/13852 [02:41<47:37,  4.59it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 2.71e-05:   5%| | 751/13852 [02:41<48:22,  4.51it/s]\u001b[A\n",
      "Training loss: 1.39e-01 lr: 2.71e-05:   5%| | 752/13852 [02:42<49:34,  4.40it/s]\u001b[A\n",
      "Training loss: 1.40e-01 lr: 2.71e-05:   5%| | 753/13852 [02:42<51:59,  4.20it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 2.72e-05:   5%| | 754/13852 [02:42<51:51,  4.21it/s]\u001b[A\n",
      "Training loss: 8.80e-02 lr: 2.72e-05:   5%| | 755/13852 [02:42<51:38,  4.23it/s]\u001b[A\n",
      "Training loss: 7.84e-02 lr: 2.73e-05:   5%| | 756/13852 [02:43<51:41,  4.22it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 2.73e-05:   5%| | 757/13852 [02:43<51:32,  4.23it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 2.73e-05:   5%| | 758/13852 [02:43<51:33,  4.23it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 2.74e-05:   5%| | 759/13852 [02:43<51:30,  4.24it/s]\u001b[A\n",
      "Training loss: 1.45e-01 lr: 2.74e-05:   5%| | 760/13852 [02:43<51:44,  4.22it/s]\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.74e-05:   5%| | 761/13852 [02:44<51:33,  4.23it/s]\u001b[A\n",
      "Training loss: 1.54e-01 lr: 2.75e-05:   6%| | 762/13852 [02:44<51:27,  4.24it/s]\u001b[A\n",
      "Training loss: 1.49e-01 lr: 2.75e-05:   6%| | 763/13852 [02:44<51:28,  4.24it/s]\u001b[A\n",
      "Training loss: 1.29e-01 lr: 2.75e-05:   6%| | 764/13852 [02:44<51:26,  4.24it/s]\u001b[A\n",
      "Training loss: 9.28e-02 lr: 2.76e-05:   6%| | 765/13852 [02:45<51:20,  4.25it/s]\u001b[A\n",
      "Training loss: 1.51e-01 lr: 2.76e-05:   6%| | 766/13852 [02:45<51:22,  4.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.72e-01 lr: 2.77e-05:   6%| | 767/13852 [02:45<51:15,  4.25it/s]\u001b[A\n",
      "Training loss: 1.42e-01 lr: 2.77e-05:   6%| | 768/13852 [02:45<51:27,  4.24it/s]\u001b[A\n",
      "Training loss: 1.37e-01 lr: 2.77e-05:   6%| | 769/13852 [02:46<51:31,  4.23it/s]\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.78e-05:   6%| | 770/13852 [02:46<51:23,  4.24it/s]\u001b[A\n",
      "Training loss: 9.29e-02 lr: 2.78e-05:   6%| | 771/13852 [02:46<51:23,  4.24it/s]\u001b[A\n",
      "Training loss: 7.64e-02 lr: 2.78e-05:   6%| | 772/13852 [02:46<51:23,  4.24it/s]\u001b[A\n",
      "Training loss: 7.37e-02 lr: 2.79e-05:   6%| | 773/13852 [02:47<51:26,  4.24it/s]\u001b[A\n",
      "Training loss: 9.42e-02 lr: 2.79e-05:   6%| | 774/13852 [02:47<52:05,  4.18it/s]\u001b[A\n",
      "Training loss: 1.46e-01 lr: 2.79e-05:   6%| | 775/13852 [02:47<52:06,  4.18it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 2.80e-05:   6%| | 776/13852 [02:47<51:50,  4.20it/s]\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.80e-05:   6%| | 777/13852 [02:47<51:36,  4.22it/s]\u001b[A\n",
      "Training loss: 9.79e-02 lr: 2.80e-05:   6%| | 778/13852 [02:48<51:27,  4.23it/s]\u001b[A\n",
      "Training loss: 1.56e-01 lr: 2.81e-05:   6%| | 779/13852 [02:48<51:29,  4.23it/s]\u001b[A\n",
      "Training loss: 1.56e-01 lr: 2.81e-05:   6%| | 780/13852 [02:48<51:24,  4.24it/s]\u001b[A\n",
      "Training loss: 1.84e-01 lr: 2.82e-05:   6%| | 781/13852 [02:48<51:23,  4.24it/s]\u001b[A\n",
      "Training loss: 1.79e-01 lr: 2.82e-05:   6%| | 782/13852 [02:49<51:19,  4.24it/s]\u001b[A\n",
      "Training loss: 1.65e-01 lr: 2.82e-05:   6%| | 783/13852 [02:49<51:13,  4.25it/s]\u001b[A\n",
      "Training loss: 1.88e-01 lr: 2.83e-05:   6%| | 784/13852 [02:49<51:11,  4.25it/s]\u001b[A\n",
      "Training loss: 1.75e-01 lr: 2.83e-05:   6%| | 785/13852 [02:49<51:13,  4.25it/s]\u001b[A\n",
      "Training loss: 2.14e-01 lr: 2.83e-05:   6%| | 786/13852 [02:50<51:21,  4.24it/s]\u001b[A\n",
      "Training loss: 1.64e-01 lr: 2.84e-05:   6%| | 787/13852 [02:50<51:25,  4.23it/s]\u001b[A\n",
      "Training loss: 1.66e-01 lr: 2.84e-05:   6%| | 788/13852 [02:50<51:22,  4.24it/s]\u001b[A\n",
      "Training loss: 1.44e-01 lr: 2.84e-05:   6%| | 789/13852 [02:50<51:17,  4.24it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 2.85e-05:   6%| | 790/13852 [02:51<51:18,  4.24it/s]\u001b[A\n",
      "Training loss: 9.99e-02 lr: 2.85e-05:   6%| | 791/13852 [02:51<51:38,  4.22it/s]\u001b[A\n",
      "Training loss: 7.63e-02 lr: 2.86e-05:   6%| | 792/13852 [02:51<51:47,  4.20it/s]\u001b[A\n",
      "Training loss: 1.12e-01 lr: 2.86e-05:   6%| | 793/13852 [02:51<51:45,  4.20it/s]\u001b[A\n",
      "Training loss: 1.65e-01 lr: 2.86e-05:   6%| | 794/13852 [02:52<51:57,  4.19it/s]\u001b[A\n",
      "Training loss: 1.41e-01 lr: 2.87e-05:   6%| | 795/13852 [02:52<52:12,  4.17it/s]\u001b[A\n",
      "Training loss: 1.16e-01 lr: 2.87e-05:   6%| | 796/13852 [02:52<51:54,  4.19it/s]\u001b[A\n",
      "Training loss: 9.16e-02 lr: 2.87e-05:   6%| | 797/13852 [02:52<51:36,  4.22it/s]\u001b[A\n",
      "Training loss: 8.31e-02 lr: 2.88e-05:   6%| | 798/13852 [02:52<51:34,  4.22it/s]\u001b[A\n",
      "Training loss: 7.85e-02 lr: 2.88e-05:   6%| | 799/13852 [02:53<51:31,  4.22it/s]\u001b[A\n",
      "Training loss: 8.08e-02 lr: 2.88e-05:   6%| | 800/13852 [02:53<51:31,  4.22it/s]\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.89e-05:   6%| | 801/13852 [02:53<51:38,  4.21it/s]\u001b[A\n",
      "Training loss: 6.93e-02 lr: 2.89e-05:   6%| | 802/13852 [02:53<51:26,  4.23it/s]\u001b[A\n",
      "Training loss: 1.06e-01 lr: 2.90e-05:   6%| | 803/13852 [02:54<51:18,  4.24it/s]\u001b[A\n",
      "Training loss: 1.93e-01 lr: 2.90e-05:   6%| | 804/13852 [02:54<51:13,  4.25it/s]\u001b[A\n",
      "Training loss: 1.48e-01 lr: 2.90e-05:   6%| | 805/13852 [02:54<51:16,  4.24it/s]\u001b[A\n",
      "Training loss: 1.47e-01 lr: 2.91e-05:   6%| | 806/13852 [02:54<51:28,  4.22it/s]\u001b[A\n",
      "Training loss: 1.20e-01 lr: 2.91e-05:   6%| | 807/13852 [02:55<51:31,  4.22it/s]\u001b[A\n",
      "Training loss: 1.18e-01 lr: 2.91e-05:   6%| | 808/13852 [02:55<51:25,  4.23it/s]\u001b[A\n",
      "Training loss: 8.99e-02 lr: 2.92e-05:   6%| | 809/13852 [02:55<51:16,  4.24it/s]\u001b[A\n",
      "Training loss: 7.46e-02 lr: 2.92e-05:   6%| | 810/13852 [02:55<51:12,  4.24it/s]\u001b[A\n",
      "Training loss: 1.49e-01 lr: 2.92e-05:   6%| | 811/13852 [02:56<51:13,  4.24it/s]\u001b[A\n",
      "Training loss: 1.78e-01 lr: 2.93e-05:   6%| | 812/13852 [02:56<51:18,  4.24it/s]\u001b[A\n",
      "Training loss: 1.41e-01 lr: 2.93e-05:   6%| | 813/13852 [02:56<51:34,  4.21it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 2.93e-05:   6%| | 814/13852 [02:56<51:28,  4.22it/s]\u001b[A\n",
      "Training loss: 9.94e-02 lr: 2.94e-05:   6%| | 815/13852 [02:56<51:15,  4.24it/s]\u001b[A\n",
      "Training loss: 8.79e-02 lr: 2.94e-05:   6%| | 816/13852 [02:57<51:32,  4.22it/s]\u001b[A\n",
      "Training loss: 8.94e-02 lr: 2.95e-05:   6%| | 817/13852 [02:57<51:31,  4.22it/s]\u001b[A\n",
      "Training loss: 1.39e-01 lr: 2.95e-05:   6%| | 818/13852 [02:57<51:27,  4.22it/s]\u001b[A\n",
      "Training loss: 1.68e-01 lr: 2.95e-05:   6%| | 819/13852 [02:57<51:23,  4.23it/s]\u001b[A\n",
      "Training loss: 1.36e-01 lr: 2.96e-05:   6%| | 820/13852 [02:58<51:17,  4.23it/s]\u001b[A\n",
      "Training loss: 1.93e-01 lr: 2.96e-05:   6%| | 821/13852 [02:58<51:13,  4.24it/s]\u001b[A\n",
      "Training loss: 1.46e-01 lr: 2.96e-05:   6%| | 822/13852 [02:58<51:29,  4.22it/s]\u001b[A\n",
      "Training loss: 1.36e-01 lr: 2.97e-05:   6%| | 823/13852 [02:58<51:21,  4.23it/s]\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.97e-05:   6%| | 824/13852 [02:59<51:26,  4.22it/s]\u001b[A\n",
      "Training loss: 8.99e-02 lr: 2.97e-05:   6%| | 825/13852 [02:59<51:27,  4.22it/s]\u001b[A\n",
      "Training loss: 7.35e-02 lr: 2.98e-05:   6%| | 826/13852 [02:59<51:17,  4.23it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 2.98e-05:   6%| | 827/13852 [02:59<51:16,  4.23it/s]\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.99e-05:   6%| | 828/13852 [03:00<51:11,  4.24it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.99e-05:   6%| | 829/13852 [03:00<51:09,  4.24it/s]\u001b[A\n",
      "Training loss: 9.33e-02 lr: 2.99e-05:   6%| | 830/13852 [03:00<51:09,  4.24it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.00e-05:   6%| | 831/13852 [03:00<51:11,  4.24it/s]\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.00e-05:   6%| | 832/13852 [03:00<51:11,  4.24it/s]\u001b[A\n",
      "Training loss: 8.93e-02 lr: 3.00e-05:   6%| | 833/13852 [03:01<51:20,  4.23it/s]\u001b[A\n",
      "Training loss: 7.55e-02 lr: 3.01e-05:   6%| | 834/13852 [03:01<51:30,  4.21it/s]\u001b[A\n",
      "Training loss: 9.14e-02 lr: 3.01e-05:   6%| | 835/13852 [03:01<51:21,  4.22it/s]\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.01e-05:   6%| | 836/13852 [03:01<51:13,  4.23it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.02e-05:   6%| | 837/13852 [03:02<51:42,  4.20it/s]\u001b[A\n",
      "Training loss: 9.41e-02 lr: 3.02e-05:   6%| | 838/13852 [03:02<51:34,  4.21it/s]\u001b[A\n",
      "Training loss: 7.87e-02 lr: 3.03e-05:   6%| | 839/13852 [03:02<51:34,  4.21it/s]\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.03e-05:   6%| | 840/13852 [03:02<51:28,  4.21it/s]\u001b[A\n",
      "Training loss: 9.23e-02 lr: 3.03e-05:   6%| | 841/13852 [03:03<51:15,  4.23it/s]\u001b[A\n",
      "Training loss: 8.56e-02 lr: 3.04e-05:   6%| | 842/13852 [03:03<51:11,  4.24it/s]\u001b[A\n",
      "Training loss: 9.95e-02 lr: 3.04e-05:   6%| | 843/13852 [03:03<51:10,  4.24it/s]\u001b[A\n",
      "Training loss: 9.60e-02 lr: 3.04e-05:   6%| | 844/13852 [03:03<51:08,  4.24it/s]\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.05e-05:   6%| | 845/13852 [03:04<51:11,  4.23it/s]\u001b[A\n",
      "Training loss: 9.18e-02 lr: 3.05e-05:   6%| | 846/13852 [03:04<51:14,  4.23it/s]\u001b[A\n",
      "Training loss: 7.98e-02 lr: 3.05e-05:   6%| | 847/13852 [03:04<51:17,  4.23it/s]\u001b[A\n",
      "Training loss: 9.30e-02 lr: 3.06e-05:   6%| | 848/13852 [03:04<51:22,  4.22it/s]\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.06e-05:   6%| | 849/13852 [03:05<51:10,  4.23it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.06e-05:   6%| | 850/13852 [03:05<51:12,  4.23it/s]\u001b[A\n",
      "Training loss: 1.53e-01 lr: 3.07e-05:   6%| | 851/13852 [03:05<51:07,  4.24it/s]\u001b[A\n",
      "Training loss: 1.44e-01 lr: 3.07e-05:   6%| | 852/13852 [03:05<51:07,  4.24it/s]\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.08e-05:   6%| | 853/13852 [03:05<51:13,  4.23it/s]\u001b[A\n",
      "Training loss: 1.60e-01 lr: 3.08e-05:   6%| | 854/13852 [03:06<51:05,  4.24it/s]\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.08e-05:   6%| | 855/13852 [03:06<50:59,  4.25it/s]\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.09e-05:   6%| | 856/13852 [03:06<50:53,  4.26it/s]\u001b[A\n",
      "Training loss: 9.42e-02 lr: 3.09e-05:   6%| | 857/13852 [03:06<50:56,  4.25it/s]\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.09e-05:   6%| | 858/13852 [03:07<51:13,  4.23it/s]\u001b[A\n",
      "Training loss: 8.30e-02 lr: 3.10e-05:   6%| | 859/13852 [03:07<51:36,  4.20it/s]\u001b[A\n",
      "Training loss: 7.32e-02 lr: 3.10e-05:   6%| | 860/13852 [03:07<51:22,  4.21it/s]\u001b[A\n",
      "Training loss: 8.86e-02 lr: 3.10e-05:   6%| | 861/13852 [03:07<51:22,  4.21it/s]\u001b[A\n",
      "Training loss: 9.33e-02 lr: 3.11e-05:   6%| | 862/13852 [03:08<51:18,  4.22it/s]\u001b[A\n",
      "Training loss: 1.75e-01 lr: 3.11e-05:   6%| | 863/13852 [03:08<51:18,  4.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.29e-01 lr: 3.12e-05:   6%| | 864/13852 [03:08<51:11,  4.23it/s]\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.12e-05:   6%| | 865/13852 [03:08<51:00,  4.24it/s]\u001b[A\n",
      "Training loss: 9.03e-02 lr: 3.12e-05:   6%| | 866/13852 [03:09<51:01,  4.24it/s]\u001b[A\n",
      "Training loss: 7.14e-02 lr: 3.13e-05:   6%| | 867/13852 [03:09<50:54,  4.25it/s]\u001b[A\n",
      "Training loss: 7.68e-02 lr: 3.13e-05:   6%| | 868/13852 [03:09<50:48,  4.26it/s]\u001b[A\n",
      "Training loss: 8.91e-02 lr: 3.13e-05:   6%| | 869/13852 [03:09<50:51,  4.25it/s]\u001b[A\n",
      "Training loss: 6.82e-02 lr: 3.14e-05:   6%| | 870/13852 [03:09<50:55,  4.25it/s]\u001b[A\n",
      "Training loss: 7.65e-02 lr: 3.14e-05:   6%| | 871/13852 [03:10<50:59,  4.24it/s]\u001b[A\n",
      "Training loss: 8.62e-02 lr: 3.14e-05:   6%| | 872/13852 [03:10<50:59,  4.24it/s]\u001b[A\n",
      "Training loss: 6.82e-02 lr: 3.15e-05:   6%| | 873/13852 [03:10<50:53,  4.25it/s]\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.15e-05:   6%| | 874/13852 [03:10<50:50,  4.25it/s]\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.16e-05:   6%| | 875/13852 [03:11<50:45,  4.26it/s]\u001b[A\n",
      "Training loss: 8.93e-02 lr: 3.16e-05:   6%| | 876/13852 [03:11<51:16,  4.22it/s]\u001b[A\n",
      "Training loss: 7.16e-02 lr: 3.16e-05:   6%| | 877/13852 [03:11<51:19,  4.21it/s]\u001b[A\n",
      "Training loss: 8.54e-02 lr: 3.17e-05:   6%| | 878/13852 [03:11<51:24,  4.21it/s]\u001b[A\n",
      "Training loss: 9.55e-02 lr: 3.17e-05:   6%| | 879/13852 [03:12<51:13,  4.22it/s]\u001b[A\n",
      "Training loss: 8.61e-02 lr: 3.17e-05:   6%| | 880/13852 [03:12<51:13,  4.22it/s]\u001b[A\n",
      "Training loss: 1.96e-01 lr: 3.18e-05:   6%| | 881/13852 [03:12<51:14,  4.22it/s]\u001b[A\n",
      "Training loss: 1.64e-01 lr: 3.18e-05:   6%| | 882/13852 [03:12<51:14,  4.22it/s]\u001b[A\n",
      "Training loss: 1.40e-01 lr: 3.18e-05:   6%| | 883/13852 [03:13<51:08,  4.23it/s]\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.19e-05:   6%| | 884/13852 [03:13<51:03,  4.23it/s]\u001b[A\n",
      "Training loss: 1.85e-01 lr: 3.19e-05:   6%| | 885/13852 [03:13<50:58,  4.24it/s]\u001b[A\n",
      "Training loss: 2.01e-01 lr: 3.19e-05:   6%| | 886/13852 [03:13<50:49,  4.25it/s]\u001b[A\n",
      "Training loss: 1.48e-01 lr: 3.20e-05:   6%| | 887/13852 [03:13<50:43,  4.26it/s]\u001b[A\n",
      "Training loss: 1.34e-01 lr: 3.20e-05:   6%| | 888/13852 [03:14<50:38,  4.27it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.21e-05:   6%| | 889/13852 [03:14<50:44,  4.26it/s]\u001b[A\n",
      "Training loss: 1.34e-01 lr: 3.21e-05:   6%| | 890/13852 [03:14<50:50,  4.25it/s]\u001b[A\n",
      "Training loss: 1.64e-01 lr: 3.21e-05:   6%| | 891/13852 [03:14<50:52,  4.25it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.22e-05:   6%| | 892/13852 [03:15<50:43,  4.26it/s]\u001b[A\n",
      "Training loss: 1.73e-01 lr: 3.22e-05:   6%| | 893/13852 [03:15<50:41,  4.26it/s]\u001b[A\n",
      "Training loss: 1.50e-01 lr: 3.22e-05:   6%| | 894/13852 [03:15<50:41,  4.26it/s]\u001b[A\n",
      "Training loss: 1.34e-01 lr: 3.23e-05:   6%| | 895/13852 [03:15<50:56,  4.24it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.23e-05:   6%| | 896/13852 [03:16<51:01,  4.23it/s]\u001b[A\n",
      "Training loss: 1.41e-01 lr: 3.23e-05:   6%| | 897/13852 [03:16<51:03,  4.23it/s]\u001b[A\n",
      "Training loss: 1.72e-01 lr: 3.24e-05:   6%| | 898/13852 [03:16<51:08,  4.22it/s]\u001b[A\n",
      "Training loss: 1.49e-01 lr: 3.24e-05:   6%| | 899/13852 [03:16<51:02,  4.23it/s]\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.25e-05:   6%| | 900/13852 [03:17<50:59,  4.23it/s]\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.25e-05:   7%| | 901/13852 [03:17<51:28,  4.19it/s]\u001b[A\n",
      "Training loss: 9.19e-02 lr: 3.25e-05:   7%| | 902/13852 [03:17<51:25,  4.20it/s]\u001b[A\n",
      "Training loss: 9.64e-02 lr: 3.26e-05:   7%| | 903/13852 [03:17<51:22,  4.20it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.26e-05:   7%| | 904/13852 [03:18<51:16,  4.21it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.26e-05:   7%| | 905/13852 [03:18<51:09,  4.22it/s]\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.27e-05:   7%| | 906/13852 [03:18<51:24,  4.20it/s]\u001b[A\n",
      "Training loss: 8.48e-02 lr: 3.27e-05:   7%| | 907/13852 [03:18<51:09,  4.22it/s]\u001b[A\n",
      "Training loss: 6.55e-02 lr: 3.27e-05:   7%| | 908/13852 [03:18<51:05,  4.22it/s]\u001b[A\n",
      "Training loss: 9.54e-02 lr: 3.28e-05:   7%| | 909/13852 [03:19<51:10,  4.22it/s]\u001b[A\n",
      "Training loss: 8.44e-02 lr: 3.28e-05:   7%| | 910/13852 [03:19<51:11,  4.21it/s]\u001b[A\n",
      "Training loss: 9.83e-02 lr: 3.28e-05:   7%| | 911/13852 [03:19<51:04,  4.22it/s]\u001b[A\n",
      "Training loss: 7.83e-02 lr: 3.29e-05:   7%| | 912/13852 [03:19<50:57,  4.23it/s]\u001b[A\n",
      "Training loss: 9.25e-02 lr: 3.29e-05:   7%| | 913/13852 [03:20<50:53,  4.24it/s]\u001b[A\n",
      "Training loss: 9.35e-02 lr: 3.30e-05:   7%| | 914/13852 [03:20<50:44,  4.25it/s]\u001b[A\n",
      "Training loss: 8.17e-02 lr: 3.30e-05:   7%| | 915/13852 [03:20<50:54,  4.24it/s]\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.30e-05:   7%| | 916/13852 [03:20<51:00,  4.23it/s]\u001b[A\n",
      "Training loss: 9.07e-02 lr: 3.31e-05:   7%| | 917/13852 [03:21<51:04,  4.22it/s]\u001b[A\n",
      "Training loss: 8.44e-02 lr: 3.31e-05:   7%| | 918/13852 [03:21<51:30,  4.18it/s]\u001b[A\n",
      "Training loss: 7.34e-02 lr: 3.31e-05:   7%| | 919/13852 [03:21<51:20,  4.20it/s]\u001b[A\n",
      "Training loss: 8.60e-02 lr: 3.32e-05:   7%| | 920/13852 [03:21<51:06,  4.22it/s]\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.32e-05:   7%| | 921/13852 [03:22<51:04,  4.22it/s]\u001b[A\n",
      "Training loss: 1.58e-01 lr: 3.32e-05:   7%| | 922/13852 [03:22<51:43,  4.17it/s]\u001b[A\n",
      "Training loss: 1.20e-01 lr: 3.33e-05:   7%| | 923/13852 [03:22<51:34,  4.18it/s]\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.33e-05:   7%| | 924/13852 [03:22<51:21,  4.20it/s]\u001b[A\n",
      "Training loss: 9.34e-02 lr: 3.34e-05:   7%| | 925/13852 [03:22<51:08,  4.21it/s]\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.34e-05:   7%| | 926/13852 [03:23<51:00,  4.22it/s]\u001b[A\n",
      "Training loss: 1.58e-01 lr: 3.34e-05:   7%| | 927/13852 [03:23<51:05,  4.22it/s]\u001b[A\n",
      "Training loss: 1.99e-01 lr: 3.35e-05:   7%| | 928/13852 [03:23<51:07,  4.21it/s]\u001b[A\n",
      "Training loss: 1.87e-01 lr: 3.35e-05:   7%| | 929/13852 [03:23<51:05,  4.22it/s]\u001b[A\n",
      "Training loss: 1.45e-01 lr: 3.35e-05:   7%| | 930/13852 [03:24<51:00,  4.22it/s]\u001b[A\n",
      "Training loss: 1.25e-01 lr: 3.36e-05:   7%| | 931/13852 [03:24<51:02,  4.22it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.36e-05:   7%| | 932/13852 [03:24<50:56,  4.23it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.36e-05:   7%| | 933/13852 [03:24<51:10,  4.21it/s]\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.37e-05:   7%| | 934/13852 [03:25<51:05,  4.21it/s]\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.37e-05:   7%| | 935/13852 [03:25<51:00,  4.22it/s]\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.38e-05:   7%| | 936/13852 [03:25<50:58,  4.22it/s]\u001b[A\n",
      "Training loss: 1.46e-01 lr: 3.38e-05:   7%| | 937/13852 [03:25<50:57,  4.22it/s]\u001b[A\n",
      "Training loss: 1.45e-01 lr: 3.38e-05:   7%| | 938/13852 [03:26<50:49,  4.23it/s]\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.39e-05:   7%| | 939/13852 [03:26<50:46,  4.24it/s]\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.39e-05:   7%| | 940/13852 [03:26<50:48,  4.24it/s]\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.39e-05:   7%| | 941/13852 [03:26<50:52,  4.23it/s]\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.40e-05:   7%| | 942/13852 [03:27<50:59,  4.22it/s]\u001b[A\n",
      "Training loss: 1.20e-01 lr: 3.40e-05:   7%| | 943/13852 [03:27<51:24,  4.19it/s]\u001b[A\n",
      "Training loss: 1.70e-01 lr: 3.40e-05:   7%| | 944/13852 [03:27<51:12,  4.20it/s]\u001b[A\n",
      "Training loss: 1.33e-01 lr: 3.41e-05:   7%| | 945/13852 [03:27<51:00,  4.22it/s]\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.41e-05:   7%| | 946/13852 [03:27<51:04,  4.21it/s]\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.41e-05:   7%| | 947/13852 [03:28<51:06,  4.21it/s]\u001b[A\n",
      "Training loss: 9.13e-02 lr: 3.42e-05:   7%| | 948/13852 [03:28<51:01,  4.21it/s]\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.42e-05:   7%| | 949/13852 [03:28<50:58,  4.22it/s]\u001b[A\n",
      "Training loss: 8.69e-02 lr: 3.43e-05:   7%| | 950/13852 [03:28<51:01,  4.21it/s]\u001b[A\n",
      "Training loss: 6.86e-02 lr: 3.43e-05:   7%| | 951/13852 [03:29<50:51,  4.23it/s]\u001b[A\n",
      "Training loss: 7.43e-02 lr: 3.43e-05:   7%| | 952/13852 [03:29<50:59,  4.22it/s]\u001b[A\n",
      "Training loss: 6.95e-02 lr: 3.44e-05:   7%| | 953/13852 [03:29<51:05,  4.21it/s]\u001b[A\n",
      "Training loss: 1.26e-01 lr: 3.44e-05:   7%| | 954/13852 [03:29<51:04,  4.21it/s]\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.44e-05:   7%| | 955/13852 [03:30<50:54,  4.22it/s]\u001b[A\n",
      "Training loss: 9.32e-02 lr: 3.45e-05:   7%| | 956/13852 [03:30<50:47,  4.23it/s]\u001b[A\n",
      "Training loss: 7.82e-02 lr: 3.45e-05:   7%| | 957/13852 [03:30<50:45,  4.23it/s]\u001b[A\n",
      "Training loss: 7.90e-02 lr: 3.45e-05:   7%| | 958/13852 [03:30<50:42,  4.24it/s]\u001b[A\n",
      "Training loss: 6.78e-02 lr: 3.46e-05:   7%| | 959/13852 [03:31<50:44,  4.23it/s]\u001b[A\n",
      "Training loss: 8.35e-02 lr: 3.46e-05:   7%| | 960/13852 [03:31<51:07,  4.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.94e-02 lr: 3.47e-05:   7%| | 961/13852 [03:31<51:05,  4.20it/s]\u001b[A\n",
      "Training loss: 5.93e-02 lr: 3.47e-05:   7%| | 962/13852 [03:31<50:59,  4.21it/s]\u001b[A\n",
      "Training loss: 7.15e-02 lr: 3.47e-05:   7%| | 963/13852 [03:32<50:46,  4.23it/s]\u001b[A\n",
      "Training loss: 6.38e-02 lr: 3.48e-05:   7%| | 964/13852 [03:32<51:08,  4.20it/s]\u001b[A\n",
      "Training loss: 6.08e-02 lr: 3.48e-05:   7%| | 965/13852 [03:32<51:22,  4.18it/s]\u001b[A\n",
      "Training loss: 5.25e-02 lr: 3.48e-05:   7%| | 966/13852 [03:32<51:21,  4.18it/s]\u001b[A\n",
      "Training loss: 7.19e-02 lr: 3.49e-05:   7%| | 967/13852 [03:32<51:13,  4.19it/s]\u001b[A\n",
      "Training loss: 9.81e-02 lr: 3.49e-05:   7%| | 968/13852 [03:33<51:01,  4.21it/s]\u001b[A\n",
      "Training loss: 8.50e-02 lr: 3.49e-05:   7%| | 969/13852 [03:33<51:03,  4.21it/s]\u001b[A\n",
      "Training loss: 6.93e-02 lr: 3.50e-05:   7%| | 970/13852 [03:33<50:56,  4.22it/s]\u001b[A\n",
      "Training loss: 1.65e-01 lr: 3.50e-05:   7%| | 971/13852 [03:33<50:52,  4.22it/s]\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.51e-05:   7%| | 972/13852 [03:34<50:55,  4.22it/s]\u001b[A\n",
      "Training loss: 9.09e-02 lr: 3.51e-05:   7%| | 973/13852 [03:34<50:54,  4.22it/s]\u001b[A\n",
      "Training loss: 7.49e-02 lr: 3.51e-05:   7%| | 974/13852 [03:34<50:56,  4.21it/s]\u001b[A\n",
      "Training loss: 6.96e-02 lr: 3.52e-05:   7%| | 975/13852 [03:34<50:45,  4.23it/s]\u001b[A\n",
      "Training loss: 6.67e-02 lr: 3.52e-05:   7%| | 976/13852 [03:35<50:40,  4.23it/s]\u001b[A\n",
      "Training loss: 5.58e-02 lr: 3.52e-05:   7%| | 977/13852 [03:35<50:48,  4.22it/s]\u001b[A\n",
      "Training loss: 6.07e-02 lr: 3.53e-05:   7%| | 978/13852 [03:35<50:51,  4.22it/s]\u001b[A\n",
      "Training loss: 5.63e-02 lr: 3.53e-05:   7%| | 979/13852 [03:35<50:55,  4.21it/s]\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.53e-05:   7%| | 980/13852 [03:36<50:47,  4.22it/s]\u001b[A\n",
      "Training loss: 7.32e-02 lr: 3.54e-05:   7%| | 981/13852 [03:36<50:40,  4.23it/s]\u001b[A\n",
      "Training loss: 5.68e-02 lr: 3.54e-05:   7%| | 982/13852 [03:36<50:33,  4.24it/s]\u001b[A\n",
      "Training loss: 1.39e-01 lr: 3.54e-05:   7%| | 983/13852 [03:36<50:28,  4.25it/s]\u001b[A\n",
      "Training loss: 2.20e-01 lr: 3.55e-05:   7%| | 984/13852 [03:36<50:53,  4.21it/s]\u001b[A\n",
      "Training loss: 1.76e-01 lr: 3.55e-05:   7%| | 985/13852 [03:37<51:08,  4.19it/s]\u001b[A\n",
      "Training loss: 1.75e-01 lr: 3.56e-05:   7%| | 986/13852 [03:37<50:13,  4.27it/s]\u001b[A\n",
      "Training loss: 1.61e-01 lr: 3.56e-05:   7%| | 987/13852 [03:37<49:16,  4.35it/s]\u001b[A\n",
      "Training loss: 1.37e-01 lr: 3.56e-05:   7%| | 988/13852 [03:37<48:36,  4.41it/s]\u001b[A\n",
      "Training loss: 1.57e-01 lr: 3.57e-05:   7%| | 989/13852 [03:38<47:58,  4.47it/s]\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.57e-05:   7%| | 990/13852 [03:38<47:48,  4.48it/s]\u001b[A\n",
      "Training loss: 9.28e-02 lr: 3.57e-05:   7%| | 991/13852 [03:38<47:29,  4.51it/s]\u001b[A\n",
      "Training loss: 7.84e-02 lr: 3.58e-05:   7%| | 992/13852 [03:38<47:12,  4.54it/s]\u001b[A\n",
      "Training loss: 6.38e-02 lr: 3.58e-05:   7%| | 993/13852 [03:38<47:11,  4.54it/s]\u001b[A\n",
      "Training loss: 6.84e-02 lr: 3.58e-05:   7%| | 994/13852 [03:39<47:17,  4.53it/s]\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.59e-05:   7%| | 995/13852 [03:39<47:14,  4.54it/s]\u001b[A\n",
      "Training loss: 9.49e-02 lr: 3.59e-05:   7%| | 996/13852 [03:39<47:13,  4.54it/s]\u001b[A\n",
      "Training loss: 9.02e-02 lr: 3.60e-05:   7%| | 997/13852 [03:39<47:10,  4.54it/s]\u001b[A\n",
      "Training loss: 6.97e-02 lr: 3.60e-05:   7%| | 998/13852 [03:40<47:04,  4.55it/s]\u001b[A\n",
      "Training loss: 6.99e-02 lr: 3.60e-05:   7%| | 999/13852 [03:40<47:04,  4.55it/s]\u001b[A\n",
      "Training loss: 7.97e-02 lr: 3.61e-05:   7%| | 1000/13852 [03:40<47:05,  4.55it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.61e-05:   7%| | 1001/13852 [03:40<47:05,  4.55it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.61e-05:   7%| | 1002/13852 [03:40<46:59,  4.56it/s\u001b[A\n",
      "Training loss: 8.69e-02 lr: 3.62e-05:   7%| | 1003/13852 [03:41<46:53,  4.57it/s\u001b[A\n",
      "Training loss: 8.76e-02 lr: 3.62e-05:   7%| | 1004/13852 [03:41<47:08,  4.54it/s\u001b[A\n",
      "Training loss: 7.37e-02 lr: 3.62e-05:   7%| | 1005/13852 [03:41<47:03,  4.55it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 3.63e-05:   7%| | 1006/13852 [03:41<48:18,  4.43it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 3.63e-05:   7%| | 1007/13852 [03:42<47:55,  4.47it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 3.64e-05:   7%| | 1008/13852 [03:42<47:51,  4.47it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 3.64e-05:   7%| | 1009/13852 [03:42<48:43,  4.39it/s\u001b[A\n",
      "Training loss: 7.80e-02 lr: 3.64e-05:   7%| | 1010/13852 [03:42<48:11,  4.44it/s\u001b[A\n",
      "Training loss: 7.21e-02 lr: 3.65e-05:   7%| | 1011/13852 [03:42<47:49,  4.48it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 3.65e-05:   7%| | 1012/13852 [03:43<47:27,  4.51it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.65e-05:   7%| | 1013/13852 [03:43<47:12,  4.53it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 3.66e-05:   7%| | 1014/13852 [03:43<47:01,  4.55it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.66e-05:   7%| | 1015/13852 [03:43<47:05,  4.54it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.66e-05:   7%| | 1016/13852 [03:44<46:47,  4.57it/s\u001b[A\n",
      "Training loss: 1.61e-01 lr: 3.67e-05:   7%| | 1017/13852 [03:44<46:50,  4.57it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 3.67e-05:   7%| | 1018/13852 [03:44<46:52,  4.56it/s\u001b[A\n",
      "Training loss: 9.78e-02 lr: 3.67e-05:   7%| | 1019/13852 [03:44<46:50,  4.57it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.68e-05:   7%| | 1020/13852 [03:44<46:49,  4.57it/s\u001b[A\n",
      "Training loss: 9.18e-02 lr: 3.68e-05:   7%| | 1021/13852 [03:45<46:50,  4.56it/s\u001b[A\n",
      "Training loss: 9.43e-02 lr: 3.69e-05:   7%| | 1022/13852 [03:45<46:51,  4.56it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.69e-05:   7%| | 1023/13852 [03:45<46:48,  4.57it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.69e-05:   7%| | 1024/13852 [03:45<46:45,  4.57it/s\u001b[A\n",
      "Training loss: 9.15e-02 lr: 3.70e-05:   7%| | 1025/13852 [03:46<46:46,  4.57it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.70e-05:   7%| | 1026/13852 [03:46<46:59,  4.55it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.70e-05:   7%| | 1027/13852 [03:46<46:45,  4.57it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.71e-05:   7%| | 1028/13852 [03:46<46:39,  4.58it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.71e-05:   7%| | 1029/13852 [03:46<46:30,  4.59it/s\u001b[A\n",
      "Training loss: 9.99e-02 lr: 3.71e-05:   7%| | 1030/13852 [03:47<46:29,  4.60it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 3.72e-05:   7%| | 1031/13852 [03:47<47:04,  4.54it/s\u001b[A\n",
      "Training loss: 9.56e-02 lr: 3.72e-05:   7%| | 1032/13852 [03:47<46:53,  4.56it/s\u001b[A\n",
      "Training loss: 7.18e-02 lr: 3.73e-05:   7%| | 1033/13852 [03:47<46:52,  4.56it/s\u001b[A\n",
      "Training loss: 6.19e-02 lr: 3.73e-05:   7%| | 1034/13852 [03:48<46:52,  4.56it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 3.73e-05:   7%| | 1035/13852 [03:48<46:50,  4.56it/s\u001b[A\n",
      "Training loss: 9.63e-02 lr: 3.74e-05:   7%| | 1036/13852 [03:48<47:03,  4.54it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 3.74e-05:   7%| | 1037/13852 [03:48<47:11,  4.53it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 3.74e-05:   7%| | 1038/13852 [03:48<47:07,  4.53it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.75e-05:   8%| | 1039/13852 [03:49<47:06,  4.53it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.75e-05:   8%| | 1040/13852 [03:49<47:02,  4.54it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.75e-05:   8%| | 1041/13852 [03:49<46:55,  4.55it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 3.76e-05:   8%| | 1042/13852 [03:49<46:45,  4.57it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 3.76e-05:   8%| | 1043/13852 [03:49<46:34,  4.58it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.77e-05:   8%| | 1044/13852 [03:50<46:38,  4.58it/s\u001b[A\n",
      "Training loss: 9.79e-02 lr: 3.77e-05:   8%| | 1045/13852 [03:50<46:33,  4.58it/s\u001b[A\n",
      "Training loss: 7.42e-02 lr: 3.77e-05:   8%| | 1046/13852 [03:50<46:47,  4.56it/s\u001b[A\n",
      "Training loss: 9.59e-02 lr: 3.78e-05:   8%| | 1047/13852 [03:50<46:51,  4.55it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.78e-05:   8%| | 1048/13852 [03:51<46:54,  4.55it/s\u001b[A\n",
      "Training loss: 9.30e-02 lr: 3.78e-05:   8%| | 1049/13852 [03:51<47:05,  4.53it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 3.79e-05:   8%| | 1050/13852 [03:51<47:00,  4.54it/s\u001b[A\n",
      "Training loss: 7.72e-02 lr: 3.79e-05:   8%| | 1051/13852 [03:51<46:57,  4.54it/s\u001b[A\n",
      "Training loss: 8.59e-02 lr: 3.79e-05:   8%| | 1052/13852 [03:51<46:56,  4.54it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 3.80e-05:   8%| | 1053/13852 [03:52<47:08,  4.52it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 3.80e-05:   8%| | 1054/13852 [03:52<47:00,  4.54it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 3.80e-05:   8%| | 1055/13852 [03:52<46:47,  4.56it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 3.81e-05:   8%| | 1056/13852 [03:52<46:36,  4.58it/s\u001b[A\n",
      "Training loss: 3.01e-02 lr: 3.81e-05:   8%| | 1057/13852 [03:53<46:37,  4.57it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.13e-02 lr: 3.82e-05:   8%| | 1058/13852 [03:53<46:51,  4.55it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 3.82e-05:   8%| | 1059/13852 [03:53<46:43,  4.56it/s\u001b[A\n",
      "Training loss: 7.13e-02 lr: 3.82e-05:   8%| | 1060/13852 [03:53<46:43,  4.56it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 3.83e-05:   8%| | 1061/13852 [03:53<46:46,  4.56it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 3.83e-05:   8%| | 1062/13852 [03:54<46:48,  4.55it/s\u001b[A\n",
      "Training loss: 1.75e-01 lr: 3.83e-05:   8%| | 1063/13852 [03:54<46:46,  4.56it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.84e-05:   8%| | 1064/13852 [03:54<46:56,  4.54it/s\u001b[A\n",
      "Training loss: 1.70e-01 lr: 3.84e-05:   8%| | 1065/13852 [03:54<46:53,  4.55it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 3.84e-05:   8%| | 1066/13852 [03:55<46:53,  4.55it/s\u001b[A\n",
      "Training loss: 9.75e-02 lr: 3.85e-05:   8%| | 1067/13852 [03:55<46:58,  4.54it/s\u001b[A\n",
      "Training loss: 2.18e-01 lr: 3.85e-05:   8%| | 1068/13852 [03:55<46:55,  4.54it/s\u001b[A\n",
      "Training loss: 2.07e-01 lr: 3.86e-05:   8%| | 1069/13852 [03:55<46:46,  4.55it/s\u001b[A\n",
      "Training loss: 1.64e-01 lr: 3.86e-05:   8%| | 1070/13852 [03:55<46:33,  4.58it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 3.86e-05:   8%| | 1071/13852 [03:56<46:30,  4.58it/s\u001b[A\n",
      "Training loss: 1.57e-01 lr: 3.87e-05:   8%| | 1072/13852 [03:56<46:35,  4.57it/s\u001b[A\n",
      "Training loss: 1.71e-01 lr: 3.87e-05:   8%| | 1073/13852 [03:56<46:46,  4.55it/s\u001b[A\n",
      "Training loss: 1.74e-01 lr: 3.87e-05:   8%| | 1074/13852 [03:56<46:51,  4.54it/s\u001b[A\n",
      "Training loss: 1.80e-01 lr: 3.88e-05:   8%| | 1075/13852 [03:57<46:45,  4.55it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 3.88e-05:   8%| | 1076/13852 [03:57<47:03,  4.52it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 3.88e-05:   8%| | 1077/13852 [03:57<46:59,  4.53it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.89e-05:   8%| | 1078/13852 [03:57<47:00,  4.53it/s\u001b[A\n",
      "Training loss: 9.58e-02 lr: 3.89e-05:   8%| | 1079/13852 [03:57<47:22,  4.49it/s\u001b[A\n",
      "Training loss: 8.26e-02 lr: 3.90e-05:   8%| | 1080/13852 [03:58<47:11,  4.51it/s\u001b[A\n",
      "Training loss: 7.41e-02 lr: 3.90e-05:   8%| | 1081/13852 [03:58<47:03,  4.52it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.90e-05:   8%| | 1082/13852 [03:58<47:00,  4.53it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.91e-05:   8%| | 1083/13852 [03:58<46:55,  4.53it/s\u001b[A\n",
      "Training loss: 8.80e-02 lr: 3.91e-05:   8%| | 1084/13852 [03:59<46:52,  4.54it/s\u001b[A\n",
      "Training loss: 7.97e-02 lr: 3.91e-05:   8%| | 1085/13852 [03:59<46:54,  4.54it/s\u001b[A\n",
      "Training loss: 7.85e-02 lr: 3.92e-05:   8%| | 1086/13852 [03:59<46:56,  4.53it/s\u001b[A\n",
      "Training loss: 7.11e-02 lr: 3.92e-05:   8%| | 1087/13852 [03:59<47:00,  4.53it/s\u001b[A\n",
      "Training loss: 9.65e-02 lr: 3.92e-05:   8%| | 1088/13852 [03:59<46:55,  4.53it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 3.93e-05:   8%| | 1089/13852 [04:00<46:52,  4.54it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 3.93e-05:   8%| | 1090/13852 [04:00<47:02,  4.52it/s\u001b[A\n",
      "Training loss: 6.41e-02 lr: 3.93e-05:   8%| | 1091/13852 [04:00<46:56,  4.53it/s\u001b[A\n",
      "Training loss: 7.96e-02 lr: 3.94e-05:   8%| | 1092/13852 [04:00<46:53,  4.54it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 3.94e-05:   8%| | 1093/13852 [04:00<46:47,  4.55it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.95e-05:   8%| | 1094/13852 [04:01<46:45,  4.55it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 3.95e-05:   8%| | 1095/13852 [04:01<46:46,  4.55it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 3.95e-05:   8%| | 1096/13852 [04:01<46:37,  4.56it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 3.96e-05:   8%| | 1097/13852 [04:01<46:30,  4.57it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 3.96e-05:   8%| | 1098/13852 [04:02<46:35,  4.56it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.96e-05:   8%| | 1099/13852 [04:02<46:53,  4.53it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.97e-05:   8%| | 1100/13852 [04:02<47:16,  4.50it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.97e-05:   8%| | 1101/13852 [04:02<47:10,  4.50it/s\u001b[A\n",
      "Training loss: 7.97e-02 lr: 3.97e-05:   8%| | 1102/13852 [04:02<47:04,  4.51it/s\u001b[A\n",
      "Training loss: 9.10e-02 lr: 3.98e-05:   8%| | 1103/13852 [04:03<46:59,  4.52it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.98e-05:   8%| | 1104/13852 [04:03<46:51,  4.53it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 3.99e-05:   8%| | 1105/13852 [04:03<46:50,  4.54it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 3.99e-05:   8%| | 1106/13852 [04:03<46:49,  4.54it/s\u001b[A\n",
      "Training loss: 7.64e-02 lr: 3.99e-05:   8%| | 1107/13852 [04:04<46:46,  4.54it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 4.00e-05:   8%| | 1108/13852 [04:04<46:38,  4.55it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 4.00e-05:   8%| | 1109/13852 [04:04<46:31,  4.57it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 4.00e-05:   8%| | 1110/13852 [04:04<46:23,  4.58it/s\u001b[A\n",
      "Training loss: 8.58e-02 lr: 4.01e-05:   8%| | 1111/13852 [04:04<46:29,  4.57it/s\u001b[A\n",
      "Training loss: 7.93e-02 lr: 4.01e-05:   8%| | 1112/13852 [04:05<46:41,  4.55it/s\u001b[A\n",
      "Training loss: 9.49e-02 lr: 4.01e-05:   8%| | 1113/13852 [04:05<46:44,  4.54it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.02e-05:   8%| | 1114/13852 [04:05<46:45,  4.54it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.02e-05:   8%| | 1115/13852 [04:05<46:43,  4.54it/s\u001b[A\n",
      "Training loss: 8.39e-02 lr: 4.02e-05:   8%| | 1116/13852 [04:06<46:49,  4.53it/s\u001b[A\n",
      "Training loss: 7.11e-02 lr: 4.03e-05:   8%| | 1117/13852 [04:06<46:45,  4.54it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 4.03e-05:   8%| | 1118/13852 [04:06<46:44,  4.54it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 4.04e-05:   8%| | 1119/13852 [04:06<46:45,  4.54it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 4.04e-05:   8%| | 1120/13852 [04:06<46:45,  4.54it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 4.04e-05:   8%| | 1121/13852 [04:07<46:56,  4.52it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 4.05e-05:   8%| | 1122/13852 [04:07<46:59,  4.52it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 4.05e-05:   8%| | 1123/13852 [04:07<49:36,  4.28it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 4.05e-05:   8%| | 1124/13852 [04:07<50:35,  4.19it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 4.06e-05:   8%| | 1125/13852 [04:08<49:25,  4.29it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.06e-05:   8%| | 1126/13852 [04:08<48:38,  4.36it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 4.06e-05:   8%| | 1127/13852 [04:08<47:59,  4.42it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.07e-05:   8%| | 1128/13852 [04:08<47:34,  4.46it/s\u001b[A\n",
      "Training loss: 1.41e-01 lr: 4.07e-05:   8%| | 1129/13852 [04:08<47:06,  4.50it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.08e-05:   8%| | 1130/13852 [04:09<46:45,  4.53it/s\u001b[A\n",
      "Training loss: 9.30e-02 lr: 4.08e-05:   8%| | 1131/13852 [04:09<46:32,  4.56it/s\u001b[A\n",
      "Training loss: 7.73e-02 lr: 4.08e-05:   8%| | 1132/13852 [04:09<46:33,  4.55it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 4.09e-05:   8%| | 1133/13852 [04:09<46:21,  4.57it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 4.09e-05:   8%| | 1134/13852 [04:10<46:24,  4.57it/s\u001b[A\n",
      "Training loss: 8.82e-02 lr: 4.09e-05:   8%| | 1135/13852 [04:10<46:31,  4.56it/s\u001b[A\n",
      "Training loss: 8.71e-02 lr: 4.10e-05:   8%| | 1136/13852 [04:10<46:33,  4.55it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.10e-05:   8%| | 1137/13852 [04:10<46:31,  4.56it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 4.10e-05:   8%| | 1138/13852 [04:10<46:30,  4.56it/s\u001b[A\n",
      "Training loss: 7.60e-02 lr: 4.11e-05:   8%| | 1139/13852 [04:11<46:34,  4.55it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.11e-05:   8%| | 1140/13852 [04:11<46:54,  4.52it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 4.12e-05:   8%| | 1141/13852 [04:11<46:52,  4.52it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 4.12e-05:   8%| | 1142/13852 [04:11<46:51,  4.52it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 4.12e-05:   8%| | 1143/13852 [04:12<46:45,  4.53it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.13e-05:   8%| | 1144/13852 [04:12<46:55,  4.51it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.13e-05:   8%| | 1145/13852 [04:12<46:37,  4.54it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.13e-05:   8%| | 1146/13852 [04:12<46:39,  4.54it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.14e-05:   8%| | 1147/13852 [04:12<46:40,  4.54it/s\u001b[A\n",
      "Training loss: 1.59e-01 lr: 4.14e-05:   8%| | 1148/13852 [04:13<46:40,  4.54it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.14e-05:   8%| | 1149/13852 [04:13<46:39,  4.54it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.15e-05:   8%| | 1150/13852 [04:13<46:38,  4.54it/s\u001b[A\n",
      "Training loss: 9.22e-02 lr: 4.15e-05:   8%| | 1151/13852 [04:13<46:37,  4.54it/s\u001b[A\n",
      "Training loss: 8.99e-02 lr: 4.15e-05:   8%| | 1152/13852 [04:14<46:33,  4.55it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 4.16e-05:   8%| | 1153/13852 [04:14<46:32,  4.55it/s\u001b[A\n",
      "Training loss: 1.44e-01 lr: 4.16e-05:   8%| | 1154/13852 [04:14<46:29,  4.55it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.48e-01 lr: 4.17e-05:   8%| | 1155/13852 [04:14<46:48,  4.52it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 4.17e-05:   8%| | 1156/13852 [04:14<46:44,  4.53it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.17e-05:   8%| | 1157/13852 [04:15<46:29,  4.55it/s\u001b[A\n",
      "Training loss: 8.28e-02 lr: 4.18e-05:   8%| | 1158/13852 [04:15<46:20,  4.57it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 4.18e-05:   8%| | 1159/13852 [04:15<46:28,  4.55it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 4.18e-05:   8%| | 1160/13852 [04:15<46:28,  4.55it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.19e-05:   8%| | 1161/13852 [04:16<46:33,  4.54it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.19e-05:   8%| | 1162/13852 [04:16<46:38,  4.53it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.19e-05:   8%| | 1163/13852 [04:16<46:40,  4.53it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 4.20e-05:   8%| | 1164/13852 [04:16<46:37,  4.54it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 4.20e-05:   8%| | 1165/13852 [04:16<46:43,  4.53it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.21e-05:   8%| | 1166/13852 [04:17<46:48,  4.52it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.21e-05:   8%| | 1167/13852 [04:17<46:58,  4.50it/s\u001b[A\n",
      "Training loss: 1.70e-01 lr: 4.21e-05:   8%| | 1168/13852 [04:17<46:50,  4.51it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 4.22e-05:   8%| | 1169/13852 [04:17<46:45,  4.52it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 4.22e-05:   8%| | 1170/13852 [04:18<46:30,  4.54it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.22e-05:   8%| | 1171/13852 [04:18<46:20,  4.56it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 4.23e-05:   8%| | 1172/13852 [04:18<46:23,  4.56it/s\u001b[A\n",
      "Training loss: 8.63e-02 lr: 4.23e-05:   8%| | 1173/13852 [04:18<46:25,  4.55it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 4.23e-05:   8%| | 1174/13852 [04:18<46:27,  4.55it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 4.24e-05:   8%| | 1175/13852 [04:19<46:32,  4.54it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 4.24e-05:   8%| | 1176/13852 [04:19<46:29,  4.54it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 4.25e-05:   8%| | 1177/13852 [04:19<46:34,  4.53it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 4.25e-05:   9%| | 1178/13852 [04:19<46:34,  4.54it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.25e-05:   9%| | 1179/13852 [04:20<46:31,  4.54it/s\u001b[A\n",
      "Training loss: 7.44e-02 lr: 4.26e-05:   9%| | 1180/13852 [04:20<46:35,  4.53it/s\u001b[A\n",
      "Training loss: 8.38e-02 lr: 4.26e-05:   9%| | 1181/13852 [04:20<46:36,  4.53it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.26e-05:   9%| | 1182/13852 [04:20<46:34,  4.53it/s\u001b[A\n",
      "Training loss: 8.78e-02 lr: 4.27e-05:   9%| | 1183/13852 [04:20<46:25,  4.55it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 4.27e-05:   9%| | 1184/13852 [04:21<46:15,  4.56it/s\u001b[A\n",
      "Training loss: 9.07e-02 lr: 4.27e-05:   9%| | 1185/13852 [04:21<46:22,  4.55it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.28e-05:   9%| | 1186/13852 [04:21<46:27,  4.54it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.28e-05:   9%| | 1187/13852 [04:21<46:40,  4.52it/s\u001b[A\n",
      "Training loss: 7.79e-02 lr: 4.28e-05:   9%| | 1188/13852 [04:21<46:39,  4.52it/s\u001b[A\n",
      "Training loss: 9.30e-02 lr: 4.29e-05:   9%| | 1189/13852 [04:22<46:59,  4.49it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 4.29e-05:   9%| | 1190/13852 [04:22<46:59,  4.49it/s\u001b[A\n",
      "Training loss: 8.72e-02 lr: 4.30e-05:   9%| | 1191/13852 [04:22<47:11,  4.47it/s\u001b[A\n",
      "Training loss: 8.92e-02 lr: 4.30e-05:   9%| | 1192/13852 [04:22<47:00,  4.49it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.30e-05:   9%| | 1193/13852 [04:23<46:50,  4.50it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.31e-05:   9%| | 1194/13852 [04:23<46:47,  4.51it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.31e-05:   9%| | 1195/13852 [04:23<46:43,  4.51it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 4.31e-05:   9%| | 1196/13852 [04:23<46:33,  4.53it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.32e-05:   9%| | 1197/13852 [04:23<46:21,  4.55it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 4.32e-05:   9%| | 1198/13852 [04:24<46:13,  4.56it/s\u001b[A\n",
      "Training loss: 8.13e-02 lr: 4.32e-05:   9%| | 1199/13852 [04:24<46:16,  4.56it/s\u001b[A\n",
      "Training loss: 9.64e-02 lr: 4.33e-05:   9%| | 1200/13852 [04:24<46:24,  4.54it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 4.33e-05:   9%| | 1201/13852 [04:24<46:35,  4.53it/s\u001b[A\n",
      "Training loss: 1.37e-01 lr: 4.34e-05:   9%| | 1202/13852 [04:25<46:32,  4.53it/s\u001b[A\n",
      "Training loss: 9.94e-02 lr: 4.34e-05:   9%| | 1203/13852 [04:25<46:29,  4.53it/s\u001b[A\n",
      "Training loss: 8.06e-02 lr: 4.34e-05:   9%| | 1204/13852 [04:25<46:25,  4.54it/s\u001b[A\n",
      "Training loss: 7.18e-02 lr: 4.35e-05:   9%| | 1205/13852 [04:25<46:20,  4.55it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 4.35e-05:   9%| | 1206/13852 [04:25<46:22,  4.54it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 4.35e-05:   9%| | 1207/13852 [04:26<46:22,  4.54it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 4.36e-05:   9%| | 1208/13852 [04:26<46:24,  4.54it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 4.36e-05:   9%| | 1209/13852 [04:26<46:17,  4.55it/s\u001b[A\n",
      "Training loss: 4.90e-02 lr: 4.36e-05:   9%| | 1210/13852 [04:26<46:09,  4.56it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 4.37e-05:   9%| | 1211/13852 [04:27<46:13,  4.56it/s\u001b[A\n",
      "Training loss: 3.18e-02 lr: 4.37e-05:   9%| | 1212/13852 [04:27<46:46,  4.50it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 4.38e-05:   9%| | 1213/13852 [04:27<46:43,  4.51it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 4.38e-05:   9%| | 1214/13852 [04:27<46:42,  4.51it/s\u001b[A\n",
      "Training loss: 4.07e-02 lr: 4.38e-05:   9%| | 1215/13852 [04:27<46:39,  4.51it/s\u001b[A\n",
      "Training loss: 2.96e-02 lr: 4.39e-05:   9%| | 1216/13852 [04:28<46:35,  4.52it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 4.39e-05:   9%| | 1217/13852 [04:28<46:48,  4.50it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 4.39e-05:   9%| | 1218/13852 [04:28<46:42,  4.51it/s\u001b[A\n",
      "Training loss: 3.52e-02 lr: 4.40e-05:   9%| | 1219/13852 [04:28<46:36,  4.52it/s\u001b[A\n",
      "Training loss: 2.80e-02 lr: 4.40e-05:   9%| | 1220/13852 [04:29<46:38,  4.51it/s\u001b[A\n",
      "Training loss: 9.62e-02 lr: 4.40e-05:   9%| | 1221/13852 [04:29<46:35,  4.52it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 4.41e-05:   9%| | 1222/13852 [04:29<46:24,  4.54it/s\u001b[A\n",
      "Training loss: 1.70e-01 lr: 4.41e-05:   9%| | 1223/13852 [04:29<46:14,  4.55it/s\u001b[A\n",
      "Training loss: 1.52e-01 lr: 4.41e-05:   9%| | 1224/13852 [04:29<46:13,  4.55it/s\u001b[A\n",
      "Training loss: 1.68e-01 lr: 4.42e-05:   9%| | 1225/13852 [04:30<46:15,  4.55it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 4.42e-05:   9%| | 1226/13852 [04:30<46:18,  4.54it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.43e-05:   9%| | 1227/13852 [04:30<46:33,  4.52it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 4.43e-05:   9%| | 1228/13852 [04:30<46:39,  4.51it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 4.43e-05:   9%| | 1229/13852 [04:31<46:43,  4.50it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 4.44e-05:   9%| | 1230/13852 [04:31<46:45,  4.50it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 4.44e-05:   9%| | 1231/13852 [04:31<46:42,  4.50it/s\u001b[A\n",
      "Training loss: 7.11e-02 lr: 4.44e-05:   9%| | 1232/13852 [04:31<46:38,  4.51it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 4.45e-05:   9%| | 1233/13852 [04:31<46:41,  4.50it/s\u001b[A\n",
      "Training loss: 1.96e-01 lr: 4.45e-05:   9%| | 1234/13852 [04:32<46:36,  4.51it/s\u001b[A\n",
      "Training loss: 1.84e-01 lr: 4.45e-05:   9%| | 1235/13852 [04:32<46:27,  4.53it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 4.46e-05:   9%| | 1236/13852 [04:32<46:36,  4.51it/s\u001b[A\n",
      "Training loss: 1.55e-01 lr: 4.46e-05:   9%| | 1237/13852 [04:32<46:45,  4.50it/s\u001b[A\n",
      "Training loss: 1.57e-01 lr: 4.47e-05:   9%| | 1238/13852 [04:33<46:40,  4.50it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 4.47e-05:   9%| | 1239/13852 [04:33<46:31,  4.52it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.47e-05:   9%| | 1240/13852 [04:33<46:37,  4.51it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 4.48e-05:   9%| | 1241/13852 [04:33<46:29,  4.52it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.48e-05:   9%| | 1242/13852 [04:33<46:25,  4.53it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.48e-05:   9%| | 1243/13852 [04:34<46:24,  4.53it/s\u001b[A\n",
      "Training loss: 9.69e-02 lr: 4.49e-05:   9%| | 1244/13852 [04:34<46:22,  4.53it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.49e-05:   9%| | 1245/13852 [04:34<46:23,  4.53it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 4.49e-05:   9%| | 1246/13852 [04:34<46:20,  4.53it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.50e-05:   9%| | 1247/13852 [04:35<46:10,  4.55it/s\u001b[A\n",
      "Training loss: 1.71e-01 lr: 4.50e-05:   9%| | 1248/13852 [04:35<45:59,  4.57it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 4.51e-05:   9%| | 1249/13852 [04:35<45:50,  4.58it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 4.51e-05:   9%| | 1250/13852 [04:35<45:53,  4.58it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.51e-05:   9%| | 1251/13852 [04:35<46:02,  4.56it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.74e-02 lr: 4.52e-05:   9%| | 1252/13852 [04:36<46:10,  4.55it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.52e-05:   9%| | 1253/13852 [04:36<46:13,  4.54it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 4.52e-05:   9%| | 1254/13852 [04:36<46:14,  4.54it/s\u001b[A\n",
      "Training loss: 9.11e-02 lr: 4.53e-05:   9%| | 1255/13852 [04:36<46:18,  4.53it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.53e-05:   9%| | 1256/13852 [04:37<46:18,  4.53it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.53e-05:   9%| | 1257/13852 [04:37<46:45,  4.49it/s\u001b[A\n",
      "Training loss: 8.45e-02 lr: 4.54e-05:   9%| | 1258/13852 [04:37<46:57,  4.47it/s\u001b[A\n",
      "Training loss: 7.07e-02 lr: 4.54e-05:   9%| | 1259/13852 [04:37<46:46,  4.49it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 4.54e-05:   9%| | 1260/13852 [04:37<47:01,  4.46it/s\u001b[A\n",
      "Training loss: 6.78e-02 lr: 4.55e-05:   9%| | 1261/13852 [04:38<48:07,  4.36it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 4.55e-05:   9%| | 1262/13852 [04:38<48:58,  4.28it/s\u001b[A\n",
      "Training loss: 6.59e-02 lr: 4.56e-05:   9%| | 1263/13852 [04:38<49:29,  4.24it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 4.56e-05:   9%| | 1264/13852 [04:38<48:43,  4.31it/s\u001b[A\n",
      "Training loss: 4.70e-02 lr: 4.56e-05:   9%| | 1265/13852 [04:39<47:56,  4.38it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 4.57e-05:   9%| | 1266/13852 [04:39<47:24,  4.43it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 4.57e-05:   9%| | 1267/13852 [04:39<46:57,  4.47it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 4.57e-05:   9%| | 1268/13852 [04:39<46:36,  4.50it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 4.58e-05:   9%| | 1269/13852 [04:39<46:19,  4.53it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 4.58e-05:   9%| | 1270/13852 [04:40<46:09,  4.54it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 4.58e-05:   9%| | 1271/13852 [04:40<46:08,  4.54it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 4.59e-05:   9%| | 1272/13852 [04:40<46:08,  4.54it/s\u001b[A\n",
      "Training loss: 6.20e-02 lr: 4.59e-05:   9%| | 1273/13852 [04:40<46:06,  4.55it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 4.60e-05:   9%| | 1274/13852 [04:41<46:02,  4.55it/s\u001b[A\n",
      "Training loss: 9.07e-02 lr: 4.60e-05:   9%| | 1275/13852 [04:41<46:08,  4.54it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 4.60e-05:   9%| | 1276/13852 [04:41<46:08,  4.54it/s\u001b[A\n",
      "Training loss: 9.71e-02 lr: 4.61e-05:   9%| | 1277/13852 [04:41<46:05,  4.55it/s\u001b[A\n",
      "Training loss: 1.62e-01 lr: 4.61e-05:   9%| | 1278/13852 [04:41<46:10,  4.54it/s\u001b[A\n",
      "Training loss: 1.51e-01 lr: 4.61e-05:   9%| | 1279/13852 [04:42<46:19,  4.52it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.62e-05:   9%| | 1280/13852 [04:42<46:19,  4.52it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.62e-05:   9%| | 1281/13852 [04:42<46:09,  4.54it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 4.62e-05:   9%| | 1282/13852 [04:42<46:33,  4.50it/s\u001b[A\n",
      "Training loss: 1.55e-01 lr: 4.63e-05:   9%| | 1283/13852 [04:43<46:37,  4.49it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.63e-05:   9%| | 1284/13852 [04:43<46:35,  4.50it/s\u001b[A\n",
      "Training loss: 1.72e-01 lr: 4.64e-05:   9%| | 1285/13852 [04:43<46:22,  4.52it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 4.64e-05:   9%| | 1286/13852 [04:43<46:16,  4.53it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.64e-05:   9%| | 1287/13852 [04:43<46:06,  4.54it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 4.65e-05:   9%| | 1288/13852 [04:44<46:04,  4.55it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 4.65e-05:   9%| | 1289/13852 [04:44<46:04,  4.54it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.65e-05:   9%| | 1290/13852 [04:44<46:02,  4.55it/s\u001b[A\n",
      "Training loss: 9.08e-02 lr: 4.66e-05:   9%| | 1291/13852 [04:44<45:59,  4.55it/s\u001b[A\n",
      "Training loss: 7.94e-02 lr: 4.66e-05:   9%| | 1292/13852 [04:45<45:54,  4.56it/s\u001b[A\n",
      "Training loss: 6.02e-02 lr: 4.66e-05:   9%| | 1293/13852 [04:45<45:49,  4.57it/s\u001b[A\n",
      "Training loss: 6.10e-02 lr: 4.67e-05:   9%| | 1294/13852 [04:45<45:47,  4.57it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 4.67e-05:   9%| | 1295/13852 [04:45<45:41,  4.58it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 4.67e-05:   9%| | 1296/13852 [04:45<45:37,  4.59it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 4.68e-05:   9%| | 1297/13852 [04:46<45:40,  4.58it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 4.68e-05:   9%| | 1298/13852 [04:46<45:48,  4.57it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 4.69e-05:   9%| | 1299/13852 [04:46<45:51,  4.56it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 4.69e-05:   9%| | 1300/13852 [04:46<45:56,  4.55it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.69e-05:   9%| | 1301/13852 [04:46<45:57,  4.55it/s\u001b[A\n",
      "Training loss: 8.63e-02 lr: 4.70e-05:   9%| | 1302/13852 [04:47<46:06,  4.54it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 4.70e-05:   9%| | 1303/13852 [04:47<46:07,  4.53it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 4.70e-05:   9%| | 1304/13852 [04:47<46:01,  4.54it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 4.71e-05:   9%| | 1305/13852 [04:47<45:59,  4.55it/s\u001b[A\n",
      "Training loss: 8.92e-02 lr: 4.71e-05:   9%| | 1306/13852 [04:48<46:01,  4.54it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 4.71e-05:   9%| | 1307/13852 [04:48<46:01,  4.54it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 4.72e-05:   9%| | 1308/13852 [04:48<46:12,  4.52it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 4.72e-05:   9%| | 1309/13852 [04:48<45:57,  4.55it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 4.73e-05:   9%| | 1310/13852 [04:48<45:47,  4.57it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 4.73e-05:   9%| | 1311/13852 [04:49<45:39,  4.58it/s\u001b[A\n",
      "Training loss: 1.64e-01 lr: 4.73e-05:   9%| | 1312/13852 [04:49<45:43,  4.57it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 4.74e-05:   9%| | 1313/13852 [04:49<45:51,  4.56it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 4.74e-05:   9%| | 1314/13852 [04:49<45:53,  4.55it/s\u001b[A\n",
      "Training loss: 9.87e-02 lr: 4.74e-05:   9%| | 1315/13852 [04:50<45:52,  4.56it/s\u001b[A\n",
      "Training loss: 1.48e-01 lr: 4.75e-05:  10%| | 1316/13852 [04:50<45:53,  4.55it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 4.75e-05:  10%| | 1317/13852 [04:50<45:51,  4.56it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.75e-05:  10%| | 1318/13852 [04:50<45:50,  4.56it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 4.76e-05:  10%| | 1319/13852 [04:50<45:49,  4.56it/s\u001b[A\n",
      "Training loss: 8.99e-02 lr: 4.76e-05:  10%| | 1320/13852 [04:51<45:52,  4.55it/s\u001b[A\n",
      "Training loss: 7.78e-02 lr: 4.76e-05:  10%| | 1321/13852 [04:51<46:06,  4.53it/s\u001b[A\n",
      "Training loss: 7.84e-02 lr: 4.77e-05:  10%| | 1322/13852 [04:51<45:56,  4.55it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 4.77e-05:  10%| | 1323/13852 [04:51<45:43,  4.57it/s\u001b[A\n",
      "Training loss: 8.51e-02 lr: 4.78e-05:  10%| | 1324/13852 [04:52<45:34,  4.58it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 4.78e-05:  10%| | 1325/13852 [04:52<46:10,  4.52it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 4.78e-05:  10%| | 1326/13852 [04:52<46:08,  4.52it/s\u001b[A\n",
      "Training loss: 3.68e-02 lr: 4.79e-05:  10%| | 1327/13852 [04:52<46:01,  4.53it/s\u001b[A\n",
      "Training loss: 2.86e-02 lr: 4.79e-05:  10%| | 1328/13852 [04:52<46:13,  4.52it/s\u001b[A\n",
      "Training loss: 3.69e-02 lr: 4.79e-05:  10%| | 1329/13852 [04:53<46:08,  4.52it/s\u001b[A\n",
      "Training loss: 3.23e-02 lr: 4.80e-05:  10%| | 1330/13852 [04:53<45:59,  4.54it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 4.80e-05:  10%| | 1331/13852 [04:53<45:58,  4.54it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.80e-05:  10%| | 1332/13852 [04:53<46:00,  4.53it/s\u001b[A\n",
      "Training loss: 8.94e-02 lr: 4.81e-05:  10%| | 1333/13852 [04:54<45:55,  4.54it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.81e-05:  10%| | 1334/13852 [04:54<45:55,  4.54it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.82e-05:  10%| | 1335/13852 [04:54<45:45,  4.56it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 4.82e-05:  10%| | 1336/13852 [04:54<45:34,  4.58it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 4.82e-05:  10%| | 1337/13852 [04:54<45:32,  4.58it/s\u001b[A\n",
      "Training loss: 1.75e-01 lr: 4.83e-05:  10%| | 1338/13852 [04:55<45:50,  4.55it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.83e-05:  10%| | 1339/13852 [04:55<45:52,  4.55it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 4.83e-05:  10%| | 1340/13852 [04:55<45:54,  4.54it/s\u001b[A\n",
      "Training loss: 8.26e-02 lr: 4.84e-05:  10%| | 1341/13852 [04:55<45:58,  4.54it/s\u001b[A\n",
      "Training loss: 8.21e-02 lr: 4.84e-05:  10%| | 1342/13852 [04:56<45:53,  4.54it/s\u001b[A\n",
      "Training loss: 9.00e-02 lr: 4.84e-05:  10%| | 1343/13852 [04:56<45:58,  4.53it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 4.85e-05:  10%| | 1344/13852 [04:56<45:54,  4.54it/s\u001b[A\n",
      "Training loss: 8.20e-02 lr: 4.85e-05:  10%| | 1345/13852 [04:56<45:54,  4.54it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 4.86e-05:  10%| | 1346/13852 [04:56<46:00,  4.53it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 4.86e-05:  10%| | 1347/13852 [04:57<45:59,  4.53it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 4.86e-05:  10%| | 1348/13852 [04:57<46:23,  4.49it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.67e-02 lr: 4.87e-05:  10%| | 1349/13852 [04:57<46:08,  4.52it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 4.87e-05:  10%| | 1350/13852 [04:57<45:55,  4.54it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 4.87e-05:  10%| | 1351/13852 [04:57<45:59,  4.53it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 4.88e-05:  10%| | 1352/13852 [04:58<45:58,  4.53it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 4.88e-05:  10%| | 1353/13852 [04:58<47:17,  4.40it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 4.88e-05:  10%| | 1354/13852 [04:58<47:07,  4.42it/s\u001b[A\n",
      "Training loss: 9.56e-02 lr: 4.89e-05:  10%| | 1355/13852 [04:58<46:47,  4.45it/s\u001b[A\n",
      "Training loss: 6.93e-02 lr: 4.89e-05:  10%| | 1356/13852 [04:59<46:45,  4.45it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 4.89e-05:  10%| | 1357/13852 [04:59<46:33,  4.47it/s\u001b[A\n",
      "Training loss: 6.57e-02 lr: 4.90e-05:  10%| | 1358/13852 [04:59<46:22,  4.49it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 4.90e-05:  10%| | 1359/13852 [04:59<46:16,  4.50it/s\u001b[A\n",
      "Training loss: 4.21e-02 lr: 4.91e-05:  10%| | 1360/13852 [05:00<46:03,  4.52it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 4.91e-05:  10%| | 1361/13852 [05:00<45:49,  4.54it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 4.91e-05:  10%| | 1362/13852 [05:00<45:38,  4.56it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 4.92e-05:  10%| | 1363/13852 [05:00<45:39,  4.56it/s\u001b[A\n",
      "Training loss: 8.58e-02 lr: 4.92e-05:  10%| | 1364/13852 [05:00<45:45,  4.55it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 4.92e-05:  10%| | 1365/13852 [05:01<45:47,  4.54it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 4.93e-05:  10%| | 1366/13852 [05:01<45:59,  4.52it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 4.93e-05:  10%| | 1367/13852 [05:01<46:07,  4.51it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 4.93e-05:  10%| | 1368/13852 [05:01<46:11,  4.50it/s\u001b[A\n",
      "Training loss: 4.01e-02 lr: 4.94e-05:  10%| | 1369/13852 [05:01<46:11,  4.50it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 4.94e-05:  10%| | 1370/13852 [05:02<46:19,  4.49it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 4.95e-05:  10%| | 1371/13852 [05:02<46:16,  4.50it/s\u001b[A\n",
      "Training loss: 3.13e-02 lr: 4.95e-05:  10%| | 1372/13852 [05:02<46:03,  4.52it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 4.95e-05:  10%| | 1373/13852 [05:02<45:45,  4.55it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 4.96e-05:  10%| | 1374/13852 [05:03<45:34,  4.56it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 4.96e-05:  10%| | 1375/13852 [05:03<46:01,  4.52it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 4.96e-05:  10%| | 1376/13852 [05:03<46:19,  4.49it/s\u001b[A\n",
      "Training loss: 8.37e-02 lr: 4.97e-05:  10%| | 1377/13852 [05:03<46:13,  4.50it/s\u001b[A\n",
      "Training loss: 8.45e-02 lr: 4.97e-05:  10%| | 1378/13852 [05:03<46:07,  4.51it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 4.97e-05:  10%| | 1379/13852 [05:04<46:03,  4.51it/s\u001b[A\n",
      "Training loss: 8.95e-02 lr: 4.98e-05:  10%| | 1380/13852 [05:04<45:56,  4.52it/s\u001b[A\n",
      "Training loss: 1.63e-01 lr: 4.98e-05:  10%| | 1381/13852 [05:04<45:56,  4.52it/s\u001b[A\n",
      "Training loss: 1.49e-01 lr: 4.99e-05:  10%| | 1382/13852 [05:04<45:55,  4.53it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 4.99e-05:  10%| | 1383/13852 [05:05<45:50,  4.53it/s\u001b[A\n",
      "Training loss: 1.64e-01 lr: 4.99e-05:  10%| | 1384/13852 [05:05<45:50,  4.53it/s\u001b[A\n",
      "Training loss: 1.41e-01 lr: 5.00e-05:  10%| | 1385/13852 [05:05<45:38,  4.55it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 5.00e-05:  10%| | 1386/13852 [05:05<45:28,  4.57it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.50e-05:  10%| | 1387/13852 [05:05<45:22,  4.58it/s\u001b[A\n",
      "Training loss: 8.40e-02 lr: 4.50e-05:  10%| | 1388/13852 [05:06<45:22,  4.58it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 4.50e-05:  10%| | 1389/13852 [05:06<45:27,  4.57it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 4.50e-05:  10%| | 1390/13852 [05:06<45:32,  4.56it/s\u001b[A\n",
      "Training loss: 9.26e-02 lr: 4.50e-05:  10%| | 1391/13852 [05:06<45:35,  4.56it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.50e-05:  10%| | 1392/13852 [05:07<45:33,  4.56it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.50e-05:  10%| | 1393/13852 [05:07<46:15,  4.49it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.50e-05:  10%| | 1394/13852 [05:07<46:17,  4.48it/s\u001b[A\n",
      "Training loss: 1.68e-01 lr: 4.50e-05:  10%| | 1395/13852 [05:07<46:16,  4.49it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 4.50e-05:  10%| | 1396/13852 [05:07<46:25,  4.47it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.50e-05:  10%| | 1397/13852 [05:08<46:15,  4.49it/s\u001b[A\n",
      "Training loss: 9.66e-02 lr: 4.50e-05:  10%| | 1398/13852 [05:08<46:02,  4.51it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 4.50e-05:  10%| | 1399/13852 [05:08<45:43,  4.54it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.49e-05:  10%| | 1400/13852 [05:08<45:28,  4.56it/s\u001b[A\n",
      "Training loss: 9.22e-02 lr: 4.49e-05:  10%| | 1401/13852 [05:09<45:40,  4.54it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 4.49e-05:  10%| | 1402/13852 [05:09<45:41,  4.54it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 4.49e-05:  10%| | 1403/13852 [05:09<45:40,  4.54it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.49e-05:  10%| | 1404/13852 [05:09<45:36,  4.55it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 4.49e-05:  10%| | 1405/13852 [05:09<45:52,  4.52it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 4.49e-05:  10%| | 1406/13852 [05:10<45:51,  4.52it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.49e-05:  10%| | 1407/13852 [05:10<45:48,  4.53it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 4.49e-05:  10%| | 1408/13852 [05:10<45:50,  4.53it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.49e-05:  10%| | 1409/13852 [05:10<45:52,  4.52it/s\u001b[A\n",
      "Training loss: 8.28e-02 lr: 4.49e-05:  10%| | 1410/13852 [05:11<45:50,  4.52it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 4.49e-05:  10%| | 1411/13852 [05:11<45:39,  4.54it/s\u001b[A\n",
      "Training loss: 1.71e-01 lr: 4.49e-05:  10%| | 1412/13852 [05:11<45:35,  4.55it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 4.49e-05:  10%| | 1413/13852 [05:11<46:00,  4.51it/s\u001b[A\n",
      "Training loss: 9.64e-02 lr: 4.49e-05:  10%| | 1414/13852 [05:11<45:55,  4.51it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.49e-05:  10%| | 1415/13852 [05:12<46:03,  4.50it/s\u001b[A\n",
      "Training loss: 9.24e-02 lr: 4.49e-05:  10%| | 1416/13852 [05:12<45:56,  4.51it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 4.49e-05:  10%| | 1417/13852 [05:12<45:51,  4.52it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.49e-05:  10%| | 1418/13852 [05:12<45:49,  4.52it/s\u001b[A\n",
      "Training loss: 8.23e-02 lr: 4.49e-05:  10%| | 1419/13852 [05:13<45:58,  4.51it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 4.49e-05:  10%| | 1420/13852 [05:13<45:52,  4.52it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 4.49e-05:  10%| | 1421/13852 [05:13<45:50,  4.52it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 4.49e-05:  10%| | 1422/13852 [05:13<45:49,  4.52it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.49e-05:  10%| | 1423/13852 [05:13<45:45,  4.53it/s\u001b[A\n",
      "Training loss: 8.31e-02 lr: 4.49e-05:  10%| | 1424/13852 [05:14<45:35,  4.54it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 4.49e-05:  10%| | 1425/13852 [05:14<45:24,  4.56it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 4.49e-05:  10%| | 1426/13852 [05:14<45:39,  4.54it/s\u001b[A\n",
      "Training loss: 8.64e-02 lr: 4.49e-05:  10%| | 1427/13852 [05:14<45:39,  4.54it/s\u001b[A\n",
      "Training loss: 9.81e-02 lr: 4.48e-05:  10%| | 1428/13852 [05:15<45:39,  4.53it/s\u001b[A\n",
      "Training loss: 9.30e-02 lr: 4.48e-05:  10%| | 1429/13852 [05:15<45:35,  4.54it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.48e-05:  10%| | 1430/13852 [05:15<45:36,  4.54it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.48e-05:  10%| | 1431/13852 [05:15<45:38,  4.54it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 4.48e-05:  10%| | 1432/13852 [05:15<45:46,  4.52it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 4.48e-05:  10%| | 1433/13852 [05:16<45:45,  4.52it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 4.48e-05:  10%| | 1434/13852 [05:16<45:48,  4.52it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.48e-05:  10%| | 1435/13852 [05:16<45:49,  4.52it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.48e-05:  10%| | 1436/13852 [05:16<45:36,  4.54it/s\u001b[A\n",
      "Training loss: 9.23e-02 lr: 4.48e-05:  10%| | 1437/13852 [05:17<45:27,  4.55it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 4.48e-05:  10%| | 1438/13852 [05:17<45:36,  4.54it/s\u001b[A\n",
      "Training loss: 9.93e-02 lr: 4.48e-05:  10%| | 1439/13852 [05:17<45:49,  4.51it/s\u001b[A\n",
      "Training loss: 9.70e-02 lr: 4.48e-05:  10%| | 1440/13852 [05:17<45:44,  4.52it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.48e-05:  10%| | 1441/13852 [05:17<45:42,  4.53it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.48e-05:  10%| | 1442/13852 [05:18<45:37,  4.53it/s\u001b[A\n",
      "Training loss: 1.51e-01 lr: 4.48e-05:  10%| | 1443/13852 [05:18<45:40,  4.53it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.48e-05:  10%| | 1444/13852 [05:18<45:47,  4.52it/s\u001b[A\n",
      "Training loss: 8.74e-02 lr: 4.48e-05:  10%| | 1445/13852 [05:18<45:45,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.06e-02 lr: 4.48e-05:  10%| | 1446/13852 [05:19<45:42,  4.52it/s\u001b[A\n",
      "Training loss: 8.37e-02 lr: 4.48e-05:  10%| | 1447/13852 [05:19<45:39,  4.53it/s\u001b[A\n",
      "Training loss: 6.22e-02 lr: 4.48e-05:  10%| | 1448/13852 [05:19<45:28,  4.55it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 4.48e-05:  10%| | 1449/13852 [05:19<45:21,  4.56it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 4.48e-05:  10%| | 1450/13852 [05:19<45:18,  4.56it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 4.48e-05:  10%| | 1451/13852 [05:20<45:11,  4.57it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 4.48e-05:  10%| | 1452/13852 [05:20<45:26,  4.55it/s\u001b[A\n",
      "Training loss: 6.52e-02 lr: 4.48e-05:  10%| | 1453/13852 [05:20<45:28,  4.54it/s\u001b[A\n",
      "Training loss: 6.20e-02 lr: 4.48e-05:  10%| | 1454/13852 [05:20<45:29,  4.54it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 4.48e-05:  11%| | 1455/13852 [05:20<45:28,  4.54it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 4.47e-05:  11%| | 1456/13852 [05:21<45:30,  4.54it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 4.47e-05:  11%| | 1457/13852 [05:21<45:48,  4.51it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 4.47e-05:  11%| | 1458/13852 [05:21<45:44,  4.52it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 4.47e-05:  11%| | 1459/13852 [05:21<45:41,  4.52it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 4.47e-05:  11%| | 1460/13852 [05:22<48:38,  4.25it/s\u001b[A\n",
      "Training loss: 6.52e-02 lr: 4.47e-05:  11%| | 1461/13852 [05:22<50:17,  4.11it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 4.47e-05:  11%| | 1462/13852 [05:22<50:06,  4.12it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 4.47e-05:  11%| | 1463/13852 [05:22<49:58,  4.13it/s\u001b[A\n",
      "Training loss: 4.90e-02 lr: 4.47e-05:  11%| | 1464/13852 [05:23<50:06,  4.12it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 4.47e-05:  11%| | 1465/13852 [05:23<49:48,  4.14it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 4.47e-05:  11%| | 1466/13852 [05:23<49:44,  4.15it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.47e-05:  11%| | 1467/13852 [05:23<49:40,  4.15it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 4.47e-05:  11%| | 1468/13852 [05:24<49:35,  4.16it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 4.47e-05:  11%| | 1469/13852 [05:24<49:36,  4.16it/s\u001b[A\n",
      "Training loss: 8.50e-02 lr: 4.47e-05:  11%| | 1470/13852 [05:24<49:35,  4.16it/s\u001b[A\n",
      "Training loss: 9.30e-02 lr: 4.47e-05:  11%| | 1471/13852 [05:24<49:24,  4.18it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 4.47e-05:  11%| | 1472/13852 [05:25<49:14,  4.19it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.47e-05:  11%| | 1473/13852 [05:25<49:22,  4.18it/s\u001b[A\n",
      "Training loss: 7.60e-02 lr: 4.47e-05:  11%| | 1474/13852 [05:25<49:19,  4.18it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.47e-05:  11%| | 1475/13852 [05:25<49:19,  4.18it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 4.47e-05:  11%| | 1476/13852 [05:25<49:22,  4.18it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.47e-05:  11%| | 1477/13852 [05:26<49:21,  4.18it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 4.47e-05:  11%| | 1478/13852 [05:26<49:14,  4.19it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.47e-05:  11%| | 1479/13852 [05:26<49:17,  4.18it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 4.47e-05:  11%| | 1480/13852 [05:26<49:21,  4.18it/s\u001b[A\n",
      "Training loss: 8.43e-02 lr: 4.47e-05:  11%| | 1481/13852 [05:27<49:25,  4.17it/s\u001b[A\n",
      "Training loss: 7.00e-02 lr: 4.47e-05:  11%| | 1482/13852 [05:27<49:35,  4.16it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 4.47e-05:  11%| | 1483/13852 [05:27<49:21,  4.18it/s\u001b[A\n",
      "Training loss: 8.38e-02 lr: 4.46e-05:  11%| | 1484/13852 [05:27<49:34,  4.16it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 4.46e-05:  11%| | 1485/13852 [05:28<49:31,  4.16it/s\u001b[A\n",
      "Training loss: 6.52e-02 lr: 4.46e-05:  11%| | 1486/13852 [05:28<49:23,  4.17it/s\u001b[A\n",
      "Training loss: 7.62e-02 lr: 4.46e-05:  11%| | 1487/13852 [05:28<49:20,  4.18it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.46e-05:  11%| | 1488/13852 [05:28<49:18,  4.18it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 4.46e-05:  11%| | 1489/13852 [05:29<49:17,  4.18it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.46e-05:  11%| | 1490/13852 [05:29<49:23,  4.17it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 4.46e-05:  11%| | 1491/13852 [05:29<49:22,  4.17it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.46e-05:  11%| | 1492/13852 [05:29<49:23,  4.17it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 4.46e-05:  11%| | 1493/13852 [05:30<49:36,  4.15it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 4.46e-05:  11%| | 1494/13852 [05:30<49:45,  4.14it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 4.46e-05:  11%| | 1495/13852 [05:30<49:29,  4.16it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 4.46e-05:  11%| | 1496/13852 [05:30<49:24,  4.17it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 4.46e-05:  11%| | 1497/13852 [05:31<49:19,  4.17it/s\u001b[A\n",
      "Training loss: 8.25e-02 lr: 4.46e-05:  11%| | 1498/13852 [05:31<49:21,  4.17it/s\u001b[A\n",
      "Training loss: 7.12e-02 lr: 4.46e-05:  11%| | 1499/13852 [05:31<49:19,  4.17it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 4.46e-05:  11%| | 1500/13852 [05:31<49:19,  4.17it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 4.46e-05:  11%| | 1501/13852 [05:31<49:18,  4.18it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 4.46e-05:  11%| | 1502/13852 [05:32<49:25,  4.16it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 4.46e-05:  11%| | 1503/13852 [05:32<49:30,  4.16it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 4.46e-05:  11%| | 1504/13852 [05:32<49:24,  4.17it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 4.46e-05:  11%| | 1505/13852 [05:32<49:21,  4.17it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 4.46e-05:  11%| | 1506/13852 [05:33<49:45,  4.14it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.46e-05:  11%| | 1507/13852 [05:33<49:38,  4.14it/s\u001b[A\n",
      "Training loss: 1.44e-01 lr: 4.46e-05:  11%| | 1508/13852 [05:33<49:32,  4.15it/s\u001b[A\n",
      "Training loss: 1.59e-01 lr: 4.46e-05:  11%| | 1509/13852 [05:33<49:26,  4.16it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.46e-05:  11%| | 1510/13852 [05:34<49:19,  4.17it/s\u001b[A\n",
      "Training loss: 1.58e-01 lr: 4.45e-05:  11%| | 1511/13852 [05:34<49:14,  4.18it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 4.45e-05:  11%| | 1512/13852 [05:34<49:10,  4.18it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.45e-05:  11%| | 1513/13852 [05:34<48:58,  4.20it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.45e-05:  11%| | 1514/13852 [05:35<49:03,  4.19it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.45e-05:  11%| | 1515/13852 [05:35<49:07,  4.19it/s\u001b[A\n",
      "Training loss: 7.93e-02 lr: 4.45e-05:  11%| | 1516/13852 [05:35<49:04,  4.19it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 4.45e-05:  11%| | 1517/13852 [05:35<49:03,  4.19it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 4.45e-05:  11%| | 1518/13852 [05:36<48:58,  4.20it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 4.45e-05:  11%| | 1519/13852 [05:36<48:55,  4.20it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 4.45e-05:  11%| | 1520/13852 [05:36<48:58,  4.20it/s\u001b[A\n",
      "Training loss: 6.19e-02 lr: 4.45e-05:  11%| | 1521/13852 [05:36<49:03,  4.19it/s\u001b[A\n",
      "Training loss: 9.92e-02 lr: 4.45e-05:  11%| | 1522/13852 [05:37<49:14,  4.17it/s\u001b[A\n",
      "Training loss: 9.48e-02 lr: 4.45e-05:  11%| | 1523/13852 [05:37<49:52,  4.12it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.45e-05:  11%| | 1524/13852 [05:37<50:02,  4.11it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.45e-05:  11%| | 1525/13852 [05:37<50:05,  4.10it/s\u001b[A\n",
      "Training loss: 8.24e-02 lr: 4.45e-05:  11%| | 1526/13852 [05:38<50:16,  4.09it/s\u001b[A\n",
      "Training loss: 9.02e-02 lr: 4.45e-05:  11%| | 1527/13852 [05:38<49:47,  4.12it/s\u001b[A\n",
      "Training loss: 7.60e-02 lr: 4.45e-05:  11%| | 1528/13852 [05:38<49:35,  4.14it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 4.45e-05:  11%| | 1529/13852 [05:38<49:24,  4.16it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 4.45e-05:  11%| | 1530/13852 [05:38<49:13,  4.17it/s\u001b[A\n",
      "Training loss: 1.41e-01 lr: 4.45e-05:  11%| | 1531/13852 [05:39<49:16,  4.17it/s\u001b[A\n",
      "Training loss: 1.37e-01 lr: 4.45e-05:  11%| | 1532/13852 [05:39<49:11,  4.17it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.45e-05:  11%| | 1533/13852 [05:39<49:10,  4.18it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.45e-05:  11%| | 1534/13852 [05:39<49:05,  4.18it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 4.45e-05:  11%| | 1535/13852 [05:40<49:06,  4.18it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.45e-05:  11%| | 1536/13852 [05:40<48:57,  4.19it/s\u001b[A\n",
      "Training loss: 1.65e-01 lr: 4.45e-05:  11%| | 1537/13852 [05:40<49:04,  4.18it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 4.45e-05:  11%| | 1538/13852 [05:40<49:04,  4.18it/s\u001b[A\n",
      "Training loss: 1.67e-01 lr: 4.44e-05:  11%| | 1539/13852 [05:41<49:05,  4.18it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 4.44e-05:  11%| | 1540/13852 [05:41<49:28,  4.15it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 4.44e-05:  11%| | 1541/13852 [05:41<49:19,  4.16it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.44e-05:  11%| | 1542/13852 [05:41<49:22,  4.16it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.11e-01 lr: 4.44e-05:  11%| | 1543/13852 [05:42<49:20,  4.16it/s\u001b[A\n",
      "Training loss: 1.54e-01 lr: 4.44e-05:  11%| | 1544/13852 [05:42<49:35,  4.14it/s\u001b[A\n",
      "Training loss: 1.41e-01 lr: 4.44e-05:  11%| | 1545/13852 [05:42<49:28,  4.15it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 4.44e-05:  11%| | 1546/13852 [05:42<49:21,  4.16it/s\u001b[A\n",
      "Training loss: 1.51e-01 lr: 4.44e-05:  11%| | 1547/13852 [05:43<49:16,  4.16it/s\u001b[A\n",
      "Training loss: 1.90e-01 lr: 4.44e-05:  11%| | 1548/13852 [05:43<49:35,  4.14it/s\u001b[A\n",
      "Training loss: 1.48e-01 lr: 4.44e-05:  11%| | 1549/13852 [05:43<49:23,  4.15it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.44e-05:  11%| | 1550/13852 [05:43<49:14,  4.16it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.44e-05:  11%| | 1551/13852 [05:44<49:08,  4.17it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.44e-05:  11%| | 1552/13852 [05:44<49:04,  4.18it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.44e-05:  11%| | 1553/13852 [05:44<48:53,  4.19it/s\u001b[A\n",
      "Training loss: 1.51e-01 lr: 4.44e-05:  11%| | 1554/13852 [05:44<48:49,  4.20it/s\u001b[A\n",
      "Training loss: 1.49e-01 lr: 4.44e-05:  11%| | 1555/13852 [05:44<48:57,  4.19it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.44e-05:  11%| | 1556/13852 [05:45<49:00,  4.18it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.44e-05:  11%| | 1557/13852 [05:45<48:57,  4.19it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.44e-05:  11%| | 1558/13852 [05:45<48:52,  4.19it/s\u001b[A\n",
      "Training loss: 9.31e-02 lr: 4.44e-05:  11%| | 1559/13852 [05:45<48:47,  4.20it/s\u001b[A\n",
      "Training loss: 9.43e-02 lr: 4.44e-05:  11%| | 1560/13852 [05:46<48:49,  4.20it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 4.44e-05:  11%| | 1561/13852 [05:46<48:55,  4.19it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 4.44e-05:  11%| | 1562/13852 [05:46<48:57,  4.18it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.44e-05:  11%| | 1563/13852 [05:46<48:49,  4.19it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 4.44e-05:  11%| | 1564/13852 [05:47<48:50,  4.19it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.44e-05:  11%| | 1565/13852 [05:47<49:09,  4.17it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 4.44e-05:  11%| | 1566/13852 [05:47<49:06,  4.17it/s\u001b[A\n",
      "Training loss: 9.00e-02 lr: 4.43e-05:  11%| | 1567/13852 [05:47<48:59,  4.18it/s\u001b[A\n",
      "Training loss: 9.03e-02 lr: 4.43e-05:  11%| | 1568/13852 [05:48<48:52,  4.19it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 4.43e-05:  11%| | 1569/13852 [05:48<48:48,  4.19it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 4.43e-05:  11%| | 1570/13852 [05:48<49:14,  4.16it/s\u001b[A\n",
      "Training loss: 9.40e-02 lr: 4.43e-05:  11%| | 1571/13852 [05:48<49:00,  4.18it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 4.43e-05:  11%| | 1572/13852 [05:49<48:54,  4.18it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 4.43e-05:  11%| | 1573/13852 [05:49<48:54,  4.18it/s\u001b[A\n",
      "Training loss: 9.75e-02 lr: 4.43e-05:  11%| | 1574/13852 [05:49<48:46,  4.19it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 4.43e-05:  11%| | 1575/13852 [05:49<48:44,  4.20it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 4.43e-05:  11%| | 1576/13852 [05:49<48:42,  4.20it/s\u001b[A\n",
      "Training loss: 8.40e-02 lr: 4.43e-05:  11%| | 1577/13852 [05:50<48:35,  4.21it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 4.43e-05:  11%| | 1578/13852 [05:50<48:25,  4.22it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.43e-05:  11%| | 1579/13852 [05:50<48:32,  4.21it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 4.43e-05:  11%| | 1580/13852 [05:50<48:38,  4.21it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.43e-05:  11%| | 1581/13852 [05:51<48:37,  4.21it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 4.43e-05:  11%| | 1582/13852 [05:51<49:05,  4.17it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 4.43e-05:  11%| | 1583/13852 [05:51<48:54,  4.18it/s\u001b[A\n",
      "Training loss: 8.24e-02 lr: 4.43e-05:  11%| | 1584/13852 [05:51<48:49,  4.19it/s\u001b[A\n",
      "Training loss: 6.79e-02 lr: 4.43e-05:  11%| | 1585/13852 [05:52<48:50,  4.19it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 4.43e-05:  11%| | 1586/13852 [05:52<48:59,  4.17it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 4.43e-05:  11%| | 1587/13852 [05:52<48:55,  4.18it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 4.43e-05:  11%| | 1588/13852 [05:52<48:54,  4.18it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 4.43e-05:  11%| | 1589/13852 [05:53<48:43,  4.19it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 4.43e-05:  11%| | 1590/13852 [05:53<48:55,  4.18it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 4.43e-05:  11%| | 1591/13852 [05:53<48:54,  4.18it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 4.43e-05:  11%| | 1592/13852 [05:53<48:49,  4.18it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 4.43e-05:  12%| | 1593/13852 [05:54<48:51,  4.18it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 4.42e-05:  12%| | 1594/13852 [05:54<48:49,  4.18it/s\u001b[A\n",
      "Training loss: 9.34e-02 lr: 4.42e-05:  12%| | 1595/13852 [05:54<48:39,  4.20it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 4.42e-05:  12%| | 1596/13852 [05:54<48:32,  4.21it/s\u001b[A\n",
      "Training loss: 1.60e-01 lr: 4.42e-05:  12%| | 1597/13852 [05:54<48:35,  4.20it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 4.42e-05:  12%| | 1598/13852 [05:55<48:34,  4.20it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 4.42e-05:  12%| | 1599/13852 [05:55<48:37,  4.20it/s\u001b[A\n",
      "Training loss: 1.78e-01 lr: 4.42e-05:  12%| | 1600/13852 [05:55<48:35,  4.20it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 4.42e-05:  12%| | 1601/13852 [05:55<48:29,  4.21it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 4.42e-05:  12%| | 1602/13852 [05:56<48:39,  4.20it/s\u001b[A\n",
      "Training loss: 2.25e-01 lr: 4.42e-05:  12%| | 1603/13852 [05:56<48:44,  4.19it/s\u001b[A\n",
      "Training loss: 1.71e-01 lr: 4.42e-05:  12%| | 1604/13852 [05:56<48:47,  4.18it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 4.42e-05:  12%| | 1605/13852 [05:56<48:44,  4.19it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.42e-05:  12%| | 1606/13852 [05:57<48:45,  4.19it/s\u001b[A\n",
      "Training loss: 8.73e-02 lr: 4.42e-05:  12%| | 1607/13852 [05:57<49:01,  4.16it/s\u001b[A\n",
      "Training loss: 8.38e-02 lr: 4.42e-05:  12%| | 1608/13852 [05:57<48:51,  4.18it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.42e-05:  12%| | 1609/13852 [05:57<48:50,  4.18it/s\u001b[A\n",
      "Training loss: 8.48e-02 lr: 4.42e-05:  12%| | 1610/13852 [05:58<48:48,  4.18it/s\u001b[A\n",
      "Training loss: 8.68e-02 lr: 4.42e-05:  12%| | 1611/13852 [05:58<48:49,  4.18it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 4.42e-05:  12%| | 1612/13852 [05:58<48:44,  4.19it/s\u001b[A\n",
      "Training loss: 8.46e-02 lr: 4.42e-05:  12%| | 1613/13852 [05:58<48:36,  4.20it/s\u001b[A\n",
      "Training loss: 7.81e-02 lr: 4.42e-05:  12%| | 1614/13852 [05:59<48:29,  4.21it/s\u001b[A\n",
      "Training loss: 6.65e-02 lr: 4.42e-05:  12%| | 1615/13852 [05:59<49:04,  4.16it/s\u001b[A\n",
      "Training loss: 4.80e-02 lr: 4.42e-05:  12%| | 1616/13852 [05:59<48:57,  4.17it/s\u001b[A\n",
      "Training loss: 6.69e-02 lr: 4.42e-05:  12%| | 1617/13852 [05:59<48:49,  4.18it/s\u001b[A\n",
      "Training loss: 8.01e-02 lr: 4.42e-05:  12%| | 1618/13852 [05:59<48:42,  4.19it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 4.42e-05:  12%| | 1619/13852 [06:00<48:44,  4.18it/s\u001b[A\n",
      "Training loss: 9.92e-02 lr: 4.42e-05:  12%| | 1620/13852 [06:00<48:29,  4.20it/s\u001b[A\n",
      "Training loss: 7.58e-02 lr: 4.42e-05:  12%| | 1621/13852 [06:00<48:32,  4.20it/s\u001b[A\n",
      "Training loss: 7.12e-02 lr: 4.41e-05:  12%| | 1622/13852 [06:00<48:33,  4.20it/s\u001b[A\n",
      "Training loss: 7.28e-02 lr: 4.41e-05:  12%| | 1623/13852 [06:01<48:35,  4.19it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 4.41e-05:  12%| | 1624/13852 [06:01<48:54,  4.17it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 4.41e-05:  12%| | 1625/13852 [06:01<48:41,  4.19it/s\u001b[A\n",
      "Training loss: 3.83e-02 lr: 4.41e-05:  12%| | 1626/13852 [06:01<48:37,  4.19it/s\u001b[A\n",
      "Training loss: 3.96e-02 lr: 4.41e-05:  12%| | 1627/13852 [06:02<48:43,  4.18it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.41e-05:  12%| | 1628/13852 [06:02<48:50,  4.17it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 4.41e-05:  12%| | 1629/13852 [06:02<48:50,  4.17it/s\u001b[A\n",
      "Training loss: 9.93e-02 lr: 4.41e-05:  12%| | 1630/13852 [06:02<48:45,  4.18it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 4.41e-05:  12%| | 1631/13852 [06:03<48:30,  4.20it/s\u001b[A\n",
      "Training loss: 9.27e-02 lr: 4.41e-05:  12%| | 1632/13852 [06:03<48:49,  4.17it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 4.41e-05:  12%| | 1633/13852 [06:03<49:06,  4.15it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 4.41e-05:  12%| | 1634/13852 [06:03<48:57,  4.16it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 4.41e-05:  12%| | 1635/13852 [06:04<48:50,  4.17it/s\u001b[A\n",
      "Training loss: 4.43e-02 lr: 4.41e-05:  12%| | 1636/13852 [06:04<48:48,  4.17it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 4.41e-05:  12%| | 1637/13852 [06:04<48:37,  4.19it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 4.41e-05:  12%| | 1638/13852 [06:04<48:37,  4.19it/s\u001b[A\n",
      "Training loss: 6.38e-02 lr: 4.41e-05:  12%| | 1639/13852 [06:05<48:41,  4.18it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.56e-01 lr: 4.41e-05:  12%| | 1640/13852 [06:05<48:41,  4.18it/s\u001b[A\n",
      "Training loss: 1.55e-01 lr: 4.41e-05:  12%| | 1641/13852 [06:05<48:39,  4.18it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 4.41e-05:  12%| | 1642/13852 [06:05<48:35,  4.19it/s\u001b[A\n",
      "Training loss: 8.56e-02 lr: 4.41e-05:  12%| | 1643/13852 [06:05<48:23,  4.20it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 4.41e-05:  12%| | 1644/13852 [06:06<48:11,  4.22it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 4.41e-05:  12%| | 1645/13852 [06:06<48:27,  4.20it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 4.41e-05:  12%| | 1646/13852 [06:06<48:32,  4.19it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 4.41e-05:  12%| | 1647/13852 [06:06<48:27,  4.20it/s\u001b[A\n",
      "Training loss: 9.73e-02 lr: 4.41e-05:  12%| | 1648/13852 [06:07<48:42,  4.18it/s\u001b[A\n",
      "Training loss: 7.18e-02 lr: 4.41e-05:  12%| | 1649/13852 [06:07<48:55,  4.16it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 4.40e-05:  12%| | 1650/13852 [06:07<49:05,  4.14it/s\u001b[A\n",
      "Training loss: 9.18e-02 lr: 4.40e-05:  12%| | 1651/13852 [06:07<49:16,  4.13it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 4.40e-05:  12%| | 1652/13852 [06:08<49:06,  4.14it/s\u001b[A\n",
      "Training loss: 7.27e-02 lr: 4.40e-05:  12%| | 1653/13852 [06:08<48:54,  4.16it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 4.40e-05:  12%| | 1654/13852 [06:08<48:46,  4.17it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 4.40e-05:  12%| | 1655/13852 [06:08<48:32,  4.19it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 4.40e-05:  12%| | 1656/13852 [06:09<48:36,  4.18it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 4.40e-05:  12%| | 1657/13852 [06:09<48:32,  4.19it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 4.40e-05:  12%| | 1658/13852 [06:09<48:28,  4.19it/s\u001b[A\n",
      "Training loss: 7.11e-02 lr: 4.40e-05:  12%| | 1659/13852 [06:09<48:27,  4.19it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 4.40e-05:  12%| | 1660/13852 [06:10<48:28,  4.19it/s\u001b[A\n",
      "Training loss: 8.12e-02 lr: 4.40e-05:  12%| | 1661/13852 [06:10<48:21,  4.20it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.40e-05:  12%| | 1662/13852 [06:10<48:21,  4.20it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 4.40e-05:  12%| | 1663/13852 [06:10<48:26,  4.19it/s\u001b[A\n",
      "Training loss: 1.63e-01 lr: 4.40e-05:  12%| | 1664/13852 [06:10<48:28,  4.19it/s\u001b[A\n",
      "Training loss: 1.44e-01 lr: 4.40e-05:  12%| | 1665/13852 [06:11<48:30,  4.19it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.40e-05:  12%| | 1666/13852 [06:11<48:42,  4.17it/s\u001b[A\n",
      "Training loss: 9.60e-02 lr: 4.40e-05:  12%| | 1667/13852 [06:11<48:30,  4.19it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.40e-05:  12%| | 1668/13852 [06:11<48:46,  4.16it/s\u001b[A\n",
      "Training loss: 8.99e-02 lr: 4.40e-05:  12%| | 1669/13852 [06:12<49:00,  4.14it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.40e-05:  12%| | 1670/13852 [06:12<48:51,  4.16it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.40e-05:  12%| | 1671/13852 [06:12<48:44,  4.16it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 4.40e-05:  12%| | 1672/13852 [06:12<48:39,  4.17it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.40e-05:  12%| | 1673/13852 [06:13<48:25,  4.19it/s\u001b[A\n",
      "Training loss: 8.75e-02 lr: 4.40e-05:  12%| | 1674/13852 [06:13<48:30,  4.18it/s\u001b[A\n",
      "Training loss: 9.43e-02 lr: 4.40e-05:  12%| | 1675/13852 [06:13<48:32,  4.18it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 4.40e-05:  12%| | 1676/13852 [06:13<48:28,  4.19it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 4.39e-05:  12%| | 1677/13852 [06:14<48:23,  4.19it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.39e-05:  12%| | 1678/13852 [06:14<48:16,  4.20it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.39e-05:  12%| | 1679/13852 [06:14<48:08,  4.21it/s\u001b[A\n",
      "Training loss: 9.45e-02 lr: 4.39e-05:  12%| | 1680/13852 [06:14<48:13,  4.21it/s\u001b[A\n",
      "Training loss: 7.64e-02 lr: 4.39e-05:  12%| | 1681/13852 [06:15<48:19,  4.20it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 4.39e-05:  12%| | 1682/13852 [06:15<48:22,  4.19it/s\u001b[A\n",
      "Training loss: 9.25e-02 lr: 4.39e-05:  12%| | 1683/13852 [06:15<48:23,  4.19it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 4.39e-05:  12%| | 1684/13852 [06:15<48:23,  4.19it/s\u001b[A\n",
      "Training loss: 9.12e-02 lr: 4.39e-05:  12%| | 1685/13852 [06:16<48:14,  4.20it/s\u001b[A\n",
      "Training loss: 9.43e-02 lr: 4.39e-05:  12%| | 1686/13852 [06:16<48:19,  4.20it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.39e-05:  12%| | 1687/13852 [06:16<48:19,  4.20it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.39e-05:  12%| | 1688/13852 [06:16<48:20,  4.19it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.39e-05:  12%| | 1689/13852 [06:16<48:17,  4.20it/s\u001b[A\n",
      "Training loss: 9.01e-02 lr: 4.39e-05:  12%| | 1690/13852 [06:17<48:22,  4.19it/s\u001b[A\n",
      "Training loss: 9.31e-02 lr: 4.39e-05:  12%| | 1691/13852 [06:17<48:19,  4.19it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 4.39e-05:  12%| | 1692/13852 [06:17<48:22,  4.19it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 4.39e-05:  12%| | 1693/13852 [06:17<48:22,  4.19it/s\u001b[A\n",
      "Training loss: 9.00e-02 lr: 4.39e-05:  12%| | 1694/13852 [06:18<48:20,  4.19it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 4.39e-05:  12%| | 1695/13852 [06:18<48:16,  4.20it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 4.39e-05:  12%| | 1696/13852 [06:18<48:27,  4.18it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.39e-05:  12%| | 1697/13852 [06:18<48:14,  4.20it/s\u001b[A\n",
      "Training loss: 8.36e-02 lr: 4.39e-05:  12%| | 1698/13852 [06:19<48:09,  4.21it/s\u001b[A\n",
      "Training loss: 9.45e-02 lr: 4.39e-05:  12%| | 1699/13852 [06:19<48:11,  4.20it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.39e-05:  12%| | 1700/13852 [06:19<48:12,  4.20it/s\u001b[A\n",
      "Training loss: 9.18e-02 lr: 4.39e-05:  12%| | 1701/13852 [06:19<48:14,  4.20it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 4.39e-05:  12%| | 1702/13852 [06:20<48:25,  4.18it/s\u001b[A\n",
      "Training loss: 6.64e-02 lr: 4.39e-05:  12%| | 1703/13852 [06:20<48:25,  4.18it/s\u001b[A\n",
      "Training loss: 4.80e-02 lr: 4.39e-05:  12%| | 1704/13852 [06:20<48:13,  4.20it/s\u001b[A\n",
      "Training loss: 4.82e-02 lr: 4.38e-05:  12%| | 1705/13852 [06:20<48:15,  4.19it/s\u001b[A\n",
      "Training loss: 3.62e-02 lr: 4.38e-05:  12%| | 1706/13852 [06:21<48:17,  4.19it/s\u001b[A\n",
      "Training loss: 3.42e-02 lr: 4.38e-05:  12%| | 1707/13852 [06:21<48:23,  4.18it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 4.38e-05:  12%| | 1708/13852 [06:21<48:26,  4.18it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.38e-05:  12%| | 1709/13852 [06:21<48:23,  4.18it/s\u001b[A\n",
      "Training loss: 1.84e-01 lr: 4.38e-05:  12%| | 1710/13852 [06:21<48:24,  4.18it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 4.38e-05:  12%| | 1711/13852 [06:22<48:36,  4.16it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.38e-05:  12%| | 1712/13852 [06:22<48:36,  4.16it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 4.38e-05:  12%| | 1713/13852 [06:22<48:35,  4.16it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 4.38e-05:  12%| | 1714/13852 [06:22<48:27,  4.18it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.38e-05:  12%| | 1715/13852 [06:23<48:23,  4.18it/s\u001b[A\n",
      "Training loss: 8.41e-02 lr: 4.38e-05:  12%| | 1716/13852 [06:23<48:23,  4.18it/s\u001b[A\n",
      "Training loss: 9.78e-02 lr: 4.38e-05:  12%| | 1717/13852 [06:23<48:31,  4.17it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 4.38e-05:  12%| | 1718/13852 [06:23<48:21,  4.18it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 4.38e-05:  12%| | 1719/13852 [06:24<48:19,  4.18it/s\u001b[A\n",
      "Training loss: 1.77e-01 lr: 4.38e-05:  12%| | 1720/13852 [06:24<48:17,  4.19it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 4.38e-05:  12%| | 1721/13852 [06:24<48:13,  4.19it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.38e-05:  12%| | 1722/13852 [06:24<48:09,  4.20it/s\u001b[A\n",
      "Training loss: 9.99e-02 lr: 4.38e-05:  12%| | 1723/13852 [06:25<48:09,  4.20it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 4.38e-05:  12%| | 1724/13852 [06:25<48:09,  4.20it/s\u001b[A\n",
      "Training loss: 9.15e-02 lr: 4.38e-05:  12%| | 1725/13852 [06:25<48:05,  4.20it/s\u001b[A\n",
      "Training loss: 7.76e-02 lr: 4.38e-05:  12%| | 1726/13852 [06:25<48:03,  4.20it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 4.38e-05:  12%| | 1727/13852 [06:26<48:00,  4.21it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 4.38e-05:  12%| | 1728/13852 [06:26<48:03,  4.20it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 4.38e-05:  12%| | 1729/13852 [06:26<48:08,  4.20it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 4.38e-05:  12%| | 1730/13852 [06:26<48:09,  4.20it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.38e-05:  12%| | 1731/13852 [06:26<48:10,  4.19it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.38e-05:  13%|▏| 1732/13852 [06:27<48:16,  4.18it/s\u001b[A\n",
      "Training loss: 8.94e-02 lr: 4.37e-05:  13%|▏| 1733/13852 [06:27<48:09,  4.19it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 4.37e-05:  13%|▏| 1734/13852 [06:27<48:05,  4.20it/s\u001b[A\n",
      "Training loss: 6.93e-02 lr: 4.37e-05:  13%|▏| 1735/13852 [06:27<48:07,  4.20it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 4.37e-05:  13%|▏| 1736/13852 [06:28<48:09,  4.19it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.87e-02 lr: 4.37e-05:  13%|▏| 1737/13852 [06:28<48:07,  4.20it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 4.37e-05:  13%|▏| 1738/13852 [06:28<48:05,  4.20it/s\u001b[A\n",
      "Training loss: 7.42e-02 lr: 4.37e-05:  13%|▏| 1739/13852 [06:28<48:05,  4.20it/s\u001b[A\n",
      "Training loss: 6.25e-02 lr: 4.37e-05:  13%|▏| 1740/13852 [06:29<48:14,  4.18it/s\u001b[A\n",
      "Training loss: 9.86e-02 lr: 4.37e-05:  13%|▏| 1741/13852 [06:29<48:11,  4.19it/s\u001b[A\n",
      "Training loss: 7.30e-02 lr: 4.37e-05:  13%|▏| 1742/13852 [06:29<48:08,  4.19it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 4.37e-05:  13%|▏| 1743/13852 [06:29<48:08,  4.19it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 4.37e-05:  13%|▏| 1744/13852 [06:30<48:08,  4.19it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 4.37e-05:  13%|▏| 1745/13852 [06:30<48:04,  4.20it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 4.37e-05:  13%|▏| 1746/13852 [06:30<47:57,  4.21it/s\u001b[A\n",
      "Training loss: 4.72e-02 lr: 4.37e-05:  13%|▏| 1747/13852 [06:30<48:04,  4.20it/s\u001b[A\n",
      "Training loss: 4.57e-02 lr: 4.37e-05:  13%|▏| 1748/13852 [06:31<48:04,  4.20it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 4.37e-05:  13%|▏| 1749/13852 [06:31<48:09,  4.19it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 4.37e-05:  13%|▏| 1750/13852 [06:31<48:08,  4.19it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 4.37e-05:  13%|▏| 1751/13852 [06:31<48:00,  4.20it/s\u001b[A\n",
      "Training loss: 8.37e-02 lr: 4.37e-05:  13%|▏| 1752/13852 [06:31<47:49,  4.22it/s\u001b[A\n",
      "Training loss: 6.30e-02 lr: 4.37e-05:  13%|▏| 1753/13852 [06:32<48:14,  4.18it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 4.37e-05:  13%|▏| 1754/13852 [06:32<48:14,  4.18it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 4.37e-05:  13%|▏| 1755/13852 [06:32<48:04,  4.19it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 4.37e-05:  13%|▏| 1756/13852 [06:32<48:06,  4.19it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 4.37e-05:  13%|▏| 1757/13852 [06:33<48:04,  4.19it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 4.37e-05:  13%|▏| 1758/13852 [06:33<47:54,  4.21it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 4.37e-05:  13%|▏| 1759/13852 [06:33<48:05,  4.19it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 4.37e-05:  13%|▏| 1760/13852 [06:33<48:08,  4.19it/s\u001b[A\n",
      "Training loss: 7.33e-02 lr: 4.36e-05:  13%|▏| 1761/13852 [06:34<48:10,  4.18it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.36e-05:  13%|▏| 1762/13852 [06:34<48:07,  4.19it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 4.36e-05:  13%|▏| 1763/13852 [06:34<47:58,  4.20it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 4.36e-05:  13%|▏| 1764/13852 [06:34<47:48,  4.21it/s\u001b[A\n",
      "Training loss: 6.64e-02 lr: 4.36e-05:  13%|▏| 1765/13852 [06:35<47:51,  4.21it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 4.36e-05:  13%|▏| 1766/13852 [06:35<48:00,  4.20it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 4.36e-05:  13%|▏| 1767/13852 [06:35<47:55,  4.20it/s\u001b[A\n",
      "Training loss: 4.90e-02 lr: 4.36e-05:  13%|▏| 1768/13852 [06:35<47:59,  4.20it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.36e-05:  13%|▏| 1769/13852 [06:36<47:57,  4.20it/s\u001b[A\n",
      "Training loss: 9.86e-02 lr: 4.36e-05:  13%|▏| 1770/13852 [06:36<47:50,  4.21it/s\u001b[A\n",
      "Training loss: 9.02e-02 lr: 4.36e-05:  13%|▏| 1771/13852 [06:36<47:54,  4.20it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 4.36e-05:  13%|▏| 1772/13852 [06:36<47:56,  4.20it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 4.36e-05:  13%|▏| 1773/13852 [06:37<48:00,  4.19it/s\u001b[A\n",
      "Training loss: 3.99e-02 lr: 4.36e-05:  13%|▏| 1774/13852 [06:37<48:34,  4.14it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 4.36e-05:  13%|▏| 1775/13852 [06:37<48:43,  4.13it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 4.36e-05:  13%|▏| 1776/13852 [06:37<48:39,  4.14it/s\u001b[A\n",
      "Training loss: 5.68e-02 lr: 4.36e-05:  13%|▏| 1777/13852 [06:37<48:41,  4.13it/s\u001b[A\n",
      "Training loss: 9.78e-02 lr: 4.36e-05:  13%|▏| 1778/13852 [06:38<48:28,  4.15it/s\u001b[A\n",
      "Training loss: 1.83e-01 lr: 4.36e-05:  13%|▏| 1779/13852 [06:38<48:20,  4.16it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 4.36e-05:  13%|▏| 1780/13852 [06:38<48:18,  4.16it/s\u001b[A\n",
      "Training loss: 9.51e-02 lr: 4.36e-05:  13%|▏| 1781/13852 [06:38<48:09,  4.18it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 4.36e-05:  13%|▏| 1782/13852 [06:39<47:59,  4.19it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 4.36e-05:  13%|▏| 1783/13852 [06:39<48:03,  4.19it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 4.36e-05:  13%|▏| 1784/13852 [06:39<48:03,  4.19it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 4.36e-05:  13%|▏| 1785/13852 [06:39<47:59,  4.19it/s\u001b[A\n",
      "Training loss: 7.96e-02 lr: 4.36e-05:  13%|▏| 1786/13852 [06:40<48:00,  4.19it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 4.36e-05:  13%|▏| 1787/13852 [06:40<47:52,  4.20it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 4.35e-05:  13%|▏| 1788/13852 [06:40<47:53,  4.20it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 4.35e-05:  13%|▏| 1789/13852 [06:40<47:54,  4.20it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.35e-05:  13%|▏| 1790/13852 [06:41<47:56,  4.19it/s\u001b[A\n",
      "Training loss: 9.57e-02 lr: 4.35e-05:  13%|▏| 1791/13852 [06:41<48:05,  4.18it/s\u001b[A\n",
      "Training loss: 9.89e-02 lr: 4.35e-05:  13%|▏| 1792/13852 [06:41<48:00,  4.19it/s\u001b[A\n",
      "Training loss: 8.26e-02 lr: 4.35e-05:  13%|▏| 1793/13852 [06:41<47:59,  4.19it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 4.35e-05:  13%|▏| 1794/13852 [06:42<47:48,  4.20it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 4.35e-05:  13%|▏| 1795/13852 [06:42<48:10,  4.17it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 4.35e-05:  13%|▏| 1796/13852 [06:42<48:06,  4.18it/s\u001b[A\n",
      "Training loss: 6.75e-02 lr: 4.35e-05:  13%|▏| 1797/13852 [06:42<48:02,  4.18it/s\u001b[A\n",
      "Training loss: 8.60e-02 lr: 4.35e-05:  13%|▏| 1798/13852 [06:42<47:57,  4.19it/s\u001b[A\n",
      "Training loss: 7.01e-02 lr: 4.35e-05:  13%|▏| 1799/13852 [06:43<47:58,  4.19it/s\u001b[A\n",
      "Training loss: 9.17e-02 lr: 4.35e-05:  13%|▏| 1800/13852 [06:43<48:05,  4.18it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 4.35e-05:  13%|▏| 1801/13852 [06:43<48:22,  4.15it/s\u001b[A\n",
      "Training loss: 1.64e-01 lr: 4.35e-05:  13%|▏| 1802/13852 [06:43<48:15,  4.16it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 4.35e-05:  13%|▏| 1803/13852 [06:44<48:11,  4.17it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 4.35e-05:  13%|▏| 1804/13852 [06:44<48:03,  4.18it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 4.35e-05:  13%|▏| 1805/13852 [06:44<47:53,  4.19it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.35e-05:  13%|▏| 1806/13852 [06:44<47:45,  4.20it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.35e-05:  13%|▏| 1807/13852 [06:45<47:53,  4.19it/s\u001b[A\n",
      "Training loss: 9.72e-02 lr: 4.35e-05:  13%|▏| 1808/13852 [06:45<47:55,  4.19it/s\u001b[A\n",
      "Training loss: 7.78e-02 lr: 4.35e-05:  13%|▏| 1809/13852 [06:45<47:53,  4.19it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 4.35e-05:  13%|▏| 1810/13852 [06:45<47:56,  4.19it/s\u001b[A\n",
      "Training loss: 9.68e-02 lr: 4.35e-05:  13%|▏| 1811/13852 [06:46<47:53,  4.19it/s\u001b[A\n",
      "Training loss: 7.99e-02 lr: 4.35e-05:  13%|▏| 1812/13852 [06:46<47:53,  4.19it/s\u001b[A\n",
      "Training loss: 7.24e-02 lr: 4.35e-05:  13%|▏| 1813/13852 [06:46<47:59,  4.18it/s\u001b[A\n",
      "Training loss: 9.18e-02 lr: 4.35e-05:  13%|▏| 1814/13852 [06:46<48:00,  4.18it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.35e-05:  13%|▏| 1815/13852 [06:47<47:52,  4.19it/s\u001b[A\n",
      "Training loss: 8.77e-02 lr: 4.34e-05:  13%|▏| 1816/13852 [06:47<48:07,  4.17it/s\u001b[A\n",
      "Training loss: 6.36e-02 lr: 4.34e-05:  13%|▏| 1817/13852 [06:47<48:36,  4.13it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.34e-05:  13%|▏| 1818/13852 [06:47<48:38,  4.12it/s\u001b[A\n",
      "Training loss: 7.78e-02 lr: 4.34e-05:  13%|▏| 1819/13852 [06:48<48:36,  4.13it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 4.34e-05:  13%|▏| 1820/13852 [06:48<47:20,  4.24it/s\u001b[A\n",
      "Training loss: 9.45e-02 lr: 4.34e-05:  13%|▏| 1821/13852 [06:48<46:52,  4.28it/s\u001b[A\n",
      "Training loss: 9.51e-02 lr: 4.34e-05:  13%|▏| 1822/13852 [06:48<46:15,  4.34it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 4.34e-05:  13%|▏| 1823/13852 [06:48<45:49,  4.37it/s\u001b[A\n",
      "Training loss: 7.92e-02 lr: 4.34e-05:  13%|▏| 1824/13852 [06:49<46:07,  4.35it/s\u001b[A\n",
      "Training loss: 6.22e-02 lr: 4.34e-05:  13%|▏| 1825/13852 [06:49<45:32,  4.40it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 4.34e-05:  13%|▏| 1826/13852 [06:49<45:16,  4.43it/s\u001b[A\n",
      "Training loss: 7.00e-02 lr: 4.34e-05:  13%|▏| 1827/13852 [06:49<45:09,  4.44it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 4.34e-05:  13%|▏| 1828/13852 [06:50<45:15,  4.43it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.34e-05:  13%|▏| 1829/13852 [06:50<45:12,  4.43it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 4.34e-05:  13%|▏| 1830/13852 [06:50<45:12,  4.43it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 4.34e-05:  13%|▏| 1831/13852 [06:50<45:10,  4.43it/s\u001b[A\n",
      "Training loss: 7.61e-02 lr: 4.34e-05:  13%|▏| 1832/13852 [06:50<45:19,  4.42it/s\u001b[A\n",
      "Training loss: 8.48e-02 lr: 4.34e-05:  13%|▏| 1833/13852 [06:51<45:08,  4.44it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.51e-02 lr: 4.34e-05:  13%|▏| 1834/13852 [06:51<45:20,  4.42it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 4.34e-05:  13%|▏| 1835/13852 [06:51<45:01,  4.45it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 4.34e-05:  13%|▏| 1836/13852 [06:51<44:57,  4.45it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 4.34e-05:  13%|▏| 1837/13852 [06:52<45:49,  4.37it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 4.34e-05:  13%|▏| 1838/13852 [06:52<46:58,  4.26it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 4.34e-05:  13%|▏| 1839/13852 [06:52<47:29,  4.22it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.34e-05:  13%|▏| 1840/13852 [06:52<46:27,  4.31it/s\u001b[A\n",
      "Training loss: 8.24e-02 lr: 4.34e-05:  13%|▏| 1841/13852 [06:53<45:43,  4.38it/s\u001b[A\n",
      "Training loss: 7.03e-02 lr: 4.34e-05:  13%|▏| 1842/13852 [06:53<45:16,  4.42it/s\u001b[A\n",
      "Training loss: 7.86e-02 lr: 4.34e-05:  13%|▏| 1843/13852 [06:53<44:46,  4.47it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 4.33e-05:  13%|▏| 1844/13852 [06:53<44:37,  4.48it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 4.33e-05:  13%|▏| 1845/13852 [06:53<44:34,  4.49it/s\u001b[A\n",
      "Training loss: 9.60e-02 lr: 4.33e-05:  13%|▏| 1846/13852 [06:54<44:27,  4.50it/s\u001b[A\n",
      "Training loss: 6.93e-02 lr: 4.33e-05:  13%|▏| 1847/13852 [06:54<44:25,  4.50it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 4.33e-05:  13%|▏| 1848/13852 [06:54<44:22,  4.51it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 4.33e-05:  13%|▏| 1849/13852 [06:54<44:17,  4.52it/s\u001b[A\n",
      "Training loss: 3.50e-02 lr: 4.33e-05:  13%|▏| 1850/13852 [06:55<44:27,  4.50it/s\u001b[A\n",
      "Training loss: 3.02e-02 lr: 4.33e-05:  13%|▏| 1851/13852 [06:55<44:19,  4.51it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.33e-05:  13%|▏| 1852/13852 [06:55<44:14,  4.52it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 4.33e-05:  13%|▏| 1853/13852 [06:55<44:07,  4.53it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.33e-05:  13%|▏| 1854/13852 [06:55<44:07,  4.53it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.33e-05:  13%|▏| 1855/13852 [06:56<44:12,  4.52it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.33e-05:  13%|▏| 1856/13852 [06:56<44:03,  4.54it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 4.33e-05:  13%|▏| 1857/13852 [06:56<44:08,  4.53it/s\u001b[A\n",
      "Training loss: 1.41e-01 lr: 4.33e-05:  13%|▏| 1858/13852 [06:56<44:06,  4.53it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.33e-05:  13%|▏| 1859/13852 [06:57<44:08,  4.53it/s\u001b[A\n",
      "Training loss: 9.31e-02 lr: 4.33e-05:  13%|▏| 1860/13852 [06:57<44:27,  4.49it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 4.33e-05:  13%|▏| 1861/13852 [06:57<44:23,  4.50it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.33e-05:  13%|▏| 1862/13852 [06:57<44:14,  4.52it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.33e-05:  13%|▏| 1863/13852 [06:57<44:07,  4.53it/s\u001b[A\n",
      "Training loss: 8.37e-02 lr: 4.33e-05:  13%|▏| 1864/13852 [06:58<44:02,  4.54it/s\u001b[A\n",
      "Training loss: 6.79e-02 lr: 4.33e-05:  13%|▏| 1865/13852 [06:58<44:09,  4.52it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 4.33e-05:  13%|▏| 1866/13852 [06:58<44:04,  4.53it/s\u001b[A\n",
      "Training loss: 6.46e-02 lr: 4.33e-05:  13%|▏| 1867/13852 [06:58<44:01,  4.54it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 4.33e-05:  13%|▏| 1868/13852 [06:58<43:49,  4.56it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 4.33e-05:  13%|▏| 1869/13852 [06:59<43:44,  4.57it/s\u001b[A\n",
      "Training loss: 7.86e-02 lr: 4.33e-05:  13%|▏| 1870/13852 [06:59<43:47,  4.56it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 4.32e-05:  14%|▏| 1871/13852 [06:59<44:00,  4.54it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 4.32e-05:  14%|▏| 1872/13852 [06:59<44:03,  4.53it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 4.32e-05:  14%|▏| 1873/13852 [07:00<44:00,  4.54it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 4.32e-05:  14%|▏| 1874/13852 [07:00<43:57,  4.54it/s\u001b[A\n",
      "Training loss: 7.18e-02 lr: 4.32e-05:  14%|▏| 1875/13852 [07:00<44:02,  4.53it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 4.32e-05:  14%|▏| 1876/13852 [07:00<43:59,  4.54it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 4.32e-05:  14%|▏| 1877/13852 [07:00<43:56,  4.54it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 4.32e-05:  14%|▏| 1878/13852 [07:01<43:57,  4.54it/s\u001b[A\n",
      "Training loss: 9.28e-02 lr: 4.32e-05:  14%|▏| 1879/13852 [07:01<44:13,  4.51it/s\u001b[A\n",
      "Training loss: 8.24e-02 lr: 4.32e-05:  14%|▏| 1880/13852 [07:01<44:08,  4.52it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 4.32e-05:  14%|▏| 1881/13852 [07:01<43:53,  4.55it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.32e-05:  14%|▏| 1882/13852 [07:02<43:41,  4.57it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 4.32e-05:  14%|▏| 1883/13852 [07:02<43:41,  4.57it/s\u001b[A\n",
      "Training loss: 8.23e-02 lr: 4.32e-05:  14%|▏| 1884/13852 [07:02<44:01,  4.53it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.32e-05:  14%|▏| 1885/13852 [07:02<43:59,  4.53it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 4.32e-05:  14%|▏| 1886/13852 [07:02<44:06,  4.52it/s\u001b[A\n",
      "Training loss: 1.85e-01 lr: 4.32e-05:  14%|▏| 1887/13852 [07:03<44:04,  4.53it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 4.32e-05:  14%|▏| 1888/13852 [07:03<43:57,  4.54it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 4.32e-05:  14%|▏| 1889/13852 [07:03<43:53,  4.54it/s\u001b[A\n",
      "Training loss: 9.39e-02 lr: 4.32e-05:  14%|▏| 1890/13852 [07:03<44:07,  4.52it/s\u001b[A\n",
      "Training loss: 7.29e-02 lr: 4.32e-05:  14%|▏| 1891/13852 [07:04<44:00,  4.53it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 4.32e-05:  14%|▏| 1892/13852 [07:04<43:59,  4.53it/s\u001b[A\n",
      "Training loss: 8.65e-02 lr: 4.32e-05:  14%|▏| 1893/13852 [07:04<43:58,  4.53it/s\u001b[A\n",
      "Training loss: 8.66e-02 lr: 4.32e-05:  14%|▏| 1894/13852 [07:04<43:59,  4.53it/s\u001b[A\n",
      "Training loss: 7.53e-02 lr: 4.32e-05:  14%|▏| 1895/13852 [07:04<43:49,  4.55it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 4.32e-05:  14%|▏| 1896/13852 [07:05<43:40,  4.56it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.32e-05:  14%|▏| 1897/13852 [07:05<43:50,  4.55it/s\u001b[A\n",
      "Training loss: 8.60e-02 lr: 4.32e-05:  14%|▏| 1898/13852 [07:05<43:52,  4.54it/s\u001b[A\n",
      "Training loss: 9.16e-02 lr: 4.31e-05:  14%|▏| 1899/13852 [07:05<43:50,  4.54it/s\u001b[A\n",
      "Training loss: 9.95e-02 lr: 4.31e-05:  14%|▏| 1900/13852 [07:06<43:55,  4.53it/s\u001b[A\n",
      "Training loss: 9.14e-02 lr: 4.31e-05:  14%|▏| 1901/13852 [07:06<43:55,  4.54it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.31e-05:  14%|▏| 1902/13852 [07:06<43:59,  4.53it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 4.31e-05:  14%|▏| 1903/13852 [07:06<43:57,  4.53it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.31e-05:  14%|▏| 1904/13852 [07:06<43:53,  4.54it/s\u001b[A\n",
      "Training loss: 8.98e-02 lr: 4.31e-05:  14%|▏| 1905/13852 [07:07<44:34,  4.47it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 4.31e-05:  14%|▏| 1906/13852 [07:07<44:57,  4.43it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 4.31e-05:  14%|▏| 1907/13852 [07:07<44:36,  4.46it/s\u001b[A\n",
      "Training loss: 8.10e-02 lr: 4.31e-05:  14%|▏| 1908/13852 [07:07<44:22,  4.49it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 4.31e-05:  14%|▏| 1909/13852 [07:08<44:15,  4.50it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 4.31e-05:  14%|▏| 1910/13852 [07:08<44:13,  4.50it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.31e-05:  14%|▏| 1911/13852 [07:08<44:05,  4.51it/s\u001b[A\n",
      "Training loss: 8.34e-02 lr: 4.31e-05:  14%|▏| 1912/13852 [07:08<44:02,  4.52it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 4.31e-05:  14%|▏| 1913/13852 [07:08<43:55,  4.53it/s\u001b[A\n",
      "Training loss: 7.19e-02 lr: 4.31e-05:  14%|▏| 1914/13852 [07:09<43:52,  4.53it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 4.31e-05:  14%|▏| 1915/13852 [07:09<43:48,  4.54it/s\u001b[A\n",
      "Training loss: 7.93e-02 lr: 4.31e-05:  14%|▏| 1916/13852 [07:09<43:51,  4.54it/s\u001b[A\n",
      "Training loss: 9.40e-02 lr: 4.31e-05:  14%|▏| 1917/13852 [07:09<43:51,  4.54it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.31e-05:  14%|▏| 1918/13852 [07:10<43:52,  4.53it/s\u001b[A\n",
      "Training loss: 1.59e-01 lr: 4.31e-05:  14%|▏| 1919/13852 [07:10<43:41,  4.55it/s\u001b[A\n",
      "Training loss: 1.76e-01 lr: 4.31e-05:  14%|▏| 1920/13852 [07:10<43:33,  4.57it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 4.31e-05:  14%|▏| 1921/13852 [07:10<43:23,  4.58it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 4.31e-05:  14%|▏| 1922/13852 [07:10<43:47,  4.54it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.31e-05:  14%|▏| 1923/13852 [07:11<43:50,  4.53it/s\u001b[A\n",
      "Training loss: 9.14e-02 lr: 4.31e-05:  14%|▏| 1924/13852 [07:11<44:07,  4.50it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.31e-05:  14%|▏| 1925/13852 [07:11<44:03,  4.51it/s\u001b[A\n",
      "Training loss: 9.62e-02 lr: 4.31e-05:  14%|▏| 1926/13852 [07:11<44:07,  4.50it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 4.30e-05:  14%|▏| 1927/13852 [07:12<44:01,  4.52it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 4.30e-05:  14%|▏| 1928/13852 [07:12<44:06,  4.51it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 4.30e-05:  14%|▏| 1929/13852 [07:12<43:59,  4.52it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 4.30e-05:  14%|▏| 1930/13852 [07:12<43:54,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.56e-02 lr: 4.30e-05:  14%|▏| 1931/13852 [07:12<43:43,  4.54it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 4.30e-05:  14%|▏| 1932/13852 [07:13<43:29,  4.57it/s\u001b[A\n",
      "Training loss: 7.30e-02 lr: 4.30e-05:  14%|▏| 1933/13852 [07:13<43:23,  4.58it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 4.30e-05:  14%|▏| 1934/13852 [07:13<43:16,  4.59it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 4.30e-05:  14%|▏| 1935/13852 [07:13<43:15,  4.59it/s\u001b[A\n",
      "Training loss: 4.90e-02 lr: 4.30e-05:  14%|▏| 1936/13852 [07:13<43:27,  4.57it/s\u001b[A\n",
      "Training loss: 6.79e-02 lr: 4.30e-05:  14%|▏| 1937/13852 [07:14<43:36,  4.55it/s\u001b[A\n",
      "Training loss: 7.73e-02 lr: 4.30e-05:  14%|▏| 1938/13852 [07:14<43:36,  4.55it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 4.30e-05:  14%|▏| 1939/13852 [07:14<43:37,  4.55it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 4.30e-05:  14%|▏| 1940/13852 [07:14<43:41,  4.54it/s\u001b[A\n",
      "Training loss: 7.15e-02 lr: 4.30e-05:  14%|▏| 1941/13852 [07:15<43:42,  4.54it/s\u001b[A\n",
      "Training loss: 7.69e-02 lr: 4.30e-05:  14%|▏| 1942/13852 [07:15<43:50,  4.53it/s\u001b[A\n",
      "Training loss: 8.85e-02 lr: 4.30e-05:  14%|▏| 1943/13852 [07:15<43:52,  4.52it/s\u001b[A\n",
      "Training loss: 7.19e-02 lr: 4.30e-05:  14%|▏| 1944/13852 [07:15<43:52,  4.52it/s\u001b[A\n",
      "Training loss: 7.11e-02 lr: 4.30e-05:  14%|▏| 1945/13852 [07:15<43:51,  4.52it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 4.30e-05:  14%|▏| 1946/13852 [07:16<44:56,  4.42it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 4.30e-05:  14%|▏| 1947/13852 [07:16<45:45,  4.34it/s\u001b[A\n",
      "Training loss: 8.61e-02 lr: 4.30e-05:  14%|▏| 1948/13852 [07:16<45:15,  4.38it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 4.30e-05:  14%|▏| 1949/13852 [07:16<44:41,  4.44it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 4.30e-05:  14%|▏| 1950/13852 [07:17<44:38,  4.44it/s\u001b[A\n",
      "Training loss: 4.22e-02 lr: 4.30e-05:  14%|▏| 1951/13852 [07:17<44:30,  4.46it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 4.30e-05:  14%|▏| 1952/13852 [07:17<44:16,  4.48it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 4.30e-05:  14%|▏| 1953/13852 [07:17<44:09,  4.49it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 4.29e-05:  14%|▏| 1954/13852 [07:18<44:01,  4.50it/s\u001b[A\n",
      "Training loss: 2.07e-01 lr: 4.29e-05:  14%|▏| 1955/13852 [07:18<43:57,  4.51it/s\u001b[A\n",
      "Training loss: 2.43e-01 lr: 4.29e-05:  14%|▏| 1956/13852 [07:18<43:47,  4.53it/s\u001b[A\n",
      "Training loss: 1.81e-01 lr: 4.29e-05:  14%|▏| 1957/13852 [07:18<43:35,  4.55it/s\u001b[A\n",
      "Training loss: 1.69e-01 lr: 4.29e-05:  14%|▏| 1958/13852 [07:18<43:53,  4.52it/s\u001b[A\n",
      "Training loss: 1.80e-01 lr: 4.29e-05:  14%|▏| 1959/13852 [07:19<43:50,  4.52it/s\u001b[A\n",
      "Training loss: 1.55e-01 lr: 4.29e-05:  14%|▏| 1960/13852 [07:19<43:51,  4.52it/s\u001b[A\n",
      "Training loss: 1.65e-01 lr: 4.29e-05:  14%|▏| 1961/13852 [07:19<43:49,  4.52it/s\u001b[A\n",
      "Training loss: 1.81e-01 lr: 4.29e-05:  14%|▏| 1962/13852 [07:19<43:48,  4.52it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 4.29e-05:  14%|▏| 1963/13852 [07:19<43:48,  4.52it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 4.29e-05:  14%|▏| 1964/13852 [07:20<43:47,  4.52it/s\u001b[A\n",
      "Training loss: 9.04e-02 lr: 4.29e-05:  14%|▏| 1965/13852 [07:20<43:49,  4.52it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.29e-05:  14%|▏| 1966/13852 [07:20<43:50,  4.52it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.29e-05:  14%|▏| 1967/13852 [07:20<43:59,  4.50it/s\u001b[A\n",
      "Training loss: 9.08e-02 lr: 4.29e-05:  14%|▏| 1968/13852 [07:21<44:06,  4.49it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 4.29e-05:  14%|▏| 1969/13852 [07:21<44:12,  4.48it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 4.29e-05:  14%|▏| 1970/13852 [07:21<43:53,  4.51it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 4.29e-05:  14%|▏| 1971/13852 [07:21<43:53,  4.51it/s\u001b[A\n",
      "Training loss: 9.44e-02 lr: 4.29e-05:  14%|▏| 1972/13852 [07:21<43:50,  4.52it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 4.29e-05:  14%|▏| 1973/13852 [07:22<44:03,  4.49it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.29e-05:  14%|▏| 1974/13852 [07:22<44:05,  4.49it/s\u001b[A\n",
      "Training loss: 8.80e-02 lr: 4.29e-05:  14%|▏| 1975/13852 [07:22<44:13,  4.48it/s\u001b[A\n",
      "Training loss: 7.00e-02 lr: 4.29e-05:  14%|▏| 1976/13852 [07:22<44:06,  4.49it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 4.29e-05:  14%|▏| 1977/13852 [07:23<43:59,  4.50it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 4.29e-05:  14%|▏| 1978/13852 [07:23<43:58,  4.50it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 4.29e-05:  14%|▏| 1979/13852 [07:23<44:00,  4.50it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 4.29e-05:  14%|▏| 1980/13852 [07:23<43:46,  4.52it/s\u001b[A\n",
      "Training loss: 4.01e-02 lr: 4.29e-05:  14%|▏| 1981/13852 [07:23<43:35,  4.54it/s\u001b[A\n",
      "Training loss: 3.80e-02 lr: 4.28e-05:  14%|▏| 1982/13852 [07:24<43:24,  4.56it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 4.28e-05:  14%|▏| 1983/13852 [07:24<43:38,  4.53it/s\u001b[A\n",
      "Training loss: 9.35e-02 lr: 4.28e-05:  14%|▏| 1984/13852 [07:24<43:39,  4.53it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 4.28e-05:  14%|▏| 1985/13852 [07:24<43:38,  4.53it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 4.28e-05:  14%|▏| 1986/13852 [07:25<43:33,  4.54it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.28e-05:  14%|▏| 1987/13852 [07:25<43:40,  4.53it/s\u001b[A\n",
      "Training loss: 7.95e-02 lr: 4.28e-05:  14%|▏| 1988/13852 [07:25<43:41,  4.53it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 4.28e-05:  14%|▏| 1989/13852 [07:25<43:41,  4.52it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 4.28e-05:  14%|▏| 1990/13852 [07:25<43:43,  4.52it/s\u001b[A\n",
      "Training loss: 8.40e-02 lr: 4.28e-05:  14%|▏| 1991/13852 [07:26<43:43,  4.52it/s\u001b[A\n",
      "Training loss: 1.44e-01 lr: 4.28e-05:  14%|▏| 1992/13852 [07:26<43:40,  4.53it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 4.28e-05:  14%|▏| 1993/13852 [07:26<43:31,  4.54it/s\u001b[A\n",
      "Training loss: 1.97e-01 lr: 4.28e-05:  14%|▏| 1994/13852 [07:26<43:24,  4.55it/s\u001b[A\n",
      "Training loss: 1.67e-01 lr: 4.28e-05:  14%|▏| 1995/13852 [07:27<43:43,  4.52it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 4.28e-05:  14%|▏| 1996/13852 [07:27<44:06,  4.48it/s\u001b[A\n",
      "Training loss: 9.10e-02 lr: 4.28e-05:  14%|▏| 1997/13852 [07:27<44:01,  4.49it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 4.28e-05:  14%|▏| 1998/13852 [07:27<43:54,  4.50it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.28e-05:  14%|▏| 1999/13852 [07:27<43:46,  4.51it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 4.28e-05:  14%|▏| 2000/13852 [07:28<43:44,  4.52it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 4.28e-05:  14%|▏| 2001/13852 [07:28<43:39,  4.52it/s\u001b[A\n",
      "Training loss: 1.57e-01 lr: 4.28e-05:  14%|▏| 2002/13852 [07:28<43:39,  4.52it/s\u001b[A\n",
      "Training loss: 1.81e-01 lr: 4.28e-05:  14%|▏| 2003/13852 [07:28<43:40,  4.52it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 4.28e-05:  14%|▏| 2004/13852 [07:29<43:38,  4.52it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.28e-05:  14%|▏| 2005/13852 [07:29<43:39,  4.52it/s\u001b[A\n",
      "Training loss: 9.37e-02 lr: 4.28e-05:  14%|▏| 2006/13852 [07:29<43:38,  4.52it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 4.28e-05:  14%|▏| 2007/13852 [07:29<43:34,  4.53it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 4.28e-05:  14%|▏| 2008/13852 [07:29<43:41,  4.52it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 4.28e-05:  15%|▏| 2009/13852 [07:30<43:40,  4.52it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.27e-05:  15%|▏| 2010/13852 [07:30<43:35,  4.53it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.27e-05:  15%|▏| 2011/13852 [07:30<43:28,  4.54it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 4.27e-05:  15%|▏| 2012/13852 [07:30<43:33,  4.53it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 4.27e-05:  15%|▏| 2013/13852 [07:31<43:34,  4.53it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.27e-05:  15%|▏| 2014/13852 [07:31<43:46,  4.51it/s\u001b[A\n",
      "Training loss: 8.83e-02 lr: 4.27e-05:  15%|▏| 2015/13852 [07:31<43:50,  4.50it/s\u001b[A\n",
      "Training loss: 1.44e-01 lr: 4.27e-05:  15%|▏| 2016/13852 [07:31<43:47,  4.50it/s\u001b[A\n",
      "Training loss: 1.90e-01 lr: 4.27e-05:  15%|▏| 2017/13852 [07:31<43:45,  4.51it/s\u001b[A\n",
      "Training loss: 1.72e-01 lr: 4.27e-05:  15%|▏| 2018/13852 [07:32<43:47,  4.50it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 4.27e-05:  15%|▏| 2019/13852 [07:32<43:29,  4.53it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.27e-05:  15%|▏| 2020/13852 [07:32<43:45,  4.51it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 4.27e-05:  15%|▏| 2021/13852 [07:32<43:44,  4.51it/s\u001b[A\n",
      "Training loss: 9.20e-02 lr: 4.27e-05:  15%|▏| 2022/13852 [07:33<43:39,  4.52it/s\u001b[A\n",
      "Training loss: 8.64e-02 lr: 4.27e-05:  15%|▏| 2023/13852 [07:33<43:38,  4.52it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 4.27e-05:  15%|▏| 2024/13852 [07:33<43:53,  4.49it/s\u001b[A\n",
      "Training loss: 9.93e-02 lr: 4.27e-05:  15%|▏| 2025/13852 [07:33<43:51,  4.49it/s\u001b[A\n",
      "Training loss: 8.18e-02 lr: 4.27e-05:  15%|▏| 2026/13852 [07:33<43:59,  4.48it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.27e-05:  15%|▏| 2027/13852 [07:34<44:01,  4.48it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.04e-01 lr: 4.27e-05:  15%|▏| 2028/13852 [07:34<43:56,  4.48it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.27e-05:  15%|▏| 2029/13852 [07:34<43:41,  4.51it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.27e-05:  15%|▏| 2030/13852 [07:34<43:28,  4.53it/s\u001b[A\n",
      "Training loss: 8.48e-02 lr: 4.27e-05:  15%|▏| 2031/13852 [07:35<43:18,  4.55it/s\u001b[A\n",
      "Training loss: 8.28e-02 lr: 4.27e-05:  15%|▏| 2032/13852 [07:35<43:13,  4.56it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 4.27e-05:  15%|▏| 2033/13852 [07:35<43:15,  4.55it/s\u001b[A\n",
      "Training loss: 7.30e-02 lr: 4.27e-05:  15%|▏| 2034/13852 [07:35<43:19,  4.55it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 4.27e-05:  15%|▏| 2035/13852 [07:35<43:22,  4.54it/s\u001b[A\n",
      "Training loss: 9.92e-02 lr: 4.27e-05:  15%|▏| 2036/13852 [07:36<43:22,  4.54it/s\u001b[A\n",
      "Training loss: 9.57e-02 lr: 4.27e-05:  15%|▏| 2037/13852 [07:36<43:27,  4.53it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 4.26e-05:  15%|▏| 2038/13852 [07:36<43:35,  4.52it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 4.26e-05:  15%|▏| 2039/13852 [07:36<43:34,  4.52it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 4.26e-05:  15%|▏| 2040/13852 [07:37<43:37,  4.51it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 4.26e-05:  15%|▏| 2041/13852 [07:37<44:05,  4.46it/s\u001b[A\n",
      "Training loss: 6.70e-02 lr: 4.26e-05:  15%|▏| 2042/13852 [07:37<44:06,  4.46it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 4.26e-05:  15%|▏| 2043/13852 [07:37<43:59,  4.47it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 4.26e-05:  15%|▏| 2044/13852 [07:37<44:54,  4.38it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 4.26e-05:  15%|▏| 2045/13852 [07:38<44:40,  4.40it/s\u001b[A\n",
      "Training loss: 4.80e-02 lr: 4.26e-05:  15%|▏| 2046/13852 [07:38<44:15,  4.45it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 4.26e-05:  15%|▏| 2047/13852 [07:38<44:06,  4.46it/s\u001b[A\n",
      "Training loss: 7.62e-02 lr: 4.26e-05:  15%|▏| 2048/13852 [07:38<44:00,  4.47it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 4.26e-05:  15%|▏| 2049/13852 [07:39<44:01,  4.47it/s\u001b[A\n",
      "Training loss: 1.61e-01 lr: 4.26e-05:  15%|▏| 2050/13852 [07:39<43:56,  4.48it/s\u001b[A\n",
      "Training loss: 1.56e-01 lr: 4.26e-05:  15%|▏| 2051/13852 [07:39<44:01,  4.47it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.26e-05:  15%|▏| 2052/13852 [07:39<43:47,  4.49it/s\u001b[A\n",
      "Training loss: 8.99e-02 lr: 4.26e-05:  15%|▏| 2053/13852 [07:39<43:32,  4.52it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 4.26e-05:  15%|▏| 2054/13852 [07:40<43:21,  4.54it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 4.26e-05:  15%|▏| 2055/13852 [07:40<43:42,  4.50it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 4.26e-05:  15%|▏| 2056/13852 [07:40<43:40,  4.50it/s\u001b[A\n",
      "Training loss: 6.20e-02 lr: 4.26e-05:  15%|▏| 2057/13852 [07:40<43:35,  4.51it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 4.26e-05:  15%|▏| 2058/13852 [07:41<43:33,  4.51it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 4.26e-05:  15%|▏| 2059/13852 [07:41<43:57,  4.47it/s\u001b[A\n",
      "Training loss: 7.17e-02 lr: 4.26e-05:  15%|▏| 2060/13852 [07:41<43:55,  4.47it/s\u001b[A\n",
      "Training loss: 1.56e-01 lr: 4.26e-05:  15%|▏| 2061/13852 [07:41<43:51,  4.48it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.26e-05:  15%|▏| 2062/13852 [07:41<43:44,  4.49it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.26e-05:  15%|▏| 2063/13852 [07:42<44:05,  4.46it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.26e-05:  15%|▏| 2064/13852 [07:42<43:48,  4.48it/s\u001b[A\n",
      "Training loss: 8.91e-02 lr: 4.25e-05:  15%|▏| 2065/13852 [07:42<43:34,  4.51it/s\u001b[A\n",
      "Training loss: 8.25e-02 lr: 4.25e-05:  15%|▏| 2066/13852 [07:42<43:48,  4.48it/s\u001b[A\n",
      "Training loss: 6.59e-02 lr: 4.25e-05:  15%|▏| 2067/13852 [07:43<43:44,  4.49it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 4.25e-05:  15%|▏| 2068/13852 [07:43<43:46,  4.49it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 4.25e-05:  15%|▏| 2069/13852 [07:43<43:43,  4.49it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 4.25e-05:  15%|▏| 2070/13852 [07:43<43:43,  4.49it/s\u001b[A\n",
      "Training loss: 3.34e-02 lr: 4.25e-05:  15%|▏| 2071/13852 [07:43<43:41,  4.49it/s\u001b[A\n",
      "Training loss: 3.19e-02 lr: 4.25e-05:  15%|▏| 2072/13852 [07:44<43:41,  4.49it/s\u001b[A\n",
      "Training loss: 2.75e-02 lr: 4.25e-05:  15%|▏| 2073/13852 [07:44<43:39,  4.50it/s\u001b[A\n",
      "Training loss: 2.91e-02 lr: 4.25e-05:  15%|▏| 2074/13852 [07:44<43:41,  4.49it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 4.25e-05:  15%|▏| 2075/13852 [07:44<43:39,  4.50it/s\u001b[A\n",
      "Training loss: 4.70e-02 lr: 4.25e-05:  15%|▏| 2076/13852 [07:45<43:24,  4.52it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 4.25e-05:  15%|▏| 2077/13852 [07:45<43:15,  4.54it/s\u001b[A\n",
      "Training loss: 4.03e-02 lr: 4.25e-05:  15%|▏| 2078/13852 [07:45<43:05,  4.55it/s\u001b[A\n",
      "Training loss: 4.43e-02 lr: 4.25e-05:  15%|▏| 2079/13852 [07:45<43:13,  4.54it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 4.25e-05:  15%|▏| 2080/13852 [07:45<43:14,  4.54it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 4.25e-05:  15%|▏| 2081/13852 [07:46<43:13,  4.54it/s\u001b[A\n",
      "Training loss: 8.76e-02 lr: 4.25e-05:  15%|▏| 2082/13852 [07:46<43:21,  4.52it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 4.25e-05:  15%|▏| 2083/13852 [07:46<43:24,  4.52it/s\u001b[A\n",
      "Training loss: 5.63e-02 lr: 4.25e-05:  15%|▏| 2084/13852 [07:46<43:21,  4.52it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 4.25e-05:  15%|▏| 2085/13852 [07:47<43:21,  4.52it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 4.25e-05:  15%|▏| 2086/13852 [07:47<43:39,  4.49it/s\u001b[A\n",
      "Training loss: 1.96e-01 lr: 4.25e-05:  15%|▏| 2087/13852 [07:47<43:37,  4.49it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 4.25e-05:  15%|▏| 2088/13852 [07:47<43:25,  4.51it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.25e-05:  15%|▏| 2089/13852 [07:47<43:21,  4.52it/s\u001b[A\n",
      "Training loss: 8.55e-02 lr: 4.25e-05:  15%|▏| 2090/13852 [07:48<43:16,  4.53it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 4.25e-05:  15%|▏| 2091/13852 [07:48<43:24,  4.51it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 4.25e-05:  15%|▏| 2092/13852 [07:48<43:25,  4.51it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 4.24e-05:  15%|▏| 2093/13852 [07:48<43:21,  4.52it/s\u001b[A\n",
      "Training loss: 6.68e-02 lr: 4.24e-05:  15%|▏| 2094/13852 [07:49<43:18,  4.52it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 4.24e-05:  15%|▏| 2095/13852 [07:49<43:27,  4.51it/s\u001b[A\n",
      "Training loss: 3.89e-02 lr: 4.24e-05:  15%|▏| 2096/13852 [07:49<43:24,  4.51it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 4.24e-05:  15%|▏| 2097/13852 [07:49<43:25,  4.51it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 4.24e-05:  15%|▏| 2098/13852 [07:49<43:30,  4.50it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 4.24e-05:  15%|▏| 2099/13852 [07:50<43:27,  4.51it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 4.24e-05:  15%|▏| 2100/13852 [07:50<43:14,  4.53it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.24e-05:  15%|▏| 2101/13852 [07:50<43:17,  4.52it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.24e-05:  15%|▏| 2102/13852 [07:50<43:14,  4.53it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.24e-05:  15%|▏| 2103/13852 [07:51<43:02,  4.55it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 4.24e-05:  15%|▏| 2104/13852 [07:51<43:15,  4.53it/s\u001b[A\n",
      "Training loss: 9.59e-02 lr: 4.24e-05:  15%|▏| 2105/13852 [07:51<43:23,  4.51it/s\u001b[A\n",
      "Training loss: 8.77e-02 lr: 4.24e-05:  15%|▏| 2106/13852 [07:51<43:19,  4.52it/s\u001b[A\n",
      "Training loss: 6.64e-02 lr: 4.24e-05:  15%|▏| 2107/13852 [07:51<43:19,  4.52it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 4.24e-05:  15%|▏| 2108/13852 [07:52<43:36,  4.49it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 4.24e-05:  15%|▏| 2109/13852 [07:52<43:50,  4.46it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 4.24e-05:  15%|▏| 2110/13852 [07:52<43:49,  4.47it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 4.24e-05:  15%|▏| 2111/13852 [07:52<43:46,  4.47it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.24e-05:  15%|▏| 2112/13852 [07:53<43:39,  4.48it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.24e-05:  15%|▏| 2113/13852 [07:53<43:25,  4.51it/s\u001b[A\n",
      "Training loss: 9.96e-02 lr: 4.24e-05:  15%|▏| 2114/13852 [07:53<43:12,  4.53it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 4.24e-05:  15%|▏| 2115/13852 [07:53<43:19,  4.51it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 4.24e-05:  15%|▏| 2116/13852 [07:53<43:21,  4.51it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 4.24e-05:  15%|▏| 2117/13852 [07:54<43:32,  4.49it/s\u001b[A\n",
      "Training loss: 5.57e-02 lr: 4.24e-05:  15%|▏| 2118/13852 [07:54<43:33,  4.49it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 4.24e-05:  15%|▏| 2119/13852 [07:54<43:43,  4.47it/s\u001b[A\n",
      "Training loss: 9.09e-02 lr: 4.24e-05:  15%|▏| 2120/13852 [07:54<43:35,  4.48it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 4.23e-05:  15%|▏| 2121/13852 [07:55<43:29,  4.49it/s\u001b[A\n",
      "Training loss: 6.06e-02 lr: 4.23e-05:  15%|▏| 2122/13852 [07:55<43:26,  4.50it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 4.23e-05:  15%|▏| 2123/13852 [07:55<43:24,  4.50it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 4.23e-05:  15%|▏| 2124/13852 [07:55<43:15,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.36e-02 lr: 4.23e-05:  15%|▏| 2125/13852 [07:55<43:02,  4.54it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 4.23e-05:  15%|▏| 2126/13852 [07:56<42:55,  4.55it/s\u001b[A\n",
      "Training loss: 7.77e-02 lr: 4.23e-05:  15%|▏| 2127/13852 [07:56<43:16,  4.52it/s\u001b[A\n",
      "Training loss: 8.97e-02 lr: 4.23e-05:  15%|▏| 2128/13852 [07:56<43:23,  4.50it/s\u001b[A\n",
      "Training loss: 7.42e-02 lr: 4.23e-05:  15%|▏| 2129/13852 [07:56<43:20,  4.51it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 4.23e-05:  15%|▏| 2130/13852 [07:57<43:22,  4.50it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 4.23e-05:  15%|▏| 2131/13852 [07:57<43:42,  4.47it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 4.23e-05:  15%|▏| 2132/13852 [07:57<43:40,  4.47it/s\u001b[A\n",
      "Training loss: 3.80e-02 lr: 4.23e-05:  15%|▏| 2133/13852 [07:57<43:46,  4.46it/s\u001b[A\n",
      "Training loss: 9.90e-02 lr: 4.23e-05:  15%|▏| 2134/13852 [07:57<43:38,  4.47it/s\u001b[A\n",
      "Training loss: 8.19e-02 lr: 4.23e-05:  15%|▏| 2135/13852 [07:58<43:28,  4.49it/s\u001b[A\n",
      "Training loss: 8.74e-02 lr: 4.23e-05:  15%|▏| 2136/13852 [07:58<43:13,  4.52it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 4.23e-05:  15%|▏| 2137/13852 [07:58<43:07,  4.53it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.23e-05:  15%|▏| 2138/13852 [07:58<43:30,  4.49it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 4.23e-05:  15%|▏| 2139/13852 [07:59<43:23,  4.50it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.23e-05:  15%|▏| 2140/13852 [07:59<43:24,  4.50it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 4.23e-05:  15%|▏| 2141/13852 [07:59<43:19,  4.51it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 4.23e-05:  15%|▏| 2142/13852 [07:59<43:38,  4.47it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 4.23e-05:  15%|▏| 2143/13852 [07:59<43:41,  4.47it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 4.23e-05:  15%|▏| 2144/13852 [08:00<43:36,  4.47it/s\u001b[A\n",
      "Training loss: 6.41e-02 lr: 4.23e-05:  15%|▏| 2145/13852 [08:00<43:30,  4.48it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 4.23e-05:  15%|▏| 2146/13852 [08:00<43:38,  4.47it/s\u001b[A\n",
      "Training loss: 6.57e-02 lr: 4.23e-05:  15%|▏| 2147/13852 [08:00<43:24,  4.49it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 4.22e-05:  16%|▏| 2148/13852 [08:01<43:10,  4.52it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 4.22e-05:  16%|▏| 2149/13852 [08:01<43:11,  4.52it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 4.22e-05:  16%|▏| 2150/13852 [08:01<43:19,  4.50it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.22e-05:  16%|▏| 2151/13852 [08:01<43:15,  4.51it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 4.22e-05:  16%|▏| 2152/13852 [08:01<43:16,  4.51it/s\u001b[A\n",
      "Training loss: 9.65e-02 lr: 4.22e-05:  16%|▏| 2153/13852 [08:02<43:30,  4.48it/s\u001b[A\n",
      "Training loss: 8.61e-02 lr: 4.22e-05:  16%|▏| 2154/13852 [08:02<43:33,  4.48it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 4.22e-05:  16%|▏| 2155/13852 [08:02<43:32,  4.48it/s\u001b[A\n",
      "Training loss: 6.64e-02 lr: 4.22e-05:  16%|▏| 2156/13852 [08:02<43:29,  4.48it/s\u001b[A\n",
      "Training loss: 8.79e-02 lr: 4.22e-05:  16%|▏| 2157/13852 [08:03<43:24,  4.49it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 4.22e-05:  16%|▏| 2158/13852 [08:03<43:20,  4.50it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.22e-05:  16%|▏| 2159/13852 [08:03<43:18,  4.50it/s\u001b[A\n",
      "Training loss: 9.01e-02 lr: 4.22e-05:  16%|▏| 2160/13852 [08:03<43:01,  4.53it/s\u001b[A\n",
      "Training loss: 7.28e-02 lr: 4.22e-05:  16%|▏| 2161/13852 [08:03<42:47,  4.55it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 4.22e-05:  16%|▏| 2162/13852 [08:04<43:14,  4.51it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 4.22e-05:  16%|▏| 2163/13852 [08:04<43:12,  4.51it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.22e-05:  16%|▏| 2164/13852 [08:04<43:15,  4.50it/s\u001b[A\n",
      "Training loss: 1.48e-01 lr: 4.22e-05:  16%|▏| 2165/13852 [08:04<43:18,  4.50it/s\u001b[A\n",
      "Training loss: 1.51e-01 lr: 4.22e-05:  16%|▏| 2166/13852 [08:05<43:17,  4.50it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.22e-05:  16%|▏| 2167/13852 [08:05<43:17,  4.50it/s\u001b[A\n",
      "Training loss: 9.17e-02 lr: 4.22e-05:  16%|▏| 2168/13852 [08:05<43:15,  4.50it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.22e-05:  16%|▏| 2169/13852 [08:05<43:17,  4.50it/s\u001b[A\n",
      "Training loss: 8.78e-02 lr: 4.22e-05:  16%|▏| 2170/13852 [08:05<43:27,  4.48it/s\u001b[A\n",
      "Training loss: 8.86e-02 lr: 4.22e-05:  16%|▏| 2171/13852 [08:06<43:14,  4.50it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 4.22e-05:  16%|▏| 2172/13852 [08:06<42:59,  4.53it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 4.22e-05:  16%|▏| 2173/13852 [08:06<43:02,  4.52it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 4.22e-05:  16%|▏| 2174/13852 [08:06<43:01,  4.52it/s\u001b[A\n",
      "Training loss: 4.78e-02 lr: 4.22e-05:  16%|▏| 2175/13852 [08:07<43:02,  4.52it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 4.21e-05:  16%|▏| 2176/13852 [08:07<46:11,  4.21it/s\u001b[A\n",
      "Training loss: 8.86e-02 lr: 4.21e-05:  16%|▏| 2177/13852 [08:07<46:39,  4.17it/s\u001b[A\n",
      "Training loss: 7.98e-02 lr: 4.21e-05:  16%|▏| 2178/13852 [08:07<47:01,  4.14it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 4.21e-05:  16%|▏| 2179/13852 [08:08<46:51,  4.15it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 4.21e-05:  16%|▏| 2180/13852 [08:08<46:50,  4.15it/s\u001b[A\n",
      "Training loss: 9.57e-02 lr: 4.21e-05:  16%|▏| 2181/13852 [08:08<46:42,  4.16it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 4.21e-05:  16%|▏| 2182/13852 [08:08<46:40,  4.17it/s\u001b[A\n",
      "Training loss: 8.22e-02 lr: 4.21e-05:  16%|▏| 2183/13852 [08:09<46:38,  4.17it/s\u001b[A\n",
      "Training loss: 7.84e-02 lr: 4.21e-05:  16%|▏| 2184/13852 [08:09<46:27,  4.19it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.21e-05:  16%|▏| 2185/13852 [08:09<46:17,  4.20it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 4.21e-05:  16%|▏| 2186/13852 [08:09<46:27,  4.19it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 4.21e-05:  16%|▏| 2187/13852 [08:09<46:30,  4.18it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 4.21e-05:  16%|▏| 2188/13852 [08:10<46:32,  4.18it/s\u001b[A\n",
      "Training loss: 8.92e-02 lr: 4.21e-05:  16%|▏| 2189/13852 [08:10<46:30,  4.18it/s\u001b[A\n",
      "Training loss: 7.79e-02 lr: 4.21e-05:  16%|▏| 2190/13852 [08:10<46:19,  4.20it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 4.21e-05:  16%|▏| 2191/13852 [08:10<46:04,  4.22it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 4.21e-05:  16%|▏| 2192/13852 [08:11<46:09,  4.21it/s\u001b[A\n",
      "Training loss: 8.77e-02 lr: 4.21e-05:  16%|▏| 2193/13852 [08:11<46:36,  4.17it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 4.21e-05:  16%|▏| 2194/13852 [08:11<46:38,  4.17it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 4.21e-05:  16%|▏| 2195/13852 [08:11<46:34,  4.17it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 4.21e-05:  16%|▏| 2196/13852 [08:12<46:26,  4.18it/s\u001b[A\n",
      "Training loss: 7.19e-02 lr: 4.21e-05:  16%|▏| 2197/13852 [08:12<46:25,  4.18it/s\u001b[A\n",
      "Training loss: 5.43e-02 lr: 4.21e-05:  16%|▏| 2198/13852 [08:12<46:30,  4.18it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 4.21e-05:  16%|▏| 2199/13852 [08:12<46:23,  4.19it/s\u001b[A\n",
      "Training loss: 4.29e-02 lr: 4.21e-05:  16%|▏| 2200/13852 [08:13<46:23,  4.19it/s\u001b[A\n",
      "Training loss: 5.07e-02 lr: 4.21e-05:  16%|▏| 2201/13852 [08:13<46:27,  4.18it/s\u001b[A\n",
      "Training loss: 7.93e-02 lr: 4.21e-05:  16%|▏| 2202/13852 [08:13<46:30,  4.17it/s\u001b[A\n",
      "Training loss: 6.02e-02 lr: 4.21e-05:  16%|▏| 2203/13852 [08:13<46:21,  4.19it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 4.20e-05:  16%|▏| 2204/13852 [08:14<46:27,  4.18it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 4.20e-05:  16%|▏| 2205/13852 [08:14<46:44,  4.15it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 4.20e-05:  16%|▏| 2206/13852 [08:14<46:35,  4.17it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 4.20e-05:  16%|▏| 2207/13852 [08:14<46:33,  4.17it/s\u001b[A\n",
      "Training loss: 5.63e-02 lr: 4.20e-05:  16%|▏| 2208/13852 [08:14<46:24,  4.18it/s\u001b[A\n",
      "Training loss: 7.98e-02 lr: 4.20e-05:  16%|▏| 2209/13852 [08:15<46:32,  4.17it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 4.20e-05:  16%|▏| 2210/13852 [08:15<46:30,  4.17it/s\u001b[A\n",
      "Training loss: 9.67e-02 lr: 4.20e-05:  16%|▏| 2211/13852 [08:15<46:26,  4.18it/s\u001b[A\n",
      "Training loss: 8.46e-02 lr: 4.20e-05:  16%|▏| 2212/13852 [08:15<46:23,  4.18it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.20e-05:  16%|▏| 2213/13852 [08:16<46:22,  4.18it/s\u001b[A\n",
      "Training loss: 7.53e-02 lr: 4.20e-05:  16%|▏| 2214/13852 [08:16<46:10,  4.20it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 4.20e-05:  16%|▏| 2215/13852 [08:16<45:06,  4.30it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 4.20e-05:  16%|▏| 2216/13852 [08:16<44:21,  4.37it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 4.20e-05:  16%|▏| 2217/13852 [08:17<43:51,  4.42it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.20e-05:  16%|▏| 2218/13852 [08:17<43:51,  4.42it/s\u001b[A\n",
      "Training loss: 9.57e-02 lr: 4.20e-05:  16%|▏| 2219/13852 [08:17<43:31,  4.46it/s\u001b[A\n",
      "Training loss: 6.93e-02 lr: 4.20e-05:  16%|▏| 2220/13852 [08:17<43:17,  4.48it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 4.20e-05:  16%|▏| 2221/13852 [08:17<43:07,  4.49it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.03e-02 lr: 4.20e-05:  16%|▏| 2222/13852 [08:18<42:57,  4.51it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 4.20e-05:  16%|▏| 2223/13852 [08:18<42:51,  4.52it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 4.20e-05:  16%|▏| 2224/13852 [08:18<42:55,  4.52it/s\u001b[A\n",
      "Training loss: 3.17e-02 lr: 4.20e-05:  16%|▏| 2225/13852 [08:18<42:45,  4.53it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 4.20e-05:  16%|▏| 2226/13852 [08:19<42:28,  4.56it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 4.20e-05:  16%|▏| 2227/13852 [08:19<42:21,  4.57it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.20e-05:  16%|▏| 2228/13852 [08:19<42:48,  4.53it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 4.20e-05:  16%|▏| 2229/13852 [08:19<42:47,  4.53it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 4.20e-05:  16%|▏| 2230/13852 [08:19<42:44,  4.53it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.20e-05:  16%|▏| 2231/13852 [08:20<42:45,  4.53it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.19e-05:  16%|▏| 2232/13852 [08:20<42:40,  4.54it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 4.19e-05:  16%|▏| 2233/13852 [08:20<42:46,  4.53it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 4.19e-05:  16%|▏| 2234/13852 [08:20<42:47,  4.52it/s\u001b[A\n",
      "Training loss: 1.54e-01 lr: 4.19e-05:  16%|▏| 2235/13852 [08:21<42:49,  4.52it/s\u001b[A\n",
      "Training loss: 1.52e-01 lr: 4.19e-05:  16%|▏| 2236/13852 [08:21<42:55,  4.51it/s\u001b[A\n",
      "Training loss: 1.57e-01 lr: 4.19e-05:  16%|▏| 2237/13852 [08:21<42:57,  4.51it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.19e-05:  16%|▏| 2238/13852 [08:21<42:56,  4.51it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 4.19e-05:  16%|▏| 2239/13852 [08:21<42:43,  4.53it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.19e-05:  16%|▏| 2240/13852 [08:22<42:43,  4.53it/s\u001b[A\n",
      "Training loss: 9.02e-02 lr: 4.19e-05:  16%|▏| 2241/13852 [08:22<42:53,  4.51it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 4.19e-05:  16%|▏| 2242/13852 [08:22<42:59,  4.50it/s\u001b[A\n",
      "Training loss: 9.95e-02 lr: 4.19e-05:  16%|▏| 2243/13852 [08:22<42:55,  4.51it/s\u001b[A\n",
      "Training loss: 7.79e-02 lr: 4.19e-05:  16%|▏| 2244/13852 [08:23<42:46,  4.52it/s\u001b[A\n",
      "Training loss: 8.99e-02 lr: 4.19e-05:  16%|▏| 2245/13852 [08:23<42:46,  4.52it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 4.19e-05:  16%|▏| 2246/13852 [08:23<42:48,  4.52it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 4.19e-05:  16%|▏| 2247/13852 [08:23<42:46,  4.52it/s\u001b[A\n",
      "Training loss: 7.58e-02 lr: 4.19e-05:  16%|▏| 2248/13852 [08:23<42:44,  4.53it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.19e-05:  16%|▏| 2249/13852 [08:24<42:46,  4.52it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.19e-05:  16%|▏| 2250/13852 [08:24<42:50,  4.51it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.19e-05:  16%|▏| 2251/13852 [08:24<42:44,  4.52it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.19e-05:  16%|▏| 2252/13852 [08:24<42:41,  4.53it/s\u001b[A\n",
      "Training loss: 9.24e-02 lr: 4.19e-05:  16%|▏| 2253/13852 [08:25<43:06,  4.48it/s\u001b[A\n",
      "Training loss: 9.18e-02 lr: 4.19e-05:  16%|▏| 2254/13852 [08:25<42:55,  4.50it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 4.19e-05:  16%|▏| 2255/13852 [08:25<42:47,  4.52it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 4.19e-05:  16%|▏| 2256/13852 [08:25<42:44,  4.52it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.19e-05:  16%|▏| 2257/13852 [08:25<42:47,  4.52it/s\u001b[A\n",
      "Training loss: 1.48e-01 lr: 4.19e-05:  16%|▏| 2258/13852 [08:26<42:54,  4.50it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.18e-05:  16%|▏| 2259/13852 [08:26<42:46,  4.52it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.18e-05:  16%|▏| 2260/13852 [08:26<42:55,  4.50it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.18e-05:  16%|▏| 2261/13852 [08:26<42:50,  4.51it/s\u001b[A\n",
      "Training loss: 9.47e-02 lr: 4.18e-05:  16%|▏| 2262/13852 [08:27<42:45,  4.52it/s\u001b[A\n",
      "Training loss: 8.37e-02 lr: 4.18e-05:  16%|▏| 2263/13852 [08:27<42:51,  4.51it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 4.18e-05:  16%|▏| 2264/13852 [08:27<42:36,  4.53it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.18e-05:  16%|▏| 2265/13852 [08:27<42:26,  4.55it/s\u001b[A\n",
      "Training loss: 9.83e-02 lr: 4.18e-05:  16%|▏| 2266/13852 [08:27<42:28,  4.55it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 4.18e-05:  16%|▏| 2267/13852 [08:28<42:33,  4.54it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 4.18e-05:  16%|▏| 2268/13852 [08:28<42:34,  4.54it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 4.18e-05:  16%|▏| 2269/13852 [08:28<42:36,  4.53it/s\u001b[A\n",
      "Training loss: 7.33e-02 lr: 4.18e-05:  16%|▏| 2270/13852 [08:28<42:39,  4.53it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 4.18e-05:  16%|▏| 2271/13852 [08:29<42:36,  4.53it/s\u001b[A\n",
      "Training loss: 9.83e-02 lr: 4.18e-05:  16%|▏| 2272/13852 [08:29<42:45,  4.51it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.18e-05:  16%|▏| 2273/13852 [08:29<42:44,  4.51it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.18e-05:  16%|▏| 2274/13852 [08:29<42:44,  4.52it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.18e-05:  16%|▏| 2275/13852 [08:29<42:45,  4.51it/s\u001b[A\n",
      "Training loss: 8.68e-02 lr: 4.18e-05:  16%|▏| 2276/13852 [08:30<42:35,  4.53it/s\u001b[A\n",
      "Training loss: 6.78e-02 lr: 4.18e-05:  16%|▏| 2277/13852 [08:30<42:22,  4.55it/s\u001b[A\n",
      "Training loss: 8.06e-02 lr: 4.18e-05:  16%|▏| 2278/13852 [08:30<42:15,  4.57it/s\u001b[A\n",
      "Training loss: 7.28e-02 lr: 4.18e-05:  16%|▏| 2279/13852 [08:30<42:26,  4.54it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.18e-05:  16%|▏| 2280/13852 [08:31<42:27,  4.54it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 4.18e-05:  16%|▏| 2281/13852 [08:31<42:36,  4.53it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 4.18e-05:  16%|▏| 2282/13852 [08:31<42:48,  4.50it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.18e-05:  16%|▏| 2283/13852 [08:31<42:46,  4.51it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.18e-05:  16%|▏| 2284/13852 [08:31<42:42,  4.51it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.18e-05:  16%|▏| 2285/13852 [08:32<42:41,  4.52it/s\u001b[A\n",
      "Training loss: 9.17e-02 lr: 4.18e-05:  17%|▏| 2286/13852 [08:32<42:46,  4.51it/s\u001b[A\n",
      "Training loss: 8.74e-02 lr: 4.17e-05:  17%|▏| 2287/13852 [08:32<42:55,  4.49it/s\u001b[A\n",
      "Training loss: 7.37e-02 lr: 4.17e-05:  17%|▏| 2288/13852 [08:32<42:40,  4.52it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 4.17e-05:  17%|▏| 2289/13852 [08:33<42:25,  4.54it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 4.17e-05:  17%|▏| 2290/13852 [08:33<42:21,  4.55it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 4.17e-05:  17%|▏| 2291/13852 [08:33<42:42,  4.51it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 4.17e-05:  17%|▏| 2292/13852 [08:33<42:38,  4.52it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 4.17e-05:  17%|▏| 2293/13852 [08:33<42:36,  4.52it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 4.17e-05:  17%|▏| 2294/13852 [08:34<42:33,  4.53it/s\u001b[A\n",
      "Training loss: 8.74e-02 lr: 4.17e-05:  17%|▏| 2295/13852 [08:34<42:36,  4.52it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 4.17e-05:  17%|▏| 2296/13852 [08:34<42:35,  4.52it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 4.17e-05:  17%|▏| 2297/13852 [08:34<42:35,  4.52it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 4.17e-05:  17%|▏| 2298/13852 [08:34<42:33,  4.52it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 4.17e-05:  17%|▏| 2299/13852 [08:35<42:31,  4.53it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 4.17e-05:  17%|▏| 2300/13852 [08:35<42:30,  4.53it/s\u001b[A\n",
      "Training loss: 9.04e-02 lr: 4.17e-05:  17%|▏| 2301/13852 [08:35<42:18,  4.55it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 4.17e-05:  17%|▏| 2302/13852 [08:35<42:13,  4.56it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.17e-05:  17%|▏| 2303/13852 [08:36<42:06,  4.57it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 4.17e-05:  17%|▏| 2304/13852 [08:36<42:00,  4.58it/s\u001b[A\n",
      "Training loss: 6.61e-02 lr: 4.17e-05:  17%|▏| 2305/13852 [08:36<42:08,  4.57it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 4.17e-05:  17%|▏| 2306/13852 [08:36<42:13,  4.56it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 4.17e-05:  17%|▏| 2307/13852 [08:36<42:15,  4.55it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 4.17e-05:  17%|▏| 2308/13852 [08:37<42:34,  4.52it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.17e-05:  17%|▏| 2309/13852 [08:37<42:51,  4.49it/s\u001b[A\n",
      "Training loss: 9.86e-02 lr: 4.17e-05:  17%|▏| 2310/13852 [08:37<42:53,  4.49it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.17e-05:  17%|▏| 2311/13852 [08:37<43:05,  4.46it/s\u001b[A\n",
      "Training loss: 7.76e-02 lr: 4.17e-05:  17%|▏| 2312/13852 [08:38<42:59,  4.47it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 4.17e-05:  17%|▏| 2313/13852 [08:38<42:53,  4.48it/s\u001b[A\n",
      "Training loss: 7.35e-02 lr: 4.17e-05:  17%|▏| 2314/13852 [08:38<42:37,  4.51it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.16e-05:  17%|▏| 2315/13852 [08:38<42:19,  4.54it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.16e-05:  17%|▏| 2316/13852 [08:38<42:15,  4.55it/s\u001b[A\n",
      "Training loss: 8.10e-02 lr: 4.16e-05:  17%|▏| 2317/13852 [08:39<42:16,  4.55it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 4.16e-05:  17%|▏| 2318/13852 [08:39<42:16,  4.55it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.25e-01 lr: 4.16e-05:  17%|▏| 2319/13852 [08:39<42:14,  4.55it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.16e-05:  17%|▏| 2320/13852 [08:39<42:20,  4.54it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.16e-05:  17%|▏| 2321/13852 [08:40<42:19,  4.54it/s\u001b[A\n",
      "Training loss: 9.37e-02 lr: 4.16e-05:  17%|▏| 2322/13852 [08:40<42:20,  4.54it/s\u001b[A\n",
      "Training loss: 9.05e-02 lr: 4.16e-05:  17%|▏| 2323/13852 [08:40<42:25,  4.53it/s\u001b[A\n",
      "Training loss: 6.78e-02 lr: 4.16e-05:  17%|▏| 2324/13852 [08:40<42:29,  4.52it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 4.16e-05:  17%|▏| 2325/13852 [08:40<42:30,  4.52it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.16e-05:  17%|▏| 2326/13852 [08:41<42:27,  4.52it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.16e-05:  17%|▏| 2327/13852 [08:41<42:29,  4.52it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.16e-05:  17%|▏| 2328/13852 [08:41<42:16,  4.54it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.16e-05:  17%|▏| 2329/13852 [08:41<42:38,  4.50it/s\u001b[A\n",
      "Training loss: 9.60e-02 lr: 4.16e-05:  17%|▏| 2330/13852 [08:42<42:31,  4.52it/s\u001b[A\n",
      "Training loss: 8.63e-02 lr: 4.16e-05:  17%|▏| 2331/13852 [08:42<42:40,  4.50it/s\u001b[A\n",
      "Training loss: 9.19e-02 lr: 4.16e-05:  17%|▏| 2332/13852 [08:42<42:35,  4.51it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.16e-05:  17%|▏| 2333/13852 [08:42<42:29,  4.52it/s\u001b[A\n",
      "Training loss: 7.78e-02 lr: 4.16e-05:  17%|▏| 2334/13852 [08:42<42:25,  4.52it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.16e-05:  17%|▏| 2335/13852 [08:43<42:23,  4.53it/s\u001b[A\n",
      "Training loss: 8.35e-02 lr: 4.16e-05:  17%|▏| 2336/13852 [08:43<42:24,  4.53it/s\u001b[A\n",
      "Training loss: 7.61e-02 lr: 4.16e-05:  17%|▏| 2337/13852 [08:43<42:23,  4.53it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 4.16e-05:  17%|▏| 2338/13852 [08:43<42:24,  4.52it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 4.16e-05:  17%|▏| 2339/13852 [08:44<42:30,  4.51it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 4.16e-05:  17%|▏| 2340/13852 [08:44<42:17,  4.54it/s\u001b[A\n",
      "Training loss: 9.05e-02 lr: 4.16e-05:  17%|▏| 2341/13852 [08:44<42:18,  4.53it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.15e-05:  17%|▏| 2342/13852 [08:44<42:24,  4.52it/s\u001b[A\n",
      "Training loss: 9.20e-02 lr: 4.15e-05:  17%|▏| 2343/13852 [08:44<42:20,  4.53it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 4.15e-05:  17%|▏| 2344/13852 [08:45<42:18,  4.53it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 4.15e-05:  17%|▏| 2345/13852 [08:45<42:15,  4.54it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 4.15e-05:  17%|▏| 2346/13852 [08:45<42:24,  4.52it/s\u001b[A\n",
      "Training loss: 8.03e-02 lr: 4.15e-05:  17%|▏| 2347/13852 [08:45<42:24,  4.52it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 4.15e-05:  17%|▏| 2348/13852 [08:46<42:25,  4.52it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 4.15e-05:  17%|▏| 2349/13852 [08:46<42:27,  4.52it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 4.15e-05:  17%|▏| 2350/13852 [08:46<42:27,  4.52it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 4.15e-05:  17%|▏| 2351/13852 [08:46<42:29,  4.51it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.15e-05:  17%|▏| 2352/13852 [08:46<42:17,  4.53it/s\u001b[A\n",
      "Training loss: 9.98e-02 lr: 4.15e-05:  17%|▏| 2353/13852 [08:47<42:11,  4.54it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.15e-05:  17%|▏| 2354/13852 [08:47<42:44,  4.48it/s\u001b[A\n",
      "Training loss: 9.24e-02 lr: 4.15e-05:  17%|▏| 2355/13852 [08:47<42:39,  4.49it/s\u001b[A\n",
      "Training loss: 7.66e-02 lr: 4.15e-05:  17%|▏| 2356/13852 [08:47<42:30,  4.51it/s\u001b[A\n",
      "Training loss: 7.73e-02 lr: 4.15e-05:  17%|▏| 2357/13852 [08:48<42:27,  4.51it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 4.15e-05:  17%|▏| 2358/13852 [08:48<42:26,  4.51it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 4.15e-05:  17%|▏| 2359/13852 [08:48<42:33,  4.50it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 4.15e-05:  17%|▏| 2360/13852 [08:48<42:28,  4.51it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 4.15e-05:  17%|▏| 2361/13852 [08:48<42:24,  4.52it/s\u001b[A\n",
      "Training loss: 8.97e-02 lr: 4.15e-05:  17%|▏| 2362/13852 [08:49<42:25,  4.51it/s\u001b[A\n",
      "Training loss: 1.82e-01 lr: 4.15e-05:  17%|▏| 2363/13852 [08:49<42:24,  4.52it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 4.15e-05:  17%|▏| 2364/13852 [08:49<42:10,  4.54it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 4.15e-05:  17%|▏| 2365/13852 [08:49<42:05,  4.55it/s\u001b[A\n",
      "Training loss: 8.97e-02 lr: 4.15e-05:  17%|▏| 2366/13852 [08:50<43:09,  4.44it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 4.15e-05:  17%|▏| 2367/13852 [08:50<42:54,  4.46it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 4.15e-05:  17%|▏| 2368/13852 [08:50<42:43,  4.48it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 4.15e-05:  17%|▏| 2369/13852 [08:50<42:38,  4.49it/s\u001b[A\n",
      "Training loss: 1.48e-01 lr: 4.14e-05:  17%|▏| 2370/13852 [08:50<42:37,  4.49it/s\u001b[A\n",
      "Training loss: 1.70e-01 lr: 4.14e-05:  17%|▏| 2371/13852 [08:51<42:30,  4.50it/s\u001b[A\n",
      "Training loss: 1.41e-01 lr: 4.14e-05:  17%|▏| 2372/13852 [08:51<42:55,  4.46it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.14e-05:  17%|▏| 2373/13852 [08:51<42:43,  4.48it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 4.14e-05:  17%|▏| 2374/13852 [08:51<42:37,  4.49it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.14e-05:  17%|▏| 2375/13852 [08:52<42:28,  4.50it/s\u001b[A\n",
      "Training loss: 7.60e-02 lr: 4.14e-05:  17%|▏| 2376/13852 [08:52<42:45,  4.47it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 4.14e-05:  17%|▏| 2377/13852 [08:52<42:22,  4.51it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 4.14e-05:  17%|▏| 2378/13852 [08:52<42:25,  4.51it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 4.14e-05:  17%|▏| 2379/13852 [08:52<42:21,  4.51it/s\u001b[A\n",
      "Training loss: 6.69e-02 lr: 4.14e-05:  17%|▏| 2380/13852 [08:53<42:14,  4.53it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 4.14e-05:  17%|▏| 2381/13852 [08:53<42:11,  4.53it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 4.14e-05:  17%|▏| 2382/13852 [08:53<42:14,  4.53it/s\u001b[A\n",
      "Training loss: 6.70e-02 lr: 4.14e-05:  17%|▏| 2383/13852 [08:53<43:18,  4.41it/s\u001b[A\n",
      "Training loss: 7.41e-02 lr: 4.14e-05:  17%|▏| 2384/13852 [08:54<43:02,  4.44it/s\u001b[A\n",
      "Training loss: 6.06e-02 lr: 4.14e-05:  17%|▏| 2385/13852 [08:54<42:51,  4.46it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 4.14e-05:  17%|▏| 2386/13852 [08:54<42:52,  4.46it/s\u001b[A\n",
      "Training loss: 6.93e-02 lr: 4.14e-05:  17%|▏| 2387/13852 [08:54<42:33,  4.49it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.14e-05:  17%|▏| 2388/13852 [08:54<42:15,  4.52it/s\u001b[A\n",
      "Training loss: 8.85e-02 lr: 4.14e-05:  17%|▏| 2389/13852 [08:55<42:25,  4.50it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 4.14e-05:  17%|▏| 2390/13852 [08:55<42:21,  4.51it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 4.14e-05:  17%|▏| 2391/13852 [08:55<42:17,  4.52it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 4.14e-05:  17%|▏| 2392/13852 [08:55<42:13,  4.52it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 4.14e-05:  17%|▏| 2393/13852 [08:56<42:12,  4.53it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 4.14e-05:  17%|▏| 2394/13852 [08:56<42:17,  4.51it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 4.14e-05:  17%|▏| 2395/13852 [08:56<42:18,  4.51it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 4.14e-05:  17%|▏| 2396/13852 [08:56<42:21,  4.51it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 4.14e-05:  17%|▏| 2397/13852 [08:56<42:19,  4.51it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 4.13e-05:  17%|▏| 2398/13852 [08:57<42:28,  4.49it/s\u001b[A\n",
      "Training loss: 3.33e-02 lr: 4.13e-05:  17%|▏| 2399/13852 [08:57<42:27,  4.50it/s\u001b[A\n",
      "Training loss: 6.22e-02 lr: 4.13e-05:  17%|▏| 2400/13852 [08:57<42:10,  4.53it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 4.13e-05:  17%|▏| 2401/13852 [08:57<42:27,  4.50it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.13e-05:  17%|▏| 2402/13852 [08:58<42:21,  4.50it/s\u001b[A\n",
      "Training loss: 8.81e-02 lr: 4.13e-05:  17%|▏| 2403/13852 [08:58<42:18,  4.51it/s\u001b[A\n",
      "Training loss: 6.25e-02 lr: 4.13e-05:  17%|▏| 2404/13852 [08:58<42:16,  4.51it/s\u001b[A\n",
      "Training loss: 4.45e-02 lr: 4.13e-05:  17%|▏| 2405/13852 [08:58<42:18,  4.51it/s\u001b[A\n",
      "Training loss: 6.88e-02 lr: 4.13e-05:  17%|▏| 2406/13852 [08:58<42:14,  4.52it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 4.13e-05:  17%|▏| 2407/13852 [08:59<42:11,  4.52it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 4.13e-05:  17%|▏| 2408/13852 [08:59<42:14,  4.51it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 4.13e-05:  17%|▏| 2409/13852 [08:59<42:15,  4.51it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 4.13e-05:  17%|▏| 2410/13852 [08:59<42:26,  4.49it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 4.13e-05:  17%|▏| 2411/13852 [09:00<42:19,  4.51it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 4.13e-05:  17%|▏| 2412/13852 [09:00<42:03,  4.53it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 4.13e-05:  17%|▏| 2413/13852 [09:00<41:54,  4.55it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 4.13e-05:  17%|▏| 2414/13852 [09:00<42:07,  4.53it/s\u001b[A\n",
      "Training loss: 4.22e-02 lr: 4.13e-05:  17%|▏| 2415/13852 [09:00<42:07,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.15e-02 lr: 4.13e-05:  17%|▏| 2416/13852 [09:01<42:06,  4.53it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 4.13e-05:  17%|▏| 2417/13852 [09:01<42:23,  4.50it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 4.13e-05:  17%|▏| 2418/13852 [09:01<42:24,  4.49it/s\u001b[A\n",
      "Training loss: 3.94e-02 lr: 4.13e-05:  17%|▏| 2419/13852 [09:01<42:21,  4.50it/s\u001b[A\n",
      "Training loss: 3.31e-02 lr: 4.13e-05:  17%|▏| 2420/13852 [09:02<42:17,  4.50it/s\u001b[A\n",
      "Training loss: 2.35e-02 lr: 4.13e-05:  17%|▏| 2421/13852 [09:02<42:45,  4.46it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 4.13e-05:  17%|▏| 2422/13852 [09:02<42:38,  4.47it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 4.13e-05:  17%|▏| 2423/13852 [09:02<42:22,  4.49it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 4.13e-05:  17%|▏| 2424/13852 [09:02<42:06,  4.52it/s\u001b[A\n",
      "Training loss: 9.77e-02 lr: 4.12e-05:  18%|▏| 2425/13852 [09:03<42:20,  4.50it/s\u001b[A\n",
      "Training loss: 9.51e-02 lr: 4.12e-05:  18%|▏| 2426/13852 [09:03<42:15,  4.51it/s\u001b[A\n",
      "Training loss: 8.45e-02 lr: 4.12e-05:  18%|▏| 2427/13852 [09:03<42:21,  4.50it/s\u001b[A\n",
      "Training loss: 9.66e-02 lr: 4.12e-05:  18%|▏| 2428/13852 [09:03<42:13,  4.51it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 4.12e-05:  18%|▏| 2429/13852 [09:04<42:08,  4.52it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 4.12e-05:  18%|▏| 2430/13852 [09:04<42:06,  4.52it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 4.12e-05:  18%|▏| 2431/13852 [09:04<42:06,  4.52it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 4.12e-05:  18%|▏| 2432/13852 [09:04<42:17,  4.50it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 4.12e-05:  18%|▏| 2433/13852 [09:04<42:19,  4.50it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 4.12e-05:  18%|▏| 2434/13852 [09:05<42:11,  4.51it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 4.12e-05:  18%|▏| 2435/13852 [09:05<41:56,  4.54it/s\u001b[A\n",
      "Training loss: 9.02e-02 lr: 4.12e-05:  18%|▏| 2436/13852 [09:05<41:48,  4.55it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 4.12e-05:  18%|▏| 2437/13852 [09:05<42:15,  4.50it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 4.12e-05:  18%|▏| 2438/13852 [09:06<42:08,  4.51it/s\u001b[A\n",
      "Training loss: 8.55e-02 lr: 4.12e-05:  18%|▏| 2439/13852 [09:06<42:07,  4.51it/s\u001b[A\n",
      "Training loss: 7.27e-02 lr: 4.12e-05:  18%|▏| 2440/13852 [09:06<42:03,  4.52it/s\u001b[A\n",
      "Training loss: 6.20e-02 lr: 4.12e-05:  18%|▏| 2441/13852 [09:06<41:58,  4.53it/s\u001b[A\n",
      "Training loss: 5.40e-02 lr: 4.12e-05:  18%|▏| 2442/13852 [09:06<42:01,  4.53it/s\u001b[A\n",
      "Training loss: 4.86e-02 lr: 4.12e-05:  18%|▏| 2443/13852 [09:07<42:03,  4.52it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 4.12e-05:  18%|▏| 2444/13852 [09:07<42:36,  4.46it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 4.12e-05:  18%|▏| 2445/13852 [09:07<42:39,  4.46it/s\u001b[A\n",
      "Training loss: 6.09e-02 lr: 4.12e-05:  18%|▏| 2446/13852 [09:07<42:46,  4.44it/s\u001b[A\n",
      "Training loss: 5.28e-02 lr: 4.12e-05:  18%|▏| 2447/13852 [09:08<42:35,  4.46it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 4.12e-05:  18%|▏| 2448/13852 [09:08<42:18,  4.49it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 4.12e-05:  18%|▏| 2449/13852 [09:08<42:18,  4.49it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 4.12e-05:  18%|▏| 2450/13852 [09:08<42:14,  4.50it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 4.12e-05:  18%|▏| 2451/13852 [09:08<42:08,  4.51it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 4.12e-05:  18%|▏| 2452/13852 [09:09<42:02,  4.52it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 4.11e-05:  18%|▏| 2453/13852 [09:09<42:06,  4.51it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 4.11e-05:  18%|▏| 2454/13852 [09:09<42:03,  4.52it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 4.11e-05:  18%|▏| 2455/13852 [09:09<42:02,  4.52it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 4.11e-05:  18%|▏| 2456/13852 [09:10<42:06,  4.51it/s\u001b[A\n",
      "Training loss: 9.77e-02 lr: 4.11e-05:  18%|▏| 2457/13852 [09:10<42:07,  4.51it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.11e-05:  18%|▏| 2458/13852 [09:10<42:04,  4.51it/s\u001b[A\n",
      "Training loss: 8.18e-02 lr: 4.11e-05:  18%|▏| 2459/13852 [09:10<41:57,  4.53it/s\u001b[A\n",
      "Training loss: 9.05e-02 lr: 4.11e-05:  18%|▏| 2460/13852 [09:10<41:48,  4.54it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 4.11e-05:  18%|▏| 2461/13852 [09:11<42:09,  4.50it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 4.11e-05:  18%|▏| 2462/13852 [09:11<42:20,  4.48it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 4.11e-05:  18%|▏| 2463/13852 [09:11<42:11,  4.50it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 4.11e-05:  18%|▏| 2464/13852 [09:11<42:06,  4.51it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 4.11e-05:  18%|▏| 2465/13852 [09:12<42:07,  4.51it/s\u001b[A\n",
      "Training loss: 4.78e-02 lr: 4.11e-05:  18%|▏| 2466/13852 [09:12<42:23,  4.48it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 4.11e-05:  18%|▏| 2467/13852 [09:12<42:16,  4.49it/s\u001b[A\n",
      "Training loss: 9.75e-02 lr: 4.11e-05:  18%|▏| 2468/13852 [09:12<42:12,  4.50it/s\u001b[A\n",
      "Training loss: 9.65e-02 lr: 4.11e-05:  18%|▏| 2469/13852 [09:12<42:07,  4.50it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 4.11e-05:  18%|▏| 2470/13852 [09:13<41:56,  4.52it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 4.11e-05:  18%|▏| 2471/13852 [09:13<41:45,  4.54it/s\u001b[A\n",
      "Training loss: 3.95e-02 lr: 4.11e-05:  18%|▏| 2472/13852 [09:13<41:37,  4.56it/s\u001b[A\n",
      "Training loss: 3.14e-02 lr: 4.11e-05:  18%|▏| 2473/13852 [09:13<41:40,  4.55it/s\u001b[A\n",
      "Training loss: 2.28e-02 lr: 4.11e-05:  18%|▏| 2474/13852 [09:14<41:46,  4.54it/s\u001b[A\n",
      "Training loss: 2.35e-02 lr: 4.11e-05:  18%|▏| 2475/13852 [09:14<41:50,  4.53it/s\u001b[A\n",
      "Training loss: 2.59e-02 lr: 4.11e-05:  18%|▏| 2476/13852 [09:14<41:53,  4.53it/s\u001b[A\n",
      "Training loss: 9.65e-02 lr: 4.11e-05:  18%|▏| 2477/13852 [09:14<42:12,  4.49it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 4.11e-05:  18%|▏| 2478/13852 [09:14<42:08,  4.50it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 4.11e-05:  18%|▏| 2479/13852 [09:15<42:04,  4.51it/s\u001b[A\n",
      "Training loss: 8.16e-02 lr: 4.11e-05:  18%|▏| 2480/13852 [09:15<42:01,  4.51it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 4.10e-05:  18%|▏| 2481/13852 [09:15<42:03,  4.51it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 4.10e-05:  18%|▏| 2482/13852 [09:15<42:04,  4.50it/s\u001b[A\n",
      "Training loss: 3.86e-02 lr: 4.10e-05:  18%|▏| 2483/13852 [09:15<41:58,  4.52it/s\u001b[A\n",
      "Training loss: 8.47e-02 lr: 4.10e-05:  18%|▏| 2484/13852 [09:16<41:44,  4.54it/s\u001b[A\n",
      "Training loss: 7.78e-02 lr: 4.10e-05:  18%|▏| 2485/13852 [09:16<41:36,  4.55it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 4.10e-05:  18%|▏| 2486/13852 [09:16<41:50,  4.53it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 4.10e-05:  18%|▏| 2487/13852 [09:16<41:50,  4.53it/s\u001b[A\n",
      "Training loss: 9.07e-02 lr: 4.10e-05:  18%|▏| 2488/13852 [09:17<41:51,  4.53it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 4.10e-05:  18%|▏| 2489/13852 [09:17<42:04,  4.50it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 4.10e-05:  18%|▏| 2490/13852 [09:17<42:06,  4.50it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 4.10e-05:  18%|▏| 2491/13852 [09:17<42:03,  4.50it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 4.10e-05:  18%|▏| 2492/13852 [09:17<42:01,  4.51it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 4.10e-05:  18%|▏| 2493/13852 [09:18<42:00,  4.51it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 4.10e-05:  18%|▏| 2494/13852 [09:18<42:01,  4.51it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 4.10e-05:  18%|▏| 2495/13852 [09:18<41:55,  4.52it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 4.10e-05:  18%|▏| 2496/13852 [09:18<41:47,  4.53it/s\u001b[A\n",
      "Training loss: 8.61e-02 lr: 4.10e-05:  18%|▏| 2497/13852 [09:19<41:40,  4.54it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 4.10e-05:  18%|▏| 2498/13852 [09:19<42:01,  4.50it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 4.10e-05:  18%|▏| 2499/13852 [09:19<42:01,  4.50it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.10e-05:  18%|▏| 2500/13852 [09:19<41:55,  4.51it/s\u001b[A\n",
      "Training loss: 9.76e-02 lr: 4.10e-05:  18%|▏| 2501/13852 [09:19<41:51,  4.52it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 4.10e-05:  18%|▏| 2502/13852 [09:20<41:52,  4.52it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 4.10e-05:  18%|▏| 2503/13852 [09:20<41:50,  4.52it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 4.10e-05:  18%|▏| 2504/13852 [09:20<41:51,  4.52it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 4.10e-05:  18%|▏| 2505/13852 [09:20<41:55,  4.51it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 4.10e-05:  18%|▏| 2506/13852 [09:21<41:59,  4.50it/s\u001b[A\n",
      "Training loss: 9.74e-02 lr: 4.10e-05:  18%|▏| 2507/13852 [09:21<42:04,  4.49it/s\u001b[A\n",
      "Training loss: 7.19e-02 lr: 4.10e-05:  18%|▏| 2508/13852 [09:21<41:54,  4.51it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.09e-05:  18%|▏| 2509/13852 [09:21<41:40,  4.54it/s\u001b[A\n",
      "Training loss: 7.78e-02 lr: 4.09e-05:  18%|▏| 2510/13852 [09:21<41:31,  4.55it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 4.09e-05:  18%|▏| 2511/13852 [09:22<41:52,  4.51it/s\u001b[A\n",
      "Training loss: 7.37e-02 lr: 4.09e-05:  18%|▏| 2512/13852 [09:22<41:51,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.25e-02 lr: 4.09e-05:  18%|▏| 2513/13852 [09:22<41:56,  4.51it/s\u001b[A\n",
      "Training loss: 6.34e-02 lr: 4.09e-05:  18%|▏| 2514/13852 [09:22<41:57,  4.50it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 4.09e-05:  18%|▏| 2515/13852 [09:23<41:57,  4.50it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 4.09e-05:  18%|▏| 2516/13852 [09:23<42:11,  4.48it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.09e-05:  18%|▏| 2517/13852 [09:23<42:11,  4.48it/s\u001b[A\n",
      "Training loss: 8.23e-02 lr: 4.09e-05:  18%|▏| 2518/13852 [09:23<42:08,  4.48it/s\u001b[A\n",
      "Training loss: 9.92e-02 lr: 4.09e-05:  18%|▏| 2519/13852 [09:23<42:06,  4.48it/s\u001b[A\n",
      "Training loss: 7.41e-02 lr: 4.09e-05:  18%|▏| 2520/13852 [09:24<41:52,  4.51it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 4.09e-05:  18%|▏| 2521/13852 [09:24<41:37,  4.54it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 4.09e-05:  18%|▏| 2522/13852 [09:24<41:24,  4.56it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 4.09e-05:  18%|▏| 2523/13852 [09:24<41:36,  4.54it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 4.09e-05:  18%|▏| 2524/13852 [09:25<41:38,  4.53it/s\u001b[A\n",
      "Training loss: 8.82e-02 lr: 4.09e-05:  18%|▏| 2525/13852 [09:25<41:39,  4.53it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 4.09e-05:  18%|▏| 2526/13852 [09:25<41:41,  4.53it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 4.09e-05:  18%|▏| 2527/13852 [09:25<41:43,  4.52it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.09e-05:  18%|▏| 2528/13852 [09:25<41:44,  4.52it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 4.09e-05:  18%|▏| 2529/13852 [09:26<41:48,  4.51it/s\u001b[A\n",
      "Training loss: 9.92e-02 lr: 4.09e-05:  18%|▏| 2530/13852 [09:26<41:49,  4.51it/s\u001b[A\n",
      "Training loss: 9.88e-02 lr: 4.09e-05:  18%|▏| 2531/13852 [09:26<41:50,  4.51it/s\u001b[A\n",
      "Training loss: 8.61e-02 lr: 4.09e-05:  18%|▏| 2532/13852 [09:26<41:45,  4.52it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 4.09e-05:  18%|▏| 2533/13852 [09:27<41:32,  4.54it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.09e-05:  18%|▏| 2534/13852 [09:27<41:46,  4.51it/s\u001b[A\n",
      "Training loss: 9.17e-02 lr: 4.09e-05:  18%|▏| 2535/13852 [09:27<41:51,  4.51it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.08e-05:  18%|▏| 2536/13852 [09:27<41:51,  4.50it/s\u001b[A\n",
      "Training loss: 8.50e-02 lr: 4.08e-05:  18%|▏| 2537/13852 [09:27<41:47,  4.51it/s\u001b[A\n",
      "Training loss: 7.63e-02 lr: 4.08e-05:  18%|▏| 2538/13852 [09:28<41:49,  4.51it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 4.08e-05:  18%|▏| 2539/13852 [09:28<42:06,  4.48it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 4.08e-05:  18%|▏| 2540/13852 [09:28<42:03,  4.48it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 4.08e-05:  18%|▏| 2541/13852 [09:28<41:57,  4.49it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 4.08e-05:  18%|▏| 2542/13852 [09:29<41:59,  4.49it/s\u001b[A\n",
      "Training loss: 9.59e-02 lr: 4.08e-05:  18%|▏| 2543/13852 [09:29<42:59,  4.38it/s\u001b[A\n",
      "Training loss: 7.96e-02 lr: 4.08e-05:  18%|▏| 2544/13852 [09:29<42:27,  4.44it/s\u001b[A\n",
      "Training loss: 8.68e-02 lr: 4.08e-05:  18%|▏| 2545/13852 [09:29<42:24,  4.44it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 4.08e-05:  18%|▏| 2546/13852 [09:29<42:11,  4.47it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 4.08e-05:  18%|▏| 2547/13852 [09:30<42:03,  4.48it/s\u001b[A\n",
      "Training loss: 7.37e-02 lr: 4.08e-05:  18%|▏| 2548/13852 [09:30<42:13,  4.46it/s\u001b[A\n",
      "Training loss: 9.25e-02 lr: 4.08e-05:  18%|▏| 2549/13852 [09:30<42:00,  4.48it/s\u001b[A\n",
      "Training loss: 8.72e-02 lr: 4.08e-05:  18%|▏| 2550/13852 [09:30<41:58,  4.49it/s\u001b[A\n",
      "Training loss: 8.43e-02 lr: 4.08e-05:  18%|▏| 2551/13852 [09:31<41:52,  4.50it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 4.08e-05:  18%|▏| 2552/13852 [09:31<41:58,  4.49it/s\u001b[A\n",
      "Training loss: 7.82e-02 lr: 4.08e-05:  18%|▏| 2553/13852 [09:31<41:54,  4.49it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 4.08e-05:  18%|▏| 2554/13852 [09:31<41:43,  4.51it/s\u001b[A\n",
      "Training loss: 9.54e-02 lr: 4.08e-05:  18%|▏| 2555/13852 [09:31<41:26,  4.54it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 4.08e-05:  18%|▏| 2556/13852 [09:32<41:35,  4.53it/s\u001b[A\n",
      "Training loss: 5.32e-02 lr: 4.08e-05:  18%|▏| 2557/13852 [09:32<41:26,  4.54it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 4.08e-05:  18%|▏| 2558/13852 [09:32<41:35,  4.53it/s\u001b[A\n",
      "Training loss: 3.04e-02 lr: 4.08e-05:  18%|▏| 2559/13852 [09:32<41:34,  4.53it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 4.08e-05:  18%|▏| 2560/13852 [09:33<41:35,  4.53it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 4.08e-05:  18%|▏| 2561/13852 [09:33<41:37,  4.52it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 4.08e-05:  18%|▏| 2562/13852 [09:33<41:59,  4.48it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 4.08e-05:  19%|▏| 2563/13852 [09:33<41:53,  4.49it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.07e-05:  19%|▏| 2564/13852 [09:33<41:52,  4.49it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 4.07e-05:  19%|▏| 2565/13852 [09:34<41:49,  4.50it/s\u001b[A\n",
      "Training loss: 9.85e-02 lr: 4.07e-05:  19%|▏| 2566/13852 [09:34<41:49,  4.50it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 4.07e-05:  19%|▏| 2567/13852 [09:34<41:43,  4.51it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 4.07e-05:  19%|▏| 2568/13852 [09:34<41:55,  4.49it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 4.07e-05:  19%|▏| 2569/13852 [09:35<41:35,  4.52it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 4.07e-05:  19%|▏| 2570/13852 [09:35<41:36,  4.52it/s\u001b[A\n",
      "Training loss: 9.52e-02 lr: 4.07e-05:  19%|▏| 2571/13852 [09:35<41:44,  4.50it/s\u001b[A\n",
      "Training loss: 8.77e-02 lr: 4.07e-05:  19%|▏| 2572/13852 [09:35<41:40,  4.51it/s\u001b[A\n",
      "Training loss: 7.69e-02 lr: 4.07e-05:  19%|▏| 2573/13852 [09:35<41:40,  4.51it/s\u001b[A\n",
      "Training loss: 6.64e-02 lr: 4.07e-05:  19%|▏| 2574/13852 [09:36<41:42,  4.51it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 4.07e-05:  19%|▏| 2575/13852 [09:36<41:41,  4.51it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 4.07e-05:  19%|▏| 2576/13852 [09:36<41:43,  4.50it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 4.07e-05:  19%|▏| 2577/13852 [09:36<41:44,  4.50it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 4.07e-05:  19%|▏| 2578/13852 [09:37<41:44,  4.50it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 4.07e-05:  19%|▏| 2579/13852 [09:37<42:20,  4.44it/s\u001b[A\n",
      "Training loss: 9.85e-02 lr: 4.07e-05:  19%|▏| 2580/13852 [09:37<43:27,  4.32it/s\u001b[A\n",
      "Training loss: 9.58e-02 lr: 4.07e-05:  19%|▏| 2581/13852 [09:37<44:24,  4.23it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 4.07e-05:  19%|▏| 2582/13852 [09:38<44:11,  4.25it/s\u001b[A\n",
      "Training loss: 7.15e-02 lr: 4.07e-05:  19%|▏| 2583/13852 [09:38<43:28,  4.32it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 4.07e-05:  19%|▏| 2584/13852 [09:38<42:56,  4.37it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 4.07e-05:  19%|▏| 2585/13852 [09:38<42:33,  4.41it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 4.07e-05:  19%|▏| 2586/13852 [09:38<42:19,  4.44it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 4.07e-05:  19%|▏| 2587/13852 [09:39<41:55,  4.48it/s\u001b[A\n",
      "Training loss: 4.78e-02 lr: 4.07e-05:  19%|▏| 2588/13852 [09:39<41:35,  4.51it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 4.07e-05:  19%|▏| 2589/13852 [09:39<41:19,  4.54it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.07e-05:  19%|▏| 2590/13852 [09:39<41:33,  4.52it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 4.07e-05:  19%|▏| 2591/13852 [09:40<41:32,  4.52it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 4.06e-05:  19%|▏| 2592/13852 [09:40<41:28,  4.52it/s\u001b[A\n",
      "Training loss: 5.68e-02 lr: 4.06e-05:  19%|▏| 2593/13852 [09:40<41:28,  4.52it/s\u001b[A\n",
      "Training loss: 7.44e-02 lr: 4.06e-05:  19%|▏| 2594/13852 [09:40<41:28,  4.52it/s\u001b[A\n",
      "Training loss: 9.28e-02 lr: 4.06e-05:  19%|▏| 2595/13852 [09:40<41:29,  4.52it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 4.06e-05:  19%|▏| 2596/13852 [09:41<41:29,  4.52it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.06e-05:  19%|▏| 2597/13852 [09:41<41:47,  4.49it/s\u001b[A\n",
      "Training loss: 2.12e-01 lr: 4.06e-05:  19%|▏| 2598/13852 [09:41<41:48,  4.49it/s\u001b[A\n",
      "Training loss: 1.57e-01 lr: 4.06e-05:  19%|▏| 2599/13852 [09:41<41:34,  4.51it/s\u001b[A\n",
      "Training loss: 2.21e-01 lr: 4.06e-05:  19%|▏| 2600/13852 [09:42<41:19,  4.54it/s\u001b[A\n",
      "Training loss: 1.80e-01 lr: 4.06e-05:  19%|▏| 2601/13852 [09:42<41:25,  4.53it/s\u001b[A\n",
      "Training loss: 1.67e-01 lr: 4.06e-05:  19%|▏| 2602/13852 [09:42<41:46,  4.49it/s\u001b[A\n",
      "Training loss: 1.80e-01 lr: 4.06e-05:  19%|▏| 2603/13852 [09:42<41:41,  4.50it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 4.06e-05:  19%|▏| 2604/13852 [09:42<41:40,  4.50it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.06e-05:  19%|▏| 2605/13852 [09:43<41:36,  4.51it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.06e-05:  19%|▏| 2606/13852 [09:43<41:42,  4.49it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 4.06e-05:  19%|▏| 2607/13852 [09:43<41:46,  4.49it/s\u001b[A\n",
      "Training loss: 9.13e-02 lr: 4.06e-05:  19%|▏| 2608/13852 [09:43<41:50,  4.48it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 4.06e-05:  19%|▏| 2609/13852 [09:44<41:44,  4.49it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.94e-02 lr: 4.06e-05:  19%|▏| 2610/13852 [09:44<41:45,  4.49it/s\u001b[A\n",
      "Training loss: 8.69e-02 lr: 4.06e-05:  19%|▏| 2611/13852 [09:44<41:31,  4.51it/s\u001b[A\n",
      "Training loss: 9.65e-02 lr: 4.06e-05:  19%|▏| 2612/13852 [09:44<41:15,  4.54it/s\u001b[A\n",
      "Training loss: 8.69e-02 lr: 4.06e-05:  19%|▏| 2613/13852 [09:44<41:23,  4.53it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 4.06e-05:  19%|▏| 2614/13852 [09:45<41:30,  4.51it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 4.06e-05:  19%|▏| 2615/13852 [09:45<41:29,  4.51it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 4.06e-05:  19%|▏| 2616/13852 [09:45<41:26,  4.52it/s\u001b[A\n",
      "Training loss: 5.40e-02 lr: 4.06e-05:  19%|▏| 2617/13852 [09:45<41:25,  4.52it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 4.06e-05:  19%|▏| 2618/13852 [09:46<41:26,  4.52it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 4.05e-05:  19%|▏| 2619/13852 [09:46<41:26,  4.52it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 4.05e-05:  19%|▏| 2620/13852 [09:46<41:26,  4.52it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 4.05e-05:  19%|▏| 2621/13852 [09:46<41:26,  4.52it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 4.05e-05:  19%|▏| 2622/13852 [09:46<41:31,  4.51it/s\u001b[A\n",
      "Training loss: 8.09e-02 lr: 4.05e-05:  19%|▏| 2623/13852 [09:47<41:23,  4.52it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 4.05e-05:  19%|▏| 2624/13852 [09:47<41:38,  4.49it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 4.05e-05:  19%|▏| 2625/13852 [09:47<41:21,  4.52it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 4.05e-05:  19%|▏| 2626/13852 [09:47<41:35,  4.50it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 4.05e-05:  19%|▏| 2627/13852 [09:48<41:31,  4.51it/s\u001b[A\n",
      "Training loss: 6.41e-02 lr: 4.05e-05:  19%|▏| 2628/13852 [09:48<41:26,  4.51it/s\u001b[A\n",
      "Training loss: 8.21e-02 lr: 4.05e-05:  19%|▏| 2629/13852 [09:48<41:32,  4.50it/s\u001b[A\n",
      "Training loss: 1.67e-01 lr: 4.05e-05:  19%|▏| 2630/13852 [09:48<41:33,  4.50it/s\u001b[A\n",
      "Training loss: 1.53e-01 lr: 4.05e-05:  19%|▏| 2631/13852 [09:48<41:33,  4.50it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 4.05e-05:  19%|▏| 2632/13852 [09:49<41:33,  4.50it/s\u001b[A\n",
      "Training loss: 9.62e-02 lr: 4.05e-05:  19%|▏| 2633/13852 [09:49<41:34,  4.50it/s\u001b[A\n",
      "Training loss: 8.22e-02 lr: 4.05e-05:  19%|▏| 2634/13852 [09:49<41:32,  4.50it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 4.05e-05:  19%|▏| 2635/13852 [09:49<41:20,  4.52it/s\u001b[A\n",
      "Training loss: 8.12e-02 lr: 4.05e-05:  19%|▏| 2636/13852 [09:49<41:05,  4.55it/s\u001b[A\n",
      "Training loss: 7.63e-02 lr: 4.05e-05:  19%|▏| 2637/13852 [09:50<40:53,  4.57it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 4.05e-05:  19%|▏| 2638/13852 [09:50<40:48,  4.58it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 4.05e-05:  19%|▏| 2639/13852 [09:50<41:06,  4.55it/s\u001b[A\n",
      "Training loss: 9.99e-02 lr: 4.05e-05:  19%|▏| 2640/13852 [09:50<41:10,  4.54it/s\u001b[A\n",
      "Training loss: 9.18e-02 lr: 4.05e-05:  19%|▏| 2641/13852 [09:51<41:14,  4.53it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 4.05e-05:  19%|▏| 2642/13852 [09:51<41:33,  4.50it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.05e-05:  19%|▏| 2643/13852 [09:51<41:35,  4.49it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 4.05e-05:  19%|▏| 2644/13852 [09:51<41:35,  4.49it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.05e-05:  19%|▏| 2645/13852 [09:51<41:35,  4.49it/s\u001b[A\n",
      "Training loss: 9.39e-02 lr: 4.05e-05:  19%|▏| 2646/13852 [09:52<41:43,  4.48it/s\u001b[A\n",
      "Training loss: 8.60e-02 lr: 4.04e-05:  19%|▏| 2647/13852 [09:52<41:41,  4.48it/s\u001b[A\n",
      "Training loss: 8.09e-02 lr: 4.04e-05:  19%|▏| 2648/13852 [09:52<41:25,  4.51it/s\u001b[A\n",
      "Training loss: 7.53e-02 lr: 4.04e-05:  19%|▏| 2649/13852 [09:52<41:10,  4.53it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 4.04e-05:  19%|▏| 2650/13852 [09:53<41:00,  4.55it/s\u001b[A\n",
      "Training loss: 4.57e-02 lr: 4.04e-05:  19%|▏| 2651/13852 [09:53<41:15,  4.52it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 4.04e-05:  19%|▏| 2652/13852 [09:53<41:18,  4.52it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 4.04e-05:  19%|▏| 2653/13852 [09:53<41:22,  4.51it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 4.04e-05:  19%|▏| 2654/13852 [09:53<41:24,  4.51it/s\u001b[A\n",
      "Training loss: 7.57e-02 lr: 4.04e-05:  19%|▏| 2655/13852 [09:54<41:26,  4.50it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 4.04e-05:  19%|▏| 2656/13852 [09:54<41:25,  4.50it/s\u001b[A\n",
      "Training loss: 8.19e-02 lr: 4.04e-05:  19%|▏| 2657/13852 [09:54<41:25,  4.50it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 4.04e-05:  19%|▏| 2658/13852 [09:54<41:28,  4.50it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 4.04e-05:  19%|▏| 2659/13852 [09:55<41:28,  4.50it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 4.04e-05:  19%|▏| 2660/13852 [09:55<41:17,  4.52it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 4.04e-05:  19%|▏| 2661/13852 [09:55<40:59,  4.55it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 4.04e-05:  19%|▏| 2662/13852 [09:55<41:05,  4.54it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 4.04e-05:  19%|▏| 2663/13852 [09:55<41:02,  4.54it/s\u001b[A\n",
      "Training loss: 8.73e-02 lr: 4.04e-05:  19%|▏| 2664/13852 [09:56<41:03,  4.54it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 4.04e-05:  19%|▏| 2665/13852 [09:56<41:03,  4.54it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 4.04e-05:  19%|▏| 2666/13852 [09:56<41:12,  4.52it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 4.04e-05:  19%|▏| 2667/13852 [09:56<41:14,  4.52it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 4.04e-05:  19%|▏| 2668/13852 [09:57<41:19,  4.51it/s\u001b[A\n",
      "Training loss: 3.27e-02 lr: 4.04e-05:  19%|▏| 2669/13852 [09:57<41:45,  4.46it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 4.04e-05:  19%|▏| 2670/13852 [09:57<41:41,  4.47it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 4.04e-05:  19%|▏| 2671/13852 [09:57<41:37,  4.48it/s\u001b[A\n",
      "Training loss: 8.94e-02 lr: 4.04e-05:  19%|▏| 2672/13852 [09:57<41:31,  4.49it/s\u001b[A\n",
      "Training loss: 7.97e-02 lr: 4.04e-05:  19%|▏| 2673/13852 [09:58<41:12,  4.52it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 4.04e-05:  19%|▏| 2674/13852 [09:58<40:58,  4.55it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 4.03e-05:  19%|▏| 2675/13852 [09:58<41:04,  4.54it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 4.03e-05:  19%|▏| 2676/13852 [09:58<41:04,  4.54it/s\u001b[A\n",
      "Training loss: 7.03e-02 lr: 4.03e-05:  19%|▏| 2677/13852 [09:59<41:06,  4.53it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 4.03e-05:  19%|▏| 2678/13852 [09:59<41:09,  4.53it/s\u001b[A\n",
      "Training loss: 9.90e-02 lr: 4.03e-05:  19%|▏| 2679/13852 [09:59<41:11,  4.52it/s\u001b[A\n",
      "Training loss: 1.56e-01 lr: 4.03e-05:  19%|▏| 2680/13852 [09:59<41:13,  4.52it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 4.03e-05:  19%|▏| 2681/13852 [09:59<41:17,  4.51it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 4.03e-05:  19%|▏| 2682/13852 [10:00<41:35,  4.48it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 4.03e-05:  19%|▏| 2683/13852 [10:00<41:38,  4.47it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 4.03e-05:  19%|▏| 2684/13852 [10:00<41:30,  4.48it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 4.03e-05:  19%|▏| 2685/13852 [10:00<41:14,  4.51it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 4.03e-05:  19%|▏| 2686/13852 [10:01<40:59,  4.54it/s\u001b[A\n",
      "Training loss: 6.06e-02 lr: 4.03e-05:  19%|▏| 2687/13852 [10:01<41:35,  4.47it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 4.03e-05:  19%|▏| 2688/13852 [10:01<41:33,  4.48it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 4.03e-05:  19%|▏| 2689/13852 [10:01<41:24,  4.49it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 4.03e-05:  19%|▏| 2690/13852 [10:01<41:24,  4.49it/s\u001b[A\n",
      "Training loss: 7.05e-02 lr: 4.03e-05:  19%|▏| 2691/13852 [10:02<41:35,  4.47it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 4.03e-05:  19%|▏| 2692/13852 [10:02<41:32,  4.48it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 4.03e-05:  19%|▏| 2693/13852 [10:02<41:28,  4.48it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 4.03e-05:  19%|▏| 2694/13852 [10:02<41:25,  4.49it/s\u001b[A\n",
      "Training loss: 4.03e-02 lr: 4.03e-05:  19%|▏| 2695/13852 [10:03<41:22,  4.49it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 4.03e-05:  19%|▏| 2696/13852 [10:03<41:06,  4.52it/s\u001b[A\n",
      "Training loss: 7.80e-02 lr: 4.03e-05:  19%|▏| 2697/13852 [10:03<41:16,  4.50it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 4.03e-05:  19%|▏| 2698/13852 [10:03<40:59,  4.53it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.03e-05:  19%|▏| 2699/13852 [10:03<41:10,  4.52it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.03e-05:  19%|▏| 2700/13852 [10:04<41:08,  4.52it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 4.03e-05:  19%|▏| 2701/13852 [10:04<41:09,  4.51it/s\u001b[A\n",
      "Training loss: 9.92e-02 lr: 4.02e-05:  20%|▏| 2702/13852 [10:04<41:06,  4.52it/s\u001b[A\n",
      "Training loss: 7.84e-02 lr: 4.02e-05:  20%|▏| 2703/13852 [10:04<41:08,  4.52it/s\u001b[A\n",
      "Training loss: 7.28e-02 lr: 4.02e-05:  20%|▏| 2704/13852 [10:05<41:20,  4.49it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 4.02e-05:  20%|▏| 2705/13852 [10:05<41:17,  4.50it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 4.02e-05:  20%|▏| 2706/13852 [10:05<41:16,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.10e-01 lr: 4.02e-05:  20%|▏| 2707/13852 [10:05<41:17,  4.50it/s\u001b[A\n",
      "Training loss: 9.65e-02 lr: 4.02e-05:  20%|▏| 2708/13852 [10:05<41:10,  4.51it/s\u001b[A\n",
      "Training loss: 9.45e-02 lr: 4.02e-05:  20%|▏| 2709/13852 [10:06<40:58,  4.53it/s\u001b[A\n",
      "Training loss: 8.65e-02 lr: 4.02e-05:  20%|▏| 2710/13852 [10:06<40:45,  4.56it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 4.02e-05:  20%|▏| 2711/13852 [10:06<41:06,  4.52it/s\u001b[A\n",
      "Training loss: 1.62e-01 lr: 4.02e-05:  20%|▏| 2712/13852 [10:06<41:03,  4.52it/s\u001b[A\n",
      "Training loss: 1.62e-01 lr: 4.02e-05:  20%|▏| 2713/13852 [10:07<40:59,  4.53it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 4.02e-05:  20%|▏| 2714/13852 [10:07<41:30,  4.47it/s\u001b[A\n",
      "Training loss: 1.62e-01 lr: 4.02e-05:  20%|▏| 2715/13852 [10:07<41:54,  4.43it/s\u001b[A\n",
      "Training loss: 1.81e-01 lr: 4.02e-05:  20%|▏| 2716/13852 [10:07<42:01,  4.42it/s\u001b[A\n",
      "Training loss: 1.56e-01 lr: 4.02e-05:  20%|▏| 2717/13852 [10:07<42:15,  4.39it/s\u001b[A\n",
      "Training loss: 1.55e-01 lr: 4.02e-05:  20%|▏| 2718/13852 [10:08<42:02,  4.41it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 4.02e-05:  20%|▏| 2719/13852 [10:08<41:39,  4.45it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.02e-05:  20%|▏| 2720/13852 [10:08<41:17,  4.49it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 4.02e-05:  20%|▏| 2721/13852 [10:08<41:31,  4.47it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 4.02e-05:  20%|▏| 2722/13852 [10:09<41:20,  4.49it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 4.02e-05:  20%|▏| 2723/13852 [10:09<41:12,  4.50it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 4.02e-05:  20%|▏| 2724/13852 [10:09<41:15,  4.50it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 4.02e-05:  20%|▏| 2725/13852 [10:09<41:12,  4.50it/s\u001b[A\n",
      "Training loss: 9.32e-02 lr: 4.02e-05:  20%|▏| 2726/13852 [10:09<41:09,  4.50it/s\u001b[A\n",
      "Training loss: 8.35e-02 lr: 4.02e-05:  20%|▏| 2727/13852 [10:10<41:10,  4.50it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 4.02e-05:  20%|▏| 2728/13852 [10:10<41:09,  4.50it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 4.02e-05:  20%|▏| 2729/13852 [10:10<41:11,  4.50it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 4.01e-05:  20%|▏| 2730/13852 [10:10<41:02,  4.52it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 4.01e-05:  20%|▏| 2731/13852 [10:11<40:49,  4.54it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 4.01e-05:  20%|▏| 2732/13852 [10:11<40:49,  4.54it/s\u001b[A\n",
      "Training loss: 7.19e-02 lr: 4.01e-05:  20%|▏| 2733/13852 [10:11<40:43,  4.55it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 4.01e-05:  20%|▏| 2734/13852 [10:11<40:58,  4.52it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 4.01e-05:  20%|▏| 2735/13852 [10:11<40:55,  4.53it/s\u001b[A\n",
      "Training loss: 6.10e-02 lr: 4.01e-05:  20%|▏| 2736/13852 [10:12<41:07,  4.50it/s\u001b[A\n",
      "Training loss: 8.07e-02 lr: 4.01e-05:  20%|▏| 2737/13852 [10:12<41:03,  4.51it/s\u001b[A\n",
      "Training loss: 6.17e-02 lr: 4.01e-05:  20%|▏| 2738/13852 [10:12<41:04,  4.51it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 4.01e-05:  20%|▏| 2739/13852 [10:12<41:05,  4.51it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 4.01e-05:  20%|▏| 2740/13852 [10:13<41:05,  4.51it/s\u001b[A\n",
      "Training loss: 4.29e-02 lr: 4.01e-05:  20%|▏| 2741/13852 [10:13<41:06,  4.51it/s\u001b[A\n",
      "Training loss: 8.57e-02 lr: 4.01e-05:  20%|▏| 2742/13852 [10:13<41:05,  4.51it/s\u001b[A\n",
      "Training loss: 6.42e-02 lr: 4.01e-05:  20%|▏| 2743/13852 [10:13<41:05,  4.51it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 4.01e-05:  20%|▏| 2744/13852 [10:13<40:48,  4.54it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 4.01e-05:  20%|▏| 2745/13852 [10:14<40:38,  4.56it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 4.01e-05:  20%|▏| 2746/13852 [10:14<40:58,  4.52it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 4.01e-05:  20%|▏| 2747/13852 [10:14<40:55,  4.52it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 4.01e-05:  20%|▏| 2748/13852 [10:14<40:53,  4.52it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 4.01e-05:  20%|▏| 2749/13852 [10:15<41:16,  4.48it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 4.01e-05:  20%|▏| 2750/13852 [10:15<41:10,  4.49it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 4.01e-05:  20%|▏| 2751/13852 [10:15<41:07,  4.50it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 4.01e-05:  20%|▏| 2752/13852 [10:15<41:05,  4.50it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 4.01e-05:  20%|▏| 2753/13852 [10:15<41:05,  4.50it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 4.01e-05:  20%|▏| 2754/13852 [10:16<41:06,  4.50it/s\u001b[A\n",
      "Training loss: 3.02e-02 lr: 4.01e-05:  20%|▏| 2755/13852 [10:16<40:52,  4.52it/s\u001b[A\n",
      "Training loss: 2.31e-02 lr: 4.01e-05:  20%|▏| 2756/13852 [10:16<40:36,  4.55it/s\u001b[A\n",
      "Training loss: 2.28e-02 lr: 4.01e-05:  20%|▏| 2757/13852 [10:16<40:32,  4.56it/s\u001b[A\n",
      "Training loss: 2.43e-02 lr: 4.00e-05:  20%|▏| 2758/13852 [10:17<41:05,  4.50it/s\u001b[A\n",
      "Training loss: 2.16e-02 lr: 4.00e-05:  20%|▏| 2759/13852 [10:17<41:22,  4.47it/s\u001b[A\n",
      "Training loss: 1.79e-02 lr: 4.00e-05:  20%|▏| 2760/13852 [10:17<41:11,  4.49it/s\u001b[A\n",
      "Training loss: 1.53e-02 lr: 4.00e-05:  20%|▏| 2761/13852 [10:17<41:11,  4.49it/s\u001b[A\n",
      "Training loss: 2.19e-02 lr: 4.00e-05:  20%|▏| 2762/13852 [10:17<41:10,  4.49it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 4.00e-05:  20%|▏| 2763/13852 [10:18<41:07,  4.49it/s\u001b[A\n",
      "Training loss: 9.46e-02 lr: 4.00e-05:  20%|▏| 2764/13852 [10:18<41:05,  4.50it/s\u001b[A\n",
      "Training loss: 7.29e-02 lr: 4.00e-05:  20%|▏| 2765/13852 [10:18<41:04,  4.50it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.00e-05:  20%|▏| 2766/13852 [10:18<41:07,  4.49it/s\u001b[A\n",
      "Training loss: 8.45e-02 lr: 4.00e-05:  20%|▏| 2767/13852 [10:19<40:53,  4.52it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 4.00e-05:  20%|▏| 2768/13852 [10:19<40:38,  4.55it/s\u001b[A\n",
      "Training loss: 1.56e-01 lr: 4.00e-05:  20%|▏| 2769/13852 [10:19<40:27,  4.57it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.00e-05:  20%|▏| 2770/13852 [10:19<40:21,  4.58it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 4.00e-05:  20%|▏| 2771/13852 [10:19<40:34,  4.55it/s\u001b[A\n",
      "Training loss: 9.79e-02 lr: 4.00e-05:  20%|▏| 2772/13852 [10:20<40:39,  4.54it/s\u001b[A\n",
      "Training loss: 7.15e-02 lr: 4.00e-05:  20%|▏| 2773/13852 [10:20<40:46,  4.53it/s\u001b[A\n",
      "Training loss: 9.77e-02 lr: 4.00e-05:  20%|▏| 2774/13852 [10:20<40:55,  4.51it/s\u001b[A\n",
      "Training loss: 7.82e-02 lr: 4.00e-05:  20%|▏| 2775/13852 [10:20<41:01,  4.50it/s\u001b[A\n",
      "Training loss: 9.94e-02 lr: 4.00e-05:  20%|▏| 2776/13852 [10:21<41:02,  4.50it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 4.00e-05:  20%|▏| 2777/13852 [10:21<41:09,  4.48it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 4.00e-05:  20%|▏| 2778/13852 [10:21<41:14,  4.47it/s\u001b[A\n",
      "Training loss: 1.53e-01 lr: 4.00e-05:  20%|▏| 2779/13852 [10:21<41:11,  4.48it/s\u001b[A\n",
      "Training loss: 1.57e-01 lr: 4.00e-05:  20%|▏| 2780/13852 [10:21<40:57,  4.50it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 4.00e-05:  20%|▏| 2781/13852 [10:22<40:51,  4.52it/s\u001b[A\n",
      "Training loss: 9.84e-02 lr: 4.00e-05:  20%|▏| 2782/13852 [10:22<40:49,  4.52it/s\u001b[A\n",
      "Training loss: 8.17e-02 lr: 4.00e-05:  20%|▏| 2783/13852 [10:22<40:54,  4.51it/s\u001b[A\n",
      "Training loss: 8.05e-02 lr: 4.00e-05:  20%|▏| 2784/13852 [10:22<40:55,  4.51it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 4.00e-05:  20%|▏| 2785/13852 [10:23<40:58,  4.50it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.99e-05:  20%|▏| 2786/13852 [10:23<41:01,  4.50it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.99e-05:  20%|▏| 2787/13852 [10:23<41:09,  4.48it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.99e-05:  20%|▏| 2788/13852 [10:23<41:09,  4.48it/s\u001b[A\n",
      "Training loss: 8.51e-02 lr: 3.99e-05:  20%|▏| 2789/13852 [10:23<41:08,  4.48it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 3.99e-05:  20%|▏| 2790/13852 [10:24<41:08,  4.48it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 3.99e-05:  20%|▏| 2791/13852 [10:24<40:57,  4.50it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 3.99e-05:  20%|▏| 2792/13852 [10:24<40:41,  4.53it/s\u001b[A\n",
      "Training loss: 6.42e-02 lr: 3.99e-05:  20%|▏| 2793/13852 [10:24<40:36,  4.54it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 3.99e-05:  20%|▏| 2794/13852 [10:25<40:55,  4.50it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 3.99e-05:  20%|▏| 2795/13852 [10:25<40:52,  4.51it/s\u001b[A\n",
      "Training loss: 4.60e-02 lr: 3.99e-05:  20%|▏| 2796/13852 [10:25<40:45,  4.52it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 3.99e-05:  20%|▏| 2797/13852 [10:25<40:46,  4.52it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 3.99e-05:  20%|▏| 2798/13852 [10:25<40:45,  4.52it/s\u001b[A\n",
      "Training loss: 8.34e-02 lr: 3.99e-05:  20%|▏| 2799/13852 [10:26<40:48,  4.51it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 3.99e-05:  20%|▏| 2800/13852 [10:26<40:48,  4.51it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 3.99e-05:  20%|▏| 2801/13852 [10:26<40:51,  4.51it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 3.99e-05:  20%|▏| 2802/13852 [10:26<40:53,  4.50it/s\u001b[A\n",
      "Training loss: 4.57e-02 lr: 3.99e-05:  20%|▏| 2803/13852 [10:27<40:42,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.42e-02 lr: 3.99e-05:  20%|▏| 2804/13852 [10:27<40:43,  4.52it/s\u001b[A\n",
      "Training loss: 8.05e-02 lr: 3.99e-05:  20%|▏| 2805/13852 [10:27<40:29,  4.55it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 3.99e-05:  20%|▏| 2806/13852 [10:27<40:28,  4.55it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 3.99e-05:  20%|▏| 2807/13852 [10:27<40:43,  4.52it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 3.99e-05:  20%|▏| 2808/13852 [10:28<40:41,  4.52it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.99e-05:  20%|▏| 2809/13852 [10:28<40:45,  4.51it/s\u001b[A\n",
      "Training loss: 9.19e-02 lr: 3.99e-05:  20%|▏| 2810/13852 [10:28<40:46,  4.51it/s\u001b[A\n",
      "Training loss: 7.94e-02 lr: 3.99e-05:  20%|▏| 2811/13852 [10:28<40:54,  4.50it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.99e-05:  20%|▏| 2812/13852 [10:29<40:50,  4.50it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.98e-05:  20%|▏| 2813/13852 [10:29<40:48,  4.51it/s\u001b[A\n",
      "Training loss: 9.80e-02 lr: 3.98e-05:  20%|▏| 2814/13852 [10:29<40:48,  4.51it/s\u001b[A\n",
      "Training loss: 7.73e-02 lr: 3.98e-05:  20%|▏| 2815/13852 [10:29<40:50,  4.50it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.98e-05:  20%|▏| 2816/13852 [10:29<40:44,  4.51it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 3.98e-05:  20%|▏| 2817/13852 [10:30<40:28,  4.54it/s\u001b[A\n",
      "Training loss: 3.45e-02 lr: 3.98e-05:  20%|▏| 2818/13852 [10:30<40:20,  4.56it/s\u001b[A\n",
      "Training loss: 3.14e-02 lr: 3.98e-05:  20%|▏| 2819/13852 [10:30<40:43,  4.51it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 3.98e-05:  20%|▏| 2820/13852 [10:30<40:41,  4.52it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 3.98e-05:  20%|▏| 2821/13852 [10:31<40:37,  4.53it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 3.98e-05:  20%|▏| 2822/13852 [10:31<40:43,  4.51it/s\u001b[A\n",
      "Training loss: 9.19e-02 lr: 3.98e-05:  20%|▏| 2823/13852 [10:31<40:49,  4.50it/s\u001b[A\n",
      "Training loss: 7.24e-02 lr: 3.98e-05:  20%|▏| 2824/13852 [10:31<40:52,  4.50it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 3.98e-05:  20%|▏| 2825/13852 [10:31<40:50,  4.50it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 3.98e-05:  20%|▏| 2826/13852 [10:32<40:51,  4.50it/s\u001b[A\n",
      "Training loss: 5.63e-02 lr: 3.98e-05:  20%|▏| 2827/13852 [10:32<40:57,  4.49it/s\u001b[A\n",
      "Training loss: 7.81e-02 lr: 3.98e-05:  20%|▏| 2828/13852 [10:32<40:47,  4.50it/s\u001b[A\n",
      "Training loss: 6.09e-02 lr: 3.98e-05:  20%|▏| 2829/13852 [10:32<40:28,  4.54it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 3.98e-05:  20%|▏| 2830/13852 [10:33<40:17,  4.56it/s\u001b[A\n",
      "Training loss: 4.29e-02 lr: 3.98e-05:  20%|▏| 2831/13852 [10:33<40:52,  4.49it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 3.98e-05:  20%|▏| 2832/13852 [10:33<41:10,  4.46it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 3.98e-05:  20%|▏| 2833/13852 [10:33<41:01,  4.48it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 3.98e-05:  20%|▏| 2834/13852 [10:33<40:56,  4.48it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 3.98e-05:  20%|▏| 2835/13852 [10:34<40:52,  4.49it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 3.98e-05:  20%|▏| 2836/13852 [10:34<40:49,  4.50it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 3.98e-05:  20%|▏| 2837/13852 [10:34<40:49,  4.50it/s\u001b[A\n",
      "Training loss: 6.02e-02 lr: 3.98e-05:  20%|▏| 2838/13852 [10:34<40:51,  4.49it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 3.98e-05:  20%|▏| 2839/13852 [10:35<40:52,  4.49it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 3.98e-05:  21%|▏| 2840/13852 [10:35<41:08,  4.46it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 3.97e-05:  21%|▏| 2841/13852 [10:35<40:53,  4.49it/s\u001b[A\n",
      "Training loss: 7.27e-02 lr: 3.97e-05:  21%|▏| 2842/13852 [10:35<40:35,  4.52it/s\u001b[A\n",
      "Training loss: 7.39e-02 lr: 3.97e-05:  21%|▏| 2843/13852 [10:35<40:38,  4.51it/s\u001b[A\n",
      "Training loss: 8.65e-02 lr: 3.97e-05:  21%|▏| 2844/13852 [10:36<40:40,  4.51it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.97e-05:  21%|▏| 2845/13852 [10:36<40:42,  4.51it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 3.97e-05:  21%|▏| 2846/13852 [10:36<40:46,  4.50it/s\u001b[A\n",
      "Training loss: 8.98e-02 lr: 3.97e-05:  21%|▏| 2847/13852 [10:36<40:46,  4.50it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.97e-05:  21%|▏| 2848/13852 [10:37<40:47,  4.50it/s\u001b[A\n",
      "Training loss: 8.98e-02 lr: 3.97e-05:  21%|▏| 2849/13852 [10:37<41:11,  4.45it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 3.97e-05:  21%|▏| 2850/13852 [10:37<41:18,  4.44it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.97e-05:  21%|▏| 2851/13852 [10:37<41:14,  4.45it/s\u001b[A\n",
      "Training loss: 8.62e-02 lr: 3.97e-05:  21%|▏| 2852/13852 [10:37<42:05,  4.36it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.97e-05:  21%|▏| 2853/13852 [10:38<42:38,  4.30it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.97e-05:  21%|▏| 2854/13852 [10:38<42:58,  4.27it/s\u001b[A\n",
      "Training loss: 9.59e-02 lr: 3.97e-05:  21%|▏| 2855/13852 [10:38<43:17,  4.23it/s\u001b[A\n",
      "Training loss: 7.11e-02 lr: 3.97e-05:  21%|▏| 2856/13852 [10:38<42:32,  4.31it/s\u001b[A\n",
      "Training loss: 9.35e-02 lr: 3.97e-05:  21%|▏| 2857/13852 [10:39<42:00,  4.36it/s\u001b[A\n",
      "Training loss: 8.31e-02 lr: 3.97e-05:  21%|▏| 2858/13852 [10:39<41:36,  4.40it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 3.97e-05:  21%|▏| 2859/13852 [10:39<41:08,  4.45it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 3.97e-05:  21%|▏| 2860/13852 [10:39<41:00,  4.47it/s\u001b[A\n",
      "Training loss: 5.68e-02 lr: 3.97e-05:  21%|▏| 2861/13852 [10:39<40:34,  4.51it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 3.97e-05:  21%|▏| 2862/13852 [10:40<40:39,  4.51it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 3.97e-05:  21%|▏| 2863/13852 [10:40<40:37,  4.51it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.97e-05:  21%|▏| 2864/13852 [10:40<40:37,  4.51it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.97e-05:  21%|▏| 2865/13852 [10:40<40:36,  4.51it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 3.97e-05:  21%|▏| 2866/13852 [10:41<40:39,  4.50it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.97e-05:  21%|▏| 2867/13852 [10:41<40:47,  4.49it/s\u001b[A\n",
      "Training loss: 9.38e-02 lr: 3.97e-05:  21%|▏| 2868/13852 [10:41<40:46,  4.49it/s\u001b[A\n",
      "Training loss: 8.76e-02 lr: 3.96e-05:  21%|▏| 2869/13852 [10:41<40:49,  4.48it/s\u001b[A\n",
      "Training loss: 7.17e-02 lr: 3.96e-05:  21%|▏| 2870/13852 [10:42<40:46,  4.49it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 3.96e-05:  21%|▏| 2871/13852 [10:42<40:44,  4.49it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 3.96e-05:  21%|▏| 2872/13852 [10:42<40:30,  4.52it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 3.96e-05:  21%|▏| 2873/13852 [10:42<40:25,  4.53it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.96e-05:  21%|▏| 2874/13852 [10:42<40:27,  4.52it/s\u001b[A\n",
      "Training loss: 8.77e-02 lr: 3.96e-05:  21%|▏| 2875/13852 [10:43<40:23,  4.53it/s\u001b[A\n",
      "Training loss: 7.57e-02 lr: 3.96e-05:  21%|▏| 2876/13852 [10:43<40:27,  4.52it/s\u001b[A\n",
      "Training loss: 8.28e-02 lr: 3.96e-05:  21%|▏| 2877/13852 [10:43<40:29,  4.52it/s\u001b[A\n",
      "Training loss: 6.41e-02 lr: 3.96e-05:  21%|▏| 2878/13852 [10:43<40:39,  4.50it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 3.96e-05:  21%|▏| 2879/13852 [10:43<40:39,  4.50it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 3.96e-05:  21%|▏| 2880/13852 [10:44<40:41,  4.49it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 3.96e-05:  21%|▏| 2881/13852 [10:44<40:46,  4.48it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 3.96e-05:  21%|▏| 2882/13852 [10:44<42:02,  4.35it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 3.96e-05:  21%|▏| 2883/13852 [10:44<43:02,  4.25it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 3.96e-05:  21%|▏| 2884/13852 [10:45<43:39,  4.19it/s\u001b[A\n",
      "Training loss: 5.43e-02 lr: 3.96e-05:  21%|▏| 2885/13852 [10:45<43:56,  4.16it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 3.96e-05:  21%|▏| 2886/13852 [10:45<44:00,  4.15it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 3.96e-05:  21%|▏| 2887/13852 [10:45<43:03,  4.24it/s\u001b[A\n",
      "Training loss: 6.46e-02 lr: 3.96e-05:  21%|▏| 2888/13852 [10:46<42:09,  4.34it/s\u001b[A\n",
      "Training loss: 9.35e-02 lr: 3.96e-05:  21%|▏| 2889/13852 [10:46<41:28,  4.41it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 3.96e-05:  21%|▏| 2890/13852 [10:46<40:58,  4.46it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 3.96e-05:  21%|▏| 2891/13852 [10:46<40:58,  4.46it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 3.96e-05:  21%|▏| 2892/13852 [10:46<40:50,  4.47it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 3.96e-05:  21%|▏| 2893/13852 [10:47<41:01,  4.45it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 3.96e-05:  21%|▏| 2894/13852 [10:47<40:56,  4.46it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 3.96e-05:  21%|▏| 2895/13852 [10:47<40:55,  4.46it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 3.95e-05:  21%|▏| 2896/13852 [10:47<40:51,  4.47it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 3.95e-05:  21%|▏| 2897/13852 [10:48<40:54,  4.46it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 3.95e-05:  21%|▏| 2898/13852 [10:48<40:48,  4.47it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 3.95e-05:  21%|▏| 2899/13852 [10:48<40:55,  4.46it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 3.95e-05:  21%|▏| 2900/13852 [10:48<40:37,  4.49it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.26e-02 lr: 3.95e-05:  21%|▏| 2901/13852 [10:49<40:28,  4.51it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 3.95e-05:  21%|▏| 2902/13852 [10:49<40:36,  4.49it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 3.95e-05:  21%|▏| 2903/13852 [10:49<40:33,  4.50it/s\u001b[A\n",
      "Training loss: 5.09e-02 lr: 3.95e-05:  21%|▏| 2904/13852 [10:49<40:28,  4.51it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 3.95e-05:  21%|▏| 2905/13852 [10:49<40:35,  4.49it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 3.95e-05:  21%|▏| 2906/13852 [10:50<40:35,  4.49it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 3.95e-05:  21%|▏| 2907/13852 [10:50<40:33,  4.50it/s\u001b[A\n",
      "Training loss: 7.84e-02 lr: 3.95e-05:  21%|▏| 2908/13852 [10:50<40:40,  4.49it/s\u001b[A\n",
      "Training loss: 7.39e-02 lr: 3.95e-05:  21%|▏| 2909/13852 [10:50<40:45,  4.48it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 3.95e-05:  21%|▏| 2910/13852 [10:51<40:44,  4.48it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 3.95e-05:  21%|▏| 2911/13852 [10:51<40:38,  4.49it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 3.95e-05:  21%|▏| 2912/13852 [10:51<40:34,  4.49it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.95e-05:  21%|▏| 2913/13852 [10:51<40:48,  4.47it/s\u001b[A\n",
      "Training loss: 9.36e-02 lr: 3.95e-05:  21%|▏| 2914/13852 [10:51<40:43,  4.48it/s\u001b[A\n",
      "Training loss: 6.70e-02 lr: 3.95e-05:  21%|▏| 2915/13852 [10:52<40:39,  4.48it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 3.95e-05:  21%|▏| 2916/13852 [10:52<40:38,  4.48it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 3.95e-05:  21%|▏| 2917/13852 [10:52<40:47,  4.47it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 3.95e-05:  21%|▏| 2918/13852 [10:52<40:44,  4.47it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 3.95e-05:  21%|▏| 2919/13852 [10:53<40:42,  4.48it/s\u001b[A\n",
      "Training loss: 4.61e-02 lr: 3.95e-05:  21%|▏| 2920/13852 [10:53<40:48,  4.46it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 3.95e-05:  21%|▏| 2921/13852 [10:53<40:42,  4.48it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.95e-05:  21%|▏| 2922/13852 [10:53<40:27,  4.50it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.95e-05:  21%|▏| 2923/13852 [10:53<40:16,  4.52it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.94e-05:  21%|▏| 2924/13852 [10:54<40:05,  4.54it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.94e-05:  21%|▏| 2925/13852 [10:54<40:15,  4.52it/s\u001b[A\n",
      "Training loss: 8.31e-02 lr: 3.94e-05:  21%|▏| 2926/13852 [10:54<40:22,  4.51it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 3.94e-05:  21%|▏| 2927/13852 [10:54<40:25,  4.50it/s\u001b[A\n",
      "Training loss: 8.16e-02 lr: 3.94e-05:  21%|▏| 2928/13852 [10:55<40:29,  4.50it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.94e-05:  21%|▏| 2929/13852 [10:55<40:28,  4.50it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.94e-05:  21%|▏| 2930/13852 [10:55<40:31,  4.49it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.94e-05:  21%|▏| 2931/13852 [10:55<40:28,  4.50it/s\u001b[A\n",
      "Training loss: 1.58e-01 lr: 3.94e-05:  21%|▏| 2932/13852 [10:55<40:33,  4.49it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 3.94e-05:  21%|▏| 2933/13852 [10:56<40:34,  4.49it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 3.94e-05:  21%|▏| 2934/13852 [10:56<40:23,  4.51it/s\u001b[A\n",
      "Training loss: 1.89e-01 lr: 3.94e-05:  21%|▏| 2935/13852 [10:56<40:12,  4.53it/s\u001b[A\n",
      "Training loss: 1.58e-01 lr: 3.94e-05:  21%|▏| 2936/13852 [10:56<40:09,  4.53it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.94e-05:  21%|▏| 2937/13852 [10:57<40:19,  4.51it/s\u001b[A\n",
      "Training loss: 1.59e-01 lr: 3.94e-05:  21%|▏| 2938/13852 [10:57<40:38,  4.48it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 3.94e-05:  21%|▏| 2939/13852 [10:57<40:37,  4.48it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.94e-05:  21%|▏| 2940/13852 [10:57<40:32,  4.49it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.94e-05:  21%|▏| 2941/13852 [10:57<40:30,  4.49it/s\u001b[A\n",
      "Training loss: 9.77e-02 lr: 3.94e-05:  21%|▏| 2942/13852 [10:58<40:32,  4.49it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 3.94e-05:  21%|▏| 2943/13852 [10:58<40:31,  4.49it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.94e-05:  21%|▏| 2944/13852 [10:58<40:46,  4.46it/s\u001b[A\n",
      "Training loss: 8.61e-02 lr: 3.94e-05:  21%|▏| 2945/13852 [10:58<40:28,  4.49it/s\u001b[A\n",
      "Training loss: 9.63e-02 lr: 3.94e-05:  21%|▏| 2946/13852 [10:59<40:12,  4.52it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 3.94e-05:  21%|▏| 2947/13852 [10:59<40:00,  4.54it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.94e-05:  21%|▏| 2948/13852 [10:59<40:25,  4.50it/s\u001b[A\n",
      "Training loss: 8.58e-02 lr: 3.94e-05:  21%|▏| 2949/13852 [10:59<40:22,  4.50it/s\u001b[A\n",
      "Training loss: 7.88e-02 lr: 3.94e-05:  21%|▏| 2950/13852 [10:59<40:20,  4.50it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 3.94e-05:  21%|▏| 2951/13852 [11:00<40:22,  4.50it/s\u001b[A\n",
      "Training loss: 9.44e-02 lr: 3.93e-05:  21%|▏| 2952/13852 [11:00<40:27,  4.49it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 3.93e-05:  21%|▏| 2953/13852 [11:00<40:32,  4.48it/s\u001b[A\n",
      "Training loss: 8.84e-02 lr: 3.93e-05:  21%|▏| 2954/13852 [11:00<40:34,  4.48it/s\u001b[A\n",
      "Training loss: 1.62e-01 lr: 3.93e-05:  21%|▏| 2955/13852 [11:01<40:32,  4.48it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.93e-05:  21%|▏| 2956/13852 [11:01<40:38,  4.47it/s\u001b[A\n",
      "Training loss: 9.20e-02 lr: 3.93e-05:  21%|▏| 2957/13852 [11:01<40:27,  4.49it/s\u001b[A\n",
      "Training loss: 8.22e-02 lr: 3.93e-05:  21%|▏| 2958/13852 [11:01<40:11,  4.52it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 3.93e-05:  21%|▏| 2959/13852 [11:01<40:02,  4.53it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 3.93e-05:  21%|▏| 2960/13852 [11:02<40:02,  4.53it/s\u001b[A\n",
      "Training loss: 7.60e-02 lr: 3.93e-05:  21%|▏| 2961/13852 [11:02<40:08,  4.52it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 3.93e-05:  21%|▏| 2962/13852 [11:02<40:12,  4.51it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 3.93e-05:  21%|▏| 2963/13852 [11:02<40:24,  4.49it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 3.93e-05:  21%|▏| 2964/13852 [11:03<40:25,  4.49it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 3.93e-05:  21%|▏| 2965/13852 [11:03<40:26,  4.49it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 3.93e-05:  21%|▏| 2966/13852 [11:03<40:36,  4.47it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 3.93e-05:  21%|▏| 2967/13852 [11:03<40:32,  4.47it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 3.93e-05:  21%|▏| 2968/13852 [11:03<40:32,  4.47it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 3.93e-05:  21%|▏| 2969/13852 [11:04<40:21,  4.49it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 3.93e-05:  21%|▏| 2970/13852 [11:04<40:08,  4.52it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 3.93e-05:  21%|▏| 2971/13852 [11:04<39:56,  4.54it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 3.93e-05:  21%|▏| 2972/13852 [11:04<40:12,  4.51it/s\u001b[A\n",
      "Training loss: 3.43e-02 lr: 3.93e-05:  21%|▏| 2973/13852 [11:05<40:11,  4.51it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 3.93e-05:  21%|▏| 2974/13852 [11:05<40:18,  4.50it/s\u001b[A\n",
      "Training loss: 9.28e-02 lr: 3.93e-05:  21%|▏| 2975/13852 [11:05<40:33,  4.47it/s\u001b[A\n",
      "Training loss: 8.23e-02 lr: 3.93e-05:  21%|▏| 2976/13852 [11:05<40:31,  4.47it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 3.93e-05:  21%|▏| 2977/13852 [11:05<40:29,  4.48it/s\u001b[A\n",
      "Training loss: 4.82e-02 lr: 3.93e-05:  21%|▏| 2978/13852 [11:06<40:26,  4.48it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 3.92e-05:  22%|▏| 2979/13852 [11:06<40:25,  4.48it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 3.92e-05:  22%|▏| 2980/13852 [11:06<40:21,  4.49it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 3.92e-05:  22%|▏| 2981/13852 [11:06<40:07,  4.52it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.92e-05:  22%|▏| 2982/13852 [11:07<39:53,  4.54it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 3.92e-05:  22%|▏| 2983/13852 [11:07<40:47,  4.44it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 3.92e-05:  22%|▏| 2984/13852 [11:07<42:17,  4.28it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 3.92e-05:  22%|▏| 2985/13852 [11:07<42:37,  4.25it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.92e-05:  22%|▏| 2986/13852 [11:07<42:55,  4.22it/s\u001b[A\n",
      "Training loss: 8.36e-02 lr: 3.92e-05:  22%|▏| 2987/13852 [11:08<42:07,  4.30it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 3.92e-05:  22%|▏| 2988/13852 [11:08<41:23,  4.38it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 3.92e-05:  22%|▏| 2989/13852 [11:08<40:45,  4.44it/s\u001b[A\n",
      "Training loss: 1.87e-01 lr: 3.92e-05:  22%|▏| 2990/13852 [11:08<40:18,  4.49it/s\u001b[A\n",
      "Training loss: 2.12e-01 lr: 3.92e-05:  22%|▏| 2991/13852 [11:09<40:34,  4.46it/s\u001b[A\n",
      "Training loss: 1.61e-01 lr: 3.92e-05:  22%|▏| 2992/13852 [11:09<40:25,  4.48it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.92e-05:  22%|▏| 2993/13852 [11:09<40:15,  4.50it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.92e-05:  22%|▏| 2994/13852 [11:09<40:21,  4.48it/s\u001b[A\n",
      "Training loss: 9.67e-02 lr: 3.92e-05:  22%|▏| 2995/13852 [11:09<40:16,  4.49it/s\u001b[A\n",
      "Training loss: 8.40e-02 lr: 3.92e-05:  22%|▏| 2996/13852 [11:10<40:18,  4.49it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.92e-05:  22%|▏| 2997/13852 [11:10<40:14,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.35e-01 lr: 3.92e-05:  22%|▏| 2998/13852 [11:10<40:18,  4.49it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 3.92e-05:  22%|▏| 2999/13852 [11:10<40:17,  4.49it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.92e-05:  22%|▏| 3000/13852 [11:11<40:07,  4.51it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.92e-05:  22%|▏| 3001/13852 [11:11<40:10,  4.50it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.92e-05:  22%|▏| 3002/13852 [11:11<40:00,  4.52it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.92e-05:  22%|▏| 3003/13852 [11:11<40:04,  4.51it/s\u001b[A\n",
      "Training loss: 8.12e-02 lr: 3.92e-05:  22%|▏| 3004/13852 [11:11<40:04,  4.51it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 3.92e-05:  22%|▏| 3005/13852 [11:12<40:15,  4.49it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 3.92e-05:  22%|▏| 3006/13852 [11:12<40:18,  4.48it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 3.91e-05:  22%|▏| 3007/13852 [11:12<40:16,  4.49it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 3.91e-05:  22%|▏| 3008/13852 [11:12<40:16,  4.49it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.91e-05:  22%|▏| 3009/13852 [11:13<40:12,  4.49it/s\u001b[A\n",
      "Training loss: 9.71e-02 lr: 3.91e-05:  22%|▏| 3010/13852 [11:13<40:11,  4.50it/s\u001b[A\n",
      "Training loss: 8.01e-02 lr: 3.91e-05:  22%|▏| 3011/13852 [11:13<40:10,  4.50it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.91e-05:  22%|▏| 3012/13852 [11:13<40:04,  4.51it/s\u001b[A\n",
      "Training loss: 8.60e-02 lr: 3.91e-05:  22%|▏| 3013/13852 [11:13<39:52,  4.53it/s\u001b[A\n",
      "Training loss: 9.18e-02 lr: 3.91e-05:  22%|▏| 3014/13852 [11:14<39:42,  4.55it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 3.91e-05:  22%|▏| 3015/13852 [11:14<39:57,  4.52it/s\u001b[A\n",
      "Training loss: 8.90e-02 lr: 3.91e-05:  22%|▏| 3016/13852 [11:14<39:57,  4.52it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 3.91e-05:  22%|▏| 3017/13852 [11:14<40:01,  4.51it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 3.91e-05:  22%|▏| 3018/13852 [11:15<40:01,  4.51it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 3.91e-05:  22%|▏| 3019/13852 [11:15<40:03,  4.51it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 3.91e-05:  22%|▏| 3020/13852 [11:15<40:13,  4.49it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 3.91e-05:  22%|▏| 3021/13852 [11:15<40:10,  4.49it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 3.91e-05:  22%|▏| 3022/13852 [11:15<40:14,  4.49it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 3.91e-05:  22%|▏| 3023/13852 [11:16<40:13,  4.49it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.91e-05:  22%|▏| 3024/13852 [11:16<39:57,  4.52it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.91e-05:  22%|▏| 3025/13852 [11:16<39:46,  4.54it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.91e-05:  22%|▏| 3026/13852 [11:16<39:34,  4.56it/s\u001b[A\n",
      "Training loss: 1.48e-01 lr: 3.91e-05:  22%|▏| 3027/13852 [11:17<40:00,  4.51it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.91e-05:  22%|▏| 3028/13852 [11:17<40:24,  4.46it/s\u001b[A\n",
      "Training loss: 9.27e-02 lr: 3.91e-05:  22%|▏| 3029/13852 [11:17<40:31,  4.45it/s\u001b[A\n",
      "Training loss: 7.94e-02 lr: 3.91e-05:  22%|▏| 3030/13852 [11:17<40:21,  4.47it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 3.91e-05:  22%|▏| 3031/13852 [11:17<40:14,  4.48it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 3.91e-05:  22%|▏| 3032/13852 [11:18<40:09,  4.49it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 3.91e-05:  22%|▏| 3033/13852 [11:18<40:06,  4.50it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 3.91e-05:  22%|▏| 3034/13852 [11:18<40:11,  4.49it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 3.90e-05:  22%|▏| 3035/13852 [11:18<39:58,  4.51it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 3.90e-05:  22%|▏| 3036/13852 [11:19<39:42,  4.54it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 3.90e-05:  22%|▏| 3037/13852 [11:19<39:32,  4.56it/s\u001b[A\n",
      "Training loss: 4.95e-02 lr: 3.90e-05:  22%|▏| 3038/13852 [11:19<39:25,  4.57it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 3.90e-05:  22%|▏| 3039/13852 [11:19<39:22,  4.58it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 3.90e-05:  22%|▏| 3040/13852 [11:19<39:32,  4.56it/s\u001b[A\n",
      "Training loss: 8.94e-02 lr: 3.90e-05:  22%|▏| 3041/13852 [11:20<39:35,  4.55it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.90e-05:  22%|▏| 3042/13852 [11:20<39:46,  4.53it/s\u001b[A\n",
      "Training loss: 9.02e-02 lr: 3.90e-05:  22%|▏| 3043/13852 [11:20<39:51,  4.52it/s\u001b[A\n",
      "Training loss: 8.28e-02 lr: 3.90e-05:  22%|▏| 3044/13852 [11:20<39:57,  4.51it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 3.90e-05:  22%|▏| 3045/13852 [11:21<40:01,  4.50it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.90e-05:  22%|▏| 3046/13852 [11:21<40:13,  4.48it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.90e-05:  22%|▏| 3047/13852 [11:21<40:13,  4.48it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 3.90e-05:  22%|▏| 3048/13852 [11:21<40:11,  4.48it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 3.90e-05:  22%|▏| 3049/13852 [11:21<39:54,  4.51it/s\u001b[A\n",
      "Training loss: 9.24e-02 lr: 3.90e-05:  22%|▏| 3050/13852 [11:22<39:51,  4.52it/s\u001b[A\n",
      "Training loss: 9.94e-02 lr: 3.90e-05:  22%|▏| 3051/13852 [11:22<40:13,  4.48it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.90e-05:  22%|▏| 3052/13852 [11:22<40:09,  4.48it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.90e-05:  22%|▏| 3053/13852 [11:22<40:09,  4.48it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.90e-05:  22%|▏| 3054/13852 [11:23<40:21,  4.46it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.90e-05:  22%|▏| 3055/13852 [11:23<40:21,  4.46it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.90e-05:  22%|▏| 3056/13852 [11:23<40:20,  4.46it/s\u001b[A\n",
      "Training loss: 8.09e-02 lr: 3.90e-05:  22%|▏| 3057/13852 [11:23<40:15,  4.47it/s\u001b[A\n",
      "Training loss: 7.71e-02 lr: 3.90e-05:  22%|▏| 3058/13852 [11:23<40:12,  4.47it/s\u001b[A\n",
      "Training loss: 8.51e-02 lr: 3.90e-05:  22%|▏| 3059/13852 [11:24<40:05,  4.49it/s\u001b[A\n",
      "Training loss: 7.30e-02 lr: 3.90e-05:  22%|▏| 3060/13852 [11:24<39:47,  4.52it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 3.90e-05:  22%|▏| 3061/13852 [11:24<39:35,  4.54it/s\u001b[A\n",
      "Training loss: 8.19e-02 lr: 3.90e-05:  22%|▏| 3062/13852 [11:24<40:02,  4.49it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 3.89e-05:  22%|▏| 3063/13852 [11:25<40:05,  4.49it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 3.89e-05:  22%|▏| 3064/13852 [11:25<39:57,  4.50it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 3.89e-05:  22%|▏| 3065/13852 [11:25<40:08,  4.48it/s\u001b[A\n",
      "Training loss: 8.82e-02 lr: 3.89e-05:  22%|▏| 3066/13852 [11:25<40:09,  4.48it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 3.89e-05:  22%|▏| 3067/13852 [11:25<41:18,  4.35it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 3.89e-05:  22%|▏| 3068/13852 [11:26<42:09,  4.26it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 3.89e-05:  22%|▏| 3069/13852 [11:26<41:22,  4.34it/s\u001b[A\n",
      "Training loss: 5.63e-02 lr: 3.89e-05:  22%|▏| 3070/13852 [11:26<40:39,  4.42it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 3.89e-05:  22%|▏| 3071/13852 [11:26<40:46,  4.41it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 3.89e-05:  22%|▏| 3072/13852 [11:27<40:35,  4.43it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 3.89e-05:  22%|▏| 3073/13852 [11:27<40:33,  4.43it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 3.89e-05:  22%|▏| 3074/13852 [11:27<40:32,  4.43it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 3.89e-05:  22%|▏| 3075/13852 [11:27<40:23,  4.45it/s\u001b[A\n",
      "Training loss: 5.63e-02 lr: 3.89e-05:  22%|▏| 3076/13852 [11:28<40:14,  4.46it/s\u001b[A\n",
      "Training loss: 8.91e-02 lr: 3.89e-05:  22%|▏| 3077/13852 [11:28<40:10,  4.47it/s\u001b[A\n",
      "Training loss: 6.93e-02 lr: 3.89e-05:  22%|▏| 3078/13852 [11:28<40:09,  4.47it/s\u001b[A\n",
      "Training loss: 7.94e-02 lr: 3.89e-05:  22%|▏| 3079/13852 [11:28<39:58,  4.49it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 3.89e-05:  22%|▏| 3080/13852 [11:28<39:45,  4.52it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 3.89e-05:  22%|▏| 3081/13852 [11:29<39:30,  4.54it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.89e-05:  22%|▏| 3082/13852 [11:29<39:22,  4.56it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 3.89e-05:  22%|▏| 3083/13852 [11:29<39:24,  4.55it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 3.89e-05:  22%|▏| 3084/13852 [11:29<39:29,  4.54it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.89e-05:  22%|▏| 3085/13852 [11:30<39:33,  4.54it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 3.89e-05:  22%|▏| 3086/13852 [11:30<39:42,  4.52it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 3.89e-05:  22%|▏| 3087/13852 [11:30<39:47,  4.51it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 3.89e-05:  22%|▏| 3088/13852 [11:30<39:52,  4.50it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 3.89e-05:  22%|▏| 3089/13852 [11:30<39:56,  4.49it/s\u001b[A\n",
      "Training loss: 6.34e-02 lr: 3.88e-05:  22%|▏| 3090/13852 [11:31<39:56,  4.49it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 3.88e-05:  22%|▏| 3091/13852 [11:31<40:16,  4.45it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 3.88e-05:  22%|▏| 3092/13852 [11:31<39:59,  4.48it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 3.88e-05:  22%|▏| 3093/13852 [11:31<39:47,  4.51it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 3.88e-05:  22%|▏| 3094/13852 [11:32<39:34,  4.53it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.30e-02 lr: 3.88e-05:  22%|▏| 3095/13852 [11:32<40:11,  4.46it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 3.88e-05:  22%|▏| 3096/13852 [11:32<40:04,  4.47it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 3.88e-05:  22%|▏| 3097/13852 [11:32<41:06,  4.36it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.88e-05:  22%|▏| 3098/13852 [11:32<40:49,  4.39it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 3.88e-05:  22%|▏| 3099/13852 [11:33<40:33,  4.42it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 3.88e-05:  22%|▏| 3100/13852 [11:33<40:21,  4.44it/s\u001b[A\n",
      "Training loss: 7.11e-02 lr: 3.88e-05:  22%|▏| 3101/13852 [11:33<40:15,  4.45it/s\u001b[A\n",
      "Training loss: 8.03e-02 lr: 3.88e-05:  22%|▏| 3102/13852 [11:33<40:03,  4.47it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 3.88e-05:  22%|▏| 3103/13852 [11:34<39:46,  4.50it/s\u001b[A\n",
      "Training loss: 7.88e-02 lr: 3.88e-05:  22%|▏| 3104/13852 [11:34<39:29,  4.54it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 3.88e-05:  22%|▏| 3105/13852 [11:34<39:50,  4.50it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 3.88e-05:  22%|▏| 3106/13852 [11:34<39:47,  4.50it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.88e-05:  22%|▏| 3107/13852 [11:34<39:47,  4.50it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.88e-05:  22%|▏| 3108/13852 [11:35<39:48,  4.50it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.88e-05:  22%|▏| 3109/13852 [11:35<39:49,  4.50it/s\u001b[A\n",
      "Training loss: 9.01e-02 lr: 3.88e-05:  22%|▏| 3110/13852 [11:35<40:03,  4.47it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 3.88e-05:  22%|▏| 3111/13852 [11:35<40:03,  4.47it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.88e-05:  22%|▏| 3112/13852 [11:36<40:04,  4.47it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 3.88e-05:  22%|▏| 3113/13852 [11:36<40:00,  4.47it/s\u001b[A\n",
      "Training loss: 9.12e-02 lr: 3.88e-05:  22%|▏| 3114/13852 [11:36<39:43,  4.50it/s\u001b[A\n",
      "Training loss: 9.00e-02 lr: 3.88e-05:  22%|▏| 3115/13852 [11:36<39:28,  4.53it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 3.88e-05:  22%|▏| 3116/13852 [11:36<39:36,  4.52it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 3.88e-05:  23%|▏| 3117/13852 [11:37<39:50,  4.49it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 3.87e-05:  23%|▏| 3118/13852 [11:37<40:06,  4.46it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 3.87e-05:  23%|▏| 3119/13852 [11:37<40:13,  4.45it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.87e-05:  23%|▏| 3120/13852 [11:37<40:21,  4.43it/s\u001b[A\n",
      "Training loss: 8.22e-02 lr: 3.87e-05:  23%|▏| 3121/13852 [11:38<40:18,  4.44it/s\u001b[A\n",
      "Training loss: 8.02e-02 lr: 3.87e-05:  23%|▏| 3122/13852 [11:38<40:13,  4.45it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 3.87e-05:  23%|▏| 3123/13852 [11:38<40:06,  4.46it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 3.87e-05:  23%|▏| 3124/13852 [11:38<39:52,  4.48it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.87e-05:  23%|▏| 3125/13852 [11:38<39:36,  4.51it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.87e-05:  23%|▏| 3126/13852 [11:39<39:27,  4.53it/s\u001b[A\n",
      "Training loss: 8.43e-02 lr: 3.87e-05:  23%|▏| 3127/13852 [11:39<39:57,  4.47it/s\u001b[A\n",
      "Training loss: 7.00e-02 lr: 3.87e-05:  23%|▏| 3128/13852 [11:39<39:46,  4.49it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 3.87e-05:  23%|▏| 3129/13852 [11:39<39:38,  4.51it/s\u001b[A\n",
      "Training loss: 8.97e-02 lr: 3.87e-05:  23%|▏| 3130/13852 [11:40<39:38,  4.51it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.87e-05:  23%|▏| 3131/13852 [11:40<40:27,  4.42it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 3.87e-05:  23%|▏| 3132/13852 [11:40<40:11,  4.44it/s\u001b[A\n",
      "Training loss: 8.28e-02 lr: 3.87e-05:  23%|▏| 3133/13852 [11:40<40:00,  4.47it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 3.87e-05:  23%|▏| 3134/13852 [11:40<39:56,  4.47it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 3.87e-05:  23%|▏| 3135/13852 [11:41<39:43,  4.50it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 3.87e-05:  23%|▏| 3136/13852 [11:41<39:51,  4.48it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 3.87e-05:  23%|▏| 3137/13852 [11:41<39:35,  4.51it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 3.87e-05:  23%|▏| 3138/13852 [11:41<39:19,  4.54it/s\u001b[A\n",
      "Training loss: 7.58e-02 lr: 3.87e-05:  23%|▏| 3139/13852 [11:42<39:34,  4.51it/s\u001b[A\n",
      "Training loss: 8.21e-02 lr: 3.87e-05:  23%|▏| 3140/13852 [11:42<39:33,  4.51it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.87e-05:  23%|▏| 3141/13852 [11:42<39:33,  4.51it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.87e-05:  23%|▏| 3142/13852 [11:42<39:32,  4.51it/s\u001b[A\n",
      "Training loss: 8.57e-02 lr: 3.87e-05:  23%|▏| 3143/13852 [11:42<39:34,  4.51it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 3.87e-05:  23%|▏| 3144/13852 [11:43<39:37,  4.50it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 3.87e-05:  23%|▏| 3145/13852 [11:43<39:36,  4.51it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 3.86e-05:  23%|▏| 3146/13852 [11:43<39:36,  4.51it/s\u001b[A\n",
      "Training loss: 6.12e-02 lr: 3.86e-05:  23%|▏| 3147/13852 [11:43<39:39,  4.50it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 3.86e-05:  23%|▏| 3148/13852 [11:44<39:31,  4.51it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 3.86e-05:  23%|▏| 3149/13852 [11:44<39:17,  4.54it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 3.86e-05:  23%|▏| 3150/13852 [11:44<39:07,  4.56it/s\u001b[A\n",
      "Training loss: 3.73e-02 lr: 3.86e-05:  23%|▏| 3151/13852 [11:44<39:35,  4.51it/s\u001b[A\n",
      "Training loss: 3.12e-02 lr: 3.86e-05:  23%|▏| 3152/13852 [11:44<39:32,  4.51it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 3.86e-05:  23%|▏| 3153/13852 [11:45<39:34,  4.51it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 3.86e-05:  23%|▏| 3154/13852 [11:45<39:32,  4.51it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 3.86e-05:  23%|▏| 3155/13852 [11:45<39:35,  4.50it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 3.86e-05:  23%|▏| 3156/13852 [11:45<39:35,  4.50it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 3.86e-05:  23%|▏| 3157/13852 [11:46<39:35,  4.50it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 3.86e-05:  23%|▏| 3158/13852 [11:46<39:38,  4.50it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 3.86e-05:  23%|▏| 3159/13852 [11:46<39:38,  4.49it/s\u001b[A\n",
      "Training loss: 2.95e-02 lr: 3.86e-05:  23%|▏| 3160/13852 [11:46<39:24,  4.52it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 3.86e-05:  23%|▏| 3161/13852 [11:46<39:11,  4.55it/s\u001b[A\n",
      "Training loss: 4.82e-02 lr: 3.86e-05:  23%|▏| 3162/13852 [11:47<39:06,  4.56it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 3.86e-05:  23%|▏| 3163/13852 [11:47<39:47,  4.48it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 3.86e-05:  23%|▏| 3164/13852 [11:47<39:42,  4.49it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 3.86e-05:  23%|▏| 3165/13852 [11:47<39:40,  4.49it/s\u001b[A\n",
      "Training loss: 9.74e-02 lr: 3.86e-05:  23%|▏| 3166/13852 [11:48<39:36,  4.50it/s\u001b[A\n",
      "Training loss: 7.24e-02 lr: 3.86e-05:  23%|▏| 3167/13852 [11:48<39:39,  4.49it/s\u001b[A\n",
      "Training loss: 9.01e-02 lr: 3.86e-05:  23%|▏| 3168/13852 [11:48<39:55,  4.46it/s\u001b[A\n",
      "Training loss: 9.38e-02 lr: 3.86e-05:  23%|▏| 3169/13852 [11:48<39:48,  4.47it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 3.86e-05:  23%|▏| 3170/13852 [11:48<39:43,  4.48it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 3.86e-05:  23%|▏| 3171/13852 [11:49<39:31,  4.50it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 3.86e-05:  23%|▏| 3172/13852 [11:49<39:23,  4.52it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 3.85e-05:  23%|▏| 3173/13852 [11:49<39:14,  4.54it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 3.85e-05:  23%|▏| 3174/13852 [11:49<39:03,  4.56it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 3.85e-05:  23%|▏| 3175/13852 [11:50<39:00,  4.56it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 3.85e-05:  23%|▏| 3176/13852 [11:50<39:05,  4.55it/s\u001b[A\n",
      "Training loss: 4.26e-02 lr: 3.85e-05:  23%|▏| 3177/13852 [11:50<39:08,  4.55it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 3.85e-05:  23%|▏| 3178/13852 [11:50<39:17,  4.53it/s\u001b[A\n",
      "Training loss: 7.58e-02 lr: 3.85e-05:  23%|▏| 3179/13852 [11:50<39:22,  4.52it/s\u001b[A\n",
      "Training loss: 8.44e-02 lr: 3.85e-05:  23%|▏| 3180/13852 [11:51<39:26,  4.51it/s\u001b[A\n",
      "Training loss: 6.68e-02 lr: 3.85e-05:  23%|▏| 3181/13852 [11:51<39:52,  4.46it/s\u001b[A\n",
      "Training loss: 6.32e-02 lr: 3.85e-05:  23%|▏| 3182/13852 [11:51<39:51,  4.46it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 3.85e-05:  23%|▏| 3183/13852 [11:51<39:44,  4.47it/s\u001b[A\n",
      "Training loss: 8.23e-02 lr: 3.85e-05:  23%|▏| 3184/13852 [11:52<39:32,  4.50it/s\u001b[A\n",
      "Training loss: 6.82e-02 lr: 3.85e-05:  23%|▏| 3185/13852 [11:52<39:25,  4.51it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 3.85e-05:  23%|▏| 3186/13852 [11:52<39:12,  4.53it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 3.85e-05:  23%|▏| 3187/13852 [11:52<39:30,  4.50it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 3.85e-05:  23%|▏| 3188/13852 [11:52<39:26,  4.51it/s\u001b[A\n",
      "Training loss: 8.05e-02 lr: 3.85e-05:  23%|▏| 3189/13852 [11:53<39:26,  4.51it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 3.85e-05:  23%|▏| 3190/13852 [11:53<39:27,  4.50it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 3.85e-05:  23%|▏| 3191/13852 [11:53<39:29,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.10e-01 lr: 3.85e-05:  23%|▏| 3192/13852 [11:53<39:27,  4.50it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.85e-05:  23%|▏| 3193/13852 [11:54<39:27,  4.50it/s\u001b[A\n",
      "Training loss: 8.45e-02 lr: 3.85e-05:  23%|▏| 3194/13852 [11:54<39:36,  4.49it/s\u001b[A\n",
      "Training loss: 8.05e-02 lr: 3.85e-05:  23%|▏| 3195/13852 [11:54<39:37,  4.48it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 3.85e-05:  23%|▏| 3196/13852 [11:54<39:23,  4.51it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 3.85e-05:  23%|▏| 3197/13852 [11:54<39:07,  4.54it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 3.85e-05:  23%|▏| 3198/13852 [11:55<38:56,  4.56it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 3.85e-05:  23%|▏| 3199/13852 [11:55<39:27,  4.50it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 3.85e-05:  23%|▏| 3200/13852 [11:55<39:24,  4.50it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 3.84e-05:  23%|▏| 3201/13852 [11:55<39:37,  4.48it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 3.84e-05:  23%|▏| 3202/13852 [11:56<39:36,  4.48it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 3.84e-05:  23%|▏| 3203/13852 [11:56<39:35,  4.48it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 3.84e-05:  23%|▏| 3204/13852 [11:56<39:33,  4.49it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 3.84e-05:  23%|▏| 3205/13852 [11:56<39:31,  4.49it/s\u001b[A\n",
      "Training loss: 8.71e-02 lr: 3.84e-05:  23%|▏| 3206/13852 [11:56<39:31,  4.49it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.84e-05:  23%|▏| 3207/13852 [11:57<39:36,  4.48it/s\u001b[A\n",
      "Training loss: 1.37e-01 lr: 3.84e-05:  23%|▏| 3208/13852 [11:57<39:34,  4.48it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.84e-05:  23%|▏| 3209/13852 [11:57<40:24,  4.39it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.84e-05:  23%|▏| 3210/13852 [11:57<40:59,  4.33it/s\u001b[A\n",
      "Training loss: 1.73e-01 lr: 3.84e-05:  23%|▏| 3211/13852 [11:58<40:30,  4.38it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 3.84e-05:  23%|▏| 3212/13852 [11:58<40:12,  4.41it/s\u001b[A\n",
      "Training loss: 9.37e-02 lr: 3.84e-05:  23%|▏| 3213/13852 [11:58<40:00,  4.43it/s\u001b[A\n",
      "Training loss: 9.27e-02 lr: 3.84e-05:  23%|▏| 3214/13852 [11:58<39:56,  4.44it/s\u001b[A\n",
      "Training loss: 9.02e-02 lr: 3.84e-05:  23%|▏| 3215/13852 [11:58<39:52,  4.45it/s\u001b[A\n",
      "Training loss: 9.86e-02 lr: 3.84e-05:  23%|▏| 3216/13852 [11:59<39:46,  4.46it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 3.84e-05:  23%|▏| 3217/13852 [11:59<39:39,  4.47it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 3.84e-05:  23%|▏| 3218/13852 [11:59<39:20,  4.50it/s\u001b[A\n",
      "Training loss: 8.56e-02 lr: 3.84e-05:  23%|▏| 3219/13852 [11:59<39:05,  4.53it/s\u001b[A\n",
      "Training loss: 7.08e-02 lr: 3.84e-05:  23%|▏| 3220/13852 [12:00<39:23,  4.50it/s\u001b[A\n",
      "Training loss: 6.06e-02 lr: 3.84e-05:  23%|▏| 3221/13852 [12:00<39:18,  4.51it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 3.84e-05:  23%|▏| 3222/13852 [12:00<39:20,  4.50it/s\u001b[A\n",
      "Training loss: 6.34e-02 lr: 3.84e-05:  23%|▏| 3223/13852 [12:00<39:26,  4.49it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 3.84e-05:  23%|▏| 3224/13852 [12:00<39:29,  4.49it/s\u001b[A\n",
      "Training loss: 8.24e-02 lr: 3.84e-05:  23%|▏| 3225/13852 [12:01<39:30,  4.48it/s\u001b[A\n",
      "Training loss: 8.52e-02 lr: 3.84e-05:  23%|▏| 3226/13852 [12:01<39:40,  4.46it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 3.84e-05:  23%|▏| 3227/13852 [12:01<39:36,  4.47it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 3.84e-05:  23%|▏| 3228/13852 [12:01<39:36,  4.47it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 3.83e-05:  23%|▏| 3229/13852 [12:02<39:20,  4.50it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 3.83e-05:  23%|▏| 3230/13852 [12:02<39:15,  4.51it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 3.83e-05:  23%|▏| 3231/13852 [12:02<39:36,  4.47it/s\u001b[A\n",
      "Training loss: 4.57e-02 lr: 3.83e-05:  23%|▏| 3232/13852 [12:02<39:40,  4.46it/s\u001b[A\n",
      "Training loss: 8.02e-02 lr: 3.83e-05:  23%|▏| 3233/13852 [12:02<39:31,  4.48it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 3.83e-05:  23%|▏| 3234/13852 [12:03<39:28,  4.48it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 3.83e-05:  23%|▏| 3235/13852 [12:03<39:27,  4.48it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 3.83e-05:  23%|▏| 3236/13852 [12:03<39:25,  4.49it/s\u001b[A\n",
      "Training loss: 3.73e-02 lr: 3.83e-05:  23%|▏| 3237/13852 [12:03<39:24,  4.49it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 3.83e-05:  23%|▏| 3238/13852 [12:04<39:24,  4.49it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 3.83e-05:  23%|▏| 3239/13852 [12:04<39:26,  4.48it/s\u001b[A\n",
      "Training loss: 5.40e-02 lr: 3.83e-05:  23%|▏| 3240/13852 [12:04<39:12,  4.51it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 3.83e-05:  23%|▏| 3241/13852 [12:04<38:58,  4.54it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 3.83e-05:  23%|▏| 3242/13852 [12:04<38:47,  4.56it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 3.83e-05:  23%|▏| 3243/13852 [12:05<38:39,  4.57it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 3.83e-05:  23%|▏| 3244/13852 [12:05<38:55,  4.54it/s\u001b[A\n",
      "Training loss: 5.07e-02 lr: 3.83e-05:  23%|▏| 3245/13852 [12:05<38:57,  4.54it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 3.83e-05:  23%|▏| 3246/13852 [12:05<39:33,  4.47it/s\u001b[A\n",
      "Training loss: 8.86e-02 lr: 3.83e-05:  23%|▏| 3247/13852 [12:06<39:31,  4.47it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 3.83e-05:  23%|▏| 3248/13852 [12:06<39:31,  4.47it/s\u001b[A\n",
      "Training loss: 9.91e-02 lr: 3.83e-05:  23%|▏| 3249/13852 [12:06<39:27,  4.48it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 3.83e-05:  23%|▏| 3250/13852 [12:06<39:25,  4.48it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 3.83e-05:  23%|▏| 3251/13852 [12:06<39:26,  4.48it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 3.83e-05:  23%|▏| 3252/13852 [12:07<39:44,  4.45it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 3.83e-05:  23%|▏| 3253/13852 [12:07<39:54,  4.43it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 3.83e-05:  23%|▏| 3254/13852 [12:07<39:52,  4.43it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 3.83e-05:  23%|▏| 3255/13852 [12:07<40:32,  4.36it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 3.82e-05:  24%|▏| 3256/13852 [12:08<40:10,  4.40it/s\u001b[A\n",
      "Training loss: 3.62e-02 lr: 3.82e-05:  24%|▏| 3257/13852 [12:08<39:54,  4.43it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.82e-05:  24%|▏| 3258/13852 [12:08<39:45,  4.44it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.82e-05:  24%|▏| 3259/13852 [12:08<39:50,  4.43it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.82e-05:  24%|▏| 3260/13852 [12:09<40:48,  4.33it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.82e-05:  24%|▏| 3261/13852 [12:09<41:33,  4.25it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 3.82e-05:  24%|▏| 3262/13852 [12:09<42:02,  4.20it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.82e-05:  24%|▏| 3263/13852 [12:09<41:52,  4.22it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 3.82e-05:  24%|▏| 3264/13852 [12:09<41:27,  4.26it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 3.82e-05:  24%|▏| 3265/13852 [12:10<41:23,  4.26it/s\u001b[A\n",
      "Training loss: 8.82e-02 lr: 3.82e-05:  24%|▏| 3266/13852 [12:10<40:57,  4.31it/s\u001b[A\n",
      "Training loss: 6.78e-02 lr: 3.82e-05:  24%|▏| 3267/13852 [12:10<40:26,  4.36it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 3.82e-05:  24%|▏| 3268/13852 [12:10<40:54,  4.31it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 3.82e-05:  24%|▏| 3269/13852 [12:11<41:37,  4.24it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 3.82e-05:  24%|▏| 3270/13852 [12:11<41:04,  4.29it/s\u001b[A\n",
      "Training loss: 9.94e-02 lr: 3.82e-05:  24%|▏| 3271/13852 [12:11<40:30,  4.35it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 3.82e-05:  24%|▏| 3272/13852 [12:11<40:08,  4.39it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.82e-05:  24%|▏| 3273/13852 [12:12<39:57,  4.41it/s\u001b[A\n",
      "Training loss: 9.40e-02 lr: 3.82e-05:  24%|▏| 3274/13852 [12:12<39:52,  4.42it/s\u001b[A\n",
      "Training loss: 7.21e-02 lr: 3.82e-05:  24%|▏| 3275/13852 [12:12<39:43,  4.44it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 3.82e-05:  24%|▏| 3276/13852 [12:12<39:24,  4.47it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 3.82e-05:  24%|▏| 3277/13852 [12:12<39:16,  4.49it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 3.82e-05:  24%|▏| 3278/13852 [12:13<38:58,  4.52it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.82e-05:  24%|▏| 3279/13852 [12:13<38:47,  4.54it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 3.82e-05:  24%|▏| 3280/13852 [12:13<39:00,  4.52it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.82e-05:  24%|▏| 3281/13852 [12:13<38:59,  4.52it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.82e-05:  24%|▏| 3282/13852 [12:14<39:03,  4.51it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.82e-05:  24%|▏| 3283/13852 [12:14<39:01,  4.51it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.81e-05:  24%|▏| 3284/13852 [12:14<39:15,  4.49it/s\u001b[A\n",
      "Training loss: 9.29e-02 lr: 3.81e-05:  24%|▏| 3285/13852 [12:14<39:15,  4.49it/s\u001b[A\n",
      "Training loss: 7.94e-02 lr: 3.81e-05:  24%|▏| 3286/13852 [12:14<39:14,  4.49it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.81e-05:  24%|▏| 3287/13852 [12:15<39:17,  4.48it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 3.81e-05:  24%|▏| 3288/13852 [12:15<39:20,  4.48it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.84e-02 lr: 3.81e-05:  24%|▏| 3289/13852 [12:15<39:07,  4.50it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.81e-05:  24%|▏| 3290/13852 [12:15<38:52,  4.53it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 3.81e-05:  24%|▏| 3291/13852 [12:16<39:05,  4.50it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.81e-05:  24%|▏| 3292/13852 [12:16<39:06,  4.50it/s\u001b[A\n",
      "Training loss: 9.16e-02 lr: 3.81e-05:  24%|▏| 3293/13852 [12:16<39:13,  4.49it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 3.81e-05:  24%|▏| 3294/13852 [12:16<39:09,  4.49it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 3.81e-05:  24%|▏| 3295/13852 [12:16<39:09,  4.49it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 3.81e-05:  24%|▏| 3296/13852 [12:17<39:15,  4.48it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 3.81e-05:  24%|▏| 3297/13852 [12:17<39:20,  4.47it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 3.81e-05:  24%|▏| 3298/13852 [12:17<39:18,  4.48it/s\u001b[A\n",
      "Training loss: 6.30e-02 lr: 3.81e-05:  24%|▏| 3299/13852 [12:17<39:18,  4.47it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 3.81e-05:  24%|▏| 3300/13852 [12:18<39:05,  4.50it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 3.81e-05:  24%|▏| 3301/13852 [12:18<38:53,  4.52it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 3.81e-05:  24%|▏| 3302/13852 [12:18<39:10,  4.49it/s\u001b[A\n",
      "Training loss: 6.69e-02 lr: 3.81e-05:  24%|▏| 3303/13852 [12:18<39:07,  4.49it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 3.81e-05:  24%|▏| 3304/13852 [12:18<39:04,  4.50it/s\u001b[A\n",
      "Training loss: 4.01e-02 lr: 3.81e-05:  24%|▏| 3305/13852 [12:19<39:09,  4.49it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.81e-05:  24%|▏| 3306/13852 [12:19<39:08,  4.49it/s\u001b[A\n",
      "Training loss: 9.45e-02 lr: 3.81e-05:  24%|▏| 3307/13852 [12:19<39:06,  4.49it/s\u001b[A\n",
      "Training loss: 7.80e-02 lr: 3.81e-05:  24%|▏| 3308/13852 [12:19<39:09,  4.49it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 3.81e-05:  24%|▏| 3309/13852 [12:20<39:08,  4.49it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 3.81e-05:  24%|▏| 3310/13852 [12:20<39:10,  4.48it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 3.81e-05:  24%|▏| 3311/13852 [12:20<38:57,  4.51it/s\u001b[A\n",
      "Training loss: 6.79e-02 lr: 3.80e-05:  24%|▏| 3312/13852 [12:20<38:43,  4.54it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.80e-05:  24%|▏| 3313/13852 [12:20<38:32,  4.56it/s\u001b[A\n",
      "Training loss: 9.67e-02 lr: 3.80e-05:  24%|▏| 3314/13852 [12:21<38:30,  4.56it/s\u001b[A\n",
      "Training loss: 7.88e-02 lr: 3.80e-05:  24%|▏| 3315/13852 [12:21<38:50,  4.52it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 3.80e-05:  24%|▏| 3316/13852 [12:21<38:52,  4.52it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 3.80e-05:  24%|▏| 3317/13852 [12:21<39:08,  4.49it/s\u001b[A\n",
      "Training loss: 8.81e-02 lr: 3.80e-05:  24%|▏| 3318/13852 [12:22<39:05,  4.49it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.80e-05:  24%|▏| 3319/13852 [12:22<39:14,  4.47it/s\u001b[A\n",
      "Training loss: 8.05e-02 lr: 3.80e-05:  24%|▏| 3320/13852 [12:22<39:20,  4.46it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 3.80e-05:  24%|▏| 3321/13852 [12:22<39:21,  4.46it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 3.80e-05:  24%|▏| 3322/13852 [12:22<39:32,  4.44it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 3.80e-05:  24%|▏| 3323/13852 [12:23<39:23,  4.46it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 3.80e-05:  24%|▏| 3324/13852 [12:23<39:05,  4.49it/s\u001b[A\n",
      "Training loss: 7.30e-02 lr: 3.80e-05:  24%|▏| 3325/13852 [12:23<38:50,  4.52it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 3.80e-05:  24%|▏| 3326/13852 [12:23<39:04,  4.49it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 3.80e-05:  24%|▏| 3327/13852 [12:24<39:00,  4.50it/s\u001b[A\n",
      "Training loss: 3.14e-02 lr: 3.80e-05:  24%|▏| 3328/13852 [12:24<39:03,  4.49it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 3.80e-05:  24%|▏| 3329/13852 [12:24<39:03,  4.49it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 3.80e-05:  24%|▏| 3330/13852 [12:24<39:07,  4.48it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 3.80e-05:  24%|▏| 3331/13852 [12:24<39:07,  4.48it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 3.80e-05:  24%|▏| 3332/13852 [12:25<39:10,  4.48it/s\u001b[A\n",
      "Training loss: 3.12e-02 lr: 3.80e-05:  24%|▏| 3333/13852 [12:25<39:13,  4.47it/s\u001b[A\n",
      "Training loss: 3.60e-02 lr: 3.80e-05:  24%|▏| 3334/13852 [12:25<39:11,  4.47it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 3.80e-05:  24%|▏| 3335/13852 [12:25<39:02,  4.49it/s\u001b[A\n",
      "Training loss: 6.68e-02 lr: 3.80e-05:  24%|▏| 3336/13852 [12:26<38:53,  4.51it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.80e-05:  24%|▏| 3337/13852 [12:26<39:10,  4.47it/s\u001b[A\n",
      "Training loss: 9.44e-02 lr: 3.80e-05:  24%|▏| 3338/13852 [12:26<39:10,  4.47it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.80e-05:  24%|▏| 3339/13852 [12:26<39:06,  4.48it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 3.79e-05:  24%|▏| 3340/13852 [12:26<39:03,  4.49it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 3.79e-05:  24%|▏| 3341/13852 [12:27<39:11,  4.47it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.79e-05:  24%|▏| 3342/13852 [12:27<39:18,  4.46it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.79e-05:  24%|▏| 3343/13852 [12:27<39:13,  4.46it/s\u001b[A\n",
      "Training loss: 9.62e-02 lr: 3.79e-05:  24%|▏| 3344/13852 [12:27<39:11,  4.47it/s\u001b[A\n",
      "Training loss: 1.57e-01 lr: 3.79e-05:  24%|▏| 3345/13852 [12:28<39:07,  4.48it/s\u001b[A\n",
      "Training loss: 1.54e-01 lr: 3.79e-05:  24%|▏| 3346/13852 [12:28<38:51,  4.51it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.79e-05:  24%|▏| 3347/13852 [12:28<38:37,  4.53it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.79e-05:  24%|▏| 3348/13852 [12:28<39:00,  4.49it/s\u001b[A\n",
      "Training loss: 8.03e-02 lr: 3.79e-05:  24%|▏| 3349/13852 [12:28<38:59,  4.49it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 3.79e-05:  24%|▏| 3350/13852 [12:29<38:56,  4.49it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 3.79e-05:  24%|▏| 3351/13852 [12:29<38:58,  4.49it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 3.79e-05:  24%|▏| 3352/13852 [12:29<38:59,  4.49it/s\u001b[A\n",
      "Training loss: 7.20e-02 lr: 3.79e-05:  24%|▏| 3353/13852 [12:29<39:02,  4.48it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 3.79e-05:  24%|▏| 3354/13852 [12:30<39:10,  4.47it/s\u001b[A\n",
      "Training loss: 7.42e-02 lr: 3.79e-05:  24%|▏| 3355/13852 [12:30<39:09,  4.47it/s\u001b[A\n",
      "Training loss: 8.19e-02 lr: 3.79e-05:  24%|▏| 3356/13852 [12:30<39:08,  4.47it/s\u001b[A\n",
      "Training loss: 6.30e-02 lr: 3.79e-05:  24%|▏| 3357/13852 [12:30<38:52,  4.50it/s\u001b[A\n",
      "Training loss: 7.20e-02 lr: 3.79e-05:  24%|▏| 3358/13852 [12:30<38:40,  4.52it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 3.79e-05:  24%|▏| 3359/13852 [12:31<39:12,  4.46it/s\u001b[A\n",
      "Training loss: 8.94e-02 lr: 3.79e-05:  24%|▏| 3360/13852 [12:31<39:17,  4.45it/s\u001b[A\n",
      "Training loss: 8.50e-02 lr: 3.79e-05:  24%|▏| 3361/13852 [12:31<39:05,  4.47it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 3.79e-05:  24%|▏| 3362/13852 [12:31<39:05,  4.47it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 3.79e-05:  24%|▏| 3363/13852 [12:32<39:09,  4.47it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 3.79e-05:  24%|▏| 3364/13852 [12:32<39:11,  4.46it/s\u001b[A\n",
      "Training loss: 3.69e-02 lr: 3.79e-05:  24%|▏| 3365/13852 [12:32<39:06,  4.47it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 3.79e-05:  24%|▏| 3366/13852 [12:32<39:05,  4.47it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 3.78e-05:  24%|▏| 3367/13852 [12:32<39:05,  4.47it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 3.78e-05:  24%|▏| 3368/13852 [12:33<38:53,  4.49it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 3.78e-05:  24%|▏| 3369/13852 [12:33<38:39,  4.52it/s\u001b[A\n",
      "Training loss: 5.45e-02 lr: 3.78e-05:  24%|▏| 3370/13852 [12:33<38:35,  4.53it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 3.78e-05:  24%|▏| 3371/13852 [12:33<38:41,  4.52it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 3.78e-05:  24%|▏| 3372/13852 [12:34<38:42,  4.51it/s\u001b[A\n",
      "Training loss: 3.95e-02 lr: 3.78e-05:  24%|▏| 3373/13852 [12:34<38:44,  4.51it/s\u001b[A\n",
      "Training loss: 3.22e-02 lr: 3.78e-05:  24%|▏| 3374/13852 [12:34<38:43,  4.51it/s\u001b[A\n",
      "Training loss: 3.45e-02 lr: 3.78e-05:  24%|▏| 3375/13852 [12:34<38:45,  4.50it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 3.78e-05:  24%|▏| 3376/13852 [12:34<38:45,  4.50it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 3.78e-05:  24%|▏| 3377/13852 [12:35<38:48,  4.50it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 3.78e-05:  24%|▏| 3378/13852 [12:35<38:50,  4.49it/s\u001b[A\n",
      "Training loss: 5.45e-02 lr: 3.78e-05:  24%|▏| 3379/13852 [12:35<38:51,  4.49it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 3.78e-05:  24%|▏| 3380/13852 [12:35<38:40,  4.51it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 3.78e-05:  24%|▏| 3381/13852 [12:36<38:40,  4.51it/s\u001b[A\n",
      "Training loss: 6.06e-02 lr: 3.78e-05:  24%|▏| 3382/13852 [12:36<38:30,  4.53it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 3.78e-05:  24%|▏| 3383/13852 [12:36<38:42,  4.51it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 3.78e-05:  24%|▏| 3384/13852 [12:36<38:41,  4.51it/s\u001b[A\n",
      "Training loss: 9.20e-02 lr: 3.78e-05:  24%|▏| 3385/13852 [12:36<38:41,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.59e-02 lr: 3.78e-05:  24%|▏| 3386/13852 [12:37<38:57,  4.48it/s\u001b[A\n",
      "Training loss: 7.20e-02 lr: 3.78e-05:  24%|▏| 3387/13852 [12:37<39:17,  4.44it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 3.78e-05:  24%|▏| 3388/13852 [12:37<40:11,  4.34it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 3.78e-05:  24%|▏| 3389/13852 [12:37<40:00,  4.36it/s\u001b[A\n",
      "Training loss: 4.43e-02 lr: 3.78e-05:  24%|▏| 3390/13852 [12:38<39:32,  4.41it/s\u001b[A\n",
      "Training loss: 8.75e-02 lr: 3.78e-05:  24%|▏| 3391/13852 [12:38<39:04,  4.46it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.78e-05:  24%|▏| 3392/13852 [12:38<38:49,  4.49it/s\u001b[A\n",
      "Training loss: 9.86e-02 lr: 3.78e-05:  24%|▏| 3393/13852 [12:38<38:55,  4.48it/s\u001b[A\n",
      "Training loss: 8.20e-02 lr: 3.78e-05:  25%|▏| 3394/13852 [12:39<38:48,  4.49it/s\u001b[A\n",
      "Training loss: 7.76e-02 lr: 3.77e-05:  25%|▏| 3395/13852 [12:39<38:52,  4.48it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 3.77e-05:  25%|▏| 3396/13852 [12:39<38:56,  4.48it/s\u001b[A\n",
      "Training loss: 4.16e-02 lr: 3.77e-05:  25%|▏| 3397/13852 [12:39<38:52,  4.48it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 3.77e-05:  25%|▏| 3398/13852 [12:39<38:54,  4.48it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 3.77e-05:  25%|▏| 3399/13852 [12:40<38:52,  4.48it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 3.77e-05:  25%|▏| 3400/13852 [12:40<38:50,  4.49it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 3.77e-05:  25%|▏| 3401/13852 [12:40<38:41,  4.50it/s\u001b[A\n",
      "Training loss: 9.51e-02 lr: 3.77e-05:  25%|▏| 3402/13852 [12:40<38:27,  4.53it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.77e-05:  25%|▏| 3403/13852 [12:41<38:19,  4.54it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.77e-05:  25%|▏| 3404/13852 [12:41<38:20,  4.54it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.77e-05:  25%|▏| 3405/13852 [12:41<38:37,  4.51it/s\u001b[A\n",
      "Training loss: 9.05e-02 lr: 3.77e-05:  25%|▏| 3406/13852 [12:41<38:37,  4.51it/s\u001b[A\n",
      "Training loss: 9.35e-02 lr: 3.77e-05:  25%|▏| 3407/13852 [12:41<38:35,  4.51it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 3.77e-05:  25%|▏| 3408/13852 [12:42<38:39,  4.50it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 3.77e-05:  25%|▏| 3409/13852 [12:42<38:58,  4.47it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 3.77e-05:  25%|▏| 3410/13852 [12:42<39:01,  4.46it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 3.77e-05:  25%|▏| 3411/13852 [12:42<38:56,  4.47it/s\u001b[A\n",
      "Training loss: 7.82e-02 lr: 3.77e-05:  25%|▏| 3412/13852 [12:43<38:56,  4.47it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 3.77e-05:  25%|▏| 3413/13852 [12:43<39:00,  4.46it/s\u001b[A\n",
      "Training loss: 6.09e-02 lr: 3.77e-05:  25%|▏| 3414/13852 [12:43<38:45,  4.49it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 3.77e-05:  25%|▏| 3415/13852 [12:43<38:32,  4.51it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 3.77e-05:  25%|▏| 3416/13852 [12:43<38:41,  4.50it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 3.77e-05:  25%|▏| 3417/13852 [12:44<38:44,  4.49it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 3.77e-05:  25%|▏| 3418/13852 [12:44<38:42,  4.49it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 3.77e-05:  25%|▏| 3419/13852 [12:44<38:39,  4.50it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 3.77e-05:  25%|▏| 3420/13852 [12:44<38:40,  4.50it/s\u001b[A\n",
      "Training loss: 3.89e-02 lr: 3.77e-05:  25%|▏| 3421/13852 [12:45<38:46,  4.48it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 3.77e-05:  25%|▏| 3422/13852 [12:45<38:45,  4.49it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 3.76e-05:  25%|▏| 3423/13852 [12:45<38:45,  4.48it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 3.76e-05:  25%|▏| 3424/13852 [12:45<38:46,  4.48it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 3.76e-05:  25%|▏| 3425/13852 [12:45<38:32,  4.51it/s\u001b[A\n",
      "Training loss: 3.16e-02 lr: 3.76e-05:  25%|▏| 3426/13852 [12:46<38:30,  4.51it/s\u001b[A\n",
      "Training loss: 7.57e-02 lr: 3.76e-05:  25%|▏| 3427/13852 [12:46<38:35,  4.50it/s\u001b[A\n",
      "Training loss: 8.80e-02 lr: 3.76e-05:  25%|▏| 3428/13852 [12:46<38:36,  4.50it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.76e-05:  25%|▏| 3429/13852 [12:46<38:32,  4.51it/s\u001b[A\n",
      "Training loss: 8.94e-02 lr: 3.76e-05:  25%|▏| 3430/13852 [12:47<38:32,  4.51it/s\u001b[A\n",
      "Training loss: 9.03e-02 lr: 3.76e-05:  25%|▏| 3431/13852 [12:47<38:46,  4.48it/s\u001b[A\n",
      "Training loss: 7.68e-02 lr: 3.76e-05:  25%|▏| 3432/13852 [12:47<38:45,  4.48it/s\u001b[A\n",
      "Training loss: 6.32e-02 lr: 3.76e-05:  25%|▏| 3433/13852 [12:47<38:40,  4.49it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 3.76e-05:  25%|▏| 3434/13852 [12:47<38:39,  4.49it/s\u001b[A\n",
      "Training loss: 9.69e-02 lr: 3.76e-05:  25%|▏| 3435/13852 [12:48<38:38,  4.49it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 3.76e-05:  25%|▏| 3436/13852 [12:48<38:27,  4.51it/s\u001b[A\n",
      "Training loss: 7.07e-02 lr: 3.76e-05:  25%|▏| 3437/13852 [12:48<38:17,  4.53it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 3.76e-05:  25%|▏| 3438/13852 [12:48<38:09,  4.55it/s\u001b[A\n",
      "Training loss: 6.20e-02 lr: 3.76e-05:  25%|▏| 3439/13852 [12:49<38:38,  4.49it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 3.76e-05:  25%|▏| 3440/13852 [12:49<38:33,  4.50it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 3.76e-05:  25%|▏| 3441/13852 [12:49<38:31,  4.50it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 3.76e-05:  25%|▏| 3442/13852 [12:49<38:31,  4.50it/s\u001b[A\n",
      "Training loss: 5.45e-02 lr: 3.76e-05:  25%|▏| 3443/13852 [12:49<38:28,  4.51it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 3.76e-05:  25%|▏| 3444/13852 [12:50<38:28,  4.51it/s\u001b[A\n",
      "Training loss: 7.58e-02 lr: 3.76e-05:  25%|▏| 3445/13852 [12:50<38:27,  4.51it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.76e-05:  25%|▏| 3446/13852 [12:50<38:31,  4.50it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.76e-05:  25%|▏| 3447/13852 [12:50<38:32,  4.50it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 3.76e-05:  25%|▏| 3448/13852 [12:51<38:21,  4.52it/s\u001b[A\n",
      "Training loss: 9.99e-02 lr: 3.76e-05:  25%|▏| 3449/13852 [12:51<38:24,  4.51it/s\u001b[A\n",
      "Training loss: 1.41e-01 lr: 3.75e-05:  25%|▏| 3450/13852 [12:51<38:20,  4.52it/s\u001b[A\n",
      "Training loss: 1.86e-01 lr: 3.75e-05:  25%|▏| 3451/13852 [12:51<38:08,  4.55it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 3.75e-05:  25%|▏| 3452/13852 [12:51<38:18,  4.52it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.75e-05:  25%|▏| 3453/13852 [12:52<38:21,  4.52it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 3.75e-05:  25%|▏| 3454/13852 [12:52<38:27,  4.51it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.75e-05:  25%|▏| 3455/13852 [12:52<38:28,  4.50it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.75e-05:  25%|▏| 3456/13852 [12:52<38:29,  4.50it/s\u001b[A\n",
      "Training loss: 7.94e-02 lr: 3.75e-05:  25%|▏| 3457/13852 [12:53<38:29,  4.50it/s\u001b[A\n",
      "Training loss: 7.80e-02 lr: 3.75e-05:  25%|▏| 3458/13852 [12:53<38:32,  4.49it/s\u001b[A\n",
      "Training loss: 9.43e-02 lr: 3.75e-05:  25%|▏| 3459/13852 [12:53<38:33,  4.49it/s\u001b[A\n",
      "Training loss: 7.92e-02 lr: 3.75e-05:  25%|▏| 3460/13852 [12:53<38:33,  4.49it/s\u001b[A\n",
      "Training loss: 6.68e-02 lr: 3.75e-05:  25%|▏| 3461/13852 [12:53<38:23,  4.51it/s\u001b[A\n",
      "Training loss: 5.57e-02 lr: 3.75e-05:  25%|▏| 3462/13852 [12:54<38:10,  4.54it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 3.75e-05:  25%|▎| 3463/13852 [12:54<37:59,  4.56it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 3.75e-05:  25%|▎| 3464/13852 [12:54<38:17,  4.52it/s\u001b[A\n",
      "Training loss: 8.96e-02 lr: 3.75e-05:  25%|▎| 3465/13852 [12:54<38:17,  4.52it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.75e-05:  25%|▎| 3466/13852 [12:55<38:22,  4.51it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.75e-05:  25%|▎| 3467/13852 [12:55<38:23,  4.51it/s\u001b[A\n",
      "Training loss: 9.00e-02 lr: 3.75e-05:  25%|▎| 3468/13852 [12:55<38:25,  4.50it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 3.75e-05:  25%|▎| 3469/13852 [12:55<38:24,  4.51it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 3.75e-05:  25%|▎| 3470/13852 [12:55<41:18,  4.19it/s\u001b[A\n",
      "Training loss: 7.80e-02 lr: 3.75e-05:  25%|▎| 3471/13852 [12:56<42:19,  4.09it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 3.75e-05:  25%|▎| 3472/13852 [12:56<42:03,  4.11it/s\u001b[A\n",
      "Training loss: 6.99e-02 lr: 3.75e-05:  25%|▎| 3473/13852 [12:56<41:55,  4.13it/s\u001b[A\n",
      "Training loss: 8.55e-02 lr: 3.75e-05:  25%|▎| 3474/13852 [12:56<41:52,  4.13it/s\u001b[A\n",
      "Training loss: 1.71e-01 lr: 3.75e-05:  25%|▎| 3475/13852 [12:57<42:05,  4.11it/s\u001b[A\n",
      "Training loss: 1.49e-01 lr: 3.75e-05:  25%|▎| 3476/13852 [12:57<41:53,  4.13it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.75e-05:  25%|▎| 3477/13852 [12:57<41:40,  4.15it/s\u001b[A\n",
      "Training loss: 8.33e-02 lr: 3.74e-05:  25%|▎| 3478/13852 [12:57<41:36,  4.16it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.74e-05:  25%|▎| 3479/13852 [12:58<41:32,  4.16it/s\u001b[A\n",
      "Training loss: 7.88e-02 lr: 3.74e-05:  25%|▎| 3480/13852 [12:58<41:33,  4.16it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 3.74e-05:  25%|▎| 3481/13852 [12:58<41:36,  4.15it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 3.74e-05:  25%|▎| 3482/13852 [12:58<41:23,  4.18it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.24e-02 lr: 3.74e-05:  25%|▎| 3483/13852 [12:59<41:23,  4.18it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 3.74e-05:  25%|▎| 3484/13852 [12:59<41:22,  4.18it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.74e-05:  25%|▎| 3485/13852 [12:59<41:22,  4.18it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.74e-05:  25%|▎| 3486/13852 [12:59<41:24,  4.17it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.74e-05:  25%|▎| 3487/13852 [13:00<41:30,  4.16it/s\u001b[A\n",
      "Training loss: 8.52e-02 lr: 3.74e-05:  25%|▎| 3488/13852 [13:00<41:20,  4.18it/s\u001b[A\n",
      "Training loss: 8.56e-02 lr: 3.74e-05:  25%|▎| 3489/13852 [13:00<41:22,  4.17it/s\u001b[A\n",
      "Training loss: 8.61e-02 lr: 3.74e-05:  25%|▎| 3490/13852 [13:00<41:20,  4.18it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.74e-05:  25%|▎| 3491/13852 [13:01<41:37,  4.15it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.74e-05:  25%|▎| 3492/13852 [13:01<41:49,  4.13it/s\u001b[A\n",
      "Training loss: 7.98e-02 lr: 3.74e-05:  25%|▎| 3493/13852 [13:01<41:40,  4.14it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 3.74e-05:  25%|▎| 3494/13852 [13:01<41:25,  4.17it/s\u001b[A\n",
      "Training loss: 8.35e-02 lr: 3.74e-05:  25%|▎| 3495/13852 [13:01<40:22,  4.28it/s\u001b[A\n",
      "Training loss: 8.39e-02 lr: 3.74e-05:  25%|▎| 3496/13852 [13:02<39:43,  4.34it/s\u001b[A\n",
      "Training loss: 9.57e-02 lr: 3.74e-05:  25%|▎| 3497/13852 [13:02<39:16,  4.39it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 3.74e-05:  25%|▎| 3498/13852 [13:02<40:02,  4.31it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 3.74e-05:  25%|▎| 3499/13852 [13:02<39:25,  4.38it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 3.74e-05:  25%|▎| 3500/13852 [13:03<39:02,  4.42it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 3.74e-05:  25%|▎| 3501/13852 [13:03<38:47,  4.45it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 3.74e-05:  25%|▎| 3502/13852 [13:03<38:54,  4.43it/s\u001b[A\n",
      "Training loss: 4.03e-02 lr: 3.74e-05:  25%|▎| 3503/13852 [13:03<38:30,  4.48it/s\u001b[A\n",
      "Training loss: 4.99e-02 lr: 3.74e-05:  25%|▎| 3504/13852 [13:03<38:08,  4.52it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 3.74e-05:  25%|▎| 3505/13852 [13:04<38:10,  4.52it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 3.73e-05:  25%|▎| 3506/13852 [13:04<38:07,  4.52it/s\u001b[A\n",
      "Training loss: 3.91e-02 lr: 3.73e-05:  25%|▎| 3507/13852 [13:04<38:06,  4.52it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 3.73e-05:  25%|▎| 3508/13852 [13:04<38:08,  4.52it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 3.73e-05:  25%|▎| 3509/13852 [13:05<38:08,  4.52it/s\u001b[A\n",
      "Training loss: 4.05e-02 lr: 3.73e-05:  25%|▎| 3510/13852 [13:05<38:07,  4.52it/s\u001b[A\n",
      "Training loss: 4.22e-02 lr: 3.73e-05:  25%|▎| 3511/13852 [13:05<38:07,  4.52it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 3.73e-05:  25%|▎| 3512/13852 [13:05<38:08,  4.52it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 3.73e-05:  25%|▎| 3513/13852 [13:05<38:07,  4.52it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 3.73e-05:  25%|▎| 3514/13852 [13:06<38:07,  4.52it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 3.73e-05:  25%|▎| 3515/13852 [13:06<37:56,  4.54it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 3.73e-05:  25%|▎| 3516/13852 [13:06<37:56,  4.54it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 3.73e-05:  25%|▎| 3517/13852 [13:06<39:20,  4.38it/s\u001b[A\n",
      "Training loss: 9.74e-02 lr: 3.73e-05:  25%|▎| 3518/13852 [13:07<40:24,  4.26it/s\u001b[A\n",
      "Training loss: 8.91e-02 lr: 3.73e-05:  25%|▎| 3519/13852 [13:07<40:37,  4.24it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 3.73e-05:  25%|▎| 3520/13852 [13:07<40:18,  4.27it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 3.73e-05:  25%|▎| 3521/13852 [13:07<39:55,  4.31it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 3.73e-05:  25%|▎| 3522/13852 [13:08<40:27,  4.26it/s\u001b[A\n",
      "Training loss: 6.36e-02 lr: 3.73e-05:  25%|▎| 3523/13852 [13:08<40:59,  4.20it/s\u001b[A\n",
      "Training loss: 9.72e-02 lr: 3.73e-05:  25%|▎| 3524/13852 [13:08<41:10,  4.18it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.73e-05:  25%|▎| 3525/13852 [13:08<41:15,  4.17it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 3.73e-05:  25%|▎| 3526/13852 [13:09<41:23,  4.16it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 3.73e-05:  25%|▎| 3527/13852 [13:09<40:24,  4.26it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.73e-05:  25%|▎| 3528/13852 [13:09<39:39,  4.34it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.73e-05:  25%|▎| 3529/13852 [13:09<39:04,  4.40it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 3.73e-05:  25%|▎| 3530/13852 [13:09<38:33,  4.46it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.73e-05:  25%|▎| 3531/13852 [13:10<38:32,  4.46it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 3.73e-05:  25%|▎| 3532/13852 [13:10<38:22,  4.48it/s\u001b[A\n",
      "Training loss: 8.30e-02 lr: 3.73e-05:  26%|▎| 3533/13852 [13:10<38:26,  4.47it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.72e-05:  26%|▎| 3534/13852 [13:10<38:15,  4.50it/s\u001b[A\n",
      "Training loss: 7.64e-02 lr: 3.72e-05:  26%|▎| 3535/13852 [13:11<38:11,  4.50it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.72e-05:  26%|▎| 3536/13852 [13:11<38:20,  4.48it/s\u001b[A\n",
      "Training loss: 9.80e-02 lr: 3.72e-05:  26%|▎| 3537/13852 [13:11<38:36,  4.45it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.72e-05:  26%|▎| 3538/13852 [13:11<38:28,  4.47it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.72e-05:  26%|▎| 3539/13852 [13:11<38:21,  4.48it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 3.72e-05:  26%|▎| 3540/13852 [13:12<38:11,  4.50it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.72e-05:  26%|▎| 3541/13852 [13:12<38:00,  4.52it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.72e-05:  26%|▎| 3542/13852 [13:12<37:53,  4.54it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.72e-05:  26%|▎| 3543/13852 [13:12<38:06,  4.51it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.72e-05:  26%|▎| 3544/13852 [13:13<38:05,  4.51it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 3.72e-05:  26%|▎| 3545/13852 [13:13<38:06,  4.51it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.72e-05:  26%|▎| 3546/13852 [13:13<38:03,  4.51it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.72e-05:  26%|▎| 3547/13852 [13:13<38:06,  4.51it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.72e-05:  26%|▎| 3548/13852 [13:13<38:07,  4.50it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 3.72e-05:  26%|▎| 3549/13852 [13:14<38:09,  4.50it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.72e-05:  26%|▎| 3550/13852 [13:14<38:17,  4.48it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.72e-05:  26%|▎| 3551/13852 [13:14<38:15,  4.49it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.72e-05:  26%|▎| 3552/13852 [13:14<38:04,  4.51it/s\u001b[A\n",
      "Training loss: 8.06e-02 lr: 3.72e-05:  26%|▎| 3553/13852 [13:15<37:52,  4.53it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 3.72e-05:  26%|▎| 3554/13852 [13:15<37:59,  4.52it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 3.72e-05:  26%|▎| 3555/13852 [13:15<37:59,  4.52it/s\u001b[A\n",
      "Training loss: 7.82e-02 lr: 3.72e-05:  26%|▎| 3556/13852 [13:15<37:58,  4.52it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 3.72e-05:  26%|▎| 3557/13852 [13:15<38:00,  4.51it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.72e-05:  26%|▎| 3558/13852 [13:16<38:00,  4.51it/s\u001b[A\n",
      "Training loss: 8.61e-02 lr: 3.72e-05:  26%|▎| 3559/13852 [13:16<38:14,  4.49it/s\u001b[A\n",
      "Training loss: 8.25e-02 lr: 3.72e-05:  26%|▎| 3560/13852 [13:16<38:10,  4.49it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 3.71e-05:  26%|▎| 3561/13852 [13:16<38:14,  4.48it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.71e-05:  26%|▎| 3562/13852 [13:17<38:10,  4.49it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 3.71e-05:  26%|▎| 3563/13852 [13:17<38:21,  4.47it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 3.71e-05:  26%|▎| 3564/13852 [13:17<38:05,  4.50it/s\u001b[A\n",
      "Training loss: 3.62e-02 lr: 3.71e-05:  26%|▎| 3565/13852 [13:17<37:51,  4.53it/s\u001b[A\n",
      "Training loss: 2.98e-02 lr: 3.71e-05:  26%|▎| 3566/13852 [13:17<37:42,  4.55it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 3.71e-05:  26%|▎| 3567/13852 [13:18<37:52,  4.53it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 3.71e-05:  26%|▎| 3568/13852 [13:18<37:54,  4.52it/s\u001b[A\n",
      "Training loss: 4.99e-02 lr: 3.71e-05:  26%|▎| 3569/13852 [13:18<38:11,  4.49it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 3.71e-05:  26%|▎| 3570/13852 [13:18<38:07,  4.49it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 3.71e-05:  26%|▎| 3571/13852 [13:19<38:06,  4.50it/s\u001b[A\n",
      "Training loss: 8.46e-02 lr: 3.71e-05:  26%|▎| 3572/13852 [13:19<38:08,  4.49it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.71e-05:  26%|▎| 3573/13852 [13:19<38:06,  4.49it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.71e-05:  26%|▎| 3574/13852 [13:19<38:03,  4.50it/s\u001b[A\n",
      "Training loss: 8.39e-02 lr: 3.71e-05:  26%|▎| 3575/13852 [13:19<38:05,  4.50it/s\u001b[A\n",
      "Training loss: 7.17e-02 lr: 3.71e-05:  26%|▎| 3576/13852 [13:20<37:56,  4.51it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 3.71e-05:  26%|▎| 3577/13852 [13:20<37:51,  4.52it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 3.71e-05:  26%|▎| 3578/13852 [13:20<37:38,  4.55it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 3.71e-05:  26%|▎| 3579/13852 [13:20<37:50,  4.53it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.71e-02 lr: 3.71e-05:  26%|▎| 3580/13852 [13:20<37:52,  4.52it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 3.71e-05:  26%|▎| 3581/13852 [13:21<38:00,  4.50it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 3.71e-05:  26%|▎| 3582/13852 [13:21<38:05,  4.49it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 3.71e-05:  26%|▎| 3583/13852 [13:21<38:02,  4.50it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 3.71e-05:  26%|▎| 3584/13852 [13:21<38:02,  4.50it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.71e-05:  26%|▎| 3585/13852 [13:22<38:01,  4.50it/s\u001b[A\n",
      "Training loss: 7.49e-02 lr: 3.71e-05:  26%|▎| 3586/13852 [13:22<38:09,  4.48it/s\u001b[A\n",
      "Training loss: 9.31e-02 lr: 3.71e-05:  26%|▎| 3587/13852 [13:22<38:16,  4.47it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 3.71e-05:  26%|▎| 3588/13852 [13:22<38:01,  4.50it/s\u001b[A\n",
      "Training loss: 7.20e-02 lr: 3.70e-05:  26%|▎| 3589/13852 [13:22<37:47,  4.53it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 3.70e-05:  26%|▎| 3590/13852 [13:23<37:58,  4.50it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 3.70e-05:  26%|▎| 3591/13852 [13:23<37:57,  4.51it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 3.70e-05:  26%|▎| 3592/13852 [13:23<37:54,  4.51it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 3.70e-05:  26%|▎| 3593/13852 [13:23<37:53,  4.51it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.70e-05:  26%|▎| 3594/13852 [13:24<37:52,  4.51it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.70e-05:  26%|▎| 3595/13852 [13:24<37:55,  4.51it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.70e-05:  26%|▎| 3596/13852 [13:24<37:55,  4.51it/s\u001b[A\n",
      "Training loss: 9.96e-02 lr: 3.70e-05:  26%|▎| 3597/13852 [13:24<37:56,  4.51it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 3.70e-05:  26%|▎| 3598/13852 [13:24<37:55,  4.51it/s\u001b[A\n",
      "Training loss: 6.75e-02 lr: 3.70e-05:  26%|▎| 3599/13852 [13:25<37:55,  4.51it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 3.70e-05:  26%|▎| 3600/13852 [13:25<37:47,  4.52it/s\u001b[A\n",
      "Training loss: 9.40e-02 lr: 3.70e-05:  26%|▎| 3601/13852 [13:25<37:36,  4.54it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.70e-05:  26%|▎| 3602/13852 [13:25<37:31,  4.55it/s\u001b[A\n",
      "Training loss: 8.47e-02 lr: 3.70e-05:  26%|▎| 3603/13852 [13:26<37:41,  4.53it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.70e-05:  26%|▎| 3604/13852 [13:26<37:41,  4.53it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.70e-05:  26%|▎| 3605/13852 [13:26<37:42,  4.53it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 3.70e-05:  26%|▎| 3606/13852 [13:26<37:46,  4.52it/s\u001b[A\n",
      "Training loss: 9.54e-02 lr: 3.70e-05:  26%|▎| 3607/13852 [13:26<37:48,  4.52it/s\u001b[A\n",
      "Training loss: 7.62e-02 lr: 3.70e-05:  26%|▎| 3608/13852 [13:27<38:04,  4.48it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 3.70e-05:  26%|▎| 3609/13852 [13:27<38:04,  4.48it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 3.70e-05:  26%|▎| 3610/13852 [13:27<39:02,  4.37it/s\u001b[A\n",
      "Training loss: 9.34e-02 lr: 3.70e-05:  26%|▎| 3611/13852 [13:27<38:42,  4.41it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 3.70e-05:  26%|▎| 3612/13852 [13:28<38:16,  4.46it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 3.70e-05:  26%|▎| 3613/13852 [13:28<37:54,  4.50it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.70e-05:  26%|▎| 3614/13852 [13:28<38:06,  4.48it/s\u001b[A\n",
      "Training loss: 7.88e-02 lr: 3.70e-05:  26%|▎| 3615/13852 [13:28<38:02,  4.49it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 3.70e-05:  26%|▎| 3616/13852 [13:29<38:01,  4.49it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 3.69e-05:  26%|▎| 3617/13852 [13:29<37:57,  4.49it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 3.69e-05:  26%|▎| 3618/13852 [13:29<37:59,  4.49it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 3.69e-05:  26%|▎| 3619/13852 [13:29<38:00,  4.49it/s\u001b[A\n",
      "Training loss: 3.84e-02 lr: 3.69e-05:  26%|▎| 3620/13852 [13:29<38:00,  4.49it/s\u001b[A\n",
      "Training loss: 2.93e-02 lr: 3.69e-05:  26%|▎| 3621/13852 [13:30<37:58,  4.49it/s\u001b[A\n",
      "Training loss: 2.45e-02 lr: 3.69e-05:  26%|▎| 3622/13852 [13:30<37:58,  4.49it/s\u001b[A\n",
      "Training loss: 2.98e-02 lr: 3.69e-05:  26%|▎| 3623/13852 [13:30<37:54,  4.50it/s\u001b[A\n",
      "Training loss: 2.99e-02 lr: 3.69e-05:  26%|▎| 3624/13852 [13:30<37:41,  4.52it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 3.69e-05:  26%|▎| 3625/13852 [13:31<37:50,  4.50it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 3.69e-05:  26%|▎| 3626/13852 [13:31<37:59,  4.49it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 3.69e-05:  26%|▎| 3627/13852 [13:31<38:09,  4.47it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 3.69e-05:  26%|▎| 3628/13852 [13:31<37:59,  4.48it/s\u001b[A\n",
      "Training loss: 3.28e-02 lr: 3.69e-05:  26%|▎| 3629/13852 [13:31<37:57,  4.49it/s\u001b[A\n",
      "Training loss: 2.47e-02 lr: 3.69e-05:  26%|▎| 3630/13852 [13:32<37:55,  4.49it/s\u001b[A\n",
      "Training loss: 1.91e-02 lr: 3.69e-05:  26%|▎| 3631/13852 [13:32<38:03,  4.48it/s\u001b[A\n",
      "Training loss: 1.84e-02 lr: 3.69e-05:  26%|▎| 3632/13852 [13:32<38:09,  4.46it/s\u001b[A\n",
      "Training loss: 1.44e-02 lr: 3.69e-05:  26%|▎| 3633/13852 [13:32<38:06,  4.47it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 3.69e-05:  26%|▎| 3634/13852 [13:33<38:01,  4.48it/s\u001b[A\n",
      "Training loss: 2.83e-02 lr: 3.69e-05:  26%|▎| 3635/13852 [13:33<37:46,  4.51it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 3.69e-05:  26%|▎| 3636/13852 [13:33<37:39,  4.52it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 3.69e-05:  26%|▎| 3637/13852 [13:33<37:38,  4.52it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 3.69e-05:  26%|▎| 3638/13852 [13:33<37:39,  4.52it/s\u001b[A\n",
      "Training loss: 8.93e-02 lr: 3.69e-05:  26%|▎| 3639/13852 [13:34<37:38,  4.52it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 3.69e-05:  26%|▎| 3640/13852 [13:34<37:43,  4.51it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.69e-05:  26%|▎| 3641/13852 [13:34<37:50,  4.50it/s\u001b[A\n",
      "Training loss: 8.41e-02 lr: 3.69e-05:  26%|▎| 3642/13852 [13:34<37:53,  4.49it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 3.69e-05:  26%|▎| 3643/13852 [13:35<37:52,  4.49it/s\u001b[A\n",
      "Training loss: 9.31e-02 lr: 3.68e-05:  26%|▎| 3644/13852 [13:35<37:51,  4.49it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 3.68e-05:  26%|▎| 3645/13852 [13:35<37:55,  4.49it/s\u001b[A\n",
      "Training loss: 6.06e-02 lr: 3.68e-05:  26%|▎| 3646/13852 [13:35<37:51,  4.49it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 3.68e-05:  26%|▎| 3647/13852 [13:35<37:38,  4.52it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 3.68e-05:  26%|▎| 3648/13852 [13:36<37:28,  4.54it/s\u001b[A\n",
      "Training loss: 2.95e-02 lr: 3.68e-05:  26%|▎| 3649/13852 [13:36<37:38,  4.52it/s\u001b[A\n",
      "Training loss: 2.46e-02 lr: 3.68e-05:  26%|▎| 3650/13852 [13:36<37:45,  4.50it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.68e-05:  26%|▎| 3651/13852 [13:36<37:41,  4.51it/s\u001b[A\n",
      "Training loss: 3.95e-02 lr: 3.68e-05:  26%|▎| 3652/13852 [13:37<37:38,  4.52it/s\u001b[A\n",
      "Training loss: 3.62e-02 lr: 3.68e-05:  26%|▎| 3653/13852 [13:37<38:46,  4.38it/s\u001b[A\n",
      "Training loss: 2.62e-02 lr: 3.68e-05:  26%|▎| 3654/13852 [13:37<38:39,  4.40it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 3.68e-05:  26%|▎| 3655/13852 [13:37<39:32,  4.30it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 3.68e-05:  26%|▎| 3656/13852 [13:37<40:04,  4.24it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 3.68e-05:  26%|▎| 3657/13852 [13:38<40:12,  4.23it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 3.68e-05:  26%|▎| 3658/13852 [13:38<39:26,  4.31it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 3.68e-05:  26%|▎| 3659/13852 [13:38<38:50,  4.37it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 3.68e-05:  26%|▎| 3660/13852 [13:38<38:37,  4.40it/s\u001b[A\n",
      "Training loss: 4.36e-02 lr: 3.68e-05:  26%|▎| 3661/13852 [13:39<38:18,  4.43it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 3.68e-05:  26%|▎| 3662/13852 [13:39<38:05,  4.46it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 3.68e-05:  26%|▎| 3663/13852 [13:39<37:57,  4.47it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 3.68e-05:  26%|▎| 3664/13852 [13:39<37:53,  4.48it/s\u001b[A\n",
      "Training loss: 7.64e-02 lr: 3.68e-05:  26%|▎| 3665/13852 [13:39<37:47,  4.49it/s\u001b[A\n",
      "Training loss: 7.99e-02 lr: 3.68e-05:  26%|▎| 3666/13852 [13:40<37:37,  4.51it/s\u001b[A\n",
      "Training loss: 7.07e-02 lr: 3.68e-05:  26%|▎| 3667/13852 [13:40<37:23,  4.54it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 3.68e-05:  26%|▎| 3668/13852 [13:40<37:40,  4.51it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 3.68e-05:  26%|▎| 3669/13852 [13:40<37:35,  4.52it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.68e-05:  26%|▎| 3670/13852 [13:41<37:32,  4.52it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 3.68e-05:  27%|▎| 3671/13852 [13:41<37:46,  4.49it/s\u001b[A\n",
      "Training loss: 8.36e-02 lr: 3.67e-05:  27%|▎| 3672/13852 [13:41<37:50,  4.48it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 3.67e-05:  27%|▎| 3673/13852 [13:41<37:45,  4.49it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.67e-05:  27%|▎| 3674/13852 [13:41<37:41,  4.50it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 3.67e-05:  27%|▎| 3675/13852 [13:42<37:44,  4.49it/s\u001b[A\n",
      "Training loss: 3.56e-02 lr: 3.67e-05:  27%|▎| 3676/13852 [13:42<37:42,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.32e-02 lr: 3.67e-05:  27%|▎| 3677/13852 [13:42<38:35,  4.39it/s\u001b[A\n",
      "Training loss: 9.91e-02 lr: 3.67e-05:  27%|▎| 3678/13852 [13:42<39:00,  4.35it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 3.67e-05:  27%|▎| 3679/13852 [13:43<38:30,  4.40it/s\u001b[A\n",
      "Training loss: 9.94e-02 lr: 3.67e-05:  27%|▎| 3680/13852 [13:43<38:08,  4.44it/s\u001b[A\n",
      "Training loss: 7.60e-02 lr: 3.67e-05:  27%|▎| 3681/13852 [13:43<37:52,  4.48it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 3.67e-05:  27%|▎| 3682/13852 [13:43<37:46,  4.49it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 3.67e-05:  27%|▎| 3683/13852 [13:43<37:41,  4.50it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 3.67e-05:  27%|▎| 3684/13852 [13:44<37:43,  4.49it/s\u001b[A\n",
      "Training loss: 4.79e-02 lr: 3.67e-05:  27%|▎| 3685/13852 [13:44<37:39,  4.50it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 3.67e-05:  27%|▎| 3686/13852 [13:44<37:37,  4.50it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 3.67e-05:  27%|▎| 3687/13852 [13:44<37:29,  4.52it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 3.67e-05:  27%|▎| 3688/13852 [13:45<37:16,  4.55it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 3.67e-05:  27%|▎| 3689/13852 [13:45<37:09,  4.56it/s\u001b[A\n",
      "Training loss: 8.26e-02 lr: 3.67e-05:  27%|▎| 3690/13852 [13:45<37:00,  4.58it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.67e-05:  27%|▎| 3691/13852 [13:45<36:53,  4.59it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 3.67e-05:  27%|▎| 3692/13852 [13:45<37:06,  4.56it/s\u001b[A\n",
      "Training loss: 7.78e-02 lr: 3.67e-05:  27%|▎| 3693/13852 [13:46<37:11,  4.55it/s\u001b[A\n",
      "Training loss: 7.64e-02 lr: 3.67e-05:  27%|▎| 3694/13852 [13:46<37:13,  4.55it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 3.67e-05:  27%|▎| 3695/13852 [13:46<37:16,  4.54it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 3.67e-05:  27%|▎| 3696/13852 [13:46<37:20,  4.53it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 3.67e-05:  27%|▎| 3697/13852 [13:47<37:21,  4.53it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 3.67e-05:  27%|▎| 3698/13852 [13:47<37:37,  4.50it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.67e-05:  27%|▎| 3699/13852 [13:47<37:33,  4.50it/s\u001b[A\n",
      "Training loss: 9.44e-02 lr: 3.66e-05:  27%|▎| 3700/13852 [13:47<37:33,  4.51it/s\u001b[A\n",
      "Training loss: 8.77e-02 lr: 3.66e-05:  27%|▎| 3701/13852 [13:47<37:24,  4.52it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.66e-05:  27%|▎| 3702/13852 [13:48<37:12,  4.55it/s\u001b[A\n",
      "Training loss: 7.73e-02 lr: 3.66e-05:  27%|▎| 3703/13852 [13:48<37:11,  4.55it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.66e-05:  27%|▎| 3704/13852 [13:48<37:25,  4.52it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 3.66e-05:  27%|▎| 3705/13852 [13:48<37:25,  4.52it/s\u001b[A\n",
      "Training loss: 1.57e-01 lr: 3.66e-05:  27%|▎| 3706/13852 [13:49<37:22,  4.53it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.66e-05:  27%|▎| 3707/13852 [13:49<37:19,  4.53it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.66e-05:  27%|▎| 3708/13852 [13:49<37:19,  4.53it/s\u001b[A\n",
      "Training loss: 9.18e-02 lr: 3.66e-05:  27%|▎| 3709/13852 [13:49<37:22,  4.52it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.66e-05:  27%|▎| 3710/13852 [13:49<37:23,  4.52it/s\u001b[A\n",
      "Training loss: 9.22e-02 lr: 3.66e-05:  27%|▎| 3711/13852 [13:50<37:24,  4.52it/s\u001b[A\n",
      "Training loss: 8.29e-02 lr: 3.66e-05:  27%|▎| 3712/13852 [13:50<37:27,  4.51it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 3.66e-05:  27%|▎| 3713/13852 [13:50<37:28,  4.51it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.66e-05:  27%|▎| 3714/13852 [13:50<37:17,  4.53it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.66e-05:  27%|▎| 3715/13852 [13:51<37:03,  4.56it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 3.66e-05:  27%|▎| 3716/13852 [13:51<37:19,  4.53it/s\u001b[A\n",
      "Training loss: 9.42e-02 lr: 3.66e-05:  27%|▎| 3717/13852 [13:51<37:25,  4.51it/s\u001b[A\n",
      "Training loss: 1.49e-01 lr: 3.66e-05:  27%|▎| 3718/13852 [13:51<37:22,  4.52it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.66e-05:  27%|▎| 3719/13852 [13:51<37:34,  4.50it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 3.66e-05:  27%|▎| 3720/13852 [13:52<37:33,  4.50it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.66e-05:  27%|▎| 3721/13852 [13:52<37:40,  4.48it/s\u001b[A\n",
      "Training loss: 8.65e-02 lr: 3.66e-05:  27%|▎| 3722/13852 [13:52<37:36,  4.49it/s\u001b[A\n",
      "Training loss: 8.52e-02 lr: 3.66e-05:  27%|▎| 3723/13852 [13:52<37:30,  4.50it/s\u001b[A\n",
      "Training loss: 7.97e-02 lr: 3.66e-05:  27%|▎| 3724/13852 [13:53<37:26,  4.51it/s\u001b[A\n",
      "Training loss: 6.99e-02 lr: 3.66e-05:  27%|▎| 3725/13852 [13:53<37:28,  4.50it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 3.66e-05:  27%|▎| 3726/13852 [13:53<37:16,  4.53it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 3.65e-05:  27%|▎| 3727/13852 [13:53<37:02,  4.55it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 3.65e-05:  27%|▎| 3728/13852 [13:53<36:55,  4.57it/s\u001b[A\n",
      "Training loss: 2.97e-02 lr: 3.65e-05:  27%|▎| 3729/13852 [13:54<36:50,  4.58it/s\u001b[A\n",
      "Training loss: 2.58e-02 lr: 3.65e-05:  27%|▎| 3730/13852 [13:54<36:57,  4.56it/s\u001b[A\n",
      "Training loss: 2.19e-02 lr: 3.65e-05:  27%|▎| 3731/13852 [13:54<37:04,  4.55it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 3.65e-05:  27%|▎| 3732/13852 [13:54<37:07,  4.54it/s\u001b[A\n",
      "Training loss: 3.16e-02 lr: 3.65e-05:  27%|▎| 3733/13852 [13:55<37:10,  4.54it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 3.65e-05:  27%|▎| 3734/13852 [13:55<37:14,  4.53it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 3.65e-05:  27%|▎| 3735/13852 [13:55<37:23,  4.51it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 3.65e-05:  27%|▎| 3736/13852 [13:55<37:28,  4.50it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 3.65e-05:  27%|▎| 3737/13852 [13:55<37:26,  4.50it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 3.65e-05:  27%|▎| 3738/13852 [13:56<37:27,  4.50it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 3.65e-05:  27%|▎| 3739/13852 [13:56<37:17,  4.52it/s\u001b[A\n",
      "Training loss: 4.45e-02 lr: 3.65e-05:  27%|▎| 3740/13852 [13:56<37:14,  4.53it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 3.65e-05:  27%|▎| 3741/13852 [13:56<37:01,  4.55it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 3.65e-05:  27%|▎| 3742/13852 [13:57<37:14,  4.52it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 3.65e-05:  27%|▎| 3743/13852 [13:57<37:22,  4.51it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 3.65e-05:  27%|▎| 3744/13852 [13:57<37:22,  4.51it/s\u001b[A\n",
      "Training loss: 8.23e-02 lr: 3.65e-05:  27%|▎| 3745/13852 [13:57<37:20,  4.51it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 3.65e-05:  27%|▎| 3746/13852 [13:57<37:26,  4.50it/s\u001b[A\n",
      "Training loss: 5.43e-02 lr: 3.65e-05:  27%|▎| 3747/13852 [13:58<37:24,  4.50it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 3.65e-05:  27%|▎| 3748/13852 [13:58<37:22,  4.51it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.65e-05:  27%|▎| 3749/13852 [13:58<37:22,  4.50it/s\u001b[A\n",
      "Training loss: 8.51e-02 lr: 3.65e-05:  27%|▎| 3750/13852 [13:58<37:25,  4.50it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 3.65e-05:  27%|▎| 3751/13852 [13:59<37:15,  4.52it/s\u001b[A\n",
      "Training loss: 8.41e-02 lr: 3.65e-05:  27%|▎| 3752/13852 [13:59<37:04,  4.54it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 3.65e-05:  27%|▎| 3753/13852 [13:59<36:52,  4.56it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.65e-05:  27%|▎| 3754/13852 [13:59<37:13,  4.52it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.64e-05:  27%|▎| 3755/13852 [13:59<37:11,  4.52it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.64e-05:  27%|▎| 3756/13852 [14:00<37:13,  4.52it/s\u001b[A\n",
      "Training loss: 7.58e-02 lr: 3.64e-05:  27%|▎| 3757/13852 [14:00<37:09,  4.53it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 3.64e-05:  27%|▎| 3758/13852 [14:00<37:12,  4.52it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 3.64e-05:  27%|▎| 3759/13852 [14:00<37:12,  4.52it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 3.64e-05:  27%|▎| 3760/13852 [14:01<37:10,  4.52it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 3.64e-05:  27%|▎| 3761/13852 [14:01<37:37,  4.47it/s\u001b[A\n",
      "Training loss: 9.54e-02 lr: 3.64e-05:  27%|▎| 3762/13852 [14:01<37:46,  4.45it/s\u001b[A\n",
      "Training loss: 9.16e-02 lr: 3.64e-05:  27%|▎| 3763/13852 [14:01<37:29,  4.48it/s\u001b[A\n",
      "Training loss: 9.57e-02 lr: 3.64e-05:  27%|▎| 3764/13852 [14:01<37:13,  4.52it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 3.64e-05:  27%|▎| 3765/13852 [14:02<37:00,  4.54it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 3.64e-05:  27%|▎| 3766/13852 [14:02<36:54,  4.56it/s\u001b[A\n",
      "Training loss: 5.07e-02 lr: 3.64e-05:  27%|▎| 3767/13852 [14:02<37:06,  4.53it/s\u001b[A\n",
      "Training loss: 8.40e-02 lr: 3.64e-05:  27%|▎| 3768/13852 [14:02<37:06,  4.53it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.64e-05:  27%|▎| 3769/13852 [14:03<37:09,  4.52it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.64e-05:  27%|▎| 3770/13852 [14:03<37:11,  4.52it/s\u001b[A\n",
      "Training loss: 9.97e-02 lr: 3.64e-05:  27%|▎| 3771/13852 [14:03<37:12,  4.51it/s\u001b[A\n",
      "Training loss: 7.85e-02 lr: 3.64e-05:  27%|▎| 3772/13852 [14:03<37:15,  4.51it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.64e-05:  27%|▎| 3773/13852 [14:03<37:15,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.26e-01 lr: 3.64e-05:  27%|▎| 3774/13852 [14:04<37:19,  4.50it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.64e-05:  27%|▎| 3775/13852 [14:04<37:18,  4.50it/s\u001b[A\n",
      "Training loss: 8.09e-02 lr: 3.64e-05:  27%|▎| 3776/13852 [14:04<37:11,  4.52it/s\u001b[A\n",
      "Training loss: 7.08e-02 lr: 3.64e-05:  27%|▎| 3777/13852 [14:04<36:58,  4.54it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 3.64e-05:  27%|▎| 3778/13852 [14:04<36:47,  4.56it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 3.64e-05:  27%|▎| 3779/13852 [14:05<37:01,  4.53it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 3.64e-05:  27%|▎| 3780/13852 [14:05<37:04,  4.53it/s\u001b[A\n",
      "Training loss: 7.97e-02 lr: 3.64e-05:  27%|▎| 3781/13852 [14:05<37:06,  4.52it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 3.64e-05:  27%|▎| 3782/13852 [14:05<37:08,  4.52it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 3.63e-05:  27%|▎| 3783/13852 [14:06<37:07,  4.52it/s\u001b[A\n",
      "Training loss: 8.31e-02 lr: 3.63e-05:  27%|▎| 3784/13852 [14:06<37:07,  4.52it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 3.63e-05:  27%|▎| 3785/13852 [14:06<37:08,  4.52it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 3.63e-05:  27%|▎| 3786/13852 [14:06<37:13,  4.51it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 3.63e-05:  27%|▎| 3787/13852 [14:06<37:13,  4.51it/s\u001b[A\n",
      "Training loss: 5.32e-02 lr: 3.63e-05:  27%|▎| 3788/13852 [14:07<37:25,  4.48it/s\u001b[A\n",
      "Training loss: 6.20e-02 lr: 3.63e-05:  27%|▎| 3789/13852 [14:07<38:32,  4.35it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 3.63e-05:  27%|▎| 3790/13852 [14:07<39:21,  4.26it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 3.63e-05:  27%|▎| 3791/13852 [14:07<40:02,  4.19it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 3.63e-05:  27%|▎| 3792/13852 [14:08<40:23,  4.15it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 3.63e-05:  27%|▎| 3793/13852 [14:08<39:28,  4.25it/s\u001b[A\n",
      "Training loss: 9.84e-02 lr: 3.63e-05:  27%|▎| 3794/13852 [14:08<38:51,  4.31it/s\u001b[A\n",
      "Training loss: 1.54e-01 lr: 3.63e-05:  27%|▎| 3795/13852 [14:08<38:13,  4.38it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 3.63e-05:  27%|▎| 3796/13852 [14:09<37:46,  4.44it/s\u001b[A\n",
      "Training loss: 9.86e-02 lr: 3.63e-05:  27%|▎| 3797/13852 [14:09<37:43,  4.44it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.63e-05:  27%|▎| 3798/13852 [14:09<37:31,  4.47it/s\u001b[A\n",
      "Training loss: 9.02e-02 lr: 3.63e-05:  27%|▎| 3799/13852 [14:09<37:22,  4.48it/s\u001b[A\n",
      "Training loss: 8.25e-02 lr: 3.63e-05:  27%|▎| 3800/13852 [14:09<37:16,  4.49it/s\u001b[A\n",
      "Training loss: 6.57e-02 lr: 3.63e-05:  27%|▎| 3801/13852 [14:10<37:12,  4.50it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 3.63e-05:  27%|▎| 3802/13852 [14:10<37:11,  4.50it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 3.63e-05:  27%|▎| 3803/13852 [14:10<37:10,  4.51it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 3.63e-05:  27%|▎| 3804/13852 [14:10<37:10,  4.50it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 3.63e-05:  27%|▎| 3805/13852 [14:11<37:11,  4.50it/s\u001b[A\n",
      "Training loss: 3.47e-02 lr: 3.63e-05:  27%|▎| 3806/13852 [14:11<37:21,  4.48it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 3.63e-05:  27%|▎| 3807/13852 [14:11<37:09,  4.51it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.63e-05:  27%|▎| 3808/13852 [14:11<36:57,  4.53it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.63e-05:  27%|▎| 3809/13852 [14:11<37:14,  4.49it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.63e-05:  28%|▎| 3810/13852 [14:12<37:24,  4.47it/s\u001b[A\n",
      "Training loss: 1.58e-01 lr: 3.62e-05:  28%|▎| 3811/13852 [14:12<37:18,  4.49it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 3.62e-05:  28%|▎| 3812/13852 [14:12<37:17,  4.49it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.62e-05:  28%|▎| 3813/13852 [14:12<37:13,  4.49it/s\u001b[A\n",
      "Training loss: 9.11e-02 lr: 3.62e-05:  28%|▎| 3814/13852 [14:13<37:12,  4.50it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.62e-05:  28%|▎| 3815/13852 [14:13<37:13,  4.49it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.62e-05:  28%|▎| 3816/13852 [14:13<37:11,  4.50it/s\u001b[A\n",
      "Training loss: 8.75e-02 lr: 3.62e-05:  28%|▎| 3817/13852 [14:13<37:13,  4.49it/s\u001b[A\n",
      "Training loss: 9.25e-02 lr: 3.62e-05:  28%|▎| 3818/13852 [14:13<37:10,  4.50it/s\u001b[A\n",
      "Training loss: 8.62e-02 lr: 3.62e-05:  28%|▎| 3819/13852 [14:14<36:57,  4.52it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 3.62e-05:  28%|▎| 3820/13852 [14:14<36:47,  4.54it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 3.62e-05:  28%|▎| 3821/13852 [14:14<36:56,  4.53it/s\u001b[A\n",
      "Training loss: 4.82e-02 lr: 3.62e-05:  28%|▎| 3822/13852 [14:14<36:56,  4.53it/s\u001b[A\n",
      "Training loss: 3.94e-02 lr: 3.62e-05:  28%|▎| 3823/13852 [14:15<36:56,  4.52it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 3.62e-05:  28%|▎| 3824/13852 [14:15<37:01,  4.51it/s\u001b[A\n",
      "Training loss: 4.86e-02 lr: 3.62e-05:  28%|▎| 3825/13852 [14:15<37:00,  4.52it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 3.62e-05:  28%|▎| 3826/13852 [14:15<36:59,  4.52it/s\u001b[A\n",
      "Training loss: 6.75e-02 lr: 3.62e-05:  28%|▎| 3827/13852 [14:15<36:59,  4.52it/s\u001b[A\n",
      "Training loss: 4.95e-02 lr: 3.62e-05:  28%|▎| 3828/13852 [14:16<37:02,  4.51it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 3.62e-05:  28%|▎| 3829/13852 [14:16<37:04,  4.51it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 3.62e-05:  28%|▎| 3830/13852 [14:16<37:05,  4.50it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 3.62e-05:  28%|▎| 3831/13852 [14:16<36:55,  4.52it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 3.62e-05:  28%|▎| 3832/13852 [14:17<36:45,  4.54it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 3.62e-05:  28%|▎| 3833/13852 [14:17<37:19,  4.47it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 3.62e-05:  28%|▎| 3834/13852 [14:17<37:14,  4.48it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 3.62e-05:  28%|▎| 3835/13852 [14:17<38:13,  4.37it/s\u001b[A\n",
      "Training loss: 4.79e-02 lr: 3.62e-05:  28%|▎| 3836/13852 [14:18<38:57,  4.29it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 3.62e-05:  28%|▎| 3837/13852 [14:18<38:22,  4.35it/s\u001b[A\n",
      "Training loss: 3.13e-02 lr: 3.61e-05:  28%|▎| 3838/13852 [14:18<38:06,  4.38it/s\u001b[A\n",
      "Training loss: 3.96e-02 lr: 3.61e-05:  28%|▎| 3839/13852 [14:18<37:45,  4.42it/s\u001b[A\n",
      "Training loss: 8.75e-02 lr: 3.61e-05:  28%|▎| 3840/13852 [14:18<37:20,  4.47it/s\u001b[A\n",
      "Training loss: 8.66e-02 lr: 3.61e-05:  28%|▎| 3841/13852 [14:19<37:01,  4.51it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 3.61e-05:  28%|▎| 3842/13852 [14:19<37:15,  4.48it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 3.61e-05:  28%|▎| 3843/13852 [14:19<37:03,  4.50it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 3.61e-05:  28%|▎| 3844/13852 [14:19<36:59,  4.51it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 3.61e-05:  28%|▎| 3845/13852 [14:19<36:58,  4.51it/s\u001b[A\n",
      "Training loss: 5.07e-02 lr: 3.61e-05:  28%|▎| 3846/13852 [14:20<36:54,  4.52it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 3.61e-05:  28%|▎| 3847/13852 [14:20<36:56,  4.51it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 3.61e-05:  28%|▎| 3848/13852 [14:20<36:56,  4.51it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 3.61e-05:  28%|▎| 3849/13852 [14:20<37:00,  4.50it/s\u001b[A\n",
      "Training loss: 5.68e-02 lr: 3.61e-05:  28%|▎| 3850/13852 [14:21<37:00,  4.50it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 3.61e-05:  28%|▎| 3851/13852 [14:21<37:25,  4.45it/s\u001b[A\n",
      "Training loss: 9.77e-02 lr: 3.61e-05:  28%|▎| 3852/13852 [14:21<37:11,  4.48it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 3.61e-05:  28%|▎| 3853/13852 [14:21<36:55,  4.51it/s\u001b[A\n",
      "Training loss: 8.64e-02 lr: 3.61e-05:  28%|▎| 3854/13852 [14:21<36:40,  4.54it/s\u001b[A\n",
      "Training loss: 6.30e-02 lr: 3.61e-05:  28%|▎| 3855/13852 [14:22<37:01,  4.50it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 3.61e-05:  28%|▎| 3856/13852 [14:22<36:59,  4.50it/s\u001b[A\n",
      "Training loss: 9.96e-02 lr: 3.61e-05:  28%|▎| 3857/13852 [14:22<37:17,  4.47it/s\u001b[A\n",
      "Training loss: 7.13e-02 lr: 3.61e-05:  28%|▎| 3858/13852 [14:22<37:12,  4.48it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 3.61e-05:  28%|▎| 3859/13852 [14:23<37:07,  4.49it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 3.61e-05:  28%|▎| 3860/13852 [14:23<37:07,  4.49it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.61e-05:  28%|▎| 3861/13852 [14:23<37:08,  4.48it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.61e-05:  28%|▎| 3862/13852 [14:23<37:06,  4.49it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.61e-05:  28%|▎| 3863/13852 [14:24<36:58,  4.50it/s\u001b[A\n",
      "Training loss: 9.27e-02 lr: 3.61e-05:  28%|▎| 3864/13852 [14:24<36:43,  4.53it/s\u001b[A\n",
      "Training loss: 8.84e-02 lr: 3.61e-05:  28%|▎| 3865/13852 [14:24<36:35,  4.55it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 3.60e-05:  28%|▎| 3866/13852 [14:24<36:57,  4.50it/s\u001b[A\n",
      "Training loss: 9.44e-02 lr: 3.60e-05:  28%|▎| 3867/13852 [14:24<36:57,  4.50it/s\u001b[A\n",
      "Training loss: 8.35e-02 lr: 3.60e-05:  28%|▎| 3868/13852 [14:25<36:55,  4.51it/s\u001b[A\n",
      "Training loss: 7.78e-02 lr: 3.60e-05:  28%|▎| 3869/13852 [14:25<36:52,  4.51it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 3.60e-05:  28%|▎| 3870/13852 [14:25<36:51,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.69e-02 lr: 3.60e-05:  28%|▎| 3871/13852 [14:25<36:51,  4.51it/s\u001b[A\n",
      "Training loss: 7.96e-02 lr: 3.60e-05:  28%|▎| 3872/13852 [14:25<36:50,  4.51it/s\u001b[A\n",
      "Training loss: 8.39e-02 lr: 3.60e-05:  28%|▎| 3873/13852 [14:26<36:51,  4.51it/s\u001b[A\n",
      "Training loss: 8.93e-02 lr: 3.60e-05:  28%|▎| 3874/13852 [14:26<36:54,  4.51it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 3.60e-05:  28%|▎| 3875/13852 [14:26<36:47,  4.52it/s\u001b[A\n",
      "Training loss: 7.18e-02 lr: 3.60e-05:  28%|▎| 3876/13852 [14:26<36:43,  4.53it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 3.60e-05:  28%|▎| 3877/13852 [14:27<36:30,  4.55it/s\u001b[A\n",
      "Training loss: 7.13e-02 lr: 3.60e-05:  28%|▎| 3878/13852 [14:27<36:41,  4.53it/s\u001b[A\n",
      "Training loss: 8.72e-02 lr: 3.60e-05:  28%|▎| 3879/13852 [14:27<36:44,  4.52it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.60e-05:  28%|▎| 3880/13852 [14:27<36:50,  4.51it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 3.60e-05:  28%|▎| 3881/13852 [14:27<36:53,  4.50it/s\u001b[A\n",
      "Training loss: 6.12e-02 lr: 3.60e-05:  28%|▎| 3882/13852 [14:28<36:49,  4.51it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.60e-05:  28%|▎| 3883/13852 [14:28<36:55,  4.50it/s\u001b[A\n",
      "Training loss: 1.54e-01 lr: 3.60e-05:  28%|▎| 3884/13852 [14:28<37:05,  4.48it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.60e-05:  28%|▎| 3885/13852 [14:28<37:13,  4.46it/s\u001b[A\n",
      "Training loss: 9.44e-02 lr: 3.60e-05:  28%|▎| 3886/13852 [14:29<37:08,  4.47it/s\u001b[A\n",
      "Training loss: 9.02e-02 lr: 3.60e-05:  28%|▎| 3887/13852 [14:29<37:11,  4.47it/s\u001b[A\n",
      "Training loss: 8.09e-02 lr: 3.60e-05:  28%|▎| 3888/13852 [14:29<37:18,  4.45it/s\u001b[A\n",
      "Training loss: 6.22e-02 lr: 3.60e-05:  28%|▎| 3889/13852 [14:29<36:57,  4.49it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 3.60e-05:  28%|▎| 3890/13852 [14:29<37:02,  4.48it/s\u001b[A\n",
      "Training loss: 5.09e-02 lr: 3.60e-05:  28%|▎| 3891/13852 [14:30<36:58,  4.49it/s\u001b[A\n",
      "Training loss: 9.68e-02 lr: 3.60e-05:  28%|▎| 3892/13852 [14:30<36:57,  4.49it/s\u001b[A\n",
      "Training loss: 9.85e-02 lr: 3.60e-05:  28%|▎| 3893/13852 [14:30<37:02,  4.48it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.59e-05:  28%|▎| 3894/13852 [14:30<37:04,  4.48it/s\u001b[A\n",
      "Training loss: 8.83e-02 lr: 3.59e-05:  28%|▎| 3895/13852 [14:31<37:03,  4.48it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 3.59e-05:  28%|▎| 3896/13852 [14:31<37:23,  4.44it/s\u001b[A\n",
      "Training loss: 1.53e-01 lr: 3.59e-05:  28%|▎| 3897/13852 [14:31<37:19,  4.44it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 3.59e-05:  28%|▎| 3898/13852 [14:31<37:04,  4.47it/s\u001b[A\n",
      "Training loss: 1.81e-01 lr: 3.59e-05:  28%|▎| 3899/13852 [14:32<36:52,  4.50it/s\u001b[A\n",
      "Training loss: 1.56e-01 lr: 3.59e-05:  28%|▎| 3900/13852 [14:32<36:49,  4.50it/s\u001b[A\n",
      "Training loss: 1.68e-01 lr: 3.59e-05:  28%|▎| 3901/13852 [14:32<36:59,  4.48it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.59e-05:  28%|▎| 3902/13852 [14:32<39:12,  4.23it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 3.59e-05:  28%|▎| 3903/13852 [14:32<39:24,  4.21it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.59e-05:  28%|▎| 3904/13852 [14:33<39:29,  4.20it/s\u001b[A\n",
      "Training loss: 9.47e-02 lr: 3.59e-05:  28%|▎| 3905/13852 [14:33<39:39,  4.18it/s\u001b[A\n",
      "Training loss: 7.94e-02 lr: 3.59e-05:  28%|▎| 3906/13852 [14:33<39:36,  4.19it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.59e-05:  28%|▎| 3907/13852 [14:33<39:39,  4.18it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.59e-05:  28%|▎| 3908/13852 [14:34<39:38,  4.18it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.59e-05:  28%|▎| 3909/13852 [14:34<39:41,  4.18it/s\u001b[A\n",
      "Training loss: 9.27e-02 lr: 3.59e-05:  28%|▎| 3910/13852 [14:34<39:44,  4.17it/s\u001b[A\n",
      "Training loss: 7.92e-02 lr: 3.59e-05:  28%|▎| 3911/13852 [14:34<39:48,  4.16it/s\u001b[A\n",
      "Training loss: 9.20e-02 lr: 3.59e-05:  28%|▎| 3912/13852 [14:35<39:36,  4.18it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.59e-05:  28%|▎| 3913/13852 [14:35<39:43,  4.17it/s\u001b[A\n",
      "Training loss: 9.42e-02 lr: 3.59e-05:  28%|▎| 3914/13852 [14:35<39:43,  4.17it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 3.59e-05:  28%|▎| 3915/13852 [14:35<39:42,  4.17it/s\u001b[A\n",
      "Training loss: 6.65e-02 lr: 3.59e-05:  28%|▎| 3916/13852 [14:36<39:44,  4.17it/s\u001b[A\n",
      "Training loss: 4.95e-02 lr: 3.59e-05:  28%|▎| 3917/13852 [14:36<39:40,  4.17it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 3.59e-05:  28%|▎| 3918/13852 [14:36<39:53,  4.15it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 3.59e-05:  28%|▎| 3919/13852 [14:36<39:50,  4.16it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 3.59e-05:  28%|▎| 3920/13852 [14:37<39:47,  4.16it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 3.58e-05:  28%|▎| 3921/13852 [14:37<40:41,  4.07it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 3.58e-05:  28%|▎| 3922/13852 [14:37<40:33,  4.08it/s\u001b[A\n",
      "Training loss: 2.54e-02 lr: 3.58e-05:  28%|▎| 3923/13852 [14:37<40:19,  4.10it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 3.58e-05:  28%|▎| 3924/13852 [14:38<40:13,  4.11it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 3.58e-05:  28%|▎| 3925/13852 [14:38<40:11,  4.12it/s\u001b[A\n",
      "Training loss: 9.30e-02 lr: 3.58e-05:  28%|▎| 3926/13852 [14:38<40:19,  4.10it/s\u001b[A\n",
      "Training loss: 8.85e-02 lr: 3.58e-05:  28%|▎| 3927/13852 [14:38<39:17,  4.21it/s\u001b[A\n",
      "Training loss: 6.82e-02 lr: 3.58e-05:  28%|▎| 3928/13852 [14:38<38:26,  4.30it/s\u001b[A\n",
      "Training loss: 6.09e-02 lr: 3.58e-05:  28%|▎| 3929/13852 [14:39<37:44,  4.38it/s\u001b[A\n",
      "Training loss: 7.53e-02 lr: 3.58e-05:  28%|▎| 3930/13852 [14:39<37:12,  4.44it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 3.58e-05:  28%|▎| 3931/13852 [14:39<37:06,  4.46it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 3.58e-05:  28%|▎| 3932/13852 [14:39<36:55,  4.48it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 3.58e-05:  28%|▎| 3933/13852 [14:40<36:46,  4.49it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 3.58e-05:  28%|▎| 3934/13852 [14:40<36:40,  4.51it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 3.58e-05:  28%|▎| 3935/13852 [14:40<36:38,  4.51it/s\u001b[A\n",
      "Training loss: 3.15e-02 lr: 3.58e-05:  28%|▎| 3936/13852 [14:40<36:39,  4.51it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 3.58e-05:  28%|▎| 3937/13852 [14:40<36:41,  4.50it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 3.58e-05:  28%|▎| 3938/13852 [14:41<36:39,  4.51it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 3.58e-05:  28%|▎| 3939/13852 [14:41<36:52,  4.48it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 3.58e-05:  28%|▎| 3940/13852 [14:41<36:46,  4.49it/s\u001b[A\n",
      "Training loss: 5.40e-02 lr: 3.58e-05:  28%|▎| 3941/13852 [14:41<36:31,  4.52it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 3.58e-05:  28%|▎| 3942/13852 [14:42<36:19,  4.55it/s\u001b[A\n",
      "Training loss: 3.44e-02 lr: 3.58e-05:  28%|▎| 3943/13852 [14:42<36:50,  4.48it/s\u001b[A\n",
      "Training loss: 3.01e-02 lr: 3.58e-05:  28%|▎| 3944/13852 [14:42<36:45,  4.49it/s\u001b[A\n",
      "Training loss: 7.37e-02 lr: 3.58e-05:  28%|▎| 3945/13852 [14:42<36:37,  4.51it/s\u001b[A\n",
      "Training loss: 8.91e-02 lr: 3.58e-05:  28%|▎| 3946/13852 [14:42<36:34,  4.51it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 3.58e-05:  28%|▎| 3947/13852 [14:43<36:32,  4.52it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 3.58e-05:  29%|▎| 3948/13852 [14:43<36:31,  4.52it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 3.57e-05:  29%|▎| 3949/13852 [14:43<36:33,  4.51it/s\u001b[A\n",
      "Training loss: 9.43e-02 lr: 3.57e-05:  29%|▎| 3950/13852 [14:43<36:34,  4.51it/s\u001b[A\n",
      "Training loss: 7.57e-02 lr: 3.57e-05:  29%|▎| 3951/13852 [14:44<36:33,  4.51it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 3.57e-05:  29%|▎| 3952/13852 [14:44<36:35,  4.51it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.57e-05:  29%|▎| 3953/13852 [14:44<36:20,  4.54it/s\u001b[A\n",
      "Training loss: 7.62e-02 lr: 3.57e-05:  29%|▎| 3954/13852 [14:44<36:12,  4.56it/s\u001b[A\n",
      "Training loss: 5.68e-02 lr: 3.57e-05:  29%|▎| 3955/13852 [14:44<36:04,  4.57it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 3.57e-05:  29%|▎| 3956/13852 [14:45<35:58,  4.58it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 3.57e-05:  29%|▎| 3957/13852 [14:45<36:05,  4.57it/s\u001b[A\n",
      "Training loss: 6.36e-02 lr: 3.57e-05:  29%|▎| 3958/13852 [14:45<36:16,  4.55it/s\u001b[A\n",
      "Training loss: 7.81e-02 lr: 3.57e-05:  29%|▎| 3959/13852 [14:45<36:19,  4.54it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 3.57e-05:  29%|▎| 3960/13852 [14:46<36:17,  4.54it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 3.57e-05:  29%|▎| 3961/13852 [14:46<36:19,  4.54it/s\u001b[A\n",
      "Training loss: 8.33e-02 lr: 3.57e-05:  29%|▎| 3962/13852 [14:46<36:22,  4.53it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.57e-05:  29%|▎| 3963/13852 [14:46<36:25,  4.53it/s\u001b[A\n",
      "Training loss: 7.78e-02 lr: 3.57e-05:  29%|▎| 3964/13852 [14:46<36:33,  4.51it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 3.57e-05:  29%|▎| 3965/13852 [14:47<36:38,  4.50it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 3.57e-05:  29%|▎| 3966/13852 [14:47<36:44,  4.49it/s\u001b[A\n",
      "Training loss: 6.82e-02 lr: 3.57e-05:  29%|▎| 3967/13852 [14:47<36:31,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.44e-02 lr: 3.57e-05:  29%|▎| 3968/13852 [14:47<36:18,  4.54it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 3.57e-05:  29%|▎| 3969/13852 [14:48<36:26,  4.52it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.57e-05:  29%|▎| 3970/13852 [14:48<36:25,  4.52it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.57e-05:  29%|▎| 3971/13852 [14:48<36:37,  4.50it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.57e-05:  29%|▎| 3972/13852 [14:48<36:32,  4.51it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 3.57e-05:  29%|▎| 3973/13852 [14:48<36:35,  4.50it/s\u001b[A\n",
      "Training loss: 6.30e-02 lr: 3.57e-05:  29%|▎| 3974/13852 [14:49<36:32,  4.51it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 3.57e-05:  29%|▎| 3975/13852 [14:49<36:29,  4.51it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 3.57e-05:  29%|▎| 3976/13852 [14:49<36:29,  4.51it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 3.56e-05:  29%|▎| 3977/13852 [14:49<36:29,  4.51it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 3.56e-05:  29%|▎| 3978/13852 [14:50<36:18,  4.53it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 3.56e-05:  29%|▎| 3979/13852 [14:50<36:06,  4.56it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 3.56e-05:  29%|▎| 3980/13852 [14:50<36:00,  4.57it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 3.56e-05:  29%|▎| 3981/13852 [14:50<36:24,  4.52it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 3.56e-05:  29%|▎| 3982/13852 [14:50<36:22,  4.52it/s\u001b[A\n",
      "Training loss: 3.99e-02 lr: 3.56e-05:  29%|▎| 3983/13852 [14:51<36:21,  4.52it/s\u001b[A\n",
      "Training loss: 3.77e-02 lr: 3.56e-05:  29%|▎| 3984/13852 [14:51<36:39,  4.49it/s\u001b[A\n",
      "Training loss: 3.52e-02 lr: 3.56e-05:  29%|▎| 3985/13852 [14:51<36:36,  4.49it/s\u001b[A\n",
      "Training loss: 2.66e-02 lr: 3.56e-05:  29%|▎| 3986/13852 [14:51<36:32,  4.50it/s\u001b[A\n",
      "Training loss: 2.19e-02 lr: 3.56e-05:  29%|▎| 3987/13852 [14:52<36:29,  4.50it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 3.56e-05:  29%|▎| 3988/13852 [14:52<36:41,  4.48it/s\u001b[A\n",
      "Training loss: 8.69e-02 lr: 3.56e-05:  29%|▎| 3989/13852 [14:52<36:40,  4.48it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.56e-05:  29%|▎| 3990/13852 [14:52<36:27,  4.51it/s\u001b[A\n",
      "Training loss: 8.25e-02 lr: 3.56e-05:  29%|▎| 3991/13852 [14:52<36:12,  4.54it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 3.56e-05:  29%|▎| 3992/13852 [14:53<36:02,  4.56it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 3.56e-05:  29%|▎| 3993/13852 [14:53<36:01,  4.56it/s\u001b[A\n",
      "Training loss: 6.75e-02 lr: 3.56e-05:  29%|▎| 3994/13852 [14:53<36:09,  4.54it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 3.56e-05:  29%|▎| 3995/13852 [14:53<36:12,  4.54it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 3.56e-05:  29%|▎| 3996/13852 [14:53<36:14,  4.53it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 3.56e-05:  29%|▎| 3997/13852 [14:54<36:14,  4.53it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 3.56e-05:  29%|▎| 3998/13852 [14:54<36:18,  4.52it/s\u001b[A\n",
      "Training loss: 9.01e-02 lr: 3.56e-05:  29%|▎| 3999/13852 [14:54<36:20,  4.52it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 3.56e-05:  29%|▎| 4000/13852 [14:54<36:20,  4.52it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 3.56e-05:  29%|▎| 4001/13852 [14:55<36:26,  4.51it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 3.56e-05:  29%|▎| 4002/13852 [14:55<36:30,  4.50it/s\u001b[A\n",
      "Training loss: 8.41e-02 lr: 3.56e-05:  29%|▎| 4003/13852 [14:55<36:26,  4.50it/s\u001b[A\n",
      "Training loss: 7.35e-02 lr: 3.55e-05:  29%|▎| 4004/13852 [14:55<36:14,  4.53it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 3.55e-05:  29%|▎| 4005/13852 [14:55<36:05,  4.55it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 3.55e-05:  29%|▎| 4006/13852 [14:56<36:23,  4.51it/s\u001b[A\n",
      "Training loss: 3.52e-02 lr: 3.55e-05:  29%|▎| 4007/13852 [14:56<36:23,  4.51it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 3.55e-05:  29%|▎| 4008/13852 [14:56<36:19,  4.52it/s\u001b[A\n",
      "Training loss: 7.00e-02 lr: 3.55e-05:  29%|▎| 4009/13852 [14:56<36:13,  4.53it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 3.55e-05:  29%|▎| 4010/13852 [14:57<36:26,  4.50it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 3.55e-05:  29%|▎| 4011/13852 [14:57<36:36,  4.48it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.55e-05:  29%|▎| 4012/13852 [14:57<36:32,  4.49it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.55e-05:  29%|▎| 4013/13852 [14:57<37:25,  4.38it/s\u001b[A\n",
      "Training loss: 8.49e-02 lr: 3.55e-05:  29%|▎| 4014/13852 [14:58<36:56,  4.44it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 3.55e-05:  29%|▎| 4015/13852 [14:58<36:32,  4.49it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 3.55e-05:  29%|▎| 4016/13852 [14:58<36:20,  4.51it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 3.55e-05:  29%|▎| 4017/13852 [14:58<36:31,  4.49it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 3.55e-05:  29%|▎| 4018/13852 [14:58<36:27,  4.49it/s\u001b[A\n",
      "Training loss: 9.74e-02 lr: 3.55e-05:  29%|▎| 4019/13852 [14:59<36:23,  4.50it/s\u001b[A\n",
      "Training loss: 7.60e-02 lr: 3.55e-05:  29%|▎| 4020/13852 [14:59<36:22,  4.51it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 3.55e-05:  29%|▎| 4021/13852 [14:59<36:21,  4.51it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.55e-05:  29%|▎| 4022/13852 [14:59<36:21,  4.51it/s\u001b[A\n",
      "Training loss: 8.44e-02 lr: 3.55e-05:  29%|▎| 4023/13852 [14:59<36:18,  4.51it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.55e-05:  29%|▎| 4024/13852 [15:00<36:19,  4.51it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.55e-05:  29%|▎| 4025/13852 [15:00<36:22,  4.50it/s\u001b[A\n",
      "Training loss: 1.44e-01 lr: 3.55e-05:  29%|▎| 4026/13852 [15:00<36:13,  4.52it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.55e-05:  29%|▎| 4027/13852 [15:00<36:02,  4.54it/s\u001b[A\n",
      "Training loss: 9.70e-02 lr: 3.55e-05:  29%|▎| 4028/13852 [15:01<35:55,  4.56it/s\u001b[A\n",
      "Training loss: 9.10e-02 lr: 3.55e-05:  29%|▎| 4029/13852 [15:01<36:06,  4.53it/s\u001b[A\n",
      "Training loss: 8.63e-02 lr: 3.55e-05:  29%|▎| 4030/13852 [15:01<36:32,  4.48it/s\u001b[A\n",
      "Training loss: 8.19e-02 lr: 3.55e-05:  29%|▎| 4031/13852 [15:01<36:30,  4.48it/s\u001b[A\n",
      "Training loss: 9.03e-02 lr: 3.54e-05:  29%|▎| 4032/13852 [15:01<36:28,  4.49it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 3.54e-05:  29%|▎| 4033/13852 [15:02<36:31,  4.48it/s\u001b[A\n",
      "Training loss: 8.39e-02 lr: 3.54e-05:  29%|▎| 4034/13852 [15:02<36:31,  4.48it/s\u001b[A\n",
      "Training loss: 1.56e-01 lr: 3.54e-05:  29%|▎| 4035/13852 [15:02<36:32,  4.48it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.54e-05:  29%|▎| 4036/13852 [15:02<36:29,  4.48it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 3.54e-05:  29%|▎| 4037/13852 [15:03<36:26,  4.49it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.54e-05:  29%|▎| 4038/13852 [15:03<36:16,  4.51it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 3.54e-05:  29%|▎| 4039/13852 [15:03<36:20,  4.50it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.54e-05:  29%|▎| 4040/13852 [15:03<36:08,  4.52it/s\u001b[A\n",
      "Training loss: 9.32e-02 lr: 3.54e-05:  29%|▎| 4041/13852 [15:03<36:10,  4.52it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 3.54e-05:  29%|▎| 4042/13852 [15:04<36:12,  4.51it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 3.54e-05:  29%|▎| 4043/13852 [15:04<36:11,  4.52it/s\u001b[A\n",
      "Training loss: 8.76e-02 lr: 3.54e-05:  29%|▎| 4044/13852 [15:04<36:14,  4.51it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 3.54e-05:  29%|▎| 4045/13852 [15:04<36:16,  4.51it/s\u001b[A\n",
      "Training loss: 7.58e-02 lr: 3.54e-05:  29%|▎| 4046/13852 [15:05<36:18,  4.50it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 3.54e-05:  29%|▎| 4047/13852 [15:05<36:19,  4.50it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 3.54e-05:  29%|▎| 4048/13852 [15:05<36:19,  4.50it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 3.54e-05:  29%|▎| 4049/13852 [15:05<36:19,  4.50it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 3.54e-05:  29%|▎| 4050/13852 [15:05<36:19,  4.50it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 3.54e-05:  29%|▎| 4051/13852 [15:06<36:08,  4.52it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 3.54e-05:  29%|▎| 4052/13852 [15:06<36:02,  4.53it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 3.54e-05:  29%|▎| 4053/13852 [15:06<36:18,  4.50it/s\u001b[A\n",
      "Training loss: 8.26e-02 lr: 3.54e-05:  29%|▎| 4054/13852 [15:06<36:14,  4.51it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.54e-05:  29%|▎| 4055/13852 [15:07<36:26,  4.48it/s\u001b[A\n",
      "Training loss: 9.15e-02 lr: 3.54e-05:  29%|▎| 4056/13852 [15:07<36:48,  4.44it/s\u001b[A\n",
      "Training loss: 8.57e-02 lr: 3.54e-05:  29%|▎| 4057/13852 [15:07<36:48,  4.43it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 3.54e-05:  29%|▎| 4058/13852 [15:07<36:49,  4.43it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 3.54e-05:  29%|▎| 4059/13852 [15:08<36:42,  4.45it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 3.53e-05:  29%|▎| 4060/13852 [15:08<36:33,  4.46it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 3.53e-05:  29%|▎| 4061/13852 [15:08<36:21,  4.49it/s\u001b[A\n",
      "Training loss: 9.37e-02 lr: 3.53e-05:  29%|▎| 4062/13852 [15:08<36:08,  4.51it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 3.53e-05:  29%|▎| 4063/13852 [15:08<35:55,  4.54it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 3.53e-05:  29%|▎| 4064/13852 [15:09<36:11,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.78e-02 lr: 3.53e-05:  29%|▎| 4065/13852 [15:09<36:11,  4.51it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 3.53e-05:  29%|▎| 4066/13852 [15:09<36:06,  4.52it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 3.53e-05:  29%|▎| 4067/13852 [15:09<36:05,  4.52it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 3.53e-05:  29%|▎| 4068/13852 [15:09<36:07,  4.51it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 3.53e-05:  29%|▎| 4069/13852 [15:10<36:06,  4.51it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 3.53e-05:  29%|▎| 4070/13852 [15:10<36:08,  4.51it/s\u001b[A\n",
      "Training loss: 3.70e-02 lr: 3.53e-05:  29%|▎| 4071/13852 [15:10<36:08,  4.51it/s\u001b[A\n",
      "Training loss: 7.33e-02 lr: 3.53e-05:  29%|▎| 4072/13852 [15:10<36:09,  4.51it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 3.53e-05:  29%|▎| 4073/13852 [15:11<36:06,  4.51it/s\u001b[A\n",
      "Training loss: 4.30e-02 lr: 3.53e-05:  29%|▎| 4074/13852 [15:11<36:15,  4.49it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 3.53e-05:  29%|▎| 4075/13852 [15:11<36:18,  4.49it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 3.53e-05:  29%|▎| 4076/13852 [15:11<36:14,  4.50it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 3.53e-05:  29%|▎| 4077/13852 [15:11<36:13,  4.50it/s\u001b[A\n",
      "Training loss: 3.28e-02 lr: 3.53e-05:  29%|▎| 4078/13852 [15:12<36:23,  4.48it/s\u001b[A\n",
      "Training loss: 2.64e-02 lr: 3.53e-05:  29%|▎| 4079/13852 [15:12<36:21,  4.48it/s\u001b[A\n",
      "Training loss: 2.50e-02 lr: 3.53e-05:  29%|▎| 4080/13852 [15:12<36:23,  4.48it/s\u001b[A\n",
      "Training loss: 2.18e-02 lr: 3.53e-05:  29%|▎| 4081/13852 [15:12<36:18,  4.49it/s\u001b[A\n",
      "Training loss: 1.66e-02 lr: 3.53e-05:  29%|▎| 4082/13852 [15:13<36:14,  4.49it/s\u001b[A\n",
      "Training loss: 1.41e-02 lr: 3.53e-05:  29%|▎| 4083/13852 [15:13<36:15,  4.49it/s\u001b[A\n",
      "Training loss: 1.82e-02 lr: 3.53e-05:  29%|▎| 4084/13852 [15:13<36:15,  4.49it/s\u001b[A\n",
      "Training loss: 2.63e-02 lr: 3.53e-05:  29%|▎| 4085/13852 [15:13<36:08,  4.50it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 3.53e-05:  29%|▎| 4086/13852 [15:13<35:57,  4.53it/s\u001b[A\n",
      "Training loss: 6.30e-02 lr: 3.53e-05:  30%|▎| 4087/13852 [15:14<35:51,  4.54it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 3.52e-05:  30%|▎| 4088/13852 [15:14<35:59,  4.52it/s\u001b[A\n",
      "Training loss: 7.07e-02 lr: 3.52e-05:  30%|▎| 4089/13852 [15:14<35:58,  4.52it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 3.52e-05:  30%|▎| 4090/13852 [15:14<35:58,  4.52it/s\u001b[A\n",
      "Training loss: 9.44e-02 lr: 3.52e-05:  30%|▎| 4091/13852 [15:15<35:57,  4.52it/s\u001b[A\n",
      "Training loss: 1.52e-01 lr: 3.52e-05:  30%|▎| 4092/13852 [15:15<36:02,  4.51it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.52e-05:  30%|▎| 4093/13852 [15:15<36:05,  4.51it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.52e-05:  30%|▎| 4094/13852 [15:15<36:07,  4.50it/s\u001b[A\n",
      "Training loss: 9.00e-02 lr: 3.52e-05:  30%|▎| 4095/13852 [15:15<36:09,  4.50it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 3.52e-05:  30%|▎| 4096/13852 [15:16<36:09,  4.50it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 3.52e-05:  30%|▎| 4097/13852 [15:16<36:00,  4.52it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 3.52e-05:  30%|▎| 4098/13852 [15:16<35:49,  4.54it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.52e-05:  30%|▎| 4099/13852 [15:16<35:40,  4.56it/s\u001b[A\n",
      "Training loss: 9.94e-02 lr: 3.52e-05:  30%|▎| 4100/13852 [15:17<36:03,  4.51it/s\u001b[A\n",
      "Training loss: 8.84e-02 lr: 3.52e-05:  30%|▎| 4101/13852 [15:17<36:19,  4.47it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.52e-05:  30%|▎| 4102/13852 [15:17<36:15,  4.48it/s\u001b[A\n",
      "Training loss: 9.38e-02 lr: 3.52e-05:  30%|▎| 4103/13852 [15:17<36:14,  4.48it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 3.52e-05:  30%|▎| 4104/13852 [15:17<36:13,  4.49it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 3.52e-05:  30%|▎| 4105/13852 [15:18<36:11,  4.49it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 3.52e-05:  30%|▎| 4106/13852 [15:18<36:10,  4.49it/s\u001b[A\n",
      "Training loss: 4.82e-02 lr: 3.52e-05:  30%|▎| 4107/13852 [15:18<36:10,  4.49it/s\u001b[A\n",
      "Training loss: 3.69e-02 lr: 3.52e-05:  30%|▎| 4108/13852 [15:18<36:09,  4.49it/s\u001b[A\n",
      "Training loss: 8.24e-02 lr: 3.52e-05:  30%|▎| 4109/13852 [15:19<36:00,  4.51it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 3.52e-05:  30%|▎| 4110/13852 [15:19<35:51,  4.53it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 3.52e-05:  30%|▎| 4111/13852 [15:19<36:08,  4.49it/s\u001b[A\n",
      "Training loss: 6.88e-02 lr: 3.52e-05:  30%|▎| 4112/13852 [15:19<36:01,  4.51it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 3.52e-05:  30%|▎| 4113/13852 [15:19<35:57,  4.51it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 3.52e-05:  30%|▎| 4114/13852 [15:20<35:59,  4.51it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.51e-05:  30%|▎| 4115/13852 [15:20<35:55,  4.52it/s\u001b[A\n",
      "Training loss: 9.42e-02 lr: 3.51e-05:  30%|▎| 4116/13852 [15:20<35:56,  4.51it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 3.51e-05:  30%|▎| 4117/13852 [15:20<35:58,  4.51it/s\u001b[A\n",
      "Training loss: 8.35e-02 lr: 3.51e-05:  30%|▎| 4118/13852 [15:21<36:00,  4.51it/s\u001b[A\n",
      "Training loss: 8.20e-02 lr: 3.51e-05:  30%|▎| 4119/13852 [15:21<36:25,  4.45it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 3.51e-05:  30%|▎| 4120/13852 [15:21<36:23,  4.46it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 3.51e-05:  30%|▎| 4121/13852 [15:21<36:09,  4.49it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 3.51e-05:  30%|▎| 4122/13852 [15:21<35:56,  4.51it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.51e-05:  30%|▎| 4123/13852 [15:22<35:59,  4.51it/s\u001b[A\n",
      "Training loss: 7.98e-02 lr: 3.51e-05:  30%|▎| 4124/13852 [15:22<36:00,  4.50it/s\u001b[A\n",
      "Training loss: 6.75e-02 lr: 3.51e-05:  30%|▎| 4125/13852 [15:22<36:11,  4.48it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 3.51e-05:  30%|▎| 4126/13852 [15:22<36:06,  4.49it/s\u001b[A\n",
      "Training loss: 7.27e-02 lr: 3.51e-05:  30%|▎| 4127/13852 [15:23<36:03,  4.50it/s\u001b[A\n",
      "Training loss: 7.03e-02 lr: 3.51e-05:  30%|▎| 4128/13852 [15:23<36:03,  4.50it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 3.51e-05:  30%|▎| 4129/13852 [15:23<36:05,  4.49it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 3.51e-05:  30%|▎| 4130/13852 [15:23<36:02,  4.50it/s\u001b[A\n",
      "Training loss: 3.44e-02 lr: 3.51e-05:  30%|▎| 4131/13852 [15:23<35:58,  4.50it/s\u001b[A\n",
      "Training loss: 9.95e-02 lr: 3.51e-05:  30%|▎| 4132/13852 [15:24<35:56,  4.51it/s\u001b[A\n",
      "Training loss: 7.57e-02 lr: 3.51e-05:  30%|▎| 4133/13852 [15:24<35:44,  4.53it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 3.51e-05:  30%|▎| 4134/13852 [15:24<35:36,  4.55it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 3.51e-05:  30%|▎| 4135/13852 [15:24<35:51,  4.52it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 3.51e-05:  30%|▎| 4136/13852 [15:25<35:49,  4.52it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 3.51e-05:  30%|▎| 4137/13852 [15:25<35:47,  4.52it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 3.51e-05:  30%|▎| 4138/13852 [15:25<35:48,  4.52it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 3.51e-05:  30%|▎| 4139/13852 [15:25<35:49,  4.52it/s\u001b[A\n",
      "Training loss: 9.27e-02 lr: 3.51e-05:  30%|▎| 4140/13852 [15:25<35:47,  4.52it/s\u001b[A\n",
      "Training loss: 6.56e-02 lr: 3.51e-05:  30%|▎| 4141/13852 [15:26<35:48,  4.52it/s\u001b[A\n",
      "Training loss: 1.55e-01 lr: 3.51e-05:  30%|▎| 4142/13852 [15:26<35:49,  4.52it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.50e-05:  30%|▎| 4143/13852 [15:26<35:50,  4.52it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.50e-05:  30%|▎| 4144/13852 [15:26<35:48,  4.52it/s\u001b[A\n",
      "Training loss: 8.33e-02 lr: 3.50e-05:  30%|▎| 4145/13852 [15:27<35:38,  4.54it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.50e-05:  30%|▎| 4146/13852 [15:27<35:51,  4.51it/s\u001b[A\n",
      "Training loss: 9.99e-02 lr: 3.50e-05:  30%|▎| 4147/13852 [15:27<35:41,  4.53it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.50e-05:  30%|▎| 4148/13852 [15:27<36:39,  4.41it/s\u001b[A\n",
      "Training loss: 7.82e-02 lr: 3.50e-05:  30%|▎| 4149/13852 [15:27<36:21,  4.45it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 3.50e-05:  30%|▎| 4150/13852 [15:28<36:07,  4.48it/s\u001b[A\n",
      "Training loss: 7.86e-02 lr: 3.50e-05:  30%|▎| 4151/13852 [15:28<36:03,  4.48it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 3.50e-05:  30%|▎| 4152/13852 [15:28<36:00,  4.49it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 3.50e-05:  30%|▎| 4153/13852 [15:28<35:54,  4.50it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 3.50e-05:  30%|▎| 4154/13852 [15:29<35:51,  4.51it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 3.50e-05:  30%|▎| 4155/13852 [15:29<35:48,  4.51it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 3.50e-05:  30%|▎| 4156/13852 [15:29<35:49,  4.51it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 3.50e-05:  30%|▎| 4157/13852 [15:29<35:40,  4.53it/s\u001b[A\n",
      "Training loss: 6.32e-02 lr: 3.50e-05:  30%|▎| 4158/13852 [15:29<35:28,  4.55it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 3.50e-05:  30%|▎| 4159/13852 [15:30<35:22,  4.57it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 3.50e-05:  30%|▎| 4160/13852 [15:30<35:30,  4.55it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 3.50e-05:  30%|▎| 4161/13852 [15:30<35:36,  4.54it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.92e-02 lr: 3.50e-05:  30%|▎| 4162/13852 [15:30<35:36,  4.54it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 3.50e-05:  30%|▎| 4163/13852 [15:31<35:33,  4.54it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 3.50e-05:  30%|▎| 4164/13852 [15:31<35:52,  4.50it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 3.50e-05:  30%|▎| 4165/13852 [15:31<35:53,  4.50it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 3.50e-05:  30%|▎| 4166/13852 [15:31<35:51,  4.50it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 3.50e-05:  30%|▎| 4167/13852 [15:31<35:49,  4.51it/s\u001b[A\n",
      "Training loss: 4.86e-02 lr: 3.50e-05:  30%|▎| 4168/13852 [15:32<35:58,  4.49it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 3.50e-05:  30%|▎| 4169/13852 [15:32<35:46,  4.51it/s\u001b[A\n",
      "Training loss: 3.20e-02 lr: 3.50e-05:  30%|▎| 4170/13852 [15:32<35:35,  4.53it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 3.49e-05:  30%|▎| 4171/13852 [15:32<35:25,  4.55it/s\u001b[A\n",
      "Training loss: 2.69e-02 lr: 3.49e-05:  30%|▎| 4172/13852 [15:33<35:43,  4.52it/s\u001b[A\n",
      "Training loss: 2.37e-02 lr: 3.49e-05:  30%|▎| 4173/13852 [15:33<35:45,  4.51it/s\u001b[A\n",
      "Training loss: 2.59e-02 lr: 3.49e-05:  30%|▎| 4174/13852 [15:33<35:58,  4.48it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 3.49e-05:  30%|▎| 4175/13852 [15:33<35:53,  4.49it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 3.49e-05:  30%|▎| 4176/13852 [15:33<35:54,  4.49it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 3.49e-05:  30%|▎| 4177/13852 [15:34<35:53,  4.49it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 3.49e-05:  30%|▎| 4178/13852 [15:34<35:49,  4.50it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 3.49e-05:  30%|▎| 4179/13852 [15:34<35:50,  4.50it/s\u001b[A\n",
      "Training loss: 3.96e-02 lr: 3.49e-05:  30%|▎| 4180/13852 [15:34<35:50,  4.50it/s\u001b[A\n",
      "Training loss: 3.54e-02 lr: 3.49e-05:  30%|▎| 4181/13852 [15:35<35:41,  4.52it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 3.49e-05:  30%|▎| 4182/13852 [15:35<35:32,  4.54it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 3.49e-05:  30%|▎| 4183/13852 [15:35<35:35,  4.53it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.49e-05:  30%|▎| 4184/13852 [15:35<35:44,  4.51it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.49e-05:  30%|▎| 4185/13852 [15:35<35:43,  4.51it/s\u001b[A\n",
      "Training loss: 8.66e-02 lr: 3.49e-05:  30%|▎| 4186/13852 [15:36<35:41,  4.51it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 3.49e-05:  30%|▎| 4187/13852 [15:36<35:39,  4.52it/s\u001b[A\n",
      "Training loss: 8.01e-02 lr: 3.49e-05:  30%|▎| 4188/13852 [15:36<35:41,  4.51it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 3.49e-05:  30%|▎| 4189/13852 [15:36<35:40,  4.51it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 3.49e-05:  30%|▎| 4190/13852 [15:37<35:39,  4.52it/s\u001b[A\n",
      "Training loss: 8.36e-02 lr: 3.49e-05:  30%|▎| 4191/13852 [15:37<36:06,  4.46it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 3.49e-05:  30%|▎| 4192/13852 [15:37<36:08,  4.45it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.49e-05:  30%|▎| 4193/13852 [15:37<35:52,  4.49it/s\u001b[A\n",
      "Training loss: 9.98e-02 lr: 3.49e-05:  30%|▎| 4194/13852 [15:37<37:02,  4.34it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 3.49e-05:  30%|▎| 4195/13852 [15:38<37:38,  4.28it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.49e-05:  30%|▎| 4196/13852 [15:38<38:01,  4.23it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.49e-05:  30%|▎| 4197/13852 [15:38<37:56,  4.24it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.48e-05:  30%|▎| 4198/13852 [15:38<37:17,  4.31it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.48e-05:  30%|▎| 4199/13852 [15:39<36:46,  4.37it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.48e-05:  30%|▎| 4200/13852 [15:39<36:17,  4.43it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.48e-05:  30%|▎| 4201/13852 [15:39<35:53,  4.48it/s\u001b[A\n",
      "Training loss: 9.12e-02 lr: 3.48e-05:  30%|▎| 4202/13852 [15:39<35:38,  4.51it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.48e-05:  30%|▎| 4203/13852 [15:40<35:26,  4.54it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 3.48e-05:  30%|▎| 4204/13852 [15:40<35:26,  4.54it/s\u001b[A\n",
      "Training loss: 9.67e-02 lr: 3.48e-05:  30%|▎| 4205/13852 [15:40<35:26,  4.54it/s\u001b[A\n",
      "Training loss: 8.01e-02 lr: 3.48e-05:  30%|▎| 4206/13852 [15:40<35:26,  4.54it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 3.48e-05:  30%|▎| 4207/13852 [15:40<35:25,  4.54it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 3.48e-05:  30%|▎| 4208/13852 [15:41<35:30,  4.53it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 3.48e-05:  30%|▎| 4209/13852 [15:41<35:49,  4.49it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 3.48e-05:  30%|▎| 4210/13852 [15:41<35:47,  4.49it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 3.48e-05:  30%|▎| 4211/13852 [15:41<35:41,  4.50it/s\u001b[A\n",
      "Training loss: 7.98e-02 lr: 3.48e-05:  30%|▎| 4212/13852 [15:42<35:44,  4.50it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 3.48e-05:  30%|▎| 4213/13852 [15:42<35:48,  4.49it/s\u001b[A\n",
      "Training loss: 8.89e-02 lr: 3.48e-05:  30%|▎| 4214/13852 [15:42<35:35,  4.51it/s\u001b[A\n",
      "Training loss: 8.77e-02 lr: 3.48e-05:  30%|▎| 4215/13852 [15:42<35:26,  4.53it/s\u001b[A\n",
      "Training loss: 7.69e-02 lr: 3.48e-05:  30%|▎| 4216/13852 [15:42<35:33,  4.52it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 3.48e-05:  30%|▎| 4217/13852 [15:43<35:32,  4.52it/s\u001b[A\n",
      "Training loss: 8.14e-02 lr: 3.48e-05:  30%|▎| 4218/13852 [15:43<35:28,  4.53it/s\u001b[A\n",
      "Training loss: 9.97e-02 lr: 3.48e-05:  30%|▎| 4219/13852 [15:43<35:26,  4.53it/s\u001b[A\n",
      "Training loss: 8.07e-02 lr: 3.48e-05:  30%|▎| 4220/13852 [15:43<35:29,  4.52it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 3.48e-05:  30%|▎| 4221/13852 [15:44<35:28,  4.52it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 3.48e-05:  30%|▎| 4222/13852 [15:44<35:30,  4.52it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 3.48e-05:  30%|▎| 4223/13852 [15:44<35:29,  4.52it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.48e-05:  30%|▎| 4224/13852 [15:44<35:28,  4.52it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.48e-05:  31%|▎| 4225/13852 [15:44<35:24,  4.53it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.47e-05:  31%|▎| 4226/13852 [15:45<35:17,  4.55it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.47e-05:  31%|▎| 4227/13852 [15:45<35:11,  4.56it/s\u001b[A\n",
      "Training loss: 8.71e-02 lr: 3.47e-05:  31%|▎| 4228/13852 [15:45<35:08,  4.56it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 3.47e-05:  31%|▎| 4229/13852 [15:45<35:20,  4.54it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 3.47e-05:  31%|▎| 4230/13852 [15:45<35:21,  4.54it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 3.47e-05:  31%|▎| 4231/13852 [15:46<35:20,  4.54it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 3.47e-05:  31%|▎| 4232/13852 [15:46<35:20,  4.54it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 3.47e-05:  31%|▎| 4233/13852 [15:46<35:24,  4.53it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 3.47e-05:  31%|▎| 4234/13852 [15:46<35:25,  4.53it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 3.47e-05:  31%|▎| 4235/13852 [15:47<35:26,  4.52it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 3.47e-05:  31%|▎| 4236/13852 [15:47<35:44,  4.48it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 3.47e-05:  31%|▎| 4237/13852 [15:47<35:39,  4.49it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 3.47e-05:  31%|▎| 4238/13852 [15:47<35:36,  4.50it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 3.47e-05:  31%|▎| 4239/13852 [15:47<35:24,  4.52it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 3.47e-05:  31%|▎| 4240/13852 [15:48<35:13,  4.55it/s\u001b[A\n",
      "Training loss: 3.10e-02 lr: 3.47e-05:  31%|▎| 4241/13852 [15:48<35:03,  4.57it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 3.47e-05:  31%|▎| 4242/13852 [15:48<35:15,  4.54it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 3.47e-05:  31%|▎| 4243/13852 [15:48<35:15,  4.54it/s\u001b[A\n",
      "Training loss: 8.57e-02 lr: 3.47e-05:  31%|▎| 4244/13852 [15:49<35:11,  4.55it/s\u001b[A\n",
      "Training loss: 6.20e-02 lr: 3.47e-05:  31%|▎| 4245/13852 [15:49<35:09,  4.55it/s\u001b[A\n",
      "Training loss: 4.70e-02 lr: 3.47e-05:  31%|▎| 4246/13852 [15:49<35:13,  4.54it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 3.47e-05:  31%|▎| 4247/13852 [15:49<35:14,  4.54it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 3.47e-05:  31%|▎| 4248/13852 [15:49<35:19,  4.53it/s\u001b[A\n",
      "Training loss: 4.80e-02 lr: 3.47e-05:  31%|▎| 4249/13852 [15:50<35:25,  4.52it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 3.47e-05:  31%|▎| 4250/13852 [15:50<35:24,  4.52it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 3.47e-05:  31%|▎| 4251/13852 [15:50<35:25,  4.52it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 3.47e-05:  31%|▎| 4252/13852 [15:50<35:15,  4.54it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 3.47e-05:  31%|▎| 4253/13852 [15:51<35:05,  4.56it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.46e-05:  31%|▎| 4254/13852 [15:51<35:22,  4.52it/s\u001b[A\n",
      "Training loss: 7.88e-02 lr: 3.46e-05:  31%|▎| 4255/13852 [15:51<35:25,  4.52it/s\u001b[A\n",
      "Training loss: 9.78e-02 lr: 3.46e-05:  31%|▎| 4256/13852 [15:51<35:22,  4.52it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.46e-05:  31%|▎| 4257/13852 [15:51<35:21,  4.52it/s\u001b[A\n",
      "Training loss: 7.77e-02 lr: 3.46e-05:  31%|▎| 4258/13852 [15:52<35:34,  4.49it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.73e-02 lr: 3.46e-05:  31%|▎| 4259/13852 [15:52<35:31,  4.50it/s\u001b[A\n",
      "Training loss: 7.77e-02 lr: 3.46e-05:  31%|▎| 4260/13852 [15:52<35:29,  4.50it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.46e-05:  31%|▎| 4261/13852 [15:52<35:24,  4.51it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 3.46e-05:  31%|▎| 4262/13852 [15:53<35:24,  4.51it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.46e-05:  31%|▎| 4263/13852 [15:53<35:22,  4.52it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 3.46e-05:  31%|▎| 4264/13852 [15:53<35:17,  4.53it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.46e-05:  31%|▎| 4265/13852 [15:53<35:10,  4.54it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.46e-05:  31%|▎| 4266/13852 [15:53<35:03,  4.56it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.46e-05:  31%|▎| 4267/13852 [15:54<35:02,  4.56it/s\u001b[A\n",
      "Training loss: 8.20e-02 lr: 3.46e-05:  31%|▎| 4268/13852 [15:54<35:03,  4.56it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 3.46e-05:  31%|▎| 4269/13852 [15:54<35:09,  4.54it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 3.46e-05:  31%|▎| 4270/13852 [15:54<35:08,  4.54it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 3.46e-05:  31%|▎| 4271/13852 [15:55<35:07,  4.55it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.46e-05:  31%|▎| 4272/13852 [15:55<35:13,  4.53it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 3.46e-05:  31%|▎| 4273/13852 [15:55<35:09,  4.54it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 3.46e-05:  31%|▎| 4274/13852 [15:55<35:25,  4.51it/s\u001b[A\n",
      "Training loss: 8.07e-02 lr: 3.46e-05:  31%|▎| 4275/13852 [15:55<35:23,  4.51it/s\u001b[A\n",
      "Training loss: 9.48e-02 lr: 3.46e-05:  31%|▎| 4276/13852 [15:56<35:22,  4.51it/s\u001b[A\n",
      "Training loss: 8.13e-02 lr: 3.46e-05:  31%|▎| 4277/13852 [15:56<35:12,  4.53it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 3.46e-05:  31%|▎| 4278/13852 [15:56<35:06,  4.55it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 3.46e-05:  31%|▎| 4279/13852 [15:56<34:57,  4.56it/s\u001b[A\n",
      "Training loss: 7.81e-02 lr: 3.46e-05:  31%|▎| 4280/13852 [15:57<35:14,  4.53it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.45e-05:  31%|▎| 4281/13852 [15:57<35:23,  4.51it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 3.45e-05:  31%|▎| 4282/13852 [15:57<35:39,  4.47it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 3.45e-05:  31%|▎| 4283/13852 [15:57<35:37,  4.48it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 3.45e-05:  31%|▎| 4284/13852 [15:57<35:32,  4.49it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 3.45e-05:  31%|▎| 4285/13852 [15:58<35:27,  4.50it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.45e-05:  31%|▎| 4286/13852 [15:58<35:24,  4.50it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 3.45e-05:  31%|▎| 4287/13852 [15:58<35:25,  4.50it/s\u001b[A\n",
      "Training loss: 8.20e-02 lr: 3.45e-05:  31%|▎| 4288/13852 [15:58<35:21,  4.51it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 3.45e-05:  31%|▎| 4289/13852 [15:59<35:11,  4.53it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 3.45e-05:  31%|▎| 4290/13852 [15:59<35:00,  4.55it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 3.45e-05:  31%|▎| 4291/13852 [15:59<34:51,  4.57it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 3.45e-05:  31%|▎| 4292/13852 [15:59<34:46,  4.58it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 3.45e-05:  31%|▎| 4293/13852 [15:59<34:56,  4.56it/s\u001b[A\n",
      "Training loss: 8.98e-02 lr: 3.45e-05:  31%|▎| 4294/13852 [16:00<34:59,  4.55it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 3.45e-05:  31%|▎| 4295/13852 [16:00<35:03,  4.54it/s\u001b[A\n",
      "Training loss: 1.57e-01 lr: 3.45e-05:  31%|▎| 4296/13852 [16:00<35:06,  4.54it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.45e-05:  31%|▎| 4297/13852 [16:00<35:07,  4.53it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.45e-05:  31%|▎| 4298/13852 [16:01<35:09,  4.53it/s\u001b[A\n",
      "Training loss: 8.26e-02 lr: 3.45e-05:  31%|▎| 4299/13852 [16:01<35:19,  4.51it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 3.45e-05:  31%|▎| 4300/13852 [16:01<35:27,  4.49it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.45e-05:  31%|▎| 4301/13852 [16:01<35:23,  4.50it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.45e-05:  31%|▎| 4302/13852 [16:01<35:27,  4.49it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.45e-05:  31%|▎| 4303/13852 [16:02<35:13,  4.52it/s\u001b[A\n",
      "Training loss: 8.17e-02 lr: 3.45e-05:  31%|▎| 4304/13852 [16:02<35:03,  4.54it/s\u001b[A\n",
      "Training loss: 8.55e-02 lr: 3.45e-05:  31%|▎| 4305/13852 [16:02<35:12,  4.52it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 3.45e-05:  31%|▎| 4306/13852 [16:02<35:11,  4.52it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 3.45e-05:  31%|▎| 4307/13852 [16:03<35:06,  4.53it/s\u001b[A\n",
      "Training loss: 4.38e-02 lr: 3.45e-05:  31%|▎| 4308/13852 [16:03<35:03,  4.54it/s\u001b[A\n",
      "Training loss: 4.60e-02 lr: 3.44e-05:  31%|▎| 4309/13852 [16:03<35:07,  4.53it/s\u001b[A\n",
      "Training loss: 8.57e-02 lr: 3.44e-05:  31%|▎| 4310/13852 [16:03<35:16,  4.51it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 3.44e-05:  31%|▎| 4311/13852 [16:03<35:21,  4.50it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 3.44e-05:  31%|▎| 4312/13852 [16:04<35:15,  4.51it/s\u001b[A\n",
      "Training loss: 8.12e-02 lr: 3.44e-05:  31%|▎| 4313/13852 [16:04<35:14,  4.51it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 3.44e-05:  31%|▎| 4314/13852 [16:04<35:10,  4.52it/s\u001b[A\n",
      "Training loss: 5.32e-02 lr: 3.44e-05:  31%|▎| 4315/13852 [16:04<35:00,  4.54it/s\u001b[A\n",
      "Training loss: 8.45e-02 lr: 3.44e-05:  31%|▎| 4316/13852 [16:04<34:52,  4.56it/s\u001b[A\n",
      "Training loss: 8.99e-02 lr: 3.44e-05:  31%|▎| 4317/13852 [16:05<35:09,  4.52it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 3.44e-05:  31%|▎| 4318/13852 [16:05<35:06,  4.52it/s\u001b[A\n",
      "Training loss: 9.49e-02 lr: 3.44e-05:  31%|▎| 4319/13852 [16:05<35:06,  4.52it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.44e-05:  31%|▎| 4320/13852 [16:05<35:13,  4.51it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.44e-05:  31%|▎| 4321/13852 [16:06<35:14,  4.51it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.44e-05:  31%|▎| 4322/13852 [16:06<35:12,  4.51it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 3.44e-05:  31%|▎| 4323/13852 [16:06<35:09,  4.52it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 3.44e-05:  31%|▎| 4324/13852 [16:06<35:09,  4.52it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 3.44e-05:  31%|▎| 4325/13852 [16:06<35:08,  4.52it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 3.44e-05:  31%|▎| 4326/13852 [16:07<35:11,  4.51it/s\u001b[A\n",
      "Training loss: 9.24e-02 lr: 3.44e-05:  31%|▎| 4327/13852 [16:07<35:18,  4.50it/s\u001b[A\n",
      "Training loss: 7.33e-02 lr: 3.44e-05:  31%|▎| 4328/13852 [16:07<35:15,  4.50it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 3.44e-05:  31%|▎| 4329/13852 [16:07<35:10,  4.51it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 3.44e-05:  31%|▎| 4330/13852 [16:08<35:12,  4.51it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 3.44e-05:  31%|▎| 4331/13852 [16:08<35:12,  4.51it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 3.44e-05:  31%|▎| 4332/13852 [16:08<35:09,  4.51it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.44e-05:  31%|▎| 4333/13852 [16:08<35:06,  4.52it/s\u001b[A\n",
      "Training loss: 8.92e-02 lr: 3.44e-05:  31%|▎| 4334/13852 [16:08<35:06,  4.52it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 3.44e-05:  31%|▎| 4335/13852 [16:09<35:04,  4.52it/s\u001b[A\n",
      "Training loss: 7.05e-02 lr: 3.44e-05:  31%|▎| 4336/13852 [16:09<35:03,  4.52it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 3.43e-05:  31%|▎| 4337/13852 [16:09<35:02,  4.53it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 3.43e-05:  31%|▎| 4338/13852 [16:09<35:00,  4.53it/s\u001b[A\n",
      "Training loss: 9.78e-02 lr: 3.43e-05:  31%|▎| 4339/13852 [16:10<34:56,  4.54it/s\u001b[A\n",
      "Training loss: 9.75e-02 lr: 3.43e-05:  31%|▎| 4340/13852 [16:10<34:51,  4.55it/s\u001b[A\n",
      "Training loss: 8.21e-02 lr: 3.43e-05:  31%|▎| 4341/13852 [16:10<34:44,  4.56it/s\u001b[A\n",
      "Training loss: 7.13e-02 lr: 3.43e-05:  31%|▎| 4342/13852 [16:10<34:44,  4.56it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 3.43e-05:  31%|▎| 4343/13852 [16:10<34:50,  4.55it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 3.43e-05:  31%|▎| 4344/13852 [16:11<34:52,  4.54it/s\u001b[A\n",
      "Training loss: 4.05e-02 lr: 3.43e-05:  31%|▎| 4345/13852 [16:11<35:07,  4.51it/s\u001b[A\n",
      "Training loss: 5.28e-02 lr: 3.43e-05:  31%|▎| 4346/13852 [16:11<35:05,  4.52it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 3.43e-05:  31%|▎| 4347/13852 [16:11<35:06,  4.51it/s\u001b[A\n",
      "Training loss: 7.61e-02 lr: 3.43e-05:  31%|▎| 4348/13852 [16:12<35:01,  4.52it/s\u001b[A\n",
      "Training loss: 6.56e-02 lr: 3.43e-05:  31%|▎| 4349/13852 [16:12<35:09,  4.51it/s\u001b[A\n",
      "Training loss: 7.24e-02 lr: 3.43e-05:  31%|▎| 4350/13852 [16:12<35:06,  4.51it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 3.43e-05:  31%|▎| 4351/13852 [16:12<35:07,  4.51it/s\u001b[A\n",
      "Training loss: 3.95e-02 lr: 3.43e-05:  31%|▎| 4352/13852 [16:12<34:56,  4.53it/s\u001b[A\n",
      "Training loss: 2.90e-02 lr: 3.43e-05:  31%|▎| 4353/13852 [16:13<34:42,  4.56it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 3.43e-05:  31%|▎| 4354/13852 [16:13<34:34,  4.58it/s\u001b[A\n",
      "Training loss: 8.31e-02 lr: 3.43e-05:  31%|▎| 4355/13852 [16:13<35:02,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.06e-01 lr: 3.43e-05:  31%|▎| 4356/13852 [16:13<35:00,  4.52it/s\u001b[A\n",
      "Training loss: 9.07e-02 lr: 3.43e-05:  31%|▎| 4357/13852 [16:14<34:56,  4.53it/s\u001b[A\n",
      "Training loss: 1.60e-01 lr: 3.43e-05:  31%|▎| 4358/13852 [16:14<34:53,  4.54it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.43e-05:  31%|▎| 4359/13852 [16:14<34:49,  4.54it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.43e-05:  31%|▎| 4360/13852 [16:14<34:52,  4.54it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.43e-05:  31%|▎| 4361/13852 [16:14<34:56,  4.53it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.43e-05:  31%|▎| 4362/13852 [16:15<34:58,  4.52it/s\u001b[A\n",
      "Training loss: 8.66e-02 lr: 3.43e-05:  31%|▎| 4363/13852 [16:15<34:58,  4.52it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 3.43e-05:  32%|▎| 4364/13852 [16:15<35:01,  4.52it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 3.42e-05:  32%|▎| 4365/13852 [16:15<35:02,  4.51it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 3.42e-05:  32%|▎| 4366/13852 [16:16<34:54,  4.53it/s\u001b[A\n",
      "Training loss: 9.95e-02 lr: 3.42e-05:  32%|▎| 4367/13852 [16:16<34:44,  4.55it/s\u001b[A\n",
      "Training loss: 8.64e-02 lr: 3.42e-05:  32%|▎| 4368/13852 [16:16<34:43,  4.55it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 3.42e-05:  32%|▎| 4369/13852 [16:16<34:42,  4.55it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 3.42e-05:  32%|▎| 4370/13852 [16:16<34:43,  4.55it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.42e-05:  32%|▎| 4371/13852 [16:17<34:48,  4.54it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.42e-05:  32%|▎| 4372/13852 [16:17<35:02,  4.51it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 3.42e-05:  32%|▎| 4373/13852 [16:17<35:22,  4.47it/s\u001b[A\n",
      "Training loss: 8.17e-02 lr: 3.42e-05:  32%|▎| 4374/13852 [16:17<35:17,  4.48it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.42e-05:  32%|▎| 4375/13852 [16:18<35:14,  4.48it/s\u001b[A\n",
      "Training loss: 8.62e-02 lr: 3.42e-05:  32%|▎| 4376/13852 [16:18<35:14,  4.48it/s\u001b[A\n",
      "Training loss: 7.29e-02 lr: 3.42e-05:  32%|▎| 4377/13852 [16:18<35:27,  4.45it/s\u001b[A\n",
      "Training loss: 9.06e-02 lr: 3.42e-05:  32%|▎| 4378/13852 [16:18<35:08,  4.49it/s\u001b[A\n",
      "Training loss: 6.75e-02 lr: 3.42e-05:  32%|▎| 4379/13852 [16:18<34:51,  4.53it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 3.42e-05:  32%|▎| 4380/13852 [16:19<34:58,  4.51it/s\u001b[A\n",
      "Training loss: 4.36e-02 lr: 3.42e-05:  32%|▎| 4381/13852 [16:19<34:55,  4.52it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 3.42e-05:  32%|▎| 4382/13852 [16:19<34:52,  4.53it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 3.42e-05:  32%|▎| 4383/13852 [16:19<34:45,  4.54it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 3.42e-05:  32%|▎| 4384/13852 [16:20<34:47,  4.53it/s\u001b[A\n",
      "Training loss: 3.46e-02 lr: 3.42e-05:  32%|▎| 4385/13852 [16:20<34:53,  4.52it/s\u001b[A\n",
      "Training loss: 2.63e-02 lr: 3.42e-05:  32%|▎| 4386/13852 [16:20<34:55,  4.52it/s\u001b[A\n",
      "Training loss: 2.05e-02 lr: 3.42e-05:  32%|▎| 4387/13852 [16:20<34:55,  4.52it/s\u001b[A\n",
      "Training loss: 2.51e-02 lr: 3.42e-05:  32%|▎| 4388/13852 [16:20<34:53,  4.52it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 3.42e-05:  32%|▎| 4389/13852 [16:21<34:51,  4.52it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.42e-05:  32%|▎| 4390/13852 [16:21<35:01,  4.50it/s\u001b[A\n",
      "Training loss: 9.06e-02 lr: 3.42e-05:  32%|▎| 4391/13852 [16:21<34:47,  4.53it/s\u001b[A\n",
      "Training loss: 8.52e-02 lr: 3.41e-05:  32%|▎| 4392/13852 [16:21<35:05,  4.49it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 3.41e-05:  32%|▎| 4393/13852 [16:22<34:58,  4.51it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 3.41e-05:  32%|▎| 4394/13852 [16:22<35:10,  4.48it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 3.41e-05:  32%|▎| 4395/13852 [16:22<35:09,  4.48it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 3.41e-05:  32%|▎| 4396/13852 [16:22<35:18,  4.46it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 3.41e-05:  32%|▎| 4397/13852 [16:22<35:10,  4.48it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 3.41e-05:  32%|▎| 4398/13852 [16:23<35:08,  4.48it/s\u001b[A\n",
      "Training loss: 5.43e-02 lr: 3.41e-05:  32%|▎| 4399/13852 [16:23<35:05,  4.49it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 3.41e-05:  32%|▎| 4400/13852 [16:23<35:03,  4.49it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 3.41e-05:  32%|▎| 4401/13852 [16:23<35:14,  4.47it/s\u001b[A\n",
      "Training loss: 3.73e-02 lr: 3.41e-05:  32%|▎| 4402/13852 [16:24<34:57,  4.51it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 3.41e-05:  32%|▎| 4403/13852 [16:24<34:44,  4.53it/s\u001b[A\n",
      "Training loss: 3.01e-02 lr: 3.41e-05:  32%|▎| 4404/13852 [16:24<34:49,  4.52it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 3.41e-05:  32%|▎| 4405/13852 [16:24<34:46,  4.53it/s\u001b[A\n",
      "Training loss: 3.46e-02 lr: 3.41e-05:  32%|▎| 4406/13852 [16:24<34:44,  4.53it/s\u001b[A\n",
      "Training loss: 2.82e-02 lr: 3.41e-05:  32%|▎| 4407/13852 [16:25<34:42,  4.54it/s\u001b[A\n",
      "Training loss: 8.66e-02 lr: 3.41e-05:  32%|▎| 4408/13852 [16:25<34:46,  4.53it/s\u001b[A\n",
      "Training loss: 6.19e-02 lr: 3.41e-05:  32%|▎| 4409/13852 [16:25<34:44,  4.53it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 3.41e-05:  32%|▎| 4410/13852 [16:25<34:48,  4.52it/s\u001b[A\n",
      "Training loss: 3.90e-02 lr: 3.41e-05:  32%|▎| 4411/13852 [16:26<34:47,  4.52it/s\u001b[A\n",
      "Training loss: 3.68e-02 lr: 3.41e-05:  32%|▎| 4412/13852 [16:26<34:45,  4.53it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 3.41e-05:  32%|▎| 4413/13852 [16:26<34:46,  4.52it/s\u001b[A\n",
      "Training loss: 7.87e-02 lr: 3.41e-05:  32%|▎| 4414/13852 [16:26<34:37,  4.54it/s\u001b[A\n",
      "Training loss: 6.30e-02 lr: 3.41e-05:  32%|▎| 4415/13852 [16:26<34:28,  4.56it/s\u001b[A\n",
      "Training loss: 7.68e-02 lr: 3.41e-05:  32%|▎| 4416/13852 [16:27<34:20,  4.58it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 3.41e-05:  32%|▎| 4417/13852 [16:27<34:59,  4.49it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 3.41e-05:  32%|▎| 4418/13852 [16:27<34:57,  4.50it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 3.41e-05:  32%|▎| 4419/13852 [16:27<34:53,  4.51it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 3.40e-05:  32%|▎| 4420/13852 [16:28<34:50,  4.51it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 3.40e-05:  32%|▎| 4421/13852 [16:28<34:53,  4.50it/s\u001b[A\n",
      "Training loss: 7.76e-02 lr: 3.40e-05:  32%|▎| 4422/13852 [16:28<34:50,  4.51it/s\u001b[A\n",
      "Training loss: 9.46e-02 lr: 3.40e-05:  32%|▎| 4423/13852 [16:28<34:48,  4.52it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 3.40e-05:  32%|▎| 4424/13852 [16:28<34:46,  4.52it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 3.40e-05:  32%|▎| 4425/13852 [16:29<34:48,  4.51it/s\u001b[A\n",
      "Training loss: 3.99e-02 lr: 3.40e-05:  32%|▎| 4426/13852 [16:29<34:48,  4.51it/s\u001b[A\n",
      "Training loss: 2.90e-02 lr: 3.40e-05:  32%|▎| 4427/13852 [16:29<34:39,  4.53it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 3.40e-05:  32%|▎| 4428/13852 [16:29<34:30,  4.55it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 3.40e-05:  32%|▎| 4429/13852 [16:29<34:21,  4.57it/s\u001b[A\n",
      "Training loss: 9.54e-02 lr: 3.40e-05:  32%|▎| 4430/13852 [16:30<34:29,  4.55it/s\u001b[A\n",
      "Training loss: 7.20e-02 lr: 3.40e-05:  32%|▎| 4431/13852 [16:30<34:32,  4.55it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 3.40e-05:  32%|▎| 4432/13852 [16:30<34:32,  4.55it/s\u001b[A\n",
      "Training loss: 9.68e-02 lr: 3.40e-05:  32%|▎| 4433/13852 [16:30<34:31,  4.55it/s\u001b[A\n",
      "Training loss: 1.69e-01 lr: 3.40e-05:  32%|▎| 4434/13852 [16:31<34:33,  4.54it/s\u001b[A\n",
      "Training loss: 1.48e-01 lr: 3.40e-05:  32%|▎| 4435/13852 [16:31<34:49,  4.51it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.40e-05:  32%|▎| 4436/13852 [16:31<34:48,  4.51it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.40e-05:  32%|▎| 4437/13852 [16:31<34:51,  4.50it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.40e-05:  32%|▎| 4438/13852 [16:31<34:53,  4.50it/s\u001b[A\n",
      "Training loss: 9.75e-02 lr: 3.40e-05:  32%|▎| 4439/13852 [16:32<34:55,  4.49it/s\u001b[A\n",
      "Training loss: 8.81e-02 lr: 3.40e-05:  32%|▎| 4440/13852 [16:32<34:43,  4.52it/s\u001b[A\n",
      "Training loss: 8.89e-02 lr: 3.40e-05:  32%|▎| 4441/13852 [16:32<34:32,  4.54it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 3.40e-05:  32%|▎| 4442/13852 [16:32<34:42,  4.52it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 3.40e-05:  32%|▎| 4443/13852 [16:33<34:41,  4.52it/s\u001b[A\n",
      "Training loss: 1.58e-01 lr: 3.40e-05:  32%|▎| 4444/13852 [16:33<34:40,  4.52it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 3.40e-05:  32%|▎| 4445/13852 [16:33<34:49,  4.50it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.40e-05:  32%|▎| 4446/13852 [16:33<34:46,  4.51it/s\u001b[A\n",
      "Training loss: 8.92e-02 lr: 3.40e-05:  32%|▎| 4447/13852 [16:33<34:45,  4.51it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 3.39e-05:  32%|▎| 4448/13852 [16:34<34:41,  4.52it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 3.39e-05:  32%|▎| 4449/13852 [16:34<34:37,  4.53it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 3.39e-05:  32%|▎| 4450/13852 [16:34<34:37,  4.52it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 3.39e-05:  32%|▎| 4451/13852 [16:34<34:33,  4.53it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 3.39e-05:  32%|▎| 4452/13852 [16:35<34:25,  4.55it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.31e-02 lr: 3.39e-05:  32%|▎| 4453/13852 [16:35<34:18,  4.56it/s\u001b[A\n",
      "Training loss: 8.79e-02 lr: 3.39e-05:  32%|▎| 4454/13852 [16:35<34:12,  4.58it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 3.39e-05:  32%|▎| 4455/13852 [16:35<34:09,  4.59it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.39e-05:  32%|▎| 4456/13852 [16:35<34:15,  4.57it/s\u001b[A\n",
      "Training loss: 9.32e-02 lr: 3.39e-05:  32%|▎| 4457/13852 [16:36<34:20,  4.56it/s\u001b[A\n",
      "Training loss: 8.60e-02 lr: 3.39e-05:  32%|▎| 4458/13852 [16:36<34:23,  4.55it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 3.39e-05:  32%|▎| 4459/13852 [16:36<34:23,  4.55it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 3.39e-05:  32%|▎| 4460/13852 [16:36<34:27,  4.54it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 3.39e-05:  32%|▎| 4461/13852 [16:37<34:28,  4.54it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 3.39e-05:  32%|▎| 4462/13852 [16:37<34:57,  4.48it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.39e-05:  32%|▎| 4463/13852 [16:37<35:12,  4.44it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 3.39e-05:  32%|▎| 4464/13852 [16:37<35:30,  4.41it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 3.39e-05:  32%|▎| 4465/13852 [16:37<35:15,  4.44it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 3.39e-05:  32%|▎| 4466/13852 [16:38<34:52,  4.48it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 3.39e-05:  32%|▎| 4467/13852 [16:38<34:48,  4.49it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 3.39e-05:  32%|▎| 4468/13852 [16:38<34:41,  4.51it/s\u001b[A\n",
      "Training loss: 4.80e-02 lr: 3.39e-05:  32%|▎| 4469/13852 [16:38<34:36,  4.52it/s\u001b[A\n",
      "Training loss: 6.10e-02 lr: 3.39e-05:  32%|▎| 4470/13852 [16:39<34:30,  4.53it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 3.39e-05:  32%|▎| 4471/13852 [16:39<34:30,  4.53it/s\u001b[A\n",
      "Training loss: 9.43e-02 lr: 3.39e-05:  32%|▎| 4472/13852 [16:39<34:31,  4.53it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.39e-05:  32%|▎| 4473/13852 [16:39<34:31,  4.53it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.39e-05:  32%|▎| 4474/13852 [16:39<34:32,  4.52it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.38e-05:  32%|▎| 4475/13852 [16:40<34:35,  4.52it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 3.38e-05:  32%|▎| 4476/13852 [16:40<34:35,  4.52it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 3.38e-05:  32%|▎| 4477/13852 [16:40<34:29,  4.53it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.38e-05:  32%|▎| 4478/13852 [16:40<34:20,  4.55it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.38e-05:  32%|▎| 4479/13852 [16:41<34:38,  4.51it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 3.38e-05:  32%|▎| 4480/13852 [16:41<34:42,  4.50it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.38e-05:  32%|▎| 4481/13852 [16:41<34:43,  4.50it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 3.38e-05:  32%|▎| 4482/13852 [16:41<34:38,  4.51it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 3.38e-05:  32%|▎| 4483/13852 [16:41<34:36,  4.51it/s\u001b[A\n",
      "Training loss: 4.90e-02 lr: 3.38e-05:  32%|▎| 4484/13852 [16:42<34:47,  4.49it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 3.38e-05:  32%|▎| 4485/13852 [16:42<34:44,  4.49it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 3.38e-05:  32%|▎| 4486/13852 [16:42<34:45,  4.49it/s\u001b[A\n",
      "Training loss: 3.60e-02 lr: 3.38e-05:  32%|▎| 4487/13852 [16:42<34:44,  4.49it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 3.38e-05:  32%|▎| 4488/13852 [16:43<34:41,  4.50it/s\u001b[A\n",
      "Training loss: 5.45e-02 lr: 3.38e-05:  32%|▎| 4489/13852 [16:43<34:29,  4.52it/s\u001b[A\n",
      "Training loss: 4.79e-02 lr: 3.38e-05:  32%|▎| 4490/13852 [16:43<34:17,  4.55it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 3.38e-05:  32%|▎| 4491/13852 [16:43<34:09,  4.57it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 3.38e-05:  32%|▎| 4492/13852 [16:43<34:20,  4.54it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 3.38e-05:  32%|▎| 4493/13852 [16:44<34:23,  4.54it/s\u001b[A\n",
      "Training loss: 6.30e-02 lr: 3.38e-05:  32%|▎| 4494/13852 [16:44<34:26,  4.53it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 3.38e-05:  32%|▎| 4495/13852 [16:44<34:28,  4.52it/s\u001b[A\n",
      "Training loss: 6.57e-02 lr: 3.38e-05:  32%|▎| 4496/13852 [16:44<34:29,  4.52it/s\u001b[A\n",
      "Training loss: 6.38e-02 lr: 3.38e-05:  32%|▎| 4497/13852 [16:45<34:27,  4.52it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 3.38e-05:  32%|▎| 4498/13852 [16:45<34:26,  4.53it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 3.38e-05:  32%|▎| 4499/13852 [16:45<34:27,  4.52it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 3.38e-05:  32%|▎| 4500/13852 [16:45<34:28,  4.52it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 3.38e-05:  32%|▎| 4501/13852 [16:45<34:28,  4.52it/s\u001b[A\n",
      "Training loss: 3.00e-02 lr: 3.38e-05:  33%|▎| 4502/13852 [16:46<34:30,  4.52it/s\u001b[A\n",
      "Training loss: 2.65e-02 lr: 3.37e-05:  33%|▎| 4503/13852 [16:46<34:19,  4.54it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 3.37e-05:  33%|▎| 4504/13852 [16:46<34:41,  4.49it/s\u001b[A\n",
      "Training loss: 3.36e-02 lr: 3.37e-05:  33%|▎| 4505/13852 [16:46<34:43,  4.49it/s\u001b[A\n",
      "Training loss: 6.70e-02 lr: 3.37e-05:  33%|▎| 4506/13852 [16:47<34:37,  4.50it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 3.37e-05:  33%|▎| 4507/13852 [16:47<34:53,  4.46it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 3.37e-05:  33%|▎| 4508/13852 [16:47<34:50,  4.47it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 3.37e-05:  33%|▎| 4509/13852 [16:47<34:48,  4.47it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 3.37e-05:  33%|▎| 4510/13852 [16:47<34:51,  4.47it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 3.37e-05:  33%|▎| 4511/13852 [16:48<34:46,  4.48it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 3.37e-05:  33%|▎| 4512/13852 [16:48<34:34,  4.50it/s\u001b[A\n",
      "Training loss: 6.52e-02 lr: 3.37e-05:  33%|▎| 4513/13852 [16:48<35:22,  4.40it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 3.37e-05:  33%|▎| 4514/13852 [16:48<34:57,  4.45it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 3.37e-05:  33%|▎| 4515/13852 [16:49<34:54,  4.46it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.37e-05:  33%|▎| 4516/13852 [16:49<34:43,  4.48it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.37e-05:  33%|▎| 4517/13852 [16:49<34:35,  4.50it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 3.37e-05:  33%|▎| 4518/13852 [16:49<34:37,  4.49it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.37e-05:  33%|▎| 4519/13852 [16:49<34:34,  4.50it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 3.37e-05:  33%|▎| 4520/13852 [16:50<34:29,  4.51it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 3.37e-05:  33%|▎| 4521/13852 [16:50<34:27,  4.51it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 3.37e-05:  33%|▎| 4522/13852 [16:50<34:32,  4.50it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 3.37e-05:  33%|▎| 4523/13852 [16:50<34:30,  4.51it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 3.37e-05:  33%|▎| 4524/13852 [16:51<34:21,  4.52it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 3.37e-05:  33%|▎| 4525/13852 [16:51<34:23,  4.52it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 3.37e-05:  33%|▎| 4526/13852 [16:51<34:20,  4.53it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 3.37e-05:  33%|▎| 4527/13852 [16:51<34:28,  4.51it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 3.37e-05:  33%|▎| 4528/13852 [16:51<34:25,  4.51it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 3.37e-05:  33%|▎| 4529/13852 [16:52<34:31,  4.50it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 3.37e-05:  33%|▎| 4530/13852 [16:52<34:31,  4.50it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 3.36e-05:  33%|▎| 4531/13852 [16:52<34:30,  4.50it/s\u001b[A\n",
      "Training loss: 6.46e-02 lr: 3.36e-05:  33%|▎| 4532/13852 [16:52<34:28,  4.51it/s\u001b[A\n",
      "Training loss: 4.86e-02 lr: 3.36e-05:  33%|▎| 4533/13852 [16:53<34:27,  4.51it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 3.36e-05:  33%|▎| 4534/13852 [16:53<34:28,  4.51it/s\u001b[A\n",
      "Training loss: 2.97e-02 lr: 3.36e-05:  33%|▎| 4535/13852 [16:53<34:29,  4.50it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 3.36e-05:  33%|▎| 4536/13852 [16:53<34:20,  4.52it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 3.36e-05:  33%|▎| 4537/13852 [16:53<34:08,  4.55it/s\u001b[A\n",
      "Training loss: 4.36e-02 lr: 3.36e-05:  33%|▎| 4538/13852 [16:54<34:01,  4.56it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 3.36e-05:  33%|▎| 4539/13852 [16:54<34:22,  4.52it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 3.36e-05:  33%|▎| 4540/13852 [16:54<34:22,  4.51it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 3.36e-05:  33%|▎| 4541/13852 [16:54<34:24,  4.51it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.36e-05:  33%|▎| 4542/13852 [16:55<34:21,  4.52it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 3.36e-05:  33%|▎| 4543/13852 [16:55<34:23,  4.51it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.36e-05:  33%|▎| 4544/13852 [16:55<34:26,  4.50it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 3.36e-05:  33%|▎| 4545/13852 [16:55<34:26,  4.50it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 3.36e-05:  33%|▎| 4546/13852 [16:55<34:25,  4.51it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 3.36e-05:  33%|▎| 4547/13852 [16:56<34:24,  4.51it/s\u001b[A\n",
      "Training loss: 7.17e-02 lr: 3.36e-05:  33%|▎| 4548/13852 [16:56<34:16,  4.52it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 3.36e-05:  33%|▎| 4549/13852 [16:56<34:13,  4.53it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.21e-02 lr: 3.36e-05:  33%|▎| 4550/13852 [16:56<34:04,  4.55it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 3.36e-05:  33%|▎| 4551/13852 [16:57<33:57,  4.57it/s\u001b[A\n",
      "Training loss: 7.17e-02 lr: 3.36e-05:  33%|▎| 4552/13852 [16:57<34:23,  4.51it/s\u001b[A\n",
      "Training loss: 6.17e-02 lr: 3.36e-05:  33%|▎| 4553/13852 [16:57<34:21,  4.51it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 3.36e-05:  33%|▎| 4554/13852 [16:57<34:22,  4.51it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 3.36e-05:  33%|▎| 4555/13852 [16:57<34:37,  4.48it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 3.36e-05:  33%|▎| 4556/13852 [16:58<34:33,  4.48it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 3.36e-05:  33%|▎| 4557/13852 [16:58<34:41,  4.47it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 3.35e-05:  33%|▎| 4558/13852 [16:58<34:44,  4.46it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 3.35e-05:  33%|▎| 4559/13852 [16:58<34:42,  4.46it/s\u001b[A\n",
      "Training loss: 2.53e-02 lr: 3.35e-05:  33%|▎| 4560/13852 [16:59<34:38,  4.47it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 3.35e-05:  33%|▎| 4561/13852 [16:59<34:22,  4.50it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 3.35e-05:  33%|▎| 4562/13852 [16:59<34:11,  4.53it/s\u001b[A\n",
      "Training loss: 3.20e-02 lr: 3.35e-05:  33%|▎| 4563/13852 [16:59<34:20,  4.51it/s\u001b[A\n",
      "Training loss: 3.47e-02 lr: 3.35e-05:  33%|▎| 4564/13852 [16:59<34:18,  4.51it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 3.35e-05:  33%|▎| 4565/13852 [17:00<34:21,  4.50it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 3.35e-05:  33%|▎| 4566/13852 [17:00<34:19,  4.51it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 3.35e-05:  33%|▎| 4567/13852 [17:00<34:20,  4.51it/s\u001b[A\n",
      "Training loss: 7.92e-02 lr: 3.35e-05:  33%|▎| 4568/13852 [17:00<34:31,  4.48it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 3.35e-05:  33%|▎| 4569/13852 [17:01<34:27,  4.49it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.35e-05:  33%|▎| 4570/13852 [17:01<34:30,  4.48it/s\u001b[A\n",
      "Training loss: 1.59e-01 lr: 3.35e-05:  33%|▎| 4571/13852 [17:01<34:35,  4.47it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.35e-05:  33%|▎| 4572/13852 [17:01<34:23,  4.50it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.35e-05:  33%|▎| 4573/13852 [17:01<34:09,  4.53it/s\u001b[A\n",
      "Training loss: 8.95e-02 lr: 3.35e-05:  33%|▎| 4574/13852 [17:02<35:14,  4.39it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 3.35e-05:  33%|▎| 4575/13852 [17:02<34:58,  4.42it/s\u001b[A\n",
      "Training loss: 7.95e-02 lr: 3.35e-05:  33%|▎| 4576/13852 [17:02<34:51,  4.44it/s\u001b[A\n",
      "Training loss: 7.20e-02 lr: 3.35e-05:  33%|▎| 4577/13852 [17:02<36:00,  4.29it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 3.35e-05:  33%|▎| 4578/13852 [17:03<36:21,  4.25it/s\u001b[A\n",
      "Training loss: 8.02e-02 lr: 3.35e-05:  33%|▎| 4579/13852 [17:03<36:23,  4.25it/s\u001b[A\n",
      "Training loss: 9.26e-02 lr: 3.35e-05:  33%|▎| 4580/13852 [17:03<35:50,  4.31it/s\u001b[A\n",
      "Training loss: 6.99e-02 lr: 3.35e-05:  33%|▎| 4581/13852 [17:03<35:11,  4.39it/s\u001b[A\n",
      "Training loss: 7.11e-02 lr: 3.35e-05:  33%|▎| 4582/13852 [17:04<35:00,  4.41it/s\u001b[A\n",
      "Training loss: 5.32e-02 lr: 3.35e-05:  33%|▎| 4583/13852 [17:04<34:56,  4.42it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 3.35e-05:  33%|▎| 4584/13852 [17:04<34:46,  4.44it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 3.35e-05:  33%|▎| 4585/13852 [17:04<34:39,  4.46it/s\u001b[A\n",
      "Training loss: 8.10e-02 lr: 3.34e-05:  33%|▎| 4586/13852 [17:04<34:35,  4.46it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 3.34e-05:  33%|▎| 4587/13852 [17:05<34:37,  4.46it/s\u001b[A\n",
      "Training loss: 9.93e-02 lr: 3.34e-05:  33%|▎| 4588/13852 [17:05<34:43,  4.45it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 3.34e-05:  33%|▎| 4589/13852 [17:05<34:35,  4.46it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.34e-05:  33%|▎| 4590/13852 [17:05<34:22,  4.49it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 3.34e-05:  33%|▎| 4591/13852 [17:06<34:08,  4.52it/s\u001b[A\n",
      "Training loss: 9.08e-02 lr: 3.34e-05:  33%|▎| 4592/13852 [17:06<34:00,  4.54it/s\u001b[A\n",
      "Training loss: 7.05e-02 lr: 3.34e-05:  33%|▎| 4593/13852 [17:06<34:21,  4.49it/s\u001b[A\n",
      "Training loss: 9.26e-02 lr: 3.34e-05:  33%|▎| 4594/13852 [17:06<34:24,  4.48it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 3.34e-05:  33%|▎| 4595/13852 [17:06<34:16,  4.50it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 3.34e-05:  33%|▎| 4596/13852 [17:07<34:15,  4.50it/s\u001b[A\n",
      "Training loss: 8.44e-02 lr: 3.34e-05:  33%|▎| 4597/13852 [17:07<34:38,  4.45it/s\u001b[A\n",
      "Training loss: 6.78e-02 lr: 3.34e-05:  33%|▎| 4598/13852 [17:07<34:53,  4.42it/s\u001b[A\n",
      "Training loss: 7.01e-02 lr: 3.34e-05:  33%|▎| 4599/13852 [17:07<34:59,  4.41it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 3.34e-05:  33%|▎| 4600/13852 [17:08<35:41,  4.32it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 3.34e-05:  33%|▎| 4601/13852 [17:08<35:06,  4.39it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 3.34e-05:  33%|▎| 4602/13852 [17:08<35:12,  4.38it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 3.34e-05:  33%|▎| 4603/13852 [17:08<34:47,  4.43it/s\u001b[A\n",
      "Training loss: 7.85e-02 lr: 3.34e-05:  33%|▎| 4604/13852 [17:08<34:36,  4.45it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 3.34e-05:  33%|▎| 4605/13852 [17:09<34:26,  4.47it/s\u001b[A\n",
      "Training loss: 6.88e-02 lr: 3.34e-05:  33%|▎| 4606/13852 [17:09<34:35,  4.46it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 3.34e-05:  33%|▎| 4607/13852 [17:09<34:29,  4.47it/s\u001b[A\n",
      "Training loss: 6.02e-02 lr: 3.34e-05:  33%|▎| 4608/13852 [17:09<34:25,  4.47it/s\u001b[A\n",
      "Training loss: 6.59e-02 lr: 3.34e-05:  33%|▎| 4609/13852 [17:10<34:20,  4.49it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 3.34e-05:  33%|▎| 4610/13852 [17:10<34:21,  4.48it/s\u001b[A\n",
      "Training loss: 8.81e-02 lr: 3.34e-05:  33%|▎| 4611/13852 [17:10<34:21,  4.48it/s\u001b[A\n",
      "Training loss: 9.21e-02 lr: 3.34e-05:  33%|▎| 4612/13852 [17:10<34:08,  4.51it/s\u001b[A\n",
      "Training loss: 8.62e-02 lr: 3.34e-05:  33%|▎| 4613/13852 [17:10<33:56,  4.54it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 3.33e-05:  33%|▎| 4614/13852 [17:11<33:46,  4.56it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.33e-05:  33%|▎| 4615/13852 [17:11<34:14,  4.50it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 3.33e-05:  33%|▎| 4616/13852 [17:11<34:12,  4.50it/s\u001b[A\n",
      "Training loss: 8.19e-02 lr: 3.33e-05:  33%|▎| 4617/13852 [17:11<34:10,  4.50it/s\u001b[A\n",
      "Training loss: 9.06e-02 lr: 3.33e-05:  33%|▎| 4618/13852 [17:12<34:18,  4.49it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 3.33e-05:  33%|▎| 4619/13852 [17:12<34:26,  4.47it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 3.33e-05:  33%|▎| 4620/13852 [17:12<34:21,  4.48it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 3.33e-05:  33%|▎| 4621/13852 [17:12<34:16,  4.49it/s\u001b[A\n",
      "Training loss: 5.57e-02 lr: 3.33e-05:  33%|▎| 4622/13852 [17:12<34:14,  4.49it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 3.33e-05:  33%|▎| 4623/13852 [17:13<34:06,  4.51it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 3.33e-05:  33%|▎| 4624/13852 [17:13<33:52,  4.54it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 3.33e-05:  33%|▎| 4625/13852 [17:13<33:44,  4.56it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 3.33e-05:  33%|▎| 4626/13852 [17:13<34:08,  4.50it/s\u001b[A\n",
      "Training loss: 9.65e-02 lr: 3.33e-05:  33%|▎| 4627/13852 [17:14<34:06,  4.51it/s\u001b[A\n",
      "Training loss: 7.26e-02 lr: 3.33e-05:  33%|▎| 4628/13852 [17:14<34:01,  4.52it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 3.33e-05:  33%|▎| 4629/13852 [17:14<34:03,  4.51it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.33e-05:  33%|▎| 4630/13852 [17:14<34:00,  4.52it/s\u001b[A\n",
      "Training loss: 9.26e-02 lr: 3.33e-05:  33%|▎| 4631/13852 [17:14<33:59,  4.52it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 3.33e-05:  33%|▎| 4632/13852 [17:15<34:00,  4.52it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 3.33e-05:  33%|▎| 4633/13852 [17:15<34:01,  4.52it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.33e-05:  33%|▎| 4634/13852 [17:15<34:10,  4.49it/s\u001b[A\n",
      "Training loss: 9.68e-02 lr: 3.33e-05:  33%|▎| 4635/13852 [17:15<34:00,  4.52it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.33e-05:  33%|▎| 4636/13852 [17:16<33:47,  4.54it/s\u001b[A\n",
      "Training loss: 8.21e-02 lr: 3.33e-05:  33%|▎| 4637/13852 [17:16<33:41,  4.56it/s\u001b[A\n",
      "Training loss: 8.73e-02 lr: 3.33e-05:  33%|▎| 4638/13852 [17:16<33:33,  4.58it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 3.33e-05:  33%|▎| 4639/13852 [17:16<33:26,  4.59it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 3.33e-05:  33%|▎| 4640/13852 [17:16<33:37,  4.57it/s\u001b[A\n",
      "Training loss: 6.96e-02 lr: 3.33e-05:  34%|▎| 4641/13852 [17:17<33:43,  4.55it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 3.32e-05:  34%|▎| 4642/13852 [17:17<34:00,  4.51it/s\u001b[A\n",
      "Training loss: 7.05e-02 lr: 3.32e-05:  34%|▎| 4643/13852 [17:17<34:01,  4.51it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 3.32e-05:  34%|▎| 4644/13852 [17:17<34:03,  4.51it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 3.32e-05:  34%|▎| 4645/13852 [17:18<34:19,  4.47it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 3.32e-05:  34%|▎| 4646/13852 [17:18<34:15,  4.48it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.75e-02 lr: 3.32e-05:  34%|▎| 4647/13852 [17:18<34:22,  4.46it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 3.32e-05:  34%|▎| 4648/13852 [17:18<34:15,  4.48it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 3.32e-05:  34%|▎| 4649/13852 [17:18<34:01,  4.51it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 3.32e-05:  34%|▎| 4650/13852 [17:19<33:49,  4.53it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 3.32e-05:  34%|▎| 4651/13852 [17:19<33:55,  4.52it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.32e-05:  34%|▎| 4652/13852 [17:19<33:53,  4.52it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.32e-05:  34%|▎| 4653/13852 [17:19<33:55,  4.52it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 3.32e-05:  34%|▎| 4654/13852 [17:20<33:55,  4.52it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 3.32e-05:  34%|▎| 4655/13852 [17:20<33:56,  4.52it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 3.32e-05:  34%|▎| 4656/13852 [17:20<34:01,  4.51it/s\u001b[A\n",
      "Training loss: 1.32e-01 lr: 3.32e-05:  34%|▎| 4657/13852 [17:20<34:00,  4.51it/s\u001b[A\n",
      "Training loss: 9.76e-02 lr: 3.32e-05:  34%|▎| 4658/13852 [17:20<33:59,  4.51it/s\u001b[A\n",
      "Training loss: 8.45e-02 lr: 3.32e-05:  34%|▎| 4659/13852 [17:21<34:01,  4.50it/s\u001b[A\n",
      "Training loss: 7.17e-02 lr: 3.32e-05:  34%|▎| 4660/13852 [17:21<34:17,  4.47it/s\u001b[A\n",
      "Training loss: 6.61e-02 lr: 3.32e-05:  34%|▎| 4661/13852 [17:21<34:02,  4.50it/s\u001b[A\n",
      "Training loss: 5.68e-02 lr: 3.32e-05:  34%|▎| 4662/13852 [17:21<33:50,  4.53it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 3.32e-05:  34%|▎| 4663/13852 [17:22<34:02,  4.50it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 3.32e-05:  34%|▎| 4664/13852 [17:22<34:12,  4.48it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 3.32e-05:  34%|▎| 4665/13852 [17:22<34:06,  4.49it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 3.32e-05:  34%|▎| 4666/13852 [17:22<34:07,  4.49it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 3.32e-05:  34%|▎| 4667/13852 [17:22<34:06,  4.49it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 3.32e-05:  34%|▎| 4668/13852 [17:23<34:04,  4.49it/s\u001b[A\n",
      "Training loss: 8.33e-02 lr: 3.31e-05:  34%|▎| 4669/13852 [17:23<34:08,  4.48it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 3.31e-05:  34%|▎| 4670/13852 [17:23<34:06,  4.49it/s\u001b[A\n",
      "Training loss: 9.48e-02 lr: 3.31e-05:  34%|▎| 4671/13852 [17:23<34:15,  4.47it/s\u001b[A\n",
      "Training loss: 7.42e-02 lr: 3.31e-05:  34%|▎| 4672/13852 [17:24<33:57,  4.50it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 3.31e-05:  34%|▎| 4673/13852 [17:24<33:45,  4.53it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.31e-05:  34%|▎| 4674/13852 [17:24<33:37,  4.55it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.31e-05:  34%|▎| 4675/13852 [17:24<33:31,  4.56it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.31e-05:  34%|▎| 4676/13852 [17:24<33:34,  4.56it/s\u001b[A\n",
      "Training loss: 9.86e-02 lr: 3.31e-05:  34%|▎| 4677/13852 [17:25<33:34,  4.55it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.31e-05:  34%|▎| 4678/13852 [17:25<33:41,  4.54it/s\u001b[A\n",
      "Training loss: 8.58e-02 lr: 3.31e-05:  34%|▎| 4679/13852 [17:25<33:43,  4.53it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 3.31e-05:  34%|▎| 4680/13852 [17:25<33:49,  4.52it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 3.31e-05:  34%|▎| 4681/13852 [17:26<33:50,  4.52it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 3.31e-05:  34%|▎| 4682/13852 [17:26<33:52,  4.51it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 3.31e-05:  34%|▎| 4683/13852 [17:26<33:53,  4.51it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 3.31e-05:  34%|▎| 4684/13852 [17:26<33:54,  4.51it/s\u001b[A\n",
      "Training loss: 1.37e-01 lr: 3.31e-05:  34%|▎| 4685/13852 [17:26<34:08,  4.48it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.31e-05:  34%|▎| 4686/13852 [17:27<33:52,  4.51it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.31e-05:  34%|▎| 4687/13852 [17:27<33:55,  4.50it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 3.31e-05:  34%|▎| 4688/13852 [17:27<33:51,  4.51it/s\u001b[A\n",
      "Training loss: 9.60e-02 lr: 3.31e-05:  34%|▎| 4689/13852 [17:27<33:54,  4.50it/s\u001b[A\n",
      "Training loss: 8.17e-02 lr: 3.31e-05:  34%|▎| 4690/13852 [17:28<33:55,  4.50it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 3.31e-05:  34%|▎| 4691/13852 [17:28<34:00,  4.49it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 3.31e-05:  34%|▎| 4692/13852 [17:28<34:01,  4.49it/s\u001b[A\n",
      "Training loss: 4.99e-02 lr: 3.31e-05:  34%|▎| 4693/13852 [17:28<33:59,  4.49it/s\u001b[A\n",
      "Training loss: 7.87e-02 lr: 3.31e-05:  34%|▎| 4694/13852 [17:28<34:11,  4.46it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 3.31e-05:  34%|▎| 4695/13852 [17:29<34:03,  4.48it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 3.31e-05:  34%|▎| 4696/13852 [17:29<33:51,  4.51it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.30e-05:  34%|▎| 4697/13852 [17:29<33:40,  4.53it/s\u001b[A\n",
      "Training loss: 8.05e-02 lr: 3.30e-05:  34%|▎| 4698/13852 [17:29<33:32,  4.55it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 3.30e-05:  34%|▎| 4699/13852 [17:30<33:49,  4.51it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.30e-05:  34%|▎| 4700/13852 [17:30<33:47,  4.52it/s\u001b[A\n",
      "Training loss: 9.75e-02 lr: 3.30e-05:  34%|▎| 4701/13852 [17:30<33:42,  4.52it/s\u001b[A\n",
      "Training loss: 8.92e-02 lr: 3.30e-05:  34%|▎| 4702/13852 [17:30<33:47,  4.51it/s\u001b[A\n",
      "Training loss: 7.12e-02 lr: 3.30e-05:  34%|▎| 4703/13852 [17:30<33:45,  4.52it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 3.30e-05:  34%|▎| 4704/13852 [17:31<33:43,  4.52it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 3.30e-05:  34%|▎| 4705/13852 [17:31<34:04,  4.47it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 3.30e-05:  34%|▎| 4706/13852 [17:31<34:01,  4.48it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 3.30e-05:  34%|▎| 4707/13852 [17:31<33:58,  4.49it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 3.30e-05:  34%|▎| 4708/13852 [17:32<33:50,  4.50it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 3.30e-05:  34%|▎| 4709/13852 [17:32<33:53,  4.50it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 3.30e-05:  34%|▎| 4710/13852 [17:32<34:01,  4.48it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 3.30e-05:  34%|▎| 4711/13852 [17:32<33:49,  4.50it/s\u001b[A\n",
      "Training loss: 3.25e-02 lr: 3.30e-05:  34%|▎| 4712/13852 [17:32<33:45,  4.51it/s\u001b[A\n",
      "Training loss: 2.44e-02 lr: 3.30e-05:  34%|▎| 4713/13852 [17:33<33:46,  4.51it/s\u001b[A\n",
      "Training loss: 2.73e-02 lr: 3.30e-05:  34%|▎| 4714/13852 [17:33<33:43,  4.52it/s\u001b[A\n",
      "Training loss: 2.49e-02 lr: 3.30e-05:  34%|▎| 4715/13852 [17:33<33:57,  4.48it/s\u001b[A\n",
      "Training loss: 2.28e-02 lr: 3.30e-05:  34%|▎| 4716/13852 [17:33<33:54,  4.49it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 3.30e-05:  34%|▎| 4717/13852 [17:34<34:11,  4.45it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 3.30e-05:  34%|▎| 4718/13852 [17:34<34:03,  4.47it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 3.30e-05:  34%|▎| 4719/13852 [17:34<33:58,  4.48it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 3.30e-05:  34%|▎| 4720/13852 [17:34<33:45,  4.51it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 3.30e-05:  34%|▎| 4721/13852 [17:34<33:31,  4.54it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.30e-05:  34%|▎| 4722/13852 [17:35<33:22,  4.56it/s\u001b[A\n",
      "Training loss: 8.58e-02 lr: 3.30e-05:  34%|▎| 4723/13852 [17:35<33:36,  4.53it/s\u001b[A\n",
      "Training loss: 8.99e-02 lr: 3.30e-05:  34%|▎| 4724/13852 [17:35<33:37,  4.52it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 3.29e-05:  34%|▎| 4725/13852 [17:35<33:39,  4.52it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 3.29e-05:  34%|▎| 4726/13852 [17:36<33:47,  4.50it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 3.29e-05:  34%|▎| 4727/13852 [17:36<33:49,  4.50it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 3.29e-05:  34%|▎| 4728/13852 [17:36<34:00,  4.47it/s\u001b[A\n",
      "Training loss: 3.40e-02 lr: 3.29e-05:  34%|▎| 4729/13852 [17:36<33:56,  4.48it/s\u001b[A\n",
      "Training loss: 3.42e-02 lr: 3.29e-05:  34%|▎| 4730/13852 [17:36<33:55,  4.48it/s\u001b[A\n",
      "Training loss: 9.85e-02 lr: 3.29e-05:  34%|▎| 4731/13852 [17:37<33:55,  4.48it/s\u001b[A\n",
      "Training loss: 8.19e-02 lr: 3.29e-05:  34%|▎| 4732/13852 [17:37<34:08,  4.45it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 3.29e-05:  34%|▎| 4733/13852 [17:37<34:18,  4.43it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 3.29e-05:  34%|▎| 4734/13852 [17:37<35:11,  4.32it/s\u001b[A\n",
      "Training loss: 3.02e-02 lr: 3.29e-05:  34%|▎| 4735/13852 [17:38<36:50,  4.12it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 3.29e-05:  34%|▎| 4736/13852 [17:38<37:12,  4.08it/s\u001b[A\n",
      "Training loss: 3.19e-02 lr: 3.29e-05:  34%|▎| 4737/13852 [17:38<37:10,  4.09it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 3.29e-05:  34%|▎| 4738/13852 [17:38<36:47,  4.13it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 3.29e-05:  34%|▎| 4739/13852 [17:39<36:38,  4.15it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 3.29e-05:  34%|▎| 4740/13852 [17:39<36:31,  4.16it/s\u001b[A\n",
      "Training loss: 4.07e-02 lr: 3.29e-05:  34%|▎| 4741/13852 [17:39<36:31,  4.16it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.29e-05:  34%|▎| 4742/13852 [17:39<36:33,  4.15it/s\u001b[A\n",
      "Training loss: 9.37e-02 lr: 3.29e-05:  34%|▎| 4743/13852 [17:40<36:25,  4.17it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.11e-01 lr: 3.29e-05:  34%|▎| 4744/13852 [17:40<36:35,  4.15it/s\u001b[A\n",
      "Training loss: 7.99e-02 lr: 3.29e-05:  34%|▎| 4745/13852 [17:40<36:31,  4.16it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 3.29e-05:  34%|▎| 4746/13852 [17:40<36:24,  4.17it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 3.29e-05:  34%|▎| 4747/13852 [17:40<36:24,  4.17it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 3.29e-05:  34%|▎| 4748/13852 [17:41<36:28,  4.16it/s\u001b[A\n",
      "Training loss: 2.98e-02 lr: 3.29e-05:  34%|▎| 4749/13852 [17:41<36:27,  4.16it/s\u001b[A\n",
      "Training loss: 2.27e-02 lr: 3.29e-05:  34%|▎| 4750/13852 [17:41<36:29,  4.16it/s\u001b[A\n",
      "Training loss: 2.27e-02 lr: 3.29e-05:  34%|▎| 4751/13852 [17:41<36:22,  4.17it/s\u001b[A\n",
      "Training loss: 3.87e-02 lr: 3.28e-05:  34%|▎| 4752/13852 [17:42<36:28,  4.16it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 3.28e-05:  34%|▎| 4753/13852 [17:42<36:29,  4.16it/s\u001b[A\n",
      "Training loss: 4.16e-02 lr: 3.28e-05:  34%|▎| 4754/13852 [17:42<36:27,  4.16it/s\u001b[A\n",
      "Training loss: 3.50e-02 lr: 3.28e-05:  34%|▎| 4755/13852 [17:42<36:14,  4.18it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 3.28e-05:  34%|▎| 4756/13852 [17:43<36:14,  4.18it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 3.28e-05:  34%|▎| 4757/13852 [17:43<36:11,  4.19it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 3.28e-05:  34%|▎| 4758/13852 [17:43<36:11,  4.19it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 3.28e-05:  34%|▎| 4759/13852 [17:43<36:16,  4.18it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 3.28e-05:  34%|▎| 4760/13852 [17:44<36:17,  4.18it/s\u001b[A\n",
      "Training loss: 9.81e-02 lr: 3.28e-05:  34%|▎| 4761/13852 [17:44<36:10,  4.19it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 3.28e-05:  34%|▎| 4762/13852 [17:44<36:06,  4.19it/s\u001b[A\n",
      "Training loss: 9.71e-02 lr: 3.28e-05:  34%|▎| 4763/13852 [17:44<36:07,  4.19it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 3.28e-05:  34%|▎| 4764/13852 [17:45<36:11,  4.18it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 3.28e-05:  34%|▎| 4765/13852 [17:45<36:14,  4.18it/s\u001b[A\n",
      "Training loss: 9.83e-02 lr: 3.28e-05:  34%|▎| 4766/13852 [17:45<36:14,  4.18it/s\u001b[A\n",
      "Training loss: 9.94e-02 lr: 3.28e-05:  34%|▎| 4767/13852 [17:45<36:07,  4.19it/s\u001b[A\n",
      "Training loss: 7.88e-02 lr: 3.28e-05:  34%|▎| 4768/13852 [17:46<36:10,  4.19it/s\u001b[A\n",
      "Training loss: 7.30e-02 lr: 3.28e-05:  34%|▎| 4769/13852 [17:46<36:14,  4.18it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 3.28e-05:  34%|▎| 4770/13852 [17:46<36:24,  4.16it/s\u001b[A\n",
      "Training loss: 6.57e-02 lr: 3.28e-05:  34%|▎| 4771/13852 [17:46<36:22,  4.16it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 3.28e-05:  34%|▎| 4772/13852 [17:46<36:22,  4.16it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 3.28e-05:  34%|▎| 4773/13852 [17:47<36:23,  4.16it/s\u001b[A\n",
      "Training loss: 3.73e-02 lr: 3.28e-05:  34%|▎| 4774/13852 [17:47<36:24,  4.15it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 3.28e-05:  34%|▎| 4775/13852 [17:47<36:19,  4.16it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 3.28e-05:  34%|▎| 4776/13852 [17:47<36:17,  4.17it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 3.28e-05:  34%|▎| 4777/13852 [17:48<36:23,  4.16it/s\u001b[A\n",
      "Training loss: 3.57e-02 lr: 3.28e-05:  34%|▎| 4778/13852 [17:48<36:13,  4.17it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 3.28e-05:  35%|▎| 4779/13852 [17:48<36:14,  4.17it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 3.27e-05:  35%|▎| 4780/13852 [17:48<36:14,  4.17it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 3.27e-05:  35%|▎| 4781/13852 [17:49<36:14,  4.17it/s\u001b[A\n",
      "Training loss: 3.43e-02 lr: 3.27e-05:  35%|▎| 4782/13852 [17:49<36:16,  4.17it/s\u001b[A\n",
      "Training loss: 3.52e-02 lr: 3.27e-05:  35%|▎| 4783/13852 [17:49<36:19,  4.16it/s\u001b[A\n",
      "Training loss: 2.74e-02 lr: 3.27e-05:  35%|▎| 4784/13852 [17:49<36:14,  4.17it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 3.27e-05:  35%|▎| 4785/13852 [17:50<36:24,  4.15it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 3.27e-05:  35%|▎| 4786/13852 [17:50<36:24,  4.15it/s\u001b[A\n",
      "Training loss: 2.93e-02 lr: 3.27e-05:  35%|▎| 4787/13852 [17:50<36:19,  4.16it/s\u001b[A\n",
      "Training loss: 2.94e-02 lr: 3.27e-05:  35%|▎| 4788/13852 [17:50<36:20,  4.16it/s\u001b[A\n",
      "Training loss: 2.43e-02 lr: 3.27e-05:  35%|▎| 4789/13852 [17:51<36:18,  4.16it/s\u001b[A\n",
      "Training loss: 7.60e-02 lr: 3.27e-05:  35%|▎| 4790/13852 [17:51<36:25,  4.15it/s\u001b[A\n",
      "Training loss: 8.44e-02 lr: 3.27e-05:  35%|▎| 4791/13852 [17:51<36:21,  4.15it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.27e-05:  35%|▎| 4792/13852 [17:51<36:19,  4.16it/s\u001b[A\n",
      "Training loss: 9.95e-02 lr: 3.27e-05:  35%|▎| 4793/13852 [17:52<36:15,  4.16it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.27e-05:  35%|▎| 4794/13852 [17:52<36:27,  4.14it/s\u001b[A\n",
      "Training loss: 8.83e-02 lr: 3.27e-05:  35%|▎| 4795/13852 [17:52<36:13,  4.17it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 3.27e-05:  35%|▎| 4796/13852 [17:52<35:59,  4.19it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.27e-05:  35%|▎| 4797/13852 [17:52<35:57,  4.20it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.27e-05:  35%|▎| 4798/13852 [17:53<36:01,  4.19it/s\u001b[A\n",
      "Training loss: 8.64e-02 lr: 3.27e-05:  35%|▎| 4799/13852 [17:53<36:08,  4.17it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.27e-05:  35%|▎| 4800/13852 [17:53<36:11,  4.17it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 3.27e-05:  35%|▎| 4801/13852 [17:53<36:10,  4.17it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 3.27e-05:  35%|▎| 4802/13852 [17:54<36:04,  4.18it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 3.27e-05:  35%|▎| 4803/13852 [17:54<36:06,  4.18it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 3.27e-05:  35%|▎| 4804/13852 [17:54<36:06,  4.18it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 3.27e-05:  35%|▎| 4805/13852 [17:54<36:08,  4.17it/s\u001b[A\n",
      "Training loss: 2.74e-02 lr: 3.27e-05:  35%|▎| 4806/13852 [17:55<36:10,  4.17it/s\u001b[A\n",
      "Training loss: 3.22e-02 lr: 3.27e-05:  35%|▎| 4807/13852 [17:55<36:12,  4.16it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 3.26e-05:  35%|▎| 4808/13852 [17:55<36:08,  4.17it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 3.26e-05:  35%|▎| 4809/13852 [17:55<36:09,  4.17it/s\u001b[A\n",
      "Training loss: 3.59e-02 lr: 3.26e-05:  35%|▎| 4810/13852 [17:56<36:08,  4.17it/s\u001b[A\n",
      "Training loss: 3.57e-02 lr: 3.26e-05:  35%|▎| 4811/13852 [17:56<36:08,  4.17it/s\u001b[A\n",
      "Training loss: 3.40e-02 lr: 3.26e-05:  35%|▎| 4812/13852 [17:56<36:11,  4.16it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 3.26e-05:  35%|▎| 4813/13852 [17:56<36:10,  4.16it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 3.26e-05:  35%|▎| 4814/13852 [17:57<36:01,  4.18it/s\u001b[A\n",
      "Training loss: 4.61e-02 lr: 3.26e-05:  35%|▎| 4815/13852 [17:57<36:23,  4.14it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 3.26e-05:  35%|▎| 4816/13852 [17:57<36:23,  4.14it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.26e-05:  35%|▎| 4817/13852 [17:57<36:18,  4.15it/s\u001b[A\n",
      "Training loss: 1.43e-01 lr: 3.26e-05:  35%|▎| 4818/13852 [17:58<36:15,  4.15it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.26e-05:  35%|▎| 4819/13852 [17:58<36:06,  4.17it/s\u001b[A\n",
      "Training loss: 8.22e-02 lr: 3.26e-05:  35%|▎| 4820/13852 [17:58<36:11,  4.16it/s\u001b[A\n",
      "Training loss: 6.61e-02 lr: 3.26e-05:  35%|▎| 4821/13852 [17:58<36:08,  4.16it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 3.26e-05:  35%|▎| 4822/13852 [17:58<36:04,  4.17it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.26e-05:  35%|▎| 4823/13852 [17:59<36:04,  4.17it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.26e-05:  35%|▎| 4824/13852 [17:59<36:05,  4.17it/s\u001b[A\n",
      "Training loss: 9.23e-02 lr: 3.26e-05:  35%|▎| 4825/13852 [17:59<36:05,  4.17it/s\u001b[A\n",
      "Training loss: 7.86e-02 lr: 3.26e-05:  35%|▎| 4826/13852 [17:59<36:03,  4.17it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 3.26e-05:  35%|▎| 4827/13852 [18:00<36:02,  4.17it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 3.26e-05:  35%|▎| 4828/13852 [18:00<36:00,  4.18it/s\u001b[A\n",
      "Training loss: 9.69e-02 lr: 3.26e-05:  35%|▎| 4829/13852 [18:00<36:02,  4.17it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 3.26e-05:  35%|▎| 4830/13852 [18:00<36:06,  4.16it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 3.26e-05:  35%|▎| 4831/13852 [18:01<36:01,  4.17it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 3.26e-05:  35%|▎| 4832/13852 [18:01<36:10,  4.16it/s\u001b[A\n",
      "Training loss: 9.11e-02 lr: 3.26e-05:  35%|▎| 4833/13852 [18:01<36:09,  4.16it/s\u001b[A\n",
      "Training loss: 7.17e-02 lr: 3.26e-05:  35%|▎| 4834/13852 [18:01<36:06,  4.16it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 3.25e-05:  35%|▎| 4835/13852 [18:02<36:05,  4.16it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 3.25e-05:  35%|▎| 4836/13852 [18:02<36:15,  4.14it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 3.25e-05:  35%|▎| 4837/13852 [18:02<36:28,  4.12it/s\u001b[A\n",
      "Training loss: 4.22e-02 lr: 3.25e-05:  35%|▎| 4838/13852 [18:02<36:26,  4.12it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 3.25e-05:  35%|▎| 4839/13852 [18:03<36:20,  4.13it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 3.25e-05:  35%|▎| 4840/13852 [18:03<37:39,  3.99it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.07e-02 lr: 3.25e-05:  35%|▎| 4841/13852 [18:03<37:03,  4.05it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 3.25e-05:  35%|▎| 4842/13852 [18:03<36:50,  4.08it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 3.25e-05:  35%|▎| 4843/13852 [18:04<35:45,  4.20it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 3.25e-05:  35%|▎| 4844/13852 [18:04<34:55,  4.30it/s\u001b[A\n",
      "Training loss: 4.43e-02 lr: 3.25e-05:  35%|▎| 4845/13852 [18:04<34:25,  4.36it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 3.25e-05:  35%|▎| 4846/13852 [18:04<34:18,  4.38it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 3.25e-05:  35%|▎| 4847/13852 [18:04<33:58,  4.42it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 3.25e-05:  35%|▎| 4848/13852 [18:05<33:46,  4.44it/s\u001b[A\n",
      "Training loss: 6.61e-02 lr: 3.25e-05:  35%|▎| 4849/13852 [18:05<33:37,  4.46it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 3.25e-05:  35%|▎| 4850/13852 [18:05<33:32,  4.47it/s\u001b[A\n",
      "Training loss: 8.37e-02 lr: 3.25e-05:  35%|▎| 4851/13852 [18:05<33:16,  4.51it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 3.25e-05:  35%|▎| 4852/13852 [18:06<33:07,  4.53it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 3.25e-05:  35%|▎| 4853/13852 [18:06<33:16,  4.51it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 3.25e-05:  35%|▎| 4854/13852 [18:06<33:21,  4.50it/s\u001b[A\n",
      "Training loss: 6.79e-02 lr: 3.25e-05:  35%|▎| 4855/13852 [18:06<33:17,  4.50it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.25e-05:  35%|▎| 4856/13852 [18:06<33:15,  4.51it/s\u001b[A\n",
      "Training loss: 8.69e-02 lr: 3.25e-05:  35%|▎| 4857/13852 [18:07<33:20,  4.50it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 3.25e-05:  35%|▎| 4858/13852 [18:07<33:29,  4.48it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 3.25e-05:  35%|▎| 4859/13852 [18:07<33:33,  4.47it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 3.25e-05:  35%|▎| 4860/13852 [18:07<34:14,  4.38it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 3.25e-05:  35%|▎| 4861/13852 [18:08<34:51,  4.30it/s\u001b[A\n",
      "Training loss: 4.42e-02 lr: 3.25e-05:  35%|▎| 4862/13852 [18:08<35:28,  4.22it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 3.24e-05:  35%|▎| 4863/13852 [18:08<35:45,  4.19it/s\u001b[A\n",
      "Training loss: 3.77e-02 lr: 3.24e-05:  35%|▎| 4864/13852 [18:08<34:56,  4.29it/s\u001b[A\n",
      "Training loss: 3.03e-02 lr: 3.24e-05:  35%|▎| 4865/13852 [18:09<34:23,  4.36it/s\u001b[A\n",
      "Training loss: 9.52e-02 lr: 3.24e-05:  35%|▎| 4866/13852 [18:09<33:58,  4.41it/s\u001b[A\n",
      "Training loss: 8.74e-02 lr: 3.24e-05:  35%|▎| 4867/13852 [18:09<33:41,  4.45it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.24e-05:  35%|▎| 4868/13852 [18:09<33:32,  4.46it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.24e-05:  35%|▎| 4869/13852 [18:09<33:18,  4.50it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.24e-05:  35%|▎| 4870/13852 [18:10<33:04,  4.53it/s\u001b[A\n",
      "Training loss: 8.13e-02 lr: 3.24e-05:  35%|▎| 4871/13852 [18:10<32:57,  4.54it/s\u001b[A\n",
      "Training loss: 7.77e-02 lr: 3.24e-05:  35%|▎| 4872/13852 [18:10<33:14,  4.50it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 3.24e-05:  35%|▎| 4873/13852 [18:10<33:07,  4.52it/s\u001b[A\n",
      "Training loss: 6.88e-02 lr: 3.24e-05:  35%|▎| 4874/13852 [18:10<33:07,  4.52it/s\u001b[A\n",
      "Training loss: 4.95e-02 lr: 3.24e-05:  35%|▎| 4875/13852 [18:11<33:07,  4.52it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 3.24e-05:  35%|▎| 4876/13852 [18:11<33:10,  4.51it/s\u001b[A\n",
      "Training loss: 9.64e-02 lr: 3.24e-05:  35%|▎| 4877/13852 [18:11<33:08,  4.51it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.24e-05:  35%|▎| 4878/13852 [18:11<33:06,  4.52it/s\u001b[A\n",
      "Training loss: 8.58e-02 lr: 3.24e-05:  35%|▎| 4879/13852 [18:12<33:05,  4.52it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 3.24e-05:  35%|▎| 4880/13852 [18:12<33:08,  4.51it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 3.24e-05:  35%|▎| 4881/13852 [18:12<33:11,  4.50it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 3.24e-05:  35%|▎| 4882/13852 [18:12<33:09,  4.51it/s\u001b[A\n",
      "Training loss: 7.62e-02 lr: 3.24e-05:  35%|▎| 4883/13852 [18:12<33:00,  4.53it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 3.24e-05:  35%|▎| 4884/13852 [18:13<32:52,  4.55it/s\u001b[A\n",
      "Training loss: 5.32e-02 lr: 3.24e-05:  35%|▎| 4885/13852 [18:13<32:59,  4.53it/s\u001b[A\n",
      "Training loss: 8.33e-02 lr: 3.24e-05:  35%|▎| 4886/13852 [18:13<33:01,  4.52it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 3.24e-05:  35%|▎| 4887/13852 [18:13<33:04,  4.52it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 3.24e-05:  35%|▎| 4888/13852 [18:14<32:57,  4.53it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.24e-05:  35%|▎| 4889/13852 [18:14<32:59,  4.53it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.24e-05:  35%|▎| 4890/13852 [18:14<33:04,  4.52it/s\u001b[A\n",
      "Training loss: 8.73e-02 lr: 3.23e-05:  35%|▎| 4891/13852 [18:14<33:06,  4.51it/s\u001b[A\n",
      "Training loss: 7.26e-02 lr: 3.23e-05:  35%|▎| 4892/13852 [18:14<33:07,  4.51it/s\u001b[A\n",
      "Training loss: 1.54e-01 lr: 3.23e-05:  35%|▎| 4893/13852 [18:15<33:07,  4.51it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.23e-05:  35%|▎| 4894/13852 [18:15<33:03,  4.52it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 3.23e-05:  35%|▎| 4895/13852 [18:15<32:56,  4.53it/s\u001b[A\n",
      "Training loss: 1.54e-01 lr: 3.23e-05:  35%|▎| 4896/13852 [18:15<32:49,  4.55it/s\u001b[A\n",
      "Training loss: 1.89e-01 lr: 3.23e-05:  35%|▎| 4897/13852 [18:16<33:07,  4.51it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 3.23e-05:  35%|▎| 4898/13852 [18:16<33:04,  4.51it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.23e-05:  35%|▎| 4899/13852 [18:16<33:04,  4.51it/s\u001b[A\n",
      "Training loss: 8.07e-02 lr: 3.23e-05:  35%|▎| 4900/13852 [18:16<33:02,  4.52it/s\u001b[A\n",
      "Training loss: 7.77e-02 lr: 3.23e-05:  35%|▎| 4901/13852 [18:16<33:03,  4.51it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 3.23e-05:  35%|▎| 4902/13852 [18:17<33:10,  4.50it/s\u001b[A\n",
      "Training loss: 6.12e-02 lr: 3.23e-05:  35%|▎| 4903/13852 [18:17<33:10,  4.50it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 3.23e-05:  35%|▎| 4904/13852 [18:17<33:10,  4.50it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 3.23e-05:  35%|▎| 4905/13852 [18:17<33:08,  4.50it/s\u001b[A\n",
      "Training loss: 6.79e-02 lr: 3.23e-05:  35%|▎| 4906/13852 [18:18<32:59,  4.52it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 3.23e-05:  35%|▎| 4907/13852 [18:18<32:48,  4.55it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 3.23e-05:  35%|▎| 4908/13852 [18:18<32:55,  4.53it/s\u001b[A\n",
      "Training loss: 9.60e-02 lr: 3.23e-05:  35%|▎| 4909/13852 [18:18<32:48,  4.54it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 3.23e-05:  35%|▎| 4910/13852 [18:18<32:57,  4.52it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.23e-05:  35%|▎| 4911/13852 [18:19<32:57,  4.52it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.23e-05:  35%|▎| 4912/13852 [18:19<32:55,  4.52it/s\u001b[A\n",
      "Training loss: 9.39e-02 lr: 3.23e-05:  35%|▎| 4913/13852 [18:19<32:54,  4.53it/s\u001b[A\n",
      "Training loss: 7.27e-02 lr: 3.23e-05:  35%|▎| 4914/13852 [18:19<32:57,  4.52it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 3.23e-05:  35%|▎| 4915/13852 [18:20<32:59,  4.51it/s\u001b[A\n",
      "Training loss: 6.32e-02 lr: 3.23e-05:  35%|▎| 4916/13852 [18:20<33:00,  4.51it/s\u001b[A\n",
      "Training loss: 6.64e-02 lr: 3.23e-05:  35%|▎| 4917/13852 [18:20<33:08,  4.49it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 3.23e-05:  36%|▎| 4918/13852 [18:20<33:11,  4.49it/s\u001b[A\n",
      "Training loss: 1.68e-01 lr: 3.22e-05:  36%|▎| 4919/13852 [18:20<33:03,  4.50it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 3.22e-05:  36%|▎| 4920/13852 [18:21<32:51,  4.53it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.22e-05:  36%|▎| 4921/13852 [18:21<32:55,  4.52it/s\u001b[A\n",
      "Training loss: 9.00e-02 lr: 3.22e-05:  36%|▎| 4922/13852 [18:21<33:00,  4.51it/s\u001b[A\n",
      "Training loss: 7.93e-02 lr: 3.22e-05:  36%|▎| 4923/13852 [18:21<32:59,  4.51it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 3.22e-05:  36%|▎| 4924/13852 [18:22<32:58,  4.51it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.22e-05:  36%|▎| 4925/13852 [18:22<33:03,  4.50it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.22e-05:  36%|▎| 4926/13852 [18:22<33:02,  4.50it/s\u001b[A\n",
      "Training loss: 8.96e-02 lr: 3.22e-05:  36%|▎| 4927/13852 [18:22<33:07,  4.49it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.22e-05:  36%|▎| 4928/13852 [18:22<33:10,  4.48it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 3.22e-05:  36%|▎| 4929/13852 [18:23<33:14,  4.47it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 3.22e-05:  36%|▎| 4930/13852 [18:23<33:11,  4.48it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 3.22e-05:  36%|▎| 4931/13852 [18:23<33:00,  4.51it/s\u001b[A\n",
      "Training loss: 7.08e-02 lr: 3.22e-05:  36%|▎| 4932/13852 [18:23<32:47,  4.53it/s\u001b[A\n",
      "Training loss: 7.08e-02 lr: 3.22e-05:  36%|▎| 4933/13852 [18:24<32:40,  4.55it/s\u001b[A\n",
      "Training loss: 6.32e-02 lr: 3.22e-05:  36%|▎| 4934/13852 [18:24<32:51,  4.52it/s\u001b[A\n",
      "Training loss: 7.18e-02 lr: 3.22e-05:  36%|▎| 4935/13852 [18:24<32:52,  4.52it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 3.22e-05:  36%|▎| 4936/13852 [18:24<32:49,  4.53it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 3.22e-05:  36%|▎| 4937/13852 [18:24<32:52,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.36e-02 lr: 3.22e-05:  36%|▎| 4938/13852 [18:25<32:55,  4.51it/s\u001b[A\n",
      "Training loss: 6.99e-02 lr: 3.22e-05:  36%|▎| 4939/13852 [18:25<32:55,  4.51it/s\u001b[A\n",
      "Training loss: 7.01e-02 lr: 3.22e-05:  36%|▎| 4940/13852 [18:25<32:57,  4.51it/s\u001b[A\n",
      "Training loss: 6.64e-02 lr: 3.22e-05:  36%|▎| 4941/13852 [18:25<32:57,  4.51it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 3.22e-05:  36%|▎| 4942/13852 [18:26<32:58,  4.50it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 3.22e-05:  36%|▎| 4943/13852 [18:26<32:52,  4.52it/s\u001b[A\n",
      "Training loss: 3.25e-02 lr: 3.22e-05:  36%|▎| 4944/13852 [18:26<32:42,  4.54it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 3.22e-05:  36%|▎| 4945/13852 [18:26<32:33,  4.56it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 3.21e-05:  36%|▎| 4946/13852 [18:26<32:57,  4.50it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 3.21e-05:  36%|▎| 4947/13852 [18:27<33:00,  4.50it/s\u001b[A\n",
      "Training loss: 8.48e-02 lr: 3.21e-05:  36%|▎| 4948/13852 [18:27<32:56,  4.50it/s\u001b[A\n",
      "Training loss: 6.17e-02 lr: 3.21e-05:  36%|▎| 4949/13852 [18:27<32:58,  4.50it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 3.21e-05:  36%|▎| 4950/13852 [18:27<33:43,  4.40it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 3.21e-05:  36%|▎| 4951/13852 [18:28<34:27,  4.30it/s\u001b[A\n",
      "Training loss: 3.68e-02 lr: 3.21e-05:  36%|▎| 4952/13852 [18:28<35:08,  4.22it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 3.21e-05:  36%|▎| 4953/13852 [18:28<34:41,  4.27it/s\u001b[A\n",
      "Training loss: 9.81e-02 lr: 3.21e-05:  36%|▎| 4954/13852 [18:28<34:20,  4.32it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.21e-05:  36%|▎| 4955/13852 [18:29<34:00,  4.36it/s\u001b[A\n",
      "Training loss: 9.85e-02 lr: 3.21e-05:  36%|▎| 4956/13852 [18:29<33:56,  4.37it/s\u001b[A\n",
      "Training loss: 9.51e-02 lr: 3.21e-05:  36%|▎| 4957/13852 [18:29<33:49,  4.38it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 3.21e-05:  36%|▎| 4958/13852 [18:29<33:44,  4.39it/s\u001b[A\n",
      "Training loss: 7.98e-02 lr: 3.21e-05:  36%|▎| 4959/13852 [18:29<33:35,  4.41it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 3.21e-05:  36%|▎| 4960/13852 [18:30<33:36,  4.41it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 3.21e-05:  36%|▎| 4961/13852 [18:30<33:36,  4.41it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 3.21e-05:  36%|▎| 4962/13852 [18:30<33:24,  4.43it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 3.21e-05:  36%|▎| 4963/13852 [18:30<33:42,  4.39it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 3.21e-05:  36%|▎| 4964/13852 [18:31<33:37,  4.41it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 3.21e-05:  36%|▎| 4965/13852 [18:31<33:46,  4.38it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 3.21e-05:  36%|▎| 4966/13852 [18:31<33:53,  4.37it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 3.21e-05:  36%|▎| 4967/13852 [18:31<33:43,  4.39it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 3.21e-05:  36%|▎| 4968/13852 [18:31<33:39,  4.40it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 3.21e-05:  36%|▎| 4969/13852 [18:32<33:47,  4.38it/s\u001b[A\n",
      "Training loss: 5.07e-02 lr: 3.21e-05:  36%|▎| 4970/13852 [18:32<33:49,  4.38it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 3.21e-05:  36%|▎| 4971/13852 [18:32<33:30,  4.42it/s\u001b[A\n",
      "Training loss: 3.50e-02 lr: 3.21e-05:  36%|▎| 4972/13852 [18:32<34:46,  4.26it/s\u001b[A\n",
      "Training loss: 7.92e-02 lr: 3.21e-05:  36%|▎| 4973/13852 [18:33<35:17,  4.19it/s\u001b[A\n",
      "Training loss: 9.12e-02 lr: 3.20e-05:  36%|▎| 4974/13852 [18:33<34:31,  4.28it/s\u001b[A\n",
      "Training loss: 6.79e-02 lr: 3.20e-05:  36%|▎| 4975/13852 [18:33<34:03,  4.34it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 3.20e-05:  36%|▎| 4976/13852 [18:33<33:44,  4.38it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 3.20e-05:  36%|▎| 4977/13852 [18:34<33:41,  4.39it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.20e-05:  36%|▎| 4978/13852 [18:34<33:19,  4.44it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 3.20e-05:  36%|▎| 4979/13852 [18:34<32:59,  4.48it/s\u001b[A\n",
      "Training loss: 9.25e-02 lr: 3.20e-05:  36%|▎| 4980/13852 [18:34<33:29,  4.42it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 3.20e-05:  36%|▎| 4981/13852 [18:34<33:16,  4.44it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 3.20e-05:  36%|▎| 4982/13852 [18:35<33:14,  4.45it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 3.20e-05:  36%|▎| 4983/13852 [18:35<33:03,  4.47it/s\u001b[A\n",
      "Training loss: 3.89e-02 lr: 3.20e-05:  36%|▎| 4984/13852 [18:35<32:57,  4.48it/s\u001b[A\n",
      "Training loss: 3.02e-02 lr: 3.20e-05:  36%|▎| 4985/13852 [18:35<32:52,  4.50it/s\u001b[A\n",
      "Training loss: 3.12e-02 lr: 3.20e-05:  36%|▎| 4986/13852 [18:36<32:50,  4.50it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 3.20e-05:  36%|▎| 4987/13852 [18:36<33:00,  4.48it/s\u001b[A\n",
      "Training loss: 3.19e-02 lr: 3.20e-05:  36%|▎| 4988/13852 [18:36<32:58,  4.48it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.20e-05:  36%|▎| 4989/13852 [18:36<32:47,  4.51it/s\u001b[A\n",
      "Training loss: 8.49e-02 lr: 3.20e-05:  36%|▎| 4990/13852 [18:36<32:35,  4.53it/s\u001b[A\n",
      "Training loss: 6.38e-02 lr: 3.20e-05:  36%|▎| 4991/13852 [18:37<32:45,  4.51it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 3.20e-05:  36%|▎| 4992/13852 [18:37<33:24,  4.42it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 3.20e-05:  36%|▎| 4993/13852 [18:37<34:10,  4.32it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 3.20e-05:  36%|▎| 4994/13852 [18:37<34:50,  4.24it/s\u001b[A\n",
      "Training loss: 2.99e-02 lr: 3.20e-05:  36%|▎| 4995/13852 [18:38<35:15,  4.19it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 3.20e-05:  36%|▎| 4996/13852 [18:38<35:33,  4.15it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 3.20e-05:  36%|▎| 4997/13852 [18:38<35:40,  4.14it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 3.20e-05:  36%|▎| 4998/13852 [18:38<35:47,  4.12it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 3.20e-05:  36%|▎| 4999/13852 [18:39<35:43,  4.13it/s\u001b[A\n",
      "Training loss: 3.75e-02 lr: 3.20e-05:  36%|▎| 5000/13852 [18:39<34:59,  4.22it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 3.20e-05:  36%|▎| 5001/13852 [18:39<34:19,  4.30it/s\u001b[A\n",
      "Training loss: 4.93e-02 lr: 3.19e-05:  36%|▎| 5002/13852 [18:39<33:52,  4.35it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 3.19e-05:  36%|▎| 5003/13852 [18:39<33:34,  4.39it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 3.19e-05:  36%|▎| 5004/13852 [18:40<33:08,  4.45it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 3.19e-05:  36%|▎| 5005/13852 [18:40<32:49,  4.49it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 3.19e-05:  36%|▎| 5006/13852 [18:40<32:57,  4.47it/s\u001b[A\n",
      "Training loss: 1.66e-01 lr: 3.19e-05:  36%|▎| 5007/13852 [18:40<32:50,  4.49it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.19e-05:  36%|▎| 5008/13852 [18:41<32:45,  4.50it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.19e-05:  36%|▎| 5009/13852 [18:41<32:56,  4.47it/s\u001b[A\n",
      "Training loss: 8.49e-02 lr: 3.19e-05:  36%|▎| 5010/13852 [18:41<32:53,  4.48it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 3.19e-05:  36%|▎| 5011/13852 [18:41<32:53,  4.48it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 3.19e-05:  36%|▎| 5012/13852 [18:41<32:50,  4.49it/s\u001b[A\n",
      "Training loss: 5.45e-02 lr: 3.19e-05:  36%|▎| 5013/13852 [18:42<32:54,  4.48it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.19e-05:  36%|▎| 5014/13852 [18:42<32:54,  4.48it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.19e-05:  36%|▎| 5015/13852 [18:42<32:42,  4.50it/s\u001b[A\n",
      "Training loss: 9.93e-02 lr: 3.19e-05:  36%|▎| 5016/13852 [18:42<32:41,  4.50it/s\u001b[A\n",
      "Training loss: 8.57e-02 lr: 3.19e-05:  36%|▎| 5017/13852 [18:43<32:29,  4.53it/s\u001b[A\n",
      "Training loss: 9.15e-02 lr: 3.19e-05:  36%|▎| 5018/13852 [18:43<32:26,  4.54it/s\u001b[A\n",
      "Training loss: 8.52e-02 lr: 3.19e-05:  36%|▎| 5019/13852 [18:43<32:31,  4.53it/s\u001b[A\n",
      "Training loss: 7.65e-02 lr: 3.19e-05:  36%|▎| 5020/13852 [18:43<32:33,  4.52it/s\u001b[A\n",
      "Training loss: 8.18e-02 lr: 3.19e-05:  36%|▎| 5021/13852 [18:43<32:35,  4.52it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 3.19e-05:  36%|▎| 5022/13852 [18:44<32:39,  4.51it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 3.19e-05:  36%|▎| 5023/13852 [18:44<32:42,  4.50it/s\u001b[A\n",
      "Training loss: 9.18e-02 lr: 3.19e-05:  36%|▎| 5024/13852 [18:44<32:43,  4.50it/s\u001b[A\n",
      "Training loss: 9.25e-02 lr: 3.19e-05:  36%|▎| 5025/13852 [18:44<32:44,  4.49it/s\u001b[A\n",
      "Training loss: 9.10e-02 lr: 3.19e-05:  36%|▎| 5026/13852 [18:45<32:43,  4.50it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 3.19e-05:  36%|▎| 5027/13852 [18:45<32:47,  4.49it/s\u001b[A\n",
      "Training loss: 9.19e-02 lr: 3.19e-05:  36%|▎| 5028/13852 [18:45<32:36,  4.51it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 3.18e-05:  36%|▎| 5029/13852 [18:45<32:28,  4.53it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 3.18e-05:  36%|▎| 5030/13852 [18:45<32:36,  4.51it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 3.18e-05:  36%|▎| 5031/13852 [18:46<32:34,  4.51it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 3.18e-05:  36%|▎| 5032/13852 [18:46<32:33,  4.52it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 3.18e-05:  36%|▎| 5033/13852 [18:46<32:37,  4.51it/s\u001b[A\n",
      "Training loss: 2.81e-02 lr: 3.18e-05:  36%|▎| 5034/13852 [18:46<32:37,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.38e-02 lr: 3.18e-05:  36%|▎| 5035/13852 [18:47<32:37,  4.50it/s\u001b[A\n",
      "Training loss: 7.96e-02 lr: 3.18e-05:  36%|▎| 5036/13852 [18:47<32:50,  4.47it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 3.18e-05:  36%|▎| 5037/13852 [18:47<32:49,  4.48it/s\u001b[A\n",
      "Training loss: 9.26e-02 lr: 3.18e-05:  36%|▎| 5038/13852 [18:47<32:47,  4.48it/s\u001b[A\n",
      "Training loss: 9.42e-02 lr: 3.18e-05:  36%|▎| 5039/13852 [18:47<32:37,  4.50it/s\u001b[A\n",
      "Training loss: 7.72e-02 lr: 3.18e-05:  36%|▎| 5040/13852 [18:48<32:23,  4.53it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.18e-05:  36%|▎| 5041/13852 [18:48<32:12,  4.56it/s\u001b[A\n",
      "Training loss: 8.34e-02 lr: 3.18e-05:  36%|▎| 5042/13852 [18:48<33:30,  4.38it/s\u001b[A\n",
      "Training loss: 6.82e-02 lr: 3.18e-05:  36%|▎| 5043/13852 [18:48<33:12,  4.42it/s\u001b[A\n",
      "Training loss: 6.34e-02 lr: 3.18e-05:  36%|▎| 5044/13852 [18:49<33:03,  4.44it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 3.18e-05:  36%|▎| 5045/13852 [18:49<32:54,  4.46it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 3.18e-05:  36%|▎| 5046/13852 [18:49<32:50,  4.47it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 3.18e-05:  36%|▎| 5047/13852 [18:49<32:46,  4.48it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 3.18e-05:  36%|▎| 5048/13852 [18:50<32:42,  4.49it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 3.18e-05:  36%|▎| 5049/13852 [18:50<32:38,  4.50it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 3.18e-05:  36%|▎| 5050/13852 [18:50<32:27,  4.52it/s\u001b[A\n",
      "Training loss: 6.52e-02 lr: 3.18e-05:  36%|▎| 5051/13852 [18:50<32:16,  4.55it/s\u001b[A\n",
      "Training loss: 1.67e-01 lr: 3.18e-05:  36%|▎| 5052/13852 [18:50<32:08,  4.56it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.18e-05:  36%|▎| 5053/13852 [18:51<32:28,  4.52it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 3.18e-05:  36%|▎| 5054/13852 [18:51<32:42,  4.48it/s\u001b[A\n",
      "Training loss: 1.44e-01 lr: 3.18e-05:  36%|▎| 5055/13852 [18:51<32:38,  4.49it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.18e-05:  37%|▎| 5056/13852 [18:51<32:36,  4.50it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 3.17e-05:  37%|▎| 5057/13852 [18:52<32:36,  4.50it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 3.17e-05:  37%|▎| 5058/13852 [18:52<32:42,  4.48it/s\u001b[A\n",
      "Training loss: 9.10e-02 lr: 3.17e-05:  37%|▎| 5059/13852 [18:52<32:43,  4.48it/s\u001b[A\n",
      "Training loss: 7.98e-02 lr: 3.17e-05:  37%|▎| 5060/13852 [18:52<32:39,  4.49it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 3.17e-05:  37%|▎| 5061/13852 [18:52<32:41,  4.48it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 3.17e-05:  37%|▎| 5062/13852 [18:53<32:31,  4.50it/s\u001b[A\n",
      "Training loss: 4.16e-02 lr: 3.17e-05:  37%|▎| 5063/13852 [18:53<32:19,  4.53it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 3.17e-05:  37%|▎| 5064/13852 [18:53<32:12,  4.55it/s\u001b[A\n",
      "Training loss: 3.00e-02 lr: 3.17e-05:  37%|▎| 5065/13852 [18:53<32:19,  4.53it/s\u001b[A\n",
      "Training loss: 2.62e-02 lr: 3.17e-05:  37%|▎| 5066/13852 [18:53<32:20,  4.53it/s\u001b[A\n",
      "Training loss: 2.69e-02 lr: 3.17e-05:  37%|▎| 5067/13852 [18:54<32:19,  4.53it/s\u001b[A\n",
      "Training loss: 3.25e-02 lr: 3.17e-05:  37%|▎| 5068/13852 [18:54<32:17,  4.53it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 3.17e-05:  37%|▎| 5069/13852 [18:54<32:21,  4.52it/s\u001b[A\n",
      "Training loss: 3.28e-02 lr: 3.17e-05:  37%|▎| 5070/13852 [18:54<32:24,  4.52it/s\u001b[A\n",
      "Training loss: 3.77e-02 lr: 3.17e-05:  37%|▎| 5071/13852 [18:55<32:23,  4.52it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 3.17e-05:  37%|▎| 5072/13852 [18:55<32:25,  4.51it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 3.17e-05:  37%|▎| 5073/13852 [18:55<32:24,  4.51it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 3.17e-05:  37%|▎| 5074/13852 [18:55<32:29,  4.50it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 3.17e-05:  37%|▎| 5075/13852 [18:55<32:17,  4.53it/s\u001b[A\n",
      "Training loss: 2.81e-02 lr: 3.17e-05:  37%|▎| 5076/13852 [18:56<32:06,  4.55it/s\u001b[A\n",
      "Training loss: 4.03e-02 lr: 3.17e-05:  37%|▎| 5077/13852 [18:56<32:24,  4.51it/s\u001b[A\n",
      "Training loss: 8.14e-02 lr: 3.17e-05:  37%|▎| 5078/13852 [18:56<32:23,  4.51it/s\u001b[A\n",
      "Training loss: 7.26e-02 lr: 3.17e-05:  37%|▎| 5079/13852 [18:56<32:30,  4.50it/s\u001b[A\n",
      "Training loss: 8.81e-02 lr: 3.17e-05:  37%|▎| 5080/13852 [18:57<32:29,  4.50it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 3.17e-05:  37%|▎| 5081/13852 [18:57<32:37,  4.48it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 3.17e-05:  37%|▎| 5082/13852 [18:57<32:33,  4.49it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 3.17e-05:  37%|▎| 5083/13852 [18:57<32:30,  4.50it/s\u001b[A\n",
      "Training loss: 7.13e-02 lr: 3.17e-05:  37%|▎| 5084/13852 [18:57<32:28,  4.50it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.16e-05:  37%|▎| 5085/13852 [18:58<32:34,  4.49it/s\u001b[A\n",
      "Training loss: 1.87e-01 lr: 3.16e-05:  37%|▎| 5086/13852 [18:58<32:31,  4.49it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 3.16e-05:  37%|▎| 5087/13852 [18:58<32:18,  4.52it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 3.16e-05:  37%|▎| 5088/13852 [18:58<32:07,  4.55it/s\u001b[A\n",
      "Training loss: 1.44e-01 lr: 3.16e-05:  37%|▎| 5089/13852 [18:59<31:58,  4.57it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.16e-05:  37%|▎| 5090/13852 [18:59<32:07,  4.55it/s\u001b[A\n",
      "Training loss: 7.76e-02 lr: 3.16e-05:  37%|▎| 5091/13852 [18:59<32:07,  4.55it/s\u001b[A\n",
      "Training loss: 7.03e-02 lr: 3.16e-05:  37%|▎| 5092/13852 [18:59<32:13,  4.53it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 3.16e-05:  37%|▎| 5093/13852 [18:59<32:12,  4.53it/s\u001b[A\n",
      "Training loss: 7.71e-02 lr: 3.16e-05:  37%|▎| 5094/13852 [19:00<32:15,  4.52it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 3.16e-05:  37%|▎| 5095/13852 [19:00<32:17,  4.52it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 3.16e-05:  37%|▎| 5096/13852 [19:00<32:18,  4.52it/s\u001b[A\n",
      "Training loss: 4.99e-02 lr: 3.16e-05:  37%|▎| 5097/13852 [19:00<32:20,  4.51it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 3.16e-05:  37%|▎| 5098/13852 [19:01<32:24,  4.50it/s\u001b[A\n",
      "Training loss: 2.95e-02 lr: 3.16e-05:  37%|▎| 5099/13852 [19:01<32:36,  4.47it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 3.16e-05:  37%|▎| 5100/13852 [19:01<32:23,  4.50it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 3.16e-05:  37%|▎| 5101/13852 [19:01<32:12,  4.53it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 3.16e-05:  37%|▎| 5102/13852 [19:01<32:20,  4.51it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 3.16e-05:  37%|▎| 5103/13852 [19:02<32:24,  4.50it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 3.16e-05:  37%|▎| 5104/13852 [19:02<32:23,  4.50it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 3.16e-05:  37%|▎| 5105/13852 [19:02<32:30,  4.49it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 3.16e-05:  37%|▎| 5106/13852 [19:02<32:34,  4.48it/s\u001b[A\n",
      "Training loss: 9.83e-02 lr: 3.16e-05:  37%|▎| 5107/13852 [19:03<32:31,  4.48it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 3.16e-05:  37%|▎| 5108/13852 [19:03<32:28,  4.49it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.16e-05:  37%|▎| 5109/13852 [19:03<32:41,  4.46it/s\u001b[A\n",
      "Training loss: 8.62e-02 lr: 3.16e-05:  37%|▎| 5110/13852 [19:03<32:31,  4.48it/s\u001b[A\n",
      "Training loss: 8.48e-02 lr: 3.16e-05:  37%|▎| 5111/13852 [19:03<32:15,  4.52it/s\u001b[A\n",
      "Training loss: 8.46e-02 lr: 3.16e-05:  37%|▎| 5112/13852 [19:04<32:05,  4.54it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 3.15e-05:  37%|▎| 5113/13852 [19:04<32:22,  4.50it/s\u001b[A\n",
      "Training loss: 6.64e-02 lr: 3.15e-05:  37%|▎| 5114/13852 [19:04<32:18,  4.51it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.15e-05:  37%|▎| 5115/13852 [19:04<32:15,  4.51it/s\u001b[A\n",
      "Training loss: 8.95e-02 lr: 3.15e-05:  37%|▎| 5116/13852 [19:05<32:16,  4.51it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 3.15e-05:  37%|▎| 5117/13852 [19:05<32:12,  4.52it/s\u001b[A\n",
      "Training loss: 9.30e-02 lr: 3.15e-05:  37%|▎| 5118/13852 [19:05<32:12,  4.52it/s\u001b[A\n",
      "Training loss: 8.14e-02 lr: 3.15e-05:  37%|▎| 5119/13852 [19:05<32:13,  4.52it/s\u001b[A\n",
      "Training loss: 7.19e-02 lr: 3.15e-05:  37%|▎| 5120/13852 [19:05<32:13,  4.52it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 3.15e-05:  37%|▎| 5121/13852 [19:06<32:17,  4.51it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 3.15e-05:  37%|▎| 5122/13852 [19:06<32:16,  4.51it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 3.15e-05:  37%|▎| 5123/13852 [19:06<32:08,  4.53it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 3.15e-05:  37%|▎| 5124/13852 [19:06<31:58,  4.55it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 3.15e-05:  37%|▎| 5125/13852 [19:07<31:54,  4.56it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 3.15e-05:  37%|▎| 5126/13852 [19:07<32:29,  4.48it/s\u001b[A\n",
      "Training loss: 3.14e-02 lr: 3.15e-05:  37%|▎| 5127/13852 [19:07<32:28,  4.48it/s\u001b[A\n",
      "Training loss: 2.63e-02 lr: 3.15e-05:  37%|▎| 5128/13852 [19:07<32:36,  4.46it/s\u001b[A\n",
      "Training loss: 2.08e-02 lr: 3.15e-05:  37%|▎| 5129/13852 [19:07<33:25,  4.35it/s\u001b[A\n",
      "Training loss: 1.60e-02 lr: 3.15e-05:  37%|▎| 5130/13852 [19:08<34:19,  4.23it/s\u001b[A\n",
      "Training loss: 3.18e-02 lr: 3.15e-05:  37%|▎| 5131/13852 [19:08<34:44,  4.18it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.39e-02 lr: 3.15e-05:  37%|▎| 5132/13852 [19:08<34:57,  4.16it/s\u001b[A\n",
      "Training loss: 1.86e-02 lr: 3.15e-05:  37%|▎| 5133/13852 [19:08<34:09,  4.25it/s\u001b[A\n",
      "Training loss: 1.69e-02 lr: 3.15e-05:  37%|▎| 5134/13852 [19:09<33:40,  4.32it/s\u001b[A\n",
      "Training loss: 4.43e-02 lr: 3.15e-05:  37%|▎| 5135/13852 [19:09<33:18,  4.36it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 3.15e-05:  37%|▎| 5136/13852 [19:09<32:59,  4.40it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 3.15e-05:  37%|▎| 5137/13852 [19:09<32:48,  4.43it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 3.15e-05:  37%|▎| 5138/13852 [19:10<32:46,  4.43it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 3.15e-05:  37%|▎| 5139/13852 [19:10<32:38,  4.45it/s\u001b[A\n",
      "Training loss: 2.80e-02 lr: 3.14e-05:  37%|▎| 5140/13852 [19:10<32:35,  4.45it/s\u001b[A\n",
      "Training loss: 2.77e-02 lr: 3.14e-05:  37%|▎| 5141/13852 [19:10<32:27,  4.47it/s\u001b[A\n",
      "Training loss: 2.11e-02 lr: 3.14e-05:  37%|▎| 5142/13852 [19:10<32:20,  4.49it/s\u001b[A\n",
      "Training loss: 9.85e-02 lr: 3.14e-05:  37%|▎| 5143/13852 [19:11<32:19,  4.49it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 3.14e-05:  37%|▎| 5144/13852 [19:11<32:25,  4.48it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 3.14e-05:  37%|▎| 5145/13852 [19:11<32:23,  4.48it/s\u001b[A\n",
      "Training loss: 8.01e-02 lr: 3.14e-05:  37%|▎| 5146/13852 [19:11<32:32,  4.46it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 3.14e-05:  37%|▎| 5147/13852 [19:12<32:32,  4.46it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 3.14e-05:  37%|▎| 5148/13852 [19:12<32:39,  4.44it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 3.14e-05:  37%|▎| 5149/13852 [19:12<32:32,  4.46it/s\u001b[A\n",
      "Training loss: 5.09e-02 lr: 3.14e-05:  37%|▎| 5150/13852 [19:12<32:39,  4.44it/s\u001b[A\n",
      "Training loss: 3.86e-02 lr: 3.14e-05:  37%|▎| 5151/13852 [19:12<32:26,  4.47it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 3.14e-05:  37%|▎| 5152/13852 [19:13<32:11,  4.50it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 3.14e-05:  37%|▎| 5153/13852 [19:13<32:00,  4.53it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 3.14e-05:  37%|▎| 5154/13852 [19:13<32:12,  4.50it/s\u001b[A\n",
      "Training loss: 8.85e-02 lr: 3.14e-05:  37%|▎| 5155/13852 [19:13<32:13,  4.50it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 3.14e-05:  37%|▎| 5156/13852 [19:14<32:15,  4.49it/s\u001b[A\n",
      "Training loss: 7.73e-02 lr: 3.14e-05:  37%|▎| 5157/13852 [19:14<32:17,  4.49it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 3.14e-05:  37%|▎| 5158/13852 [19:14<32:18,  4.49it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 3.14e-05:  37%|▎| 5159/13852 [19:14<32:18,  4.48it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 3.14e-05:  37%|▎| 5160/13852 [19:14<32:21,  4.48it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 3.14e-05:  37%|▎| 5161/13852 [19:15<32:21,  4.48it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 3.14e-05:  37%|▎| 5162/13852 [19:15<32:25,  4.47it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 3.14e-05:  37%|▎| 5163/13852 [19:15<32:09,  4.50it/s\u001b[A\n",
      "Training loss: 6.34e-02 lr: 3.14e-05:  37%|▎| 5164/13852 [19:15<31:58,  4.53it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.14e-05:  37%|▎| 5165/13852 [19:16<32:21,  4.47it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.14e-05:  37%|▎| 5166/13852 [19:16<32:17,  4.48it/s\u001b[A\n",
      "Training loss: 8.61e-02 lr: 3.14e-05:  37%|▎| 5167/13852 [19:16<32:12,  4.49it/s\u001b[A\n",
      "Training loss: 8.36e-02 lr: 3.13e-05:  37%|▎| 5168/13852 [19:16<32:14,  4.49it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 3.13e-05:  37%|▎| 5169/13852 [19:16<32:15,  4.49it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 3.13e-05:  37%|▎| 5170/13852 [19:17<32:18,  4.48it/s\u001b[A\n",
      "Training loss: 7.41e-02 lr: 3.13e-05:  37%|▎| 5171/13852 [19:17<32:24,  4.46it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 3.13e-05:  37%|▎| 5172/13852 [19:17<32:25,  4.46it/s\u001b[A\n",
      "Training loss: 9.87e-02 lr: 3.13e-05:  37%|▎| 5173/13852 [19:17<32:29,  4.45it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 3.13e-05:  37%|▎| 5174/13852 [19:18<32:15,  4.48it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 3.13e-05:  37%|▎| 5175/13852 [19:18<32:04,  4.51it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 3.13e-05:  37%|▎| 5176/13852 [19:18<31:59,  4.52it/s\u001b[A\n",
      "Training loss: 3.29e-02 lr: 3.13e-05:  37%|▎| 5177/13852 [19:18<32:04,  4.51it/s\u001b[A\n",
      "Training loss: 2.86e-02 lr: 3.13e-05:  37%|▎| 5178/13852 [19:18<32:12,  4.49it/s\u001b[A\n",
      "Training loss: 2.22e-02 lr: 3.13e-05:  37%|▎| 5179/13852 [19:19<32:14,  4.48it/s\u001b[A\n",
      "Training loss: 6.79e-02 lr: 3.13e-05:  37%|▎| 5180/13852 [19:19<32:17,  4.47it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.13e-05:  37%|▎| 5181/13852 [19:19<32:26,  4.46it/s\u001b[A\n",
      "Training loss: 9.13e-02 lr: 3.13e-05:  37%|▎| 5182/13852 [19:19<32:23,  4.46it/s\u001b[A\n",
      "Training loss: 8.18e-02 lr: 3.13e-05:  37%|▎| 5183/13852 [19:20<32:24,  4.46it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 3.13e-05:  37%|▎| 5184/13852 [19:20<32:22,  4.46it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 3.13e-05:  37%|▎| 5185/13852 [19:20<32:13,  4.48it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 3.13e-05:  37%|▎| 5186/13852 [19:20<32:11,  4.49it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 3.13e-05:  37%|▎| 5187/13852 [19:20<31:57,  4.52it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 3.13e-05:  37%|▎| 5188/13852 [19:21<32:07,  4.50it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 3.13e-05:  37%|▎| 5189/13852 [19:21<32:13,  4.48it/s\u001b[A\n",
      "Training loss: 3.30e-02 lr: 3.13e-05:  37%|▎| 5190/13852 [19:21<32:13,  4.48it/s\u001b[A\n",
      "Training loss: 9.09e-02 lr: 3.13e-05:  37%|▎| 5191/13852 [19:21<32:15,  4.48it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 3.13e-05:  37%|▎| 5192/13852 [19:22<32:17,  4.47it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 3.13e-05:  37%|▎| 5193/13852 [19:22<32:19,  4.46it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 3.13e-05:  37%|▎| 5194/13852 [19:22<32:20,  4.46it/s\u001b[A\n",
      "Training loss: 3.02e-02 lr: 3.13e-05:  38%|▍| 5195/13852 [19:22<32:19,  4.46it/s\u001b[A\n",
      "Training loss: 2.98e-02 lr: 3.12e-05:  38%|▍| 5196/13852 [19:23<32:09,  4.49it/s\u001b[A\n",
      "Training loss: 2.74e-02 lr: 3.12e-05:  38%|▍| 5197/13852 [19:23<31:57,  4.51it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 3.12e-05:  38%|▍| 5198/13852 [19:23<31:50,  4.53it/s\u001b[A\n",
      "Training loss: 8.89e-02 lr: 3.12e-05:  38%|▍| 5199/13852 [19:23<32:06,  4.49it/s\u001b[A\n",
      "Training loss: 7.71e-02 lr: 3.12e-05:  38%|▍| 5200/13852 [19:23<32:03,  4.50it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 3.12e-05:  38%|▍| 5201/13852 [19:24<32:07,  4.49it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 3.12e-05:  38%|▍| 5202/13852 [19:24<32:13,  4.47it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 3.12e-05:  38%|▍| 5203/13852 [19:24<32:20,  4.46it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 3.12e-05:  38%|▍| 5204/13852 [19:24<32:17,  4.46it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 3.12e-05:  38%|▍| 5205/13852 [19:25<32:14,  4.47it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 3.12e-05:  38%|▍| 5206/13852 [19:25<32:12,  4.47it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 3.12e-05:  38%|▍| 5207/13852 [19:25<32:02,  4.50it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 3.12e-05:  38%|▍| 5208/13852 [19:25<31:51,  4.52it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 3.12e-05:  38%|▍| 5209/13852 [19:25<31:45,  4.54it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 3.12e-05:  38%|▍| 5210/13852 [19:26<32:07,  4.48it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 3.12e-05:  38%|▍| 5211/13852 [19:26<32:04,  4.49it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 3.12e-05:  38%|▍| 5212/13852 [19:26<32:01,  4.50it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 3.12e-05:  38%|▍| 5213/13852 [19:26<32:01,  4.50it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 3.12e-05:  38%|▍| 5214/13852 [19:27<32:03,  4.49it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 3.12e-05:  38%|▍| 5215/13852 [19:27<32:11,  4.47it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 3.12e-05:  38%|▍| 5216/13852 [19:27<32:14,  4.46it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 3.12e-05:  38%|▍| 5217/13852 [19:27<32:10,  4.47it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 3.12e-05:  38%|▍| 5218/13852 [19:27<32:12,  4.47it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 3.12e-05:  38%|▍| 5219/13852 [19:28<32:00,  4.50it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 3.12e-05:  38%|▍| 5220/13852 [19:28<31:46,  4.53it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 3.12e-05:  38%|▍| 5221/13852 [19:28<31:40,  4.54it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 3.12e-05:  38%|▍| 5222/13852 [19:28<31:48,  4.52it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 3.11e-05:  38%|▍| 5223/13852 [19:29<31:53,  4.51it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 3.11e-05:  38%|▍| 5224/13852 [19:29<31:59,  4.50it/s\u001b[A\n",
      "Training loss: 3.77e-02 lr: 3.11e-05:  38%|▍| 5225/13852 [19:29<31:57,  4.50it/s\u001b[A\n",
      "Training loss: 2.85e-02 lr: 3.11e-05:  38%|▍| 5226/13852 [19:29<31:55,  4.50it/s\u001b[A\n",
      "Training loss: 6.82e-02 lr: 3.11e-05:  38%|▍| 5227/13852 [19:29<31:54,  4.50it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 3.11e-05:  38%|▍| 5228/13852 [19:30<31:56,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.44e-02 lr: 3.11e-05:  38%|▍| 5229/13852 [19:30<32:00,  4.49it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 3.11e-05:  38%|▍| 5230/13852 [19:30<32:02,  4.48it/s\u001b[A\n",
      "Training loss: 6.96e-02 lr: 3.11e-05:  38%|▍| 5231/13852 [19:30<31:53,  4.50it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 3.11e-05:  38%|▍| 5232/13852 [19:31<31:42,  4.53it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 3.11e-05:  38%|▍| 5233/13852 [19:31<31:39,  4.54it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 3.11e-05:  38%|▍| 5234/13852 [19:31<32:04,  4.48it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 3.11e-05:  38%|▍| 5235/13852 [19:31<31:58,  4.49it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 3.11e-05:  38%|▍| 5236/13852 [19:31<31:59,  4.49it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 3.11e-05:  38%|▍| 5237/13852 [19:32<32:04,  4.48it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 3.11e-05:  38%|▍| 5238/13852 [19:32<32:04,  4.48it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 3.11e-05:  38%|▍| 5239/13852 [19:32<32:17,  4.44it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 3.11e-05:  38%|▍| 5240/13852 [19:32<32:14,  4.45it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 3.11e-05:  38%|▍| 5241/13852 [19:33<32:10,  4.46it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 3.11e-05:  38%|▍| 5242/13852 [19:33<31:57,  4.49it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 3.11e-05:  38%|▍| 5243/13852 [19:33<31:49,  4.51it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 3.11e-05:  38%|▍| 5244/13852 [19:33<31:39,  4.53it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 3.11e-05:  38%|▍| 5245/13852 [19:33<31:54,  4.50it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 3.11e-05:  38%|▍| 5246/13852 [19:34<31:53,  4.50it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 3.11e-05:  38%|▍| 5247/13852 [19:34<31:55,  4.49it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 3.11e-05:  38%|▍| 5248/13852 [19:34<31:56,  4.49it/s\u001b[A\n",
      "Training loss: 2.91e-02 lr: 3.11e-05:  38%|▍| 5249/13852 [19:34<31:57,  4.49it/s\u001b[A\n",
      "Training loss: 2.13e-02 lr: 3.11e-05:  38%|▍| 5250/13852 [19:35<31:58,  4.48it/s\u001b[A\n",
      "Training loss: 2.01e-02 lr: 3.10e-05:  38%|▍| 5251/13852 [19:35<31:57,  4.49it/s\u001b[A\n",
      "Training loss: 1.54e-02 lr: 3.10e-05:  38%|▍| 5252/13852 [19:35<31:57,  4.49it/s\u001b[A\n",
      "Training loss: 1.73e-02 lr: 3.10e-05:  38%|▍| 5253/13852 [19:35<31:49,  4.50it/s\u001b[A\n",
      "Training loss: 1.61e-02 lr: 3.10e-05:  38%|▍| 5254/13852 [19:35<31:39,  4.53it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 3.10e-05:  38%|▍| 5255/13852 [19:36<31:35,  4.54it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 3.10e-05:  38%|▍| 5256/13852 [19:36<31:30,  4.55it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 3.10e-05:  38%|▍| 5257/13852 [19:36<31:36,  4.53it/s\u001b[A\n",
      "Training loss: 2.30e-02 lr: 3.10e-05:  38%|▍| 5258/13852 [19:36<31:37,  4.53it/s\u001b[A\n",
      "Training loss: 2.93e-02 lr: 3.10e-05:  38%|▍| 5259/13852 [19:37<31:41,  4.52it/s\u001b[A\n",
      "Training loss: 2.48e-02 lr: 3.10e-05:  38%|▍| 5260/13852 [19:37<32:02,  4.47it/s\u001b[A\n",
      "Training loss: 1.96e-02 lr: 3.10e-05:  38%|▍| 5261/13852 [19:37<32:25,  4.42it/s\u001b[A\n",
      "Training loss: 9.11e-02 lr: 3.10e-05:  38%|▍| 5262/13852 [19:37<32:28,  4.41it/s\u001b[A\n",
      "Training loss: 8.76e-02 lr: 3.10e-05:  38%|▍| 5263/13852 [19:37<33:19,  4.29it/s\u001b[A\n",
      "Training loss: 9.77e-02 lr: 3.10e-05:  38%|▍| 5264/13852 [19:38<33:36,  4.26it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 3.10e-05:  38%|▍| 5265/13852 [19:38<33:50,  4.23it/s\u001b[A\n",
      "Training loss: 6.10e-02 lr: 3.10e-05:  38%|▍| 5266/13852 [19:38<33:38,  4.25it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.10e-05:  38%|▍| 5267/13852 [19:38<33:02,  4.33it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 3.10e-05:  38%|▍| 5268/13852 [19:39<32:51,  4.35it/s\u001b[A\n",
      "Training loss: 9.51e-02 lr: 3.10e-05:  38%|▍| 5269/13852 [19:39<32:33,  4.39it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 3.10e-05:  38%|▍| 5270/13852 [19:39<32:20,  4.42it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 3.10e-05:  38%|▍| 5271/13852 [19:39<32:19,  4.43it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 3.10e-05:  38%|▍| 5272/13852 [19:40<32:02,  4.46it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 3.10e-05:  38%|▍| 5273/13852 [19:40<31:43,  4.51it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 3.10e-05:  38%|▍| 5274/13852 [19:40<31:33,  4.53it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 3.10e-05:  38%|▍| 5275/13852 [19:40<31:25,  4.55it/s\u001b[A\n",
      "Training loss: 2.33e-02 lr: 3.10e-05:  38%|▍| 5276/13852 [19:40<31:35,  4.52it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 3.10e-05:  38%|▍| 5277/13852 [19:41<31:35,  4.52it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 3.10e-05:  38%|▍| 5278/13852 [19:41<31:55,  4.48it/s\u001b[A\n",
      "Training loss: 4.26e-02 lr: 3.09e-05:  38%|▍| 5279/13852 [19:41<31:54,  4.48it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 3.09e-05:  38%|▍| 5280/13852 [19:41<31:55,  4.47it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 3.09e-05:  38%|▍| 5281/13852 [19:42<31:55,  4.47it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 3.09e-05:  38%|▍| 5282/13852 [19:42<32:02,  4.46it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 3.09e-05:  38%|▍| 5283/13852 [19:42<31:58,  4.47it/s\u001b[A\n",
      "Training loss: 3.94e-02 lr: 3.09e-05:  38%|▍| 5284/13852 [19:42<31:48,  4.49it/s\u001b[A\n",
      "Training loss: 2.99e-02 lr: 3.09e-05:  38%|▍| 5285/13852 [19:42<31:34,  4.52it/s\u001b[A\n",
      "Training loss: 2.34e-02 lr: 3.09e-05:  38%|▍| 5286/13852 [19:43<31:26,  4.54it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.09e-05:  38%|▍| 5287/13852 [19:43<31:37,  4.51it/s\u001b[A\n",
      "Training loss: 8.83e-02 lr: 3.09e-05:  38%|▍| 5288/13852 [19:43<31:35,  4.52it/s\u001b[A\n",
      "Training loss: 8.12e-02 lr: 3.09e-05:  38%|▍| 5289/13852 [19:43<31:35,  4.52it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.09e-05:  38%|▍| 5290/13852 [19:43<31:35,  4.52it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.09e-05:  38%|▍| 5291/13852 [19:44<31:36,  4.51it/s\u001b[A\n",
      "Training loss: 8.48e-02 lr: 3.09e-05:  38%|▍| 5292/13852 [19:44<31:35,  4.52it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.09e-05:  38%|▍| 5293/13852 [19:44<31:39,  4.51it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 3.09e-05:  38%|▍| 5294/13852 [19:44<31:40,  4.50it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 3.09e-05:  38%|▍| 5295/13852 [19:45<31:38,  4.51it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 3.09e-05:  38%|▍| 5296/13852 [19:45<31:33,  4.52it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 3.09e-05:  38%|▍| 5297/13852 [19:45<31:25,  4.54it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 3.09e-05:  38%|▍| 5298/13852 [19:45<31:17,  4.56it/s\u001b[A\n",
      "Training loss: 4.95e-02 lr: 3.09e-05:  38%|▍| 5299/13852 [19:45<31:41,  4.50it/s\u001b[A\n",
      "Training loss: 9.56e-02 lr: 3.09e-05:  38%|▍| 5300/13852 [19:46<31:36,  4.51it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 3.09e-05:  38%|▍| 5301/13852 [19:46<31:31,  4.52it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 3.09e-05:  38%|▍| 5302/13852 [19:46<31:37,  4.51it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 3.09e-05:  38%|▍| 5303/13852 [19:46<31:51,  4.47it/s\u001b[A\n",
      "Training loss: 8.40e-02 lr: 3.09e-05:  38%|▍| 5304/13852 [19:47<31:50,  4.47it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 3.09e-05:  38%|▍| 5305/13852 [19:47<31:57,  4.46it/s\u001b[A\n",
      "Training loss: 8.52e-02 lr: 3.08e-05:  38%|▍| 5306/13852 [19:47<31:52,  4.47it/s\u001b[A\n",
      "Training loss: 6.64e-02 lr: 3.08e-05:  38%|▍| 5307/13852 [19:47<31:47,  4.48it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 3.08e-05:  38%|▍| 5308/13852 [19:47<31:35,  4.51it/s\u001b[A\n",
      "Training loss: 7.07e-02 lr: 3.08e-05:  38%|▍| 5309/13852 [19:48<31:25,  4.53it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 3.08e-05:  38%|▍| 5310/13852 [19:48<31:16,  4.55it/s\u001b[A\n",
      "Training loss: 3.73e-02 lr: 3.08e-05:  38%|▍| 5311/13852 [19:48<31:09,  4.57it/s\u001b[A\n",
      "Training loss: 4.01e-02 lr: 3.08e-05:  38%|▍| 5312/13852 [19:48<31:18,  4.55it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 3.08e-05:  38%|▍| 5313/13852 [19:49<31:33,  4.51it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 3.08e-05:  38%|▍| 5314/13852 [19:49<31:35,  4.50it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 3.08e-05:  38%|▍| 5315/13852 [19:49<31:36,  4.50it/s\u001b[A\n",
      "Training loss: 7.96e-02 lr: 3.08e-05:  38%|▍| 5316/13852 [19:49<31:40,  4.49it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 3.08e-05:  38%|▍| 5317/13852 [19:49<31:39,  4.49it/s\u001b[A\n",
      "Training loss: 7.12e-02 lr: 3.08e-05:  38%|▍| 5318/13852 [19:50<31:44,  4.48it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 3.08e-05:  38%|▍| 5319/13852 [19:50<31:44,  4.48it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 3.08e-05:  38%|▍| 5320/13852 [19:50<31:41,  4.49it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 3.08e-05:  38%|▍| 5321/13852 [19:50<31:27,  4.52it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 3.08e-05:  38%|▍| 5322/13852 [19:51<31:18,  4.54it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 3.08e-05:  38%|▍| 5323/13852 [19:51<31:41,  4.48it/s\u001b[A\n",
      "Training loss: 6.56e-02 lr: 3.08e-05:  38%|▍| 5324/13852 [19:51<31:38,  4.49it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 3.08e-05:  38%|▍| 5325/13852 [19:51<31:33,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.99e-02 lr: 3.08e-05:  38%|▍| 5326/13852 [19:51<31:30,  4.51it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 3.08e-05:  38%|▍| 5327/13852 [19:52<31:38,  4.49it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 3.08e-05:  38%|▍| 5328/13852 [19:52<31:36,  4.50it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.08e-05:  38%|▍| 5329/13852 [19:52<31:36,  4.50it/s\u001b[A\n",
      "Training loss: 9.35e-02 lr: 3.08e-05:  38%|▍| 5330/13852 [19:52<31:34,  4.50it/s\u001b[A\n",
      "Training loss: 7.71e-02 lr: 3.08e-05:  38%|▍| 5331/13852 [19:53<31:33,  4.50it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 3.08e-05:  38%|▍| 5332/13852 [19:53<31:24,  4.52it/s\u001b[A\n",
      "Training loss: 9.05e-02 lr: 3.08e-05:  38%|▍| 5333/13852 [19:53<31:16,  4.54it/s\u001b[A\n",
      "Training loss: 8.21e-02 lr: 3.07e-05:  39%|▍| 5334/13852 [19:53<31:09,  4.56it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 3.07e-05:  39%|▍| 5335/13852 [19:53<31:29,  4.51it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 3.07e-05:  39%|▍| 5336/13852 [19:54<31:27,  4.51it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 3.07e-05:  39%|▍| 5337/13852 [19:54<31:23,  4.52it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 3.07e-05:  39%|▍| 5338/13852 [19:54<31:26,  4.51it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 3.07e-05:  39%|▍| 5339/13852 [19:54<31:27,  4.51it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 3.07e-05:  39%|▍| 5340/13852 [19:55<31:27,  4.51it/s\u001b[A\n",
      "Training loss: 4.93e-02 lr: 3.07e-05:  39%|▍| 5341/13852 [19:55<31:27,  4.51it/s\u001b[A\n",
      "Training loss: 4.29e-02 lr: 3.07e-05:  39%|▍| 5342/13852 [19:55<31:26,  4.51it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 3.07e-05:  39%|▍| 5343/13852 [19:55<31:29,  4.50it/s\u001b[A\n",
      "Training loss: 3.20e-02 lr: 3.07e-05:  39%|▍| 5344/13852 [19:55<31:20,  4.52it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 3.07e-05:  39%|▍| 5345/13852 [19:56<31:12,  4.54it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 3.07e-05:  39%|▍| 5346/13852 [19:56<31:04,  4.56it/s\u001b[A\n",
      "Training loss: 2.86e-02 lr: 3.07e-05:  39%|▍| 5347/13852 [19:56<31:01,  4.57it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 3.07e-05:  39%|▍| 5348/13852 [19:56<31:16,  4.53it/s\u001b[A\n",
      "Training loss: 2.72e-02 lr: 3.07e-05:  39%|▍| 5349/13852 [19:57<31:15,  4.53it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 3.07e-05:  39%|▍| 5350/13852 [19:57<31:32,  4.49it/s\u001b[A\n",
      "Training loss: 2.89e-02 lr: 3.07e-05:  39%|▍| 5351/13852 [19:57<31:30,  4.50it/s\u001b[A\n",
      "Training loss: 7.66e-02 lr: 3.07e-05:  39%|▍| 5352/13852 [19:57<31:29,  4.50it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 3.07e-05:  39%|▍| 5353/13852 [19:57<31:27,  4.50it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 3.07e-05:  39%|▍| 5354/13852 [19:58<31:28,  4.50it/s\u001b[A\n",
      "Training loss: 4.99e-02 lr: 3.07e-05:  39%|▍| 5355/13852 [19:58<31:29,  4.50it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 3.07e-05:  39%|▍| 5356/13852 [19:58<31:34,  4.49it/s\u001b[A\n",
      "Training loss: 3.01e-02 lr: 3.07e-05:  39%|▍| 5357/13852 [19:58<31:22,  4.51it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 3.07e-05:  39%|▍| 5358/13852 [19:59<31:46,  4.46it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 3.07e-05:  39%|▍| 5359/13852 [19:59<31:44,  4.46it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 3.07e-05:  39%|▍| 5360/13852 [19:59<31:37,  4.47it/s\u001b[A\n",
      "Training loss: 3.20e-02 lr: 3.07e-05:  39%|▍| 5361/13852 [19:59<31:30,  4.49it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 3.06e-05:  39%|▍| 5362/13852 [19:59<31:26,  4.50it/s\u001b[A\n",
      "Training loss: 2.80e-02 lr: 3.06e-05:  39%|▍| 5363/13852 [20:00<31:27,  4.50it/s\u001b[A\n",
      "Training loss: 3.05e-02 lr: 3.06e-05:  39%|▍| 5364/13852 [20:00<31:27,  4.50it/s\u001b[A\n",
      "Training loss: 2.20e-02 lr: 3.06e-05:  39%|▍| 5365/13852 [20:00<31:26,  4.50it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.06e-05:  39%|▍| 5366/13852 [20:00<31:26,  4.50it/s\u001b[A\n",
      "Training loss: 8.10e-02 lr: 3.06e-05:  39%|▍| 5367/13852 [20:01<31:25,  4.50it/s\u001b[A\n",
      "Training loss: 7.69e-02 lr: 3.06e-05:  39%|▍| 5368/13852 [20:01<31:29,  4.49it/s\u001b[A\n",
      "Training loss: 8.31e-02 lr: 3.06e-05:  39%|▍| 5369/13852 [20:01<31:21,  4.51it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 3.06e-05:  39%|▍| 5370/13852 [20:01<31:08,  4.54it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 3.06e-05:  39%|▍| 5371/13852 [20:01<31:24,  4.50it/s\u001b[A\n",
      "Training loss: 3.09e-02 lr: 3.06e-05:  39%|▍| 5372/13852 [20:02<31:31,  4.48it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 3.06e-05:  39%|▍| 5373/13852 [20:02<31:24,  4.50it/s\u001b[A\n",
      "Training loss: 3.02e-02 lr: 3.06e-05:  39%|▍| 5374/13852 [20:02<31:26,  4.49it/s\u001b[A\n",
      "Training loss: 2.21e-02 lr: 3.06e-05:  39%|▍| 5375/13852 [20:02<31:36,  4.47it/s\u001b[A\n",
      "Training loss: 7.81e-02 lr: 3.06e-05:  39%|▍| 5376/13852 [20:03<31:32,  4.48it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.06e-05:  39%|▍| 5377/13852 [20:03<31:36,  4.47it/s\u001b[A\n",
      "Training loss: 8.22e-02 lr: 3.06e-05:  39%|▍| 5378/13852 [20:03<31:38,  4.46it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.06e-05:  39%|▍| 5379/13852 [20:03<31:25,  4.49it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 3.06e-05:  39%|▍| 5380/13852 [20:03<31:11,  4.53it/s\u001b[A\n",
      "Training loss: 8.33e-02 lr: 3.06e-05:  39%|▍| 5381/13852 [20:04<31:01,  4.55it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.06e-05:  39%|▍| 5382/13852 [20:04<30:54,  4.57it/s\u001b[A\n",
      "Training loss: 1.73e-01 lr: 3.06e-05:  39%|▍| 5383/13852 [20:04<30:50,  4.58it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 3.06e-05:  39%|▍| 5384/13852 [20:04<30:59,  4.55it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.06e-05:  39%|▍| 5385/13852 [20:05<31:07,  4.53it/s\u001b[A\n",
      "Training loss: 8.38e-02 lr: 3.06e-05:  39%|▍| 5386/13852 [20:05<31:12,  4.52it/s\u001b[A\n",
      "Training loss: 7.68e-02 lr: 3.06e-05:  39%|▍| 5387/13852 [20:05<31:11,  4.52it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 3.06e-05:  39%|▍| 5388/13852 [20:05<31:12,  4.52it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 3.06e-05:  39%|▍| 5389/13852 [20:05<31:12,  4.52it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 3.05e-05:  39%|▍| 5390/13852 [20:06<31:12,  4.52it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 3.05e-05:  39%|▍| 5391/13852 [20:06<31:12,  4.52it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 3.05e-05:  39%|▍| 5392/13852 [20:06<31:13,  4.51it/s\u001b[A\n",
      "Training loss: 4.78e-02 lr: 3.05e-05:  39%|▍| 5393/13852 [20:06<31:06,  4.53it/s\u001b[A\n",
      "Training loss: 3.52e-02 lr: 3.05e-05:  39%|▍| 5394/13852 [20:07<30:55,  4.56it/s\u001b[A\n",
      "Training loss: 2.58e-02 lr: 3.05e-05:  39%|▍| 5395/13852 [20:07<31:27,  4.48it/s\u001b[A\n",
      "Training loss: 2.43e-02 lr: 3.05e-05:  39%|▍| 5396/13852 [20:07<31:44,  4.44it/s\u001b[A\n",
      "Training loss: 3.14e-02 lr: 3.05e-05:  39%|▍| 5397/13852 [20:07<31:51,  4.42it/s\u001b[A\n",
      "Training loss: 3.03e-02 lr: 3.05e-05:  39%|▍| 5398/13852 [20:07<32:45,  4.30it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 3.05e-05:  39%|▍| 5399/13852 [20:08<33:18,  4.23it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 3.05e-05:  39%|▍| 5400/13852 [20:08<33:41,  4.18it/s\u001b[A\n",
      "Training loss: 8.50e-02 lr: 3.05e-05:  39%|▍| 5401/13852 [20:08<33:41,  4.18it/s\u001b[A\n",
      "Training loss: 8.82e-02 lr: 3.05e-05:  39%|▍| 5402/13852 [20:08<32:54,  4.28it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 3.05e-05:  39%|▍| 5403/13852 [20:09<32:22,  4.35it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 3.05e-05:  39%|▍| 5404/13852 [20:09<32:02,  4.39it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 3.05e-05:  39%|▍| 5405/13852 [20:09<31:50,  4.42it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 3.05e-05:  39%|▍| 5406/13852 [20:09<31:45,  4.43it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 3.05e-05:  39%|▍| 5407/13852 [20:10<31:36,  4.45it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 3.05e-05:  39%|▍| 5408/13852 [20:10<31:33,  4.46it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 3.05e-05:  39%|▍| 5409/13852 [20:10<31:29,  4.47it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.05e-05:  39%|▍| 5410/13852 [20:10<31:26,  4.48it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 3.05e-05:  39%|▍| 5411/13852 [20:10<31:14,  4.50it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 3.05e-05:  39%|▍| 5412/13852 [20:11<31:04,  4.53it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 3.05e-05:  39%|▍| 5413/13852 [20:11<31:20,  4.49it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 3.05e-05:  39%|▍| 5414/13852 [20:11<31:16,  4.50it/s\u001b[A\n",
      "Training loss: 8.55e-02 lr: 3.05e-05:  39%|▍| 5415/13852 [20:11<31:14,  4.50it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.05e-05:  39%|▍| 5416/13852 [20:12<31:13,  4.50it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 3.04e-05:  39%|▍| 5417/13852 [20:12<31:23,  4.48it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 3.04e-05:  39%|▍| 5418/13852 [20:12<31:20,  4.49it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.04e-05:  39%|▍| 5419/13852 [20:12<31:22,  4.48it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.04e-05:  39%|▍| 5420/13852 [20:12<31:35,  4.45it/s\u001b[A\n",
      "Training loss: 9.30e-02 lr: 3.04e-05:  39%|▍| 5421/13852 [20:13<31:31,  4.46it/s\u001b[A\n",
      "Training loss: 7.07e-02 lr: 3.04e-05:  39%|▍| 5422/13852 [20:13<31:20,  4.48it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.05e-02 lr: 3.04e-05:  39%|▍| 5423/13852 [20:13<31:10,  4.51it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 3.04e-05:  39%|▍| 5424/13852 [20:13<31:23,  4.47it/s\u001b[A\n",
      "Training loss: 8.12e-02 lr: 3.04e-05:  39%|▍| 5425/13852 [20:14<31:16,  4.49it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 3.04e-05:  39%|▍| 5426/13852 [20:14<31:10,  4.50it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 3.04e-05:  39%|▍| 5427/13852 [20:14<31:11,  4.50it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 3.04e-05:  39%|▍| 5428/13852 [20:14<31:08,  4.51it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 3.04e-05:  39%|▍| 5429/13852 [20:14<31:06,  4.51it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 3.04e-05:  39%|▍| 5430/13852 [20:15<31:06,  4.51it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 3.04e-05:  39%|▍| 5431/13852 [20:15<31:08,  4.51it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 3.04e-05:  39%|▍| 5432/13852 [20:15<31:06,  4.51it/s\u001b[A\n",
      "Training loss: 9.12e-02 lr: 3.04e-05:  39%|▍| 5433/13852 [20:15<31:04,  4.51it/s\u001b[A\n",
      "Training loss: 8.45e-02 lr: 3.04e-05:  39%|▍| 5434/13852 [20:16<30:54,  4.54it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 3.04e-05:  39%|▍| 5435/13852 [20:16<30:49,  4.55it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 3.04e-05:  39%|▍| 5436/13852 [20:16<30:42,  4.57it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 3.04e-05:  39%|▍| 5437/13852 [20:16<30:38,  4.58it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 3.04e-05:  39%|▍| 5438/13852 [20:16<30:43,  4.56it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 3.04e-05:  39%|▍| 5439/13852 [20:17<30:52,  4.54it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 3.04e-05:  39%|▍| 5440/13852 [20:17<31:10,  4.50it/s\u001b[A\n",
      "Training loss: 4.61e-02 lr: 3.04e-05:  39%|▍| 5441/13852 [20:17<31:10,  4.50it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 3.04e-05:  39%|▍| 5442/13852 [20:17<31:11,  4.49it/s\u001b[A\n",
      "Training loss: 3.48e-02 lr: 3.04e-05:  39%|▍| 5443/13852 [20:18<31:11,  4.49it/s\u001b[A\n",
      "Training loss: 3.15e-02 lr: 3.04e-05:  39%|▍| 5444/13852 [20:18<31:12,  4.49it/s\u001b[A\n",
      "Training loss: 2.50e-02 lr: 3.03e-05:  39%|▍| 5445/13852 [20:18<31:27,  4.45it/s\u001b[A\n",
      "Training loss: 2.41e-02 lr: 3.03e-05:  39%|▍| 5446/13852 [20:18<31:17,  4.48it/s\u001b[A\n",
      "Training loss: 1.81e-02 lr: 3.03e-05:  39%|▍| 5447/13852 [20:18<31:02,  4.51it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 3.03e-05:  39%|▍| 5448/13852 [20:19<30:51,  4.54it/s\u001b[A\n",
      "Training loss: 8.62e-02 lr: 3.03e-05:  39%|▍| 5449/13852 [20:19<31:05,  4.51it/s\u001b[A\n",
      "Training loss: 6.17e-02 lr: 3.03e-05:  39%|▍| 5450/13852 [20:19<31:02,  4.51it/s\u001b[A\n",
      "Training loss: 8.26e-02 lr: 3.03e-05:  39%|▍| 5451/13852 [20:19<31:02,  4.51it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.03e-05:  39%|▍| 5452/13852 [20:20<30:59,  4.52it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 3.03e-05:  39%|▍| 5453/13852 [20:20<31:03,  4.51it/s\u001b[A\n",
      "Training loss: 8.28e-02 lr: 3.03e-05:  39%|▍| 5454/13852 [20:20<31:06,  4.50it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 3.03e-05:  39%|▍| 5455/13852 [20:20<31:05,  4.50it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 3.03e-05:  39%|▍| 5456/13852 [20:20<31:04,  4.50it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 3.03e-05:  39%|▍| 5457/13852 [20:21<31:05,  4.50it/s\u001b[A\n",
      "Training loss: 8.19e-02 lr: 3.03e-05:  39%|▍| 5458/13852 [20:21<31:11,  4.48it/s\u001b[A\n",
      "Training loss: 7.66e-02 lr: 3.03e-05:  39%|▍| 5459/13852 [20:21<30:59,  4.51it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 3.03e-05:  39%|▍| 5460/13852 [20:21<30:53,  4.53it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 3.03e-05:  39%|▍| 5461/13852 [20:22<31:01,  4.51it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 3.03e-05:  39%|▍| 5462/13852 [20:22<31:10,  4.49it/s\u001b[A\n",
      "Training loss: 8.39e-02 lr: 3.03e-05:  39%|▍| 5463/13852 [20:22<31:07,  4.49it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.03e-05:  39%|▍| 5464/13852 [20:22<31:11,  4.48it/s\u001b[A\n",
      "Training loss: 8.46e-02 lr: 3.03e-05:  39%|▍| 5465/13852 [20:22<31:07,  4.49it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 3.03e-05:  39%|▍| 5466/13852 [20:23<31:06,  4.49it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 3.03e-05:  39%|▍| 5467/13852 [20:23<31:06,  4.49it/s\u001b[A\n",
      "Training loss: 6.70e-02 lr: 3.03e-05:  39%|▍| 5468/13852 [20:23<31:07,  4.49it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 3.03e-05:  39%|▍| 5469/13852 [20:23<31:04,  4.50it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 3.03e-05:  39%|▍| 5470/13852 [20:24<30:51,  4.53it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 3.03e-05:  39%|▍| 5471/13852 [20:24<30:43,  4.55it/s\u001b[A\n",
      "Training loss: 6.41e-02 lr: 3.03e-05:  40%|▍| 5472/13852 [20:24<30:37,  4.56it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 3.02e-05:  40%|▍| 5473/13852 [20:24<30:37,  4.56it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 3.02e-05:  40%|▍| 5474/13852 [20:24<30:40,  4.55it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 3.02e-05:  40%|▍| 5475/13852 [20:25<30:43,  4.54it/s\u001b[A\n",
      "Training loss: 8.41e-02 lr: 3.02e-05:  40%|▍| 5476/13852 [20:25<30:49,  4.53it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 3.02e-05:  40%|▍| 5477/13852 [20:25<30:53,  4.52it/s\u001b[A\n",
      "Training loss: 9.75e-02 lr: 3.02e-05:  40%|▍| 5478/13852 [20:25<31:07,  4.48it/s\u001b[A\n",
      "Training loss: 8.50e-02 lr: 3.02e-05:  40%|▍| 5479/13852 [20:26<31:07,  4.48it/s\u001b[A\n",
      "Training loss: 6.20e-02 lr: 3.02e-05:  40%|▍| 5480/13852 [20:26<31:05,  4.49it/s\u001b[A\n",
      "Training loss: 9.95e-02 lr: 3.02e-05:  40%|▍| 5481/13852 [20:26<31:03,  4.49it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.02e-05:  40%|▍| 5482/13852 [20:26<31:03,  4.49it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 3.02e-05:  40%|▍| 5483/13852 [20:26<30:53,  4.51it/s\u001b[A\n",
      "Training loss: 8.96e-02 lr: 3.02e-05:  40%|▍| 5484/13852 [20:27<30:48,  4.53it/s\u001b[A\n",
      "Training loss: 6.56e-02 lr: 3.02e-05:  40%|▍| 5485/13852 [20:27<31:03,  4.49it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 3.02e-05:  40%|▍| 5486/13852 [20:27<31:01,  4.49it/s\u001b[A\n",
      "Training loss: 7.79e-02 lr: 3.02e-05:  40%|▍| 5487/13852 [20:27<30:56,  4.51it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 3.02e-05:  40%|▍| 5488/13852 [20:28<30:55,  4.51it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 3.02e-05:  40%|▍| 5489/13852 [20:28<30:55,  4.51it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 3.02e-05:  40%|▍| 5490/13852 [20:28<30:53,  4.51it/s\u001b[A\n",
      "Training loss: 3.99e-02 lr: 3.02e-05:  40%|▍| 5491/13852 [20:28<30:54,  4.51it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 3.02e-05:  40%|▍| 5492/13852 [20:28<30:53,  4.51it/s\u001b[A\n",
      "Training loss: 7.35e-02 lr: 3.02e-05:  40%|▍| 5493/13852 [20:29<30:54,  4.51it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 3.02e-05:  40%|▍| 5494/13852 [20:29<31:01,  4.49it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 3.02e-05:  40%|▍| 5495/13852 [20:29<30:50,  4.52it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 3.02e-05:  40%|▍| 5496/13852 [20:29<30:38,  4.54it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 3.02e-05:  40%|▍| 5497/13852 [20:30<30:54,  4.51it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 3.02e-05:  40%|▍| 5498/13852 [20:30<30:52,  4.51it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 3.02e-05:  40%|▍| 5499/13852 [20:30<30:50,  4.51it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 3.01e-05:  40%|▍| 5500/13852 [20:30<30:52,  4.51it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 3.01e-05:  40%|▍| 5501/13852 [20:30<30:54,  4.50it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 3.01e-05:  40%|▍| 5502/13852 [20:31<30:53,  4.51it/s\u001b[A\n",
      "Training loss: 3.95e-02 lr: 3.01e-05:  40%|▍| 5503/13852 [20:31<31:09,  4.47it/s\u001b[A\n",
      "Training loss: 3.19e-02 lr: 3.01e-05:  40%|▍| 5504/13852 [20:31<31:06,  4.47it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 3.01e-05:  40%|▍| 5505/13852 [20:31<31:01,  4.48it/s\u001b[A\n",
      "Training loss: 7.15e-02 lr: 3.01e-05:  40%|▍| 5506/13852 [20:32<30:56,  4.49it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 3.01e-05:  40%|▍| 5507/13852 [20:32<30:54,  4.50it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 3.01e-05:  40%|▍| 5508/13852 [20:32<30:43,  4.53it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 3.01e-05:  40%|▍| 5509/13852 [20:32<30:47,  4.52it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 3.01e-05:  40%|▍| 5510/13852 [20:32<30:44,  4.52it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 3.01e-05:  40%|▍| 5511/13852 [20:33<30:43,  4.52it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 3.01e-05:  40%|▍| 5512/13852 [20:33<30:44,  4.52it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 3.01e-05:  40%|▍| 5513/13852 [20:33<30:48,  4.51it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 3.01e-05:  40%|▍| 5514/13852 [20:33<30:49,  4.51it/s\u001b[A\n",
      "Training loss: 9.63e-02 lr: 3.01e-05:  40%|▍| 5515/13852 [20:34<30:50,  4.51it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 3.01e-05:  40%|▍| 5516/13852 [20:34<30:51,  4.50it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 3.01e-05:  40%|▍| 5517/13852 [20:34<30:51,  4.50it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 3.01e-05:  40%|▍| 5518/13852 [20:34<30:47,  4.51it/s\u001b[A\n",
      "Training loss: 9.37e-02 lr: 3.01e-05:  40%|▍| 5519/13852 [20:34<30:39,  4.53it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.98e-02 lr: 3.01e-05:  40%|▍| 5520/13852 [20:35<30:33,  4.55it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 3.01e-05:  40%|▍| 5521/13852 [20:35<30:45,  4.52it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 3.01e-05:  40%|▍| 5522/13852 [20:35<30:43,  4.52it/s\u001b[A\n",
      "Training loss: 6.12e-02 lr: 3.01e-05:  40%|▍| 5523/13852 [20:35<30:44,  4.52it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 3.01e-05:  40%|▍| 5524/13852 [20:36<30:39,  4.53it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 3.01e-05:  40%|▍| 5525/13852 [20:36<30:42,  4.52it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 3.01e-05:  40%|▍| 5526/13852 [20:36<30:44,  4.51it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 3.01e-05:  40%|▍| 5527/13852 [20:36<30:43,  4.51it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 3.00e-05:  40%|▍| 5528/13852 [20:36<30:45,  4.51it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 3.00e-05:  40%|▍| 5529/13852 [20:37<30:45,  4.51it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 3.00e-05:  40%|▍| 5530/13852 [20:37<32:07,  4.32it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 3.00e-05:  40%|▍| 5531/13852 [20:37<32:32,  4.26it/s\u001b[A\n",
      "Training loss: 3.40e-02 lr: 3.00e-05:  40%|▍| 5532/13852 [20:37<32:53,  4.22it/s\u001b[A\n",
      "Training loss: 3.00e-02 lr: 3.00e-05:  40%|▍| 5533/13852 [20:38<33:12,  4.17it/s\u001b[A\n",
      "Training loss: 3.83e-02 lr: 3.00e-05:  40%|▍| 5534/13852 [20:38<33:21,  4.16it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 3.00e-05:  40%|▍| 5535/13852 [20:38<33:20,  4.16it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 3.00e-05:  40%|▍| 5536/13852 [20:38<33:08,  4.18it/s\u001b[A\n",
      "Training loss: 9.24e-02 lr: 3.00e-05:  40%|▍| 5537/13852 [20:39<32:23,  4.28it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 3.00e-05:  40%|▍| 5538/13852 [20:39<31:53,  4.35it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.00e-05:  40%|▍| 5539/13852 [20:39<31:41,  4.37it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 3.00e-05:  40%|▍| 5540/13852 [20:39<31:21,  4.42it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 3.00e-05:  40%|▍| 5541/13852 [20:39<31:12,  4.44it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 3.00e-05:  40%|▍| 5542/13852 [20:40<31:03,  4.46it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 3.00e-05:  40%|▍| 5543/13852 [20:40<30:59,  4.47it/s\u001b[A\n",
      "Training loss: 3.19e-02 lr: 3.00e-05:  40%|▍| 5544/13852 [20:40<30:53,  4.48it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 3.00e-05:  40%|▍| 5545/13852 [20:40<30:59,  4.47it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 3.00e-05:  40%|▍| 5546/13852 [20:41<30:47,  4.50it/s\u001b[A\n",
      "Training loss: 3.20e-02 lr: 3.00e-05:  40%|▍| 5547/13852 [20:41<30:42,  4.51it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 3.00e-05:  40%|▍| 5548/13852 [20:41<31:03,  4.46it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 3.00e-05:  40%|▍| 5549/13852 [20:41<30:56,  4.47it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 3.00e-05:  40%|▍| 5550/13852 [20:41<30:50,  4.49it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 3.00e-05:  40%|▍| 5551/13852 [20:42<30:53,  4.48it/s\u001b[A\n",
      "Training loss: 4.26e-02 lr: 3.00e-05:  40%|▍| 5552/13852 [20:42<30:52,  4.48it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.00e-05:  40%|▍| 5553/13852 [20:42<30:52,  4.48it/s\u001b[A\n",
      "Training loss: 6.10e-02 lr: 3.00e-05:  40%|▍| 5554/13852 [20:42<30:48,  4.49it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 3.00e-05:  40%|▍| 5555/13852 [20:43<30:52,  4.48it/s\u001b[A\n",
      "Training loss: 3.36e-02 lr: 2.99e-05:  40%|▍| 5556/13852 [20:43<30:49,  4.48it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 2.99e-05:  40%|▍| 5557/13852 [20:43<30:39,  4.51it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 2.99e-05:  40%|▍| 5558/13852 [20:43<30:35,  4.52it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 2.99e-05:  40%|▍| 5559/13852 [20:43<30:53,  4.48it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.99e-05:  40%|▍| 5560/13852 [20:44<30:47,  4.49it/s\u001b[A\n",
      "Training loss: 9.15e-02 lr: 2.99e-05:  40%|▍| 5561/13852 [20:44<30:41,  4.50it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 2.99e-05:  40%|▍| 5562/13852 [20:44<30:49,  4.48it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 2.99e-05:  40%|▍| 5563/13852 [20:44<30:42,  4.50it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 2.99e-05:  40%|▍| 5564/13852 [20:45<30:38,  4.51it/s\u001b[A\n",
      "Training loss: 8.80e-02 lr: 2.99e-05:  40%|▍| 5565/13852 [20:45<30:35,  4.51it/s\u001b[A\n",
      "Training loss: 7.18e-02 lr: 2.99e-05:  40%|▍| 5566/13852 [20:45<30:38,  4.51it/s\u001b[A\n",
      "Training loss: 7.26e-02 lr: 2.99e-05:  40%|▍| 5567/13852 [20:45<30:36,  4.51it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 2.99e-05:  40%|▍| 5568/13852 [20:45<30:35,  4.51it/s\u001b[A\n",
      "Training loss: 8.10e-02 lr: 2.99e-05:  40%|▍| 5569/13852 [20:46<30:29,  4.53it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 2.99e-05:  40%|▍| 5570/13852 [20:46<30:20,  4.55it/s\u001b[A\n",
      "Training loss: 6.25e-02 lr: 2.99e-05:  40%|▍| 5571/13852 [20:46<30:17,  4.56it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 2.99e-05:  40%|▍| 5572/13852 [20:46<30:26,  4.53it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 2.99e-05:  40%|▍| 5573/13852 [20:47<30:32,  4.52it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 2.99e-05:  40%|▍| 5574/13852 [20:47<30:49,  4.48it/s\u001b[A\n",
      "Training loss: 8.12e-02 lr: 2.99e-05:  40%|▍| 5575/13852 [20:47<30:44,  4.49it/s\u001b[A\n",
      "Training loss: 9.06e-02 lr: 2.99e-05:  40%|▍| 5576/13852 [20:47<30:41,  4.49it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 2.99e-05:  40%|▍| 5577/13852 [20:47<30:40,  4.50it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 2.99e-05:  40%|▍| 5578/13852 [20:48<32:38,  4.22it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 2.99e-05:  40%|▍| 5579/13852 [20:48<32:38,  4.22it/s\u001b[A\n",
      "Training loss: 3.00e-02 lr: 2.99e-05:  40%|▍| 5580/13852 [20:48<32:40,  4.22it/s\u001b[A\n",
      "Training loss: 3.56e-02 lr: 2.99e-05:  40%|▍| 5581/13852 [20:48<32:45,  4.21it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 2.99e-05:  40%|▍| 5582/13852 [20:49<32:47,  4.20it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 2.98e-05:  40%|▍| 5583/13852 [20:49<32:55,  4.19it/s\u001b[A\n",
      "Training loss: 9.53e-02 lr: 2.98e-05:  40%|▍| 5584/13852 [20:49<33:08,  4.16it/s\u001b[A\n",
      "Training loss: 9.00e-02 lr: 2.98e-05:  40%|▍| 5585/13852 [20:49<33:06,  4.16it/s\u001b[A\n",
      "Training loss: 8.90e-02 lr: 2.98e-05:  40%|▍| 5586/13852 [20:50<33:05,  4.16it/s\u001b[A\n",
      "Training loss: 8.94e-02 lr: 2.98e-05:  40%|▍| 5587/13852 [20:50<33:02,  4.17it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 2.98e-05:  40%|▍| 5588/13852 [20:50<33:00,  4.17it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 2.98e-05:  40%|▍| 5589/13852 [20:50<32:58,  4.18it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 2.98e-05:  40%|▍| 5590/13852 [20:51<33:03,  4.17it/s\u001b[A\n",
      "Training loss: 7.18e-02 lr: 2.98e-05:  40%|▍| 5591/13852 [20:51<33:09,  4.15it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 2.98e-05:  40%|▍| 5592/13852 [20:51<33:12,  4.14it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 2.98e-05:  40%|▍| 5593/13852 [20:51<33:08,  4.15it/s\u001b[A\n",
      "Training loss: 6.99e-02 lr: 2.98e-05:  40%|▍| 5594/13852 [20:52<33:04,  4.16it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 2.98e-05:  40%|▍| 5595/13852 [20:52<33:16,  4.14it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.98e-05:  40%|▍| 5596/13852 [20:52<33:10,  4.15it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 2.98e-05:  40%|▍| 5597/13852 [20:52<33:03,  4.16it/s\u001b[A\n",
      "Training loss: 8.83e-02 lr: 2.98e-05:  40%|▍| 5598/13852 [20:53<33:10,  4.15it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 2.98e-05:  40%|▍| 5599/13852 [20:53<33:10,  4.15it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 2.98e-05:  40%|▍| 5600/13852 [20:53<33:06,  4.15it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 2.98e-05:  40%|▍| 5601/13852 [20:53<33:01,  4.16it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 2.98e-05:  40%|▍| 5602/13852 [20:53<32:52,  4.18it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 2.98e-05:  40%|▍| 5603/13852 [20:54<32:56,  4.17it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 2.98e-05:  40%|▍| 5604/13852 [20:54<32:53,  4.18it/s\u001b[A\n",
      "Training loss: 6.12e-02 lr: 2.98e-05:  40%|▍| 5605/13852 [20:54<32:50,  4.18it/s\u001b[A\n",
      "Training loss: 4.43e-02 lr: 2.98e-05:  40%|▍| 5606/13852 [20:54<32:57,  4.17it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 2.98e-05:  40%|▍| 5607/13852 [20:55<32:52,  4.18it/s\u001b[A\n",
      "Training loss: 3.02e-02 lr: 2.98e-05:  40%|▍| 5608/13852 [20:55<32:45,  4.19it/s\u001b[A\n",
      "Training loss: 4.95e-02 lr: 2.98e-05:  40%|▍| 5609/13852 [20:55<32:46,  4.19it/s\u001b[A\n",
      "Training loss: 9.30e-02 lr: 2.98e-05:  40%|▍| 5610/13852 [20:55<32:51,  4.18it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 2.97e-05:  41%|▍| 5611/13852 [20:56<32:51,  4.18it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 2.97e-05:  41%|▍| 5612/13852 [20:56<32:53,  4.18it/s\u001b[A\n",
      "Training loss: 3.94e-02 lr: 2.97e-05:  41%|▍| 5613/13852 [20:56<32:52,  4.18it/s\u001b[A\n",
      "Training loss: 3.27e-02 lr: 2.97e-05:  41%|▍| 5614/13852 [20:56<32:45,  4.19it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 2.97e-05:  41%|▍| 5615/13852 [20:57<32:41,  4.20it/s\u001b[A\n",
      "Training loss: 2.34e-02 lr: 2.97e-05:  41%|▍| 5616/13852 [20:57<33:04,  4.15it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.71e-02 lr: 2.97e-05:  41%|▍| 5617/13852 [20:57<32:58,  4.16it/s\u001b[A\n",
      "Training loss: 2.94e-02 lr: 2.97e-05:  41%|▍| 5618/13852 [20:57<33:02,  4.15it/s\u001b[A\n",
      "Training loss: 2.45e-02 lr: 2.97e-05:  41%|▍| 5619/13852 [20:58<33:08,  4.14it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 2.97e-05:  41%|▍| 5620/13852 [20:58<32:57,  4.16it/s\u001b[A\n",
      "Training loss: 7.73e-02 lr: 2.97e-05:  41%|▍| 5621/13852 [20:58<33:03,  4.15it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 2.97e-05:  41%|▍| 5622/13852 [20:58<32:58,  4.16it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 2.97e-05:  41%|▍| 5623/13852 [20:59<32:48,  4.18it/s\u001b[A\n",
      "Training loss: 3.83e-02 lr: 2.97e-05:  41%|▍| 5624/13852 [20:59<32:47,  4.18it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 2.97e-05:  41%|▍| 5625/13852 [20:59<32:44,  4.19it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 2.97e-05:  41%|▍| 5626/13852 [20:59<32:41,  4.19it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.97e-05:  41%|▍| 5627/13852 [20:59<32:50,  4.17it/s\u001b[A\n",
      "Training loss: 9.47e-02 lr: 2.97e-05:  41%|▍| 5628/13852 [21:00<32:50,  4.17it/s\u001b[A\n",
      "Training loss: 8.26e-02 lr: 2.97e-05:  41%|▍| 5629/13852 [21:00<32:44,  4.19it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 2.97e-05:  41%|▍| 5630/13852 [21:00<32:42,  4.19it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 2.97e-05:  41%|▍| 5631/13852 [21:00<32:43,  4.19it/s\u001b[A\n",
      "Training loss: 9.04e-02 lr: 2.97e-05:  41%|▍| 5632/13852 [21:01<32:46,  4.18it/s\u001b[A\n",
      "Training loss: 7.99e-02 lr: 2.97e-05:  41%|▍| 5633/13852 [21:01<32:59,  4.15it/s\u001b[A\n",
      "Training loss: 7.35e-02 lr: 2.97e-05:  41%|▍| 5634/13852 [21:01<32:55,  4.16it/s\u001b[A\n",
      "Training loss: 5.43e-02 lr: 2.97e-05:  41%|▍| 5635/13852 [21:01<32:48,  4.17it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 2.97e-05:  41%|▍| 5636/13852 [21:02<32:45,  4.18it/s\u001b[A\n",
      "Training loss: 3.04e-02 lr: 2.97e-05:  41%|▍| 5637/13852 [21:02<32:46,  4.18it/s\u001b[A\n",
      "Training loss: 3.84e-02 lr: 2.97e-05:  41%|▍| 5638/13852 [21:02<32:38,  4.19it/s\u001b[A\n",
      "Training loss: 3.70e-02 lr: 2.96e-05:  41%|▍| 5639/13852 [21:02<32:41,  4.19it/s\u001b[A\n",
      "Training loss: 2.99e-02 lr: 2.96e-05:  41%|▍| 5640/13852 [21:03<32:48,  4.17it/s\u001b[A\n",
      "Training loss: 3.27e-02 lr: 2.96e-05:  41%|▍| 5641/13852 [21:03<32:59,  4.15it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 2.96e-05:  41%|▍| 5642/13852 [21:03<33:06,  4.13it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 2.96e-05:  41%|▍| 5643/13852 [21:03<32:52,  4.16it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 2.96e-05:  41%|▍| 5644/13852 [21:04<32:55,  4.16it/s\u001b[A\n",
      "Training loss: 8.62e-02 lr: 2.96e-05:  41%|▍| 5645/13852 [21:04<32:56,  4.15it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 2.96e-05:  41%|▍| 5646/13852 [21:04<32:50,  4.17it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 2.96e-05:  41%|▍| 5647/13852 [21:04<32:44,  4.18it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 2.96e-05:  41%|▍| 5648/13852 [21:04<32:39,  4.19it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 2.96e-05:  41%|▍| 5649/13852 [21:05<32:34,  4.20it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 2.96e-05:  41%|▍| 5650/13852 [21:05<32:38,  4.19it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 2.96e-05:  41%|▍| 5651/13852 [21:05<32:36,  4.19it/s\u001b[A\n",
      "Training loss: 3.62e-02 lr: 2.96e-05:  41%|▍| 5652/13852 [21:05<32:42,  4.18it/s\u001b[A\n",
      "Training loss: 3.31e-02 lr: 2.96e-05:  41%|▍| 5653/13852 [21:06<32:40,  4.18it/s\u001b[A\n",
      "Training loss: 3.08e-02 lr: 2.96e-05:  41%|▍| 5654/13852 [21:06<32:39,  4.18it/s\u001b[A\n",
      "Training loss: 2.22e-02 lr: 2.96e-05:  41%|▍| 5655/13852 [21:06<32:37,  4.19it/s\u001b[A\n",
      "Training loss: 2.10e-02 lr: 2.96e-05:  41%|▍| 5656/13852 [21:06<32:29,  4.21it/s\u001b[A\n",
      "Training loss: 1.68e-02 lr: 2.96e-05:  41%|▍| 5657/13852 [21:07<32:38,  4.18it/s\u001b[A\n",
      "Training loss: 1.77e-02 lr: 2.96e-05:  41%|▍| 5658/13852 [21:07<32:52,  4.15it/s\u001b[A\n",
      "Training loss: 7.17e-02 lr: 2.96e-05:  41%|▍| 5659/13852 [21:07<32:53,  4.15it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 2.96e-05:  41%|▍| 5660/13852 [21:07<33:01,  4.13it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.96e-05:  41%|▍| 5661/13852 [21:08<32:07,  4.25it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 2.96e-05:  41%|▍| 5662/13852 [21:08<31:45,  4.30it/s\u001b[A\n",
      "Training loss: 6.78e-02 lr: 2.96e-05:  41%|▍| 5663/13852 [21:08<31:16,  4.36it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.96e-05:  41%|▍| 5664/13852 [21:08<30:54,  4.42it/s\u001b[A\n",
      "Training loss: 9.12e-02 lr: 2.96e-05:  41%|▍| 5665/13852 [21:08<30:43,  4.44it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 2.96e-05:  41%|▍| 5666/13852 [21:09<30:29,  4.47it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 2.95e-05:  41%|▍| 5667/13852 [21:09<30:23,  4.49it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 2.95e-05:  41%|▍| 5668/13852 [21:09<30:27,  4.48it/s\u001b[A\n",
      "Training loss: 7.71e-02 lr: 2.95e-05:  41%|▍| 5669/13852 [21:09<30:27,  4.48it/s\u001b[A\n",
      "Training loss: 7.03e-02 lr: 2.95e-05:  41%|▍| 5670/13852 [21:10<30:19,  4.50it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 2.95e-05:  41%|▍| 5671/13852 [21:10<30:13,  4.51it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.95e-05:  41%|▍| 5672/13852 [21:10<30:10,  4.52it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 2.95e-05:  41%|▍| 5673/13852 [21:10<30:00,  4.54it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 2.95e-05:  41%|▍| 5674/13852 [21:10<29:58,  4.55it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 2.95e-05:  41%|▍| 5675/13852 [21:11<30:05,  4.53it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 2.95e-05:  41%|▍| 5676/13852 [21:11<30:13,  4.51it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 2.95e-05:  41%|▍| 5677/13852 [21:11<30:15,  4.50it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 2.95e-05:  41%|▍| 5678/13852 [21:11<30:07,  4.52it/s\u001b[A\n",
      "Training loss: 9.25e-02 lr: 2.95e-05:  41%|▍| 5679/13852 [21:12<30:08,  4.52it/s\u001b[A\n",
      "Training loss: 9.43e-02 lr: 2.95e-05:  41%|▍| 5680/13852 [21:12<30:18,  4.49it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 2.95e-05:  41%|▍| 5681/13852 [21:12<30:14,  4.50it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 2.95e-05:  41%|▍| 5682/13852 [21:12<30:10,  4.51it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 2.95e-05:  41%|▍| 5683/13852 [21:12<30:07,  4.52it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.95e-05:  41%|▍| 5684/13852 [21:13<30:03,  4.53it/s\u001b[A\n",
      "Training loss: 3.60e-02 lr: 2.95e-05:  41%|▍| 5685/13852 [21:13<29:54,  4.55it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 2.95e-05:  41%|▍| 5686/13852 [21:13<29:51,  4.56it/s\u001b[A\n",
      "Training loss: 3.59e-02 lr: 2.95e-05:  41%|▍| 5687/13852 [21:13<30:05,  4.52it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 2.95e-05:  41%|▍| 5688/13852 [21:14<30:15,  4.50it/s\u001b[A\n",
      "Training loss: 3.10e-02 lr: 2.95e-05:  41%|▍| 5689/13852 [21:14<30:11,  4.51it/s\u001b[A\n",
      "Training loss: 2.28e-02 lr: 2.95e-05:  41%|▍| 5690/13852 [21:14<30:09,  4.51it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 2.95e-05:  41%|▍| 5691/13852 [21:14<30:05,  4.52it/s\u001b[A\n",
      "Training loss: 2.48e-02 lr: 2.95e-05:  41%|▍| 5692/13852 [21:14<30:02,  4.53it/s\u001b[A\n",
      "Training loss: 2.02e-02 lr: 2.95e-05:  41%|▍| 5693/13852 [21:15<30:00,  4.53it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 2.94e-05:  41%|▍| 5694/13852 [21:15<30:00,  4.53it/s\u001b[A\n",
      "Training loss: 9.09e-02 lr: 2.94e-05:  41%|▍| 5695/13852 [21:15<30:06,  4.51it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 2.94e-05:  41%|▍| 5696/13852 [21:15<30:03,  4.52it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 2.94e-05:  41%|▍| 5697/13852 [21:16<29:57,  4.54it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 2.94e-05:  41%|▍| 5698/13852 [21:16<29:52,  4.55it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 2.94e-05:  41%|▍| 5699/13852 [21:16<29:47,  4.56it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 2.94e-05:  41%|▍| 5700/13852 [21:16<29:43,  4.57it/s\u001b[A\n",
      "Training loss: 3.68e-02 lr: 2.94e-05:  41%|▍| 5701/13852 [21:16<29:46,  4.56it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 2.94e-05:  41%|▍| 5702/13852 [21:17<29:54,  4.54it/s\u001b[A\n",
      "Training loss: 6.61e-02 lr: 2.94e-05:  41%|▍| 5703/13852 [21:17<30:18,  4.48it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 2.94e-05:  41%|▍| 5704/13852 [21:17<30:17,  4.48it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 2.94e-05:  41%|▍| 5705/13852 [21:17<30:11,  4.50it/s\u001b[A\n",
      "Training loss: 2.85e-02 lr: 2.94e-05:  41%|▍| 5706/13852 [21:18<30:08,  4.50it/s\u001b[A\n",
      "Training loss: 3.34e-02 lr: 2.94e-05:  41%|▍| 5707/13852 [21:18<30:04,  4.51it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 2.94e-05:  41%|▍| 5708/13852 [21:18<30:15,  4.49it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 2.94e-05:  41%|▍| 5709/13852 [21:18<30:12,  4.49it/s\u001b[A\n",
      "Training loss: 3.89e-02 lr: 2.94e-05:  41%|▍| 5710/13852 [21:18<30:01,  4.52it/s\u001b[A\n",
      "Training loss: 8.21e-02 lr: 2.94e-05:  41%|▍| 5711/13852 [21:19<29:57,  4.53it/s\u001b[A\n",
      "Training loss: 8.63e-02 lr: 2.94e-05:  41%|▍| 5712/13852 [21:19<30:00,  4.52it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 2.94e-05:  41%|▍| 5713/13852 [21:19<30:00,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.91e-02 lr: 2.94e-05:  41%|▍| 5714/13852 [21:19<30:07,  4.50it/s\u001b[A\n",
      "Training loss: 7.68e-02 lr: 2.94e-05:  41%|▍| 5715/13852 [21:20<30:03,  4.51it/s\u001b[A\n",
      "Training loss: 7.69e-02 lr: 2.94e-05:  41%|▍| 5716/13852 [21:20<30:01,  4.52it/s\u001b[A\n",
      "Training loss: 7.41e-02 lr: 2.94e-05:  41%|▍| 5717/13852 [21:20<30:01,  4.52it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 2.94e-05:  41%|▍| 5718/13852 [21:20<30:12,  4.49it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 2.94e-05:  41%|▍| 5719/13852 [21:20<30:14,  4.48it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 2.94e-05:  41%|▍| 5720/13852 [21:21<30:10,  4.49it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 2.94e-05:  41%|▍| 5721/13852 [21:21<30:08,  4.50it/s\u001b[A\n",
      "Training loss: 3.69e-02 lr: 2.93e-05:  41%|▍| 5722/13852 [21:21<30:02,  4.51it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 2.93e-05:  41%|▍| 5723/13852 [21:21<29:48,  4.54it/s\u001b[A\n",
      "Training loss: 6.46e-02 lr: 2.93e-05:  41%|▍| 5724/13852 [21:22<30:04,  4.50it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 2.93e-05:  41%|▍| 5725/13852 [21:22<30:16,  4.47it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 2.93e-05:  41%|▍| 5726/13852 [21:22<30:09,  4.49it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 2.93e-05:  41%|▍| 5727/13852 [21:22<30:08,  4.49it/s\u001b[A\n",
      "Training loss: 3.23e-02 lr: 2.93e-05:  41%|▍| 5728/13852 [21:22<30:17,  4.47it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 2.93e-05:  41%|▍| 5729/13852 [21:23<30:14,  4.48it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.93e-05:  41%|▍| 5730/13852 [21:23<30:11,  4.48it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 2.93e-05:  41%|▍| 5731/13852 [21:23<30:08,  4.49it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 2.93e-05:  41%|▍| 5732/13852 [21:23<30:06,  4.49it/s\u001b[A\n",
      "Training loss: 9.52e-02 lr: 2.93e-05:  41%|▍| 5733/13852 [21:24<30:01,  4.51it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 2.93e-05:  41%|▍| 5734/13852 [21:24<29:50,  4.53it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 2.93e-05:  41%|▍| 5735/13852 [21:24<29:42,  4.55it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 2.93e-05:  41%|▍| 5736/13852 [21:24<29:53,  4.53it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 2.93e-05:  41%|▍| 5737/13852 [21:24<29:52,  4.53it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 2.93e-05:  41%|▍| 5738/13852 [21:25<29:52,  4.53it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.93e-05:  41%|▍| 5739/13852 [21:25<29:47,  4.54it/s\u001b[A\n",
      "Training loss: 4.26e-02 lr: 2.93e-05:  41%|▍| 5740/13852 [21:25<29:48,  4.54it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 2.93e-05:  41%|▍| 5741/13852 [21:25<29:52,  4.52it/s\u001b[A\n",
      "Training loss: 2.87e-02 lr: 2.93e-05:  41%|▍| 5742/13852 [21:26<29:54,  4.52it/s\u001b[A\n",
      "Training loss: 3.37e-02 lr: 2.93e-05:  41%|▍| 5743/13852 [21:26<29:57,  4.51it/s\u001b[A\n",
      "Training loss: 2.79e-02 lr: 2.93e-05:  41%|▍| 5744/13852 [21:26<29:56,  4.51it/s\u001b[A\n",
      "Training loss: 2.87e-02 lr: 2.93e-05:  41%|▍| 5745/13852 [21:26<29:55,  4.51it/s\u001b[A\n",
      "Training loss: 2.19e-02 lr: 2.93e-05:  41%|▍| 5746/13852 [21:26<29:49,  4.53it/s\u001b[A\n",
      "Training loss: 7.71e-02 lr: 2.93e-05:  41%|▍| 5747/13852 [21:27<29:42,  4.55it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.93e-05:  41%|▍| 5748/13852 [21:27<29:50,  4.53it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 2.93e-05:  42%|▍| 5749/13852 [21:27<29:50,  4.52it/s\u001b[A\n",
      "Training loss: 3.04e-02 lr: 2.92e-05:  42%|▍| 5750/13852 [21:27<29:54,  4.52it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 2.92e-05:  42%|▍| 5751/13852 [21:28<29:56,  4.51it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 2.92e-05:  42%|▍| 5752/13852 [21:28<29:58,  4.50it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 2.92e-05:  42%|▍| 5753/13852 [21:28<29:56,  4.51it/s\u001b[A\n",
      "Training loss: 6.22e-02 lr: 2.92e-05:  42%|▍| 5754/13852 [21:28<29:56,  4.51it/s\u001b[A\n",
      "Training loss: 8.10e-02 lr: 2.92e-05:  42%|▍| 5755/13852 [21:28<29:53,  4.52it/s\u001b[A\n",
      "Training loss: 6.06e-02 lr: 2.92e-05:  42%|▍| 5756/13852 [21:29<29:52,  4.52it/s\u001b[A\n",
      "Training loss: 8.46e-02 lr: 2.92e-05:  42%|▍| 5757/13852 [21:29<29:56,  4.51it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 2.92e-05:  42%|▍| 5758/13852 [21:29<29:48,  4.53it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 2.92e-05:  42%|▍| 5759/13852 [21:29<29:52,  4.52it/s\u001b[A\n",
      "Training loss: 7.01e-02 lr: 2.92e-05:  42%|▍| 5760/13852 [21:30<29:44,  4.53it/s\u001b[A\n",
      "Training loss: 5.32e-02 lr: 2.92e-05:  42%|▍| 5761/13852 [21:30<29:40,  4.54it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 2.92e-05:  42%|▍| 5762/13852 [21:30<29:41,  4.54it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 2.92e-05:  42%|▍| 5763/13852 [21:30<29:39,  4.54it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 2.92e-05:  42%|▍| 5764/13852 [21:30<29:44,  4.53it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 2.92e-05:  42%|▍| 5765/13852 [21:31<29:45,  4.53it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 2.92e-05:  42%|▍| 5766/13852 [21:31<29:59,  4.49it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 2.92e-05:  42%|▍| 5767/13852 [21:31<30:02,  4.48it/s\u001b[A\n",
      "Training loss: 4.61e-02 lr: 2.92e-05:  42%|▍| 5768/13852 [21:31<29:59,  4.49it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 2.92e-05:  42%|▍| 5769/13852 [21:32<29:57,  4.50it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 2.92e-05:  42%|▍| 5770/13852 [21:32<30:09,  4.47it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 2.92e-05:  42%|▍| 5771/13852 [21:32<30:03,  4.48it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 2.92e-05:  42%|▍| 5772/13852 [21:32<29:51,  4.51it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 2.92e-05:  42%|▍| 5773/13852 [21:32<29:57,  4.49it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 2.92e-05:  42%|▍| 5774/13852 [21:33<30:13,  4.45it/s\u001b[A\n",
      "Training loss: 8.44e-02 lr: 2.92e-05:  42%|▍| 5775/13852 [21:33<30:05,  4.47it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 2.92e-05:  42%|▍| 5776/13852 [21:33<30:09,  4.46it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.91e-05:  42%|▍| 5777/13852 [21:33<30:02,  4.48it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 2.91e-05:  42%|▍| 5778/13852 [21:34<30:00,  4.49it/s\u001b[A\n",
      "Training loss: 8.22e-02 lr: 2.91e-05:  42%|▍| 5779/13852 [21:34<29:56,  4.49it/s\u001b[A\n",
      "Training loss: 7.69e-02 lr: 2.91e-05:  42%|▍| 5780/13852 [21:34<29:54,  4.50it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 2.91e-05:  42%|▍| 5781/13852 [21:34<29:51,  4.51it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 2.91e-05:  42%|▍| 5782/13852 [21:34<29:42,  4.53it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 2.91e-05:  42%|▍| 5783/13852 [21:35<29:32,  4.55it/s\u001b[A\n",
      "Training loss: 3.65e-02 lr: 2.91e-05:  42%|▍| 5784/13852 [21:35<29:30,  4.56it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 2.91e-05:  42%|▍| 5785/13852 [21:35<29:43,  4.52it/s\u001b[A\n",
      "Training loss: 4.16e-02 lr: 2.91e-05:  42%|▍| 5786/13852 [21:35<29:43,  4.52it/s\u001b[A\n",
      "Training loss: 7.12e-02 lr: 2.91e-05:  42%|▍| 5787/13852 [21:36<29:44,  4.52it/s\u001b[A\n",
      "Training loss: 7.57e-02 lr: 2.91e-05:  42%|▍| 5788/13852 [21:36<29:47,  4.51it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 2.91e-05:  42%|▍| 5789/13852 [21:36<29:49,  4.51it/s\u001b[A\n",
      "Training loss: 6.96e-02 lr: 2.91e-05:  42%|▍| 5790/13852 [21:36<29:47,  4.51it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 2.91e-05:  42%|▍| 5791/13852 [21:36<29:45,  4.52it/s\u001b[A\n",
      "Training loss: 7.39e-02 lr: 2.91e-05:  42%|▍| 5792/13852 [21:37<29:45,  4.51it/s\u001b[A\n",
      "Training loss: 6.20e-02 lr: 2.91e-05:  42%|▍| 5793/13852 [21:37<29:58,  4.48it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 2.91e-05:  42%|▍| 5794/13852 [21:37<29:53,  4.49it/s\u001b[A\n",
      "Training loss: 9.34e-02 lr: 2.91e-05:  42%|▍| 5795/13852 [21:37<29:46,  4.51it/s\u001b[A\n",
      "Training loss: 7.82e-02 lr: 2.91e-05:  42%|▍| 5796/13852 [21:38<30:49,  4.36it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 2.91e-05:  42%|▍| 5797/13852 [21:38<31:21,  4.28it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 2.91e-05:  42%|▍| 5798/13852 [21:38<31:43,  4.23it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 2.91e-05:  42%|▍| 5799/13852 [21:38<31:13,  4.30it/s\u001b[A\n",
      "Training loss: 8.83e-02 lr: 2.91e-05:  42%|▍| 5800/13852 [21:38<30:46,  4.36it/s\u001b[A\n",
      "Training loss: 8.63e-02 lr: 2.91e-05:  42%|▍| 5801/13852 [21:39<30:26,  4.41it/s\u001b[A\n",
      "Training loss: 7.94e-02 lr: 2.91e-05:  42%|▍| 5802/13852 [21:39<30:06,  4.46it/s\u001b[A\n",
      "Training loss: 6.93e-02 lr: 2.91e-05:  42%|▍| 5803/13852 [21:39<29:47,  4.50it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 2.91e-05:  42%|▍| 5804/13852 [21:39<29:47,  4.50it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 2.90e-05:  42%|▍| 5805/13852 [21:40<30:04,  4.46it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 2.90e-05:  42%|▍| 5806/13852 [21:40<30:03,  4.46it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 2.90e-05:  42%|▍| 5807/13852 [21:40<29:59,  4.47it/s\u001b[A\n",
      "Training loss: 2.89e-02 lr: 2.90e-05:  42%|▍| 5808/13852 [21:40<29:52,  4.49it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 2.90e-05:  42%|▍| 5809/13852 [21:40<29:50,  4.49it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 2.90e-05:  42%|▍| 5810/13852 [21:41<29:47,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.70e-02 lr: 2.90e-05:  42%|▍| 5811/13852 [21:41<29:58,  4.47it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 2.90e-05:  42%|▍| 5812/13852 [21:41<29:51,  4.49it/s\u001b[A\n",
      "Training loss: 2.75e-02 lr: 2.90e-05:  42%|▍| 5813/13852 [21:41<29:48,  4.49it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 2.90e-05:  42%|▍| 5814/13852 [21:42<29:37,  4.52it/s\u001b[A\n",
      "Training loss: 9.46e-02 lr: 2.90e-05:  42%|▍| 5815/13852 [21:42<29:36,  4.52it/s\u001b[A\n",
      "Training loss: 6.68e-02 lr: 2.90e-05:  42%|▍| 5816/13852 [21:42<29:31,  4.54it/s\u001b[A\n",
      "Training loss: 9.13e-02 lr: 2.90e-05:  42%|▍| 5817/13852 [21:42<29:36,  4.52it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 2.90e-05:  42%|▍| 5818/13852 [21:42<29:35,  4.53it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 2.90e-05:  42%|▍| 5819/13852 [21:43<29:36,  4.52it/s\u001b[A\n",
      "Training loss: 7.24e-02 lr: 2.90e-05:  42%|▍| 5820/13852 [21:43<29:40,  4.51it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 2.90e-05:  42%|▍| 5821/13852 [21:43<29:46,  4.50it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 2.90e-05:  42%|▍| 5822/13852 [21:43<29:42,  4.50it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 2.90e-05:  42%|▍| 5823/13852 [21:44<29:38,  4.51it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 2.90e-05:  42%|▍| 5824/13852 [21:44<29:39,  4.51it/s\u001b[A\n",
      "Training loss: 5.63e-02 lr: 2.90e-05:  42%|▍| 5825/13852 [21:44<29:41,  4.51it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.90e-05:  42%|▍| 5826/13852 [21:44<29:40,  4.51it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 2.90e-05:  42%|▍| 5827/13852 [21:44<29:34,  4.52it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.90e-05:  42%|▍| 5828/13852 [21:45<29:25,  4.55it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 2.90e-05:  42%|▍| 5829/13852 [21:45<29:36,  4.51it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 2.90e-05:  42%|▍| 5830/13852 [21:45<29:36,  4.52it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 2.90e-05:  42%|▍| 5831/13852 [21:45<29:32,  4.52it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 2.90e-05:  42%|▍| 5832/13852 [21:46<29:32,  4.52it/s\u001b[A\n",
      "Training loss: 4.45e-02 lr: 2.89e-05:  42%|▍| 5833/13852 [21:46<29:33,  4.52it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 2.89e-05:  42%|▍| 5834/13852 [21:46<29:35,  4.52it/s\u001b[A\n",
      "Training loss: 8.46e-02 lr: 2.89e-05:  42%|▍| 5835/13852 [21:46<29:34,  4.52it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 2.89e-05:  42%|▍| 5836/13852 [21:46<29:35,  4.52it/s\u001b[A\n",
      "Training loss: 9.14e-02 lr: 2.89e-05:  42%|▍| 5837/13852 [21:47<29:41,  4.50it/s\u001b[A\n",
      "Training loss: 6.61e-02 lr: 2.89e-05:  42%|▍| 5838/13852 [21:47<29:48,  4.48it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 2.89e-05:  42%|▍| 5839/13852 [21:47<29:35,  4.51it/s\u001b[A\n",
      "Training loss: 8.85e-02 lr: 2.89e-05:  42%|▍| 5840/13852 [21:47<29:23,  4.54it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 2.89e-05:  42%|▍| 5841/13852 [21:48<30:06,  4.44it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 2.89e-05:  42%|▍| 5842/13852 [21:48<29:55,  4.46it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 2.89e-05:  42%|▍| 5843/13852 [21:48<30:04,  4.44it/s\u001b[A\n",
      "Training loss: 9.45e-02 lr: 2.89e-05:  42%|▍| 5844/13852 [21:48<29:55,  4.46it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 2.89e-05:  42%|▍| 5845/13852 [21:48<29:48,  4.48it/s\u001b[A\n",
      "Training loss: 8.40e-02 lr: 2.89e-05:  42%|▍| 5846/13852 [21:49<29:40,  4.50it/s\u001b[A\n",
      "Training loss: 6.25e-02 lr: 2.89e-05:  42%|▍| 5847/13852 [21:49<29:36,  4.51it/s\u001b[A\n",
      "Training loss: 4.72e-02 lr: 2.89e-05:  42%|▍| 5848/13852 [21:49<29:36,  4.51it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 2.89e-05:  42%|▍| 5849/13852 [21:49<29:32,  4.51it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 2.89e-05:  42%|▍| 5850/13852 [21:50<29:23,  4.54it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 2.89e-05:  42%|▍| 5851/13852 [21:50<29:15,  4.56it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 2.89e-05:  42%|▍| 5852/13852 [21:50<29:11,  4.57it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 2.89e-05:  42%|▍| 5853/13852 [21:50<29:07,  4.58it/s\u001b[A\n",
      "Training loss: 3.09e-02 lr: 2.89e-05:  42%|▍| 5854/13852 [21:50<29:12,  4.56it/s\u001b[A\n",
      "Training loss: 4.21e-02 lr: 2.89e-05:  42%|▍| 5855/13852 [21:51<29:14,  4.56it/s\u001b[A\n",
      "Training loss: 3.42e-02 lr: 2.89e-05:  42%|▍| 5856/13852 [21:51<29:33,  4.51it/s\u001b[A\n",
      "Training loss: 2.54e-02 lr: 2.89e-05:  42%|▍| 5857/13852 [21:51<29:30,  4.51it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 2.89e-05:  42%|▍| 5858/13852 [21:51<29:32,  4.51it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 2.89e-05:  42%|▍| 5859/13852 [21:52<29:31,  4.51it/s\u001b[A\n",
      "Training loss: 3.08e-02 lr: 2.88e-05:  42%|▍| 5860/13852 [21:52<29:38,  4.49it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 2.88e-05:  42%|▍| 5861/13852 [21:52<29:38,  4.49it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 2.88e-05:  42%|▍| 5862/13852 [21:52<29:37,  4.50it/s\u001b[A\n",
      "Training loss: 1.66e-01 lr: 2.88e-05:  42%|▍| 5863/13852 [21:52<29:27,  4.52it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 2.88e-05:  42%|▍| 5864/13852 [21:53<29:18,  4.54it/s\u001b[A\n",
      "Training loss: 9.63e-02 lr: 2.88e-05:  42%|▍| 5865/13852 [21:53<29:09,  4.57it/s\u001b[A\n",
      "Training loss: 7.63e-02 lr: 2.88e-05:  42%|▍| 5866/13852 [21:53<29:19,  4.54it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 2.88e-05:  42%|▍| 5867/13852 [21:53<29:20,  4.54it/s\u001b[A\n",
      "Training loss: 4.72e-02 lr: 2.88e-05:  42%|▍| 5868/13852 [21:54<29:21,  4.53it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 2.88e-05:  42%|▍| 5869/13852 [21:54<29:18,  4.54it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 2.88e-05:  42%|▍| 5870/13852 [21:54<29:20,  4.53it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.88e-05:  42%|▍| 5871/13852 [21:54<29:19,  4.54it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 2.88e-05:  42%|▍| 5872/13852 [21:54<29:21,  4.53it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 2.88e-05:  42%|▍| 5873/13852 [21:55<29:22,  4.53it/s\u001b[A\n",
      "Training loss: 8.31e-02 lr: 2.88e-05:  42%|▍| 5874/13852 [21:55<29:23,  4.52it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.88e-05:  42%|▍| 5875/13852 [21:55<29:24,  4.52it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 2.88e-05:  42%|▍| 5876/13852 [21:55<29:21,  4.53it/s\u001b[A\n",
      "Training loss: 9.63e-02 lr: 2.88e-05:  42%|▍| 5877/13852 [21:56<29:13,  4.55it/s\u001b[A\n",
      "Training loss: 7.21e-02 lr: 2.88e-05:  42%|▍| 5878/13852 [21:56<29:31,  4.50it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 2.88e-05:  42%|▍| 5879/13852 [21:56<29:27,  4.51it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 2.88e-05:  42%|▍| 5880/13852 [21:56<29:27,  4.51it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 2.88e-05:  42%|▍| 5881/13852 [21:56<29:23,  4.52it/s\u001b[A\n",
      "Training loss: 7.05e-02 lr: 2.88e-05:  42%|▍| 5882/13852 [21:57<29:18,  4.53it/s\u001b[A\n",
      "Training loss: 8.73e-02 lr: 2.88e-05:  42%|▍| 5883/13852 [21:57<29:25,  4.51it/s\u001b[A\n",
      "Training loss: 8.56e-02 lr: 2.88e-05:  42%|▍| 5884/13852 [21:57<29:26,  4.51it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.88e-05:  42%|▍| 5885/13852 [21:57<29:23,  4.52it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.88e-05:  42%|▍| 5886/13852 [21:58<29:23,  4.52it/s\u001b[A\n",
      "Training loss: 9.80e-02 lr: 2.88e-05:  42%|▍| 5887/13852 [21:58<30:16,  4.38it/s\u001b[A\n",
      "Training loss: 8.21e-02 lr: 2.87e-05:  43%|▍| 5888/13852 [21:58<30:38,  4.33it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 2.87e-05:  43%|▍| 5889/13852 [21:58<30:15,  4.39it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 2.87e-05:  43%|▍| 5890/13852 [21:58<30:01,  4.42it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 2.87e-05:  43%|▍| 5891/13852 [21:59<29:49,  4.45it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 2.87e-05:  43%|▍| 5892/13852 [21:59<29:41,  4.47it/s\u001b[A\n",
      "Training loss: 5.09e-02 lr: 2.87e-05:  43%|▍| 5893/13852 [21:59<29:37,  4.48it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 2.87e-05:  43%|▍| 5894/13852 [21:59<29:33,  4.49it/s\u001b[A\n",
      "Training loss: 6.32e-02 lr: 2.87e-05:  43%|▍| 5895/13852 [22:00<29:44,  4.46it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 2.87e-05:  43%|▍| 5896/13852 [22:00<29:43,  4.46it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 2.87e-05:  43%|▍| 5897/13852 [22:00<29:42,  4.46it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 2.87e-05:  43%|▍| 5898/13852 [22:00<29:30,  4.49it/s\u001b[A\n",
      "Training loss: 3.56e-02 lr: 2.87e-05:  43%|▍| 5899/13852 [22:00<29:18,  4.52it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 2.87e-05:  43%|▍| 5900/13852 [22:01<29:20,  4.52it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 2.87e-05:  43%|▍| 5901/13852 [22:01<29:31,  4.49it/s\u001b[A\n",
      "Training loss: 4.08e-02 lr: 2.87e-05:  43%|▍| 5902/13852 [22:01<29:27,  4.50it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 2.87e-05:  43%|▍| 5903/13852 [22:01<29:19,  4.52it/s\u001b[A\n",
      "Training loss: 3.99e-02 lr: 2.87e-05:  43%|▍| 5904/13852 [22:02<29:20,  4.52it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 2.87e-05:  43%|▍| 5905/13852 [22:02<29:34,  4.48it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 2.87e-05:  43%|▍| 5906/13852 [22:02<29:28,  4.49it/s\u001b[A\n",
      "Training loss: 4.93e-02 lr: 2.87e-05:  43%|▍| 5907/13852 [22:02<29:26,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.46e-02 lr: 2.87e-05:  43%|▍| 5908/13852 [22:02<29:25,  4.50it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 2.87e-05:  43%|▍| 5909/13852 [22:03<29:23,  4.50it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 2.87e-05:  43%|▍| 5910/13852 [22:03<29:26,  4.50it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 2.87e-05:  43%|▍| 5911/13852 [22:03<29:17,  4.52it/s\u001b[A\n",
      "Training loss: 4.38e-02 lr: 2.87e-05:  43%|▍| 5912/13852 [22:03<29:25,  4.50it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 2.87e-05:  43%|▍| 5913/13852 [22:04<29:23,  4.50it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 2.87e-05:  43%|▍| 5914/13852 [22:04<29:21,  4.51it/s\u001b[A\n",
      "Training loss: 3.90e-02 lr: 2.87e-05:  43%|▍| 5915/13852 [22:04<29:16,  4.52it/s\u001b[A\n",
      "Training loss: 2.95e-02 lr: 2.86e-05:  43%|▍| 5916/13852 [22:04<29:17,  4.52it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 2.86e-05:  43%|▍| 5917/13852 [22:04<29:13,  4.52it/s\u001b[A\n",
      "Training loss: 3.12e-02 lr: 2.86e-05:  43%|▍| 5918/13852 [22:05<29:14,  4.52it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 2.86e-05:  43%|▍| 5919/13852 [22:05<29:15,  4.52it/s\u001b[A\n",
      "Training loss: 9.53e-02 lr: 2.86e-05:  43%|▍| 5920/13852 [22:05<29:15,  4.52it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.86e-05:  43%|▍| 5921/13852 [22:05<29:09,  4.53it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 2.86e-05:  43%|▍| 5922/13852 [22:06<29:01,  4.55it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 2.86e-05:  43%|▍| 5923/13852 [22:06<28:58,  4.56it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 2.86e-05:  43%|▍| 5924/13852 [22:06<28:55,  4.57it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 2.86e-05:  43%|▍| 5925/13852 [22:06<28:54,  4.57it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.86e-05:  43%|▍| 5926/13852 [22:06<28:58,  4.56it/s\u001b[A\n",
      "Training loss: 8.02e-02 lr: 2.86e-05:  43%|▍| 5927/13852 [22:07<29:11,  4.52it/s\u001b[A\n",
      "Training loss: 1.26e-01 lr: 2.86e-05:  43%|▍| 5928/13852 [22:07<29:32,  4.47it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 2.86e-05:  43%|▍| 5929/13852 [22:07<29:34,  4.46it/s\u001b[A\n",
      "Training loss: 8.59e-02 lr: 2.86e-05:  43%|▍| 5930/13852 [22:07<29:41,  4.45it/s\u001b[A\n",
      "Training loss: 7.42e-02 lr: 2.86e-05:  43%|▍| 5931/13852 [22:08<29:39,  4.45it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 2.86e-05:  43%|▍| 5932/13852 [22:08<29:32,  4.47it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 2.86e-05:  43%|▍| 5933/13852 [22:08<29:28,  4.48it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 2.86e-05:  43%|▍| 5934/13852 [22:08<29:18,  4.50it/s\u001b[A\n",
      "Training loss: 8.12e-02 lr: 2.86e-05:  43%|▍| 5935/13852 [22:08<29:07,  4.53it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 2.86e-05:  43%|▍| 5936/13852 [22:09<28:57,  4.56it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 2.86e-05:  43%|▍| 5937/13852 [22:09<29:05,  4.53it/s\u001b[A\n",
      "Training loss: 4.21e-02 lr: 2.86e-05:  43%|▍| 5938/13852 [22:09<29:09,  4.52it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 2.86e-05:  43%|▍| 5939/13852 [22:09<29:08,  4.53it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 2.86e-05:  43%|▍| 5940/13852 [22:10<29:09,  4.52it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 2.86e-05:  43%|▍| 5941/13852 [22:10<29:22,  4.49it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 2.86e-05:  43%|▍| 5942/13852 [22:10<29:22,  4.49it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 2.86e-05:  43%|▍| 5943/13852 [22:10<29:19,  4.49it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 2.85e-05:  43%|▍| 5944/13852 [22:10<29:17,  4.50it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.85e-05:  43%|▍| 5945/13852 [22:11<29:13,  4.51it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 2.85e-05:  43%|▍| 5946/13852 [22:11<29:18,  4.50it/s\u001b[A\n",
      "Training loss: 8.91e-02 lr: 2.85e-05:  43%|▍| 5947/13852 [22:11<29:11,  4.51it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 2.85e-05:  43%|▍| 5948/13852 [22:11<29:25,  4.48it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 2.85e-05:  43%|▍| 5949/13852 [22:12<29:19,  4.49it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 2.85e-05:  43%|▍| 5950/13852 [22:12<29:25,  4.48it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 2.85e-05:  43%|▍| 5951/13852 [22:12<29:19,  4.49it/s\u001b[A\n",
      "Training loss: 6.56e-02 lr: 2.85e-05:  43%|▍| 5952/13852 [22:12<29:16,  4.50it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.85e-05:  43%|▍| 5953/13852 [22:12<29:14,  4.50it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 2.85e-05:  43%|▍| 5954/13852 [22:13<29:11,  4.51it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 2.85e-05:  43%|▍| 5955/13852 [22:13<29:10,  4.51it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 2.85e-05:  43%|▍| 5956/13852 [22:13<29:13,  4.50it/s\u001b[A\n",
      "Training loss: 9.34e-02 lr: 2.85e-05:  43%|▍| 5957/13852 [22:13<29:06,  4.52it/s\u001b[A\n",
      "Training loss: 8.18e-02 lr: 2.85e-05:  43%|▍| 5958/13852 [22:14<28:57,  4.54it/s\u001b[A\n",
      "Training loss: 8.79e-02 lr: 2.85e-05:  43%|▍| 5959/13852 [22:14<28:51,  4.56it/s\u001b[A\n",
      "Training loss: 9.27e-02 lr: 2.85e-05:  43%|▍| 5960/13852 [22:14<28:47,  4.57it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 2.85e-05:  43%|▍| 5961/13852 [22:14<28:48,  4.57it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 2.85e-05:  43%|▍| 5962/13852 [22:14<28:55,  4.55it/s\u001b[A\n",
      "Training loss: 7.33e-02 lr: 2.85e-05:  43%|▍| 5963/13852 [22:15<28:57,  4.54it/s\u001b[A\n",
      "Training loss: 5.40e-02 lr: 2.85e-05:  43%|▍| 5964/13852 [22:15<29:00,  4.53it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 2.85e-05:  43%|▍| 5965/13852 [22:15<29:06,  4.52it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 2.85e-05:  43%|▍| 5966/13852 [22:15<29:08,  4.51it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 2.85e-05:  43%|▍| 5967/13852 [22:16<29:09,  4.51it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 2.85e-05:  43%|▍| 5968/13852 [22:16<29:13,  4.50it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 2.85e-05:  43%|▍| 5969/13852 [22:16<29:13,  4.50it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.85e-05:  43%|▍| 5970/13852 [22:16<29:13,  4.50it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 2.84e-05:  43%|▍| 5971/13852 [22:16<29:05,  4.52it/s\u001b[A\n",
      "Training loss: 9.44e-02 lr: 2.84e-05:  43%|▍| 5972/13852 [22:17<28:57,  4.54it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 2.84e-05:  43%|▍| 5973/13852 [22:17<29:02,  4.52it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.84e-05:  43%|▍| 5974/13852 [22:17<29:06,  4.51it/s\u001b[A\n",
      "Training loss: 8.20e-02 lr: 2.84e-05:  43%|▍| 5975/13852 [22:17<29:05,  4.51it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 2.84e-05:  43%|▍| 5976/13852 [22:17<29:05,  4.51it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 2.84e-05:  43%|▍| 5977/13852 [22:18<29:06,  4.51it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 2.84e-05:  43%|▍| 5978/13852 [22:18<29:12,  4.49it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 2.84e-05:  43%|▍| 5979/13852 [22:18<29:10,  4.50it/s\u001b[A\n",
      "Training loss: 8.81e-02 lr: 2.84e-05:  43%|▍| 5980/13852 [22:18<29:11,  4.49it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 2.84e-05:  43%|▍| 5981/13852 [22:19<29:13,  4.49it/s\u001b[A\n",
      "Training loss: 6.99e-02 lr: 2.84e-05:  43%|▍| 5982/13852 [22:19<29:08,  4.50it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 2.84e-05:  43%|▍| 5983/13852 [22:19<28:58,  4.53it/s\u001b[A\n",
      "Training loss: 9.05e-02 lr: 2.84e-05:  43%|▍| 5984/13852 [22:19<28:51,  4.54it/s\u001b[A\n",
      "Training loss: 8.35e-02 lr: 2.84e-05:  43%|▍| 5985/13852 [22:19<29:08,  4.50it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 2.84e-05:  43%|▍| 5986/13852 [22:20<29:09,  4.50it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 2.84e-05:  43%|▍| 5987/13852 [22:20<29:06,  4.50it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.84e-05:  43%|▍| 5988/13852 [22:20<29:04,  4.51it/s\u001b[A\n",
      "Training loss: 1.76e-01 lr: 2.84e-05:  43%|▍| 5989/13852 [22:20<29:03,  4.51it/s\u001b[A\n",
      "Training loss: 1.76e-01 lr: 2.84e-05:  43%|▍| 5990/13852 [22:21<29:02,  4.51it/s\u001b[A\n",
      "Training loss: 1.81e-01 lr: 2.84e-05:  43%|▍| 5991/13852 [22:21<29:09,  4.49it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 2.84e-05:  43%|▍| 5992/13852 [22:21<29:12,  4.48it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 2.84e-05:  43%|▍| 5993/13852 [22:21<29:11,  4.49it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.84e-05:  43%|▍| 5994/13852 [22:21<29:02,  4.51it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.84e-05:  43%|▍| 5995/13852 [22:22<28:58,  4.52it/s\u001b[A\n",
      "Training loss: 8.80e-02 lr: 2.84e-05:  43%|▍| 5996/13852 [22:22<28:50,  4.54it/s\u001b[A\n",
      "Training loss: 9.08e-02 lr: 2.84e-05:  43%|▍| 5997/13852 [22:22<28:49,  4.54it/s\u001b[A\n",
      "Training loss: 7.86e-02 lr: 2.84e-05:  43%|▍| 5998/13852 [22:22<28:50,  4.54it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 2.83e-05:  43%|▍| 5999/13852 [22:23<28:56,  4.52it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 2.83e-05:  43%|▍| 6000/13852 [22:23<28:56,  4.52it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 2.83e-05:  43%|▍| 6001/13852 [22:23<29:00,  4.51it/s\u001b[A\n",
      "Training loss: 8.16e-02 lr: 2.83e-05:  43%|▍| 6002/13852 [22:23<28:59,  4.51it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 2.83e-05:  43%|▍| 6003/13852 [22:23<28:59,  4.51it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 2.83e-05:  43%|▍| 6004/13852 [22:24<29:00,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.98e-02 lr: 2.83e-05:  43%|▍| 6005/13852 [22:24<28:58,  4.51it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 2.83e-05:  43%|▍| 6006/13852 [22:24<29:03,  4.50it/s\u001b[A\n",
      "Training loss: 1.48e-01 lr: 2.83e-05:  43%|▍| 6007/13852 [22:24<28:55,  4.52it/s\u001b[A\n",
      "Training loss: 1.64e-01 lr: 2.83e-05:  43%|▍| 6008/13852 [22:25<28:47,  4.54it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 2.83e-05:  43%|▍| 6009/13852 [22:25<28:43,  4.55it/s\u001b[A\n",
      "Training loss: 9.91e-02 lr: 2.83e-05:  43%|▍| 6010/13852 [22:25<28:53,  4.52it/s\u001b[A\n",
      "Training loss: 7.41e-02 lr: 2.83e-05:  43%|▍| 6011/13852 [22:25<28:56,  4.52it/s\u001b[A\n",
      "Training loss: 8.42e-02 lr: 2.83e-05:  43%|▍| 6012/13852 [22:25<28:53,  4.52it/s\u001b[A\n",
      "Training loss: 9.97e-02 lr: 2.83e-05:  43%|▍| 6013/13852 [22:26<28:53,  4.52it/s\u001b[A\n",
      "Training loss: 1.41e-01 lr: 2.83e-05:  43%|▍| 6014/13852 [22:26<28:52,  4.52it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 2.83e-05:  43%|▍| 6015/13852 [22:26<28:54,  4.52it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 2.83e-05:  43%|▍| 6016/13852 [22:26<28:56,  4.51it/s\u001b[A\n",
      "Training loss: 8.76e-02 lr: 2.83e-05:  43%|▍| 6017/13852 [22:27<28:56,  4.51it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 2.83e-05:  43%|▍| 6018/13852 [22:27<29:12,  4.47it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 2.83e-05:  43%|▍| 6019/13852 [22:27<29:02,  4.49it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 2.83e-05:  43%|▍| 6020/13852 [22:27<28:51,  4.52it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.83e-05:  43%|▍| 6021/13852 [22:27<28:44,  4.54it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 2.83e-05:  43%|▍| 6022/13852 [22:28<29:52,  4.37it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 2.83e-05:  43%|▍| 6023/13852 [22:28<30:21,  4.30it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 2.83e-05:  43%|▍| 6024/13852 [22:28<29:56,  4.36it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 2.83e-05:  43%|▍| 6025/13852 [22:28<29:37,  4.40it/s\u001b[A\n",
      "Training loss: 9.72e-02 lr: 2.83e-05:  44%|▍| 6026/13852 [22:29<29:25,  4.43it/s\u001b[A\n",
      "Training loss: 7.29e-02 lr: 2.82e-05:  44%|▍| 6027/13852 [22:29<29:15,  4.46it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 2.82e-05:  44%|▍| 6028/13852 [22:29<29:10,  4.47it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 2.82e-05:  44%|▍| 6029/13852 [22:29<28:59,  4.50it/s\u001b[A\n",
      "Training loss: 8.76e-02 lr: 2.82e-05:  44%|▍| 6030/13852 [22:30<28:51,  4.52it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 2.82e-05:  44%|▍| 6031/13852 [22:30<28:54,  4.51it/s\u001b[A\n",
      "Training loss: 7.41e-02 lr: 2.82e-05:  44%|▍| 6032/13852 [22:30<28:54,  4.51it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 2.82e-05:  44%|▍| 6033/13852 [22:30<28:51,  4.52it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 2.82e-05:  44%|▍| 6034/13852 [22:30<28:50,  4.52it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 2.82e-05:  44%|▍| 6035/13852 [22:31<28:50,  4.52it/s\u001b[A\n",
      "Training loss: 9.65e-02 lr: 2.82e-05:  44%|▍| 6036/13852 [22:31<29:04,  4.48it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 2.82e-05:  44%|▍| 6037/13852 [22:31<29:01,  4.49it/s\u001b[A\n",
      "Training loss: 8.76e-02 lr: 2.82e-05:  44%|▍| 6038/13852 [22:31<28:58,  4.50it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 2.82e-05:  44%|▍| 6039/13852 [22:32<28:59,  4.49it/s\u001b[A\n",
      "Training loss: 6.57e-02 lr: 2.82e-05:  44%|▍| 6040/13852 [22:32<29:07,  4.47it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.82e-05:  44%|▍| 6041/13852 [22:32<28:55,  4.50it/s\u001b[A\n",
      "Training loss: 4.60e-02 lr: 2.82e-05:  44%|▍| 6042/13852 [22:32<28:44,  4.53it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 2.82e-05:  44%|▍| 6043/13852 [22:32<28:36,  4.55it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 2.82e-05:  44%|▍| 6044/13852 [22:33<28:50,  4.51it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 2.82e-05:  44%|▍| 6045/13852 [22:33<28:49,  4.51it/s\u001b[A\n",
      "Training loss: 8.79e-02 lr: 2.82e-05:  44%|▍| 6046/13852 [22:33<29:01,  4.48it/s\u001b[A\n",
      "Training loss: 9.46e-02 lr: 2.82e-05:  44%|▍| 6047/13852 [22:33<28:56,  4.49it/s\u001b[A\n",
      "Training loss: 7.77e-02 lr: 2.82e-05:  44%|▍| 6048/13852 [22:34<28:55,  4.50it/s\u001b[A\n",
      "Training loss: 7.98e-02 lr: 2.82e-05:  44%|▍| 6049/13852 [22:34<28:54,  4.50it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 2.82e-05:  44%|▍| 6050/13852 [22:34<28:51,  4.51it/s\u001b[A\n",
      "Training loss: 6.25e-02 lr: 2.82e-05:  44%|▍| 6051/13852 [22:34<28:52,  4.50it/s\u001b[A\n",
      "Training loss: 7.99e-02 lr: 2.82e-05:  44%|▍| 6052/13852 [22:34<28:50,  4.51it/s\u001b[A\n",
      "Training loss: 7.55e-02 lr: 2.82e-05:  44%|▍| 6053/13852 [22:35<28:46,  4.52it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 2.81e-05:  44%|▍| 6054/13852 [22:35<28:39,  4.54it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 2.81e-05:  44%|▍| 6055/13852 [22:35<28:30,  4.56it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 2.81e-05:  44%|▍| 6056/13852 [22:35<28:43,  4.52it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 2.81e-05:  44%|▍| 6057/13852 [22:35<28:43,  4.52it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 2.81e-05:  44%|▍| 6058/13852 [22:36<28:41,  4.53it/s\u001b[A\n",
      "Training loss: 4.07e-02 lr: 2.81e-05:  44%|▍| 6059/13852 [22:36<28:43,  4.52it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 2.81e-05:  44%|▍| 6060/13852 [22:36<28:49,  4.50it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 2.81e-05:  44%|▍| 6061/13852 [22:36<28:49,  4.50it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 2.81e-05:  44%|▍| 6062/13852 [22:37<28:48,  4.51it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 2.81e-05:  44%|▍| 6063/13852 [22:37<29:07,  4.46it/s\u001b[A\n",
      "Training loss: 3.90e-02 lr: 2.81e-05:  44%|▍| 6064/13852 [22:37<29:13,  4.44it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 2.81e-05:  44%|▍| 6065/13852 [22:37<29:06,  4.46it/s\u001b[A\n",
      "Training loss: 3.94e-02 lr: 2.81e-05:  44%|▍| 6066/13852 [22:38<28:59,  4.48it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 2.81e-05:  44%|▍| 6067/13852 [22:38<29:04,  4.46it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 2.81e-05:  44%|▍| 6068/13852 [22:38<28:58,  4.48it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 2.81e-05:  44%|▍| 6069/13852 [22:38<28:51,  4.50it/s\u001b[A\n",
      "Training loss: 7.03e-02 lr: 2.81e-05:  44%|▍| 6070/13852 [22:38<28:46,  4.51it/s\u001b[A\n",
      "Training loss: 7.11e-02 lr: 2.81e-05:  44%|▍| 6071/13852 [22:39<28:46,  4.51it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 2.81e-05:  44%|▍| 6072/13852 [22:39<28:45,  4.51it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 2.81e-05:  44%|▍| 6073/13852 [22:39<28:43,  4.51it/s\u001b[A\n",
      "Training loss: 3.30e-02 lr: 2.81e-05:  44%|▍| 6074/13852 [22:39<28:48,  4.50it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 2.81e-05:  44%|▍| 6075/13852 [22:40<28:53,  4.49it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 2.81e-05:  44%|▍| 6076/13852 [22:40<28:52,  4.49it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 2.81e-05:  44%|▍| 6077/13852 [22:40<28:44,  4.51it/s\u001b[A\n",
      "Training loss: 3.14e-02 lr: 2.81e-05:  44%|▍| 6078/13852 [22:40<28:35,  4.53it/s\u001b[A\n",
      "Training loss: 2.63e-02 lr: 2.81e-05:  44%|▍| 6079/13852 [22:40<28:29,  4.55it/s\u001b[A\n",
      "Training loss: 2.17e-02 lr: 2.81e-05:  44%|▍| 6080/13852 [22:41<28:29,  4.55it/s\u001b[A\n",
      "Training loss: 1.90e-02 lr: 2.81e-05:  44%|▍| 6081/13852 [22:41<28:44,  4.51it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 2.80e-05:  44%|▍| 6082/13852 [22:41<28:43,  4.51it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 2.80e-05:  44%|▍| 6083/13852 [22:41<28:45,  4.50it/s\u001b[A\n",
      "Training loss: 6.68e-02 lr: 2.80e-05:  44%|▍| 6084/13852 [22:41<28:44,  4.50it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 2.80e-05:  44%|▍| 6085/13852 [22:42<28:47,  4.50it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 2.80e-05:  44%|▍| 6086/13852 [22:42<28:45,  4.50it/s\u001b[A\n",
      "Training loss: 2.61e-02 lr: 2.80e-05:  44%|▍| 6087/13852 [22:42<28:43,  4.51it/s\u001b[A\n",
      "Training loss: 6.99e-02 lr: 2.80e-05:  44%|▍| 6088/13852 [22:42<28:40,  4.51it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 2.80e-05:  44%|▍| 6089/13852 [22:43<28:37,  4.52it/s\u001b[A\n",
      "Training loss: 9.13e-02 lr: 2.80e-05:  44%|▍| 6090/13852 [22:43<28:28,  4.54it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 2.80e-05:  44%|▍| 6091/13852 [22:43<28:25,  4.55it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.80e-05:  44%|▍| 6092/13852 [22:43<28:29,  4.54it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 2.80e-05:  44%|▍| 6093/13852 [22:43<28:27,  4.54it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 2.80e-05:  44%|▍| 6094/13852 [22:44<28:27,  4.54it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 2.80e-05:  44%|▍| 6095/13852 [22:44<28:27,  4.54it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 2.80e-05:  44%|▍| 6096/13852 [22:44<28:32,  4.53it/s\u001b[A\n",
      "Training loss: 1.55e-01 lr: 2.80e-05:  44%|▍| 6097/13852 [22:44<28:31,  4.53it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 2.80e-05:  44%|▍| 6098/13852 [22:45<28:31,  4.53it/s\u001b[A\n",
      "Training loss: 9.65e-02 lr: 2.80e-05:  44%|▍| 6099/13852 [22:45<28:30,  4.53it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 2.80e-05:  44%|▍| 6100/13852 [22:45<28:32,  4.53it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 2.80e-05:  44%|▍| 6101/13852 [22:45<28:28,  4.54it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.07e-02 lr: 2.80e-05:  44%|▍| 6102/13852 [22:45<28:20,  4.56it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 2.80e-05:  44%|▍| 6103/13852 [22:46<28:16,  4.57it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 2.80e-05:  44%|▍| 6104/13852 [22:46<28:12,  4.58it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.80e-05:  44%|▍| 6105/13852 [22:46<28:11,  4.58it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 2.80e-05:  44%|▍| 6106/13852 [22:46<28:19,  4.56it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.80e-05:  44%|▍| 6107/13852 [22:47<28:21,  4.55it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 2.80e-05:  44%|▍| 6108/13852 [22:47<28:36,  4.51it/s\u001b[A\n",
      "Training loss: 6.06e-02 lr: 2.80e-05:  44%|▍| 6109/13852 [22:47<28:37,  4.51it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 2.79e-05:  44%|▍| 6110/13852 [22:47<28:40,  4.50it/s\u001b[A\n",
      "Training loss: 3.42e-02 lr: 2.79e-05:  44%|▍| 6111/13852 [22:47<28:40,  4.50it/s\u001b[A\n",
      "Training loss: 3.08e-02 lr: 2.79e-05:  44%|▍| 6112/13852 [22:48<28:37,  4.51it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 2.79e-05:  44%|▍| 6113/13852 [22:48<28:35,  4.51it/s\u001b[A\n",
      "Training loss: 3.52e-02 lr: 2.79e-05:  44%|▍| 6114/13852 [22:48<28:59,  4.45it/s\u001b[A\n",
      "Training loss: 2.91e-02 lr: 2.79e-05:  44%|▍| 6115/13852 [22:48<28:46,  4.48it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 2.79e-05:  44%|▍| 6116/13852 [22:49<28:33,  4.51it/s\u001b[A\n",
      "Training loss: 8.17e-02 lr: 2.79e-05:  44%|▍| 6117/13852 [22:49<28:39,  4.50it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 2.79e-05:  44%|▍| 6118/13852 [22:49<28:36,  4.51it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 2.79e-05:  44%|▍| 6119/13852 [22:49<28:35,  4.51it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 2.79e-05:  44%|▍| 6120/13852 [22:49<28:32,  4.52it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 2.79e-05:  44%|▍| 6121/13852 [22:50<28:31,  4.52it/s\u001b[A\n",
      "Training loss: 3.36e-02 lr: 2.79e-05:  44%|▍| 6122/13852 [22:50<28:40,  4.49it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 2.79e-05:  44%|▍| 6123/13852 [22:50<28:39,  4.50it/s\u001b[A\n",
      "Training loss: 3.34e-02 lr: 2.79e-05:  44%|▍| 6124/13852 [22:50<28:45,  4.48it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 2.79e-05:  44%|▍| 6125/13852 [22:51<28:45,  4.48it/s\u001b[A\n",
      "Training loss: 2.54e-02 lr: 2.79e-05:  44%|▍| 6126/13852 [22:51<28:38,  4.49it/s\u001b[A\n",
      "Training loss: 2.30e-02 lr: 2.79e-05:  44%|▍| 6127/13852 [22:51<28:28,  4.52it/s\u001b[A\n",
      "Training loss: 2.10e-02 lr: 2.79e-05:  44%|▍| 6128/13852 [22:51<28:21,  4.54it/s\u001b[A\n",
      "Training loss: 1.75e-02 lr: 2.79e-05:  44%|▍| 6129/13852 [22:51<28:35,  4.50it/s\u001b[A\n",
      "Training loss: 1.89e-02 lr: 2.79e-05:  44%|▍| 6130/13852 [22:52<28:42,  4.48it/s\u001b[A\n",
      "Training loss: 4.72e-02 lr: 2.79e-05:  44%|▍| 6131/13852 [22:52<28:40,  4.49it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 2.79e-05:  44%|▍| 6132/13852 [22:52<28:43,  4.48it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 2.79e-05:  44%|▍| 6133/13852 [22:52<28:40,  4.49it/s\u001b[A\n",
      "Training loss: 8.57e-02 lr: 2.79e-05:  44%|▍| 6134/13852 [22:53<28:38,  4.49it/s\u001b[A\n",
      "Training loss: 7.00e-02 lr: 2.79e-05:  44%|▍| 6135/13852 [22:53<28:35,  4.50it/s\u001b[A\n",
      "Training loss: 8.16e-02 lr: 2.79e-05:  44%|▍| 6136/13852 [22:53<28:34,  4.50it/s\u001b[A\n",
      "Training loss: 9.39e-02 lr: 2.78e-05:  44%|▍| 6137/13852 [22:53<28:33,  4.50it/s\u001b[A\n",
      "Training loss: 9.70e-02 lr: 2.78e-05:  44%|▍| 6138/13852 [22:53<28:27,  4.52it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 2.78e-05:  44%|▍| 6139/13852 [22:54<28:19,  4.54it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 2.78e-05:  44%|▍| 6140/13852 [22:54<28:12,  4.56it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 2.78e-05:  44%|▍| 6141/13852 [22:54<28:11,  4.56it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 2.78e-05:  44%|▍| 6142/13852 [22:54<28:14,  4.55it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 2.78e-05:  44%|▍| 6143/13852 [22:55<28:15,  4.55it/s\u001b[A\n",
      "Training loss: 8.34e-02 lr: 2.78e-05:  44%|▍| 6144/13852 [22:55<28:17,  4.54it/s\u001b[A\n",
      "Training loss: 7.13e-02 lr: 2.78e-05:  44%|▍| 6145/13852 [22:55<28:21,  4.53it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 2.78e-05:  44%|▍| 6146/13852 [22:55<28:23,  4.52it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 2.78e-05:  44%|▍| 6147/13852 [22:55<28:23,  4.52it/s\u001b[A\n",
      "Training loss: 8.47e-02 lr: 2.78e-05:  44%|▍| 6148/13852 [22:56<28:26,  4.51it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 2.78e-05:  44%|▍| 6149/13852 [22:56<28:26,  4.51it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 2.78e-05:  44%|▍| 6150/13852 [22:56<28:27,  4.51it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 2.78e-05:  44%|▍| 6151/13852 [22:56<28:21,  4.53it/s\u001b[A\n",
      "Training loss: 3.83e-02 lr: 2.78e-05:  44%|▍| 6152/13852 [22:57<28:18,  4.53it/s\u001b[A\n",
      "Training loss: 3.28e-02 lr: 2.78e-05:  44%|▍| 6153/13852 [22:57<28:25,  4.51it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 2.78e-05:  44%|▍| 6154/13852 [22:57<28:23,  4.52it/s\u001b[A\n",
      "Training loss: 3.00e-02 lr: 2.78e-05:  44%|▍| 6155/13852 [22:57<28:24,  4.52it/s\u001b[A\n",
      "Training loss: 2.33e-02 lr: 2.78e-05:  44%|▍| 6156/13852 [22:57<28:23,  4.52it/s\u001b[A\n",
      "Training loss: 8.18e-02 lr: 2.78e-05:  44%|▍| 6157/13852 [22:58<28:25,  4.51it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 2.78e-05:  44%|▍| 6158/13852 [22:58<28:26,  4.51it/s\u001b[A\n",
      "Training loss: 8.56e-02 lr: 2.78e-05:  44%|▍| 6159/13852 [22:58<28:37,  4.48it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 2.78e-05:  44%|▍| 6160/13852 [22:58<28:33,  4.49it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.78e-05:  44%|▍| 6161/13852 [22:59<28:31,  4.49it/s\u001b[A\n",
      "Training loss: 9.90e-02 lr: 2.78e-05:  44%|▍| 6162/13852 [22:59<28:31,  4.49it/s\u001b[A\n",
      "Training loss: 9.58e-02 lr: 2.78e-05:  44%|▍| 6163/13852 [22:59<28:21,  4.52it/s\u001b[A\n",
      "Training loss: 9.13e-02 lr: 2.78e-05:  44%|▍| 6164/13852 [22:59<28:16,  4.53it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 2.77e-05:  45%|▍| 6165/13852 [22:59<28:08,  4.55it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 2.77e-05:  45%|▍| 6166/13852 [23:00<28:22,  4.51it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 2.77e-05:  45%|▍| 6167/13852 [23:00<28:25,  4.51it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 2.77e-05:  45%|▍| 6168/13852 [23:00<28:26,  4.50it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 2.77e-05:  45%|▍| 6169/13852 [23:00<28:25,  4.50it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 2.77e-05:  45%|▍| 6170/13852 [23:01<28:27,  4.50it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 2.77e-05:  45%|▍| 6171/13852 [23:01<28:33,  4.48it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 2.77e-05:  45%|▍| 6172/13852 [23:01<28:35,  4.48it/s\u001b[A\n",
      "Training loss: 6.56e-02 lr: 2.77e-05:  45%|▍| 6173/13852 [23:01<28:36,  4.47it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 2.77e-05:  45%|▍| 6174/13852 [23:01<28:34,  4.48it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 2.77e-05:  45%|▍| 6175/13852 [23:02<28:29,  4.49it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 2.77e-05:  45%|▍| 6176/13852 [23:02<28:20,  4.51it/s\u001b[A\n",
      "Training loss: 3.27e-02 lr: 2.77e-05:  45%|▍| 6177/13852 [23:02<28:35,  4.48it/s\u001b[A\n",
      "Training loss: 2.62e-02 lr: 2.77e-05:  45%|▍| 6178/13852 [23:02<28:30,  4.49it/s\u001b[A\n",
      "Training loss: 2.05e-02 lr: 2.77e-05:  45%|▍| 6179/13852 [23:03<28:25,  4.50it/s\u001b[A\n",
      "Training loss: 1.79e-02 lr: 2.77e-05:  45%|▍| 6180/13852 [23:03<28:23,  4.50it/s\u001b[A\n",
      "Training loss: 1.61e-02 lr: 2.77e-05:  45%|▍| 6181/13852 [23:03<28:39,  4.46it/s\u001b[A\n",
      "Training loss: 1.35e-02 lr: 2.77e-05:  45%|▍| 6182/13852 [23:03<29:22,  4.35it/s\u001b[A\n",
      "Training loss: 8.52e-02 lr: 2.77e-05:  45%|▍| 6183/13852 [23:03<29:54,  4.27it/s\u001b[A\n",
      "Training loss: 6.52e-02 lr: 2.77e-05:  45%|▍| 6184/13852 [23:04<29:22,  4.35it/s\u001b[A\n",
      "Training loss: 9.83e-02 lr: 2.77e-05:  45%|▍| 6185/13852 [23:04<28:51,  4.43it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 2.77e-05:  45%|▍| 6186/13852 [23:04<28:52,  4.42it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.77e-05:  45%|▍| 6187/13852 [23:04<28:43,  4.45it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 2.77e-05:  45%|▍| 6188/13852 [23:05<28:33,  4.47it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.77e-05:  45%|▍| 6189/13852 [23:05<28:26,  4.49it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.77e-05:  45%|▍| 6190/13852 [23:05<28:20,  4.50it/s\u001b[A\n",
      "Training loss: 8.55e-02 lr: 2.77e-05:  45%|▍| 6191/13852 [23:05<28:18,  4.51it/s\u001b[A\n",
      "Training loss: 6.82e-02 lr: 2.77e-05:  45%|▍| 6192/13852 [23:05<28:16,  4.51it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 2.76e-05:  45%|▍| 6193/13852 [23:06<28:16,  4.51it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.76e-05:  45%|▍| 6194/13852 [23:06<28:19,  4.50it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.76e-05:  45%|▍| 6195/13852 [23:06<28:20,  4.50it/s\u001b[A\n",
      "Training loss: 9.38e-02 lr: 2.76e-05:  45%|▍| 6196/13852 [23:06<28:21,  4.50it/s\u001b[A\n",
      "Training loss: 9.10e-02 lr: 2.76e-05:  45%|▍| 6197/13852 [23:07<28:09,  4.53it/s\u001b[A\n",
      "Training loss: 8.17e-02 lr: 2.76e-05:  45%|▍| 6198/13852 [23:07<29:07,  4.38it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.95e-02 lr: 2.76e-05:  45%|▍| 6199/13852 [23:07<29:40,  4.30it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 2.76e-05:  45%|▍| 6200/13852 [23:07<30:06,  4.24it/s\u001b[A\n",
      "Training loss: 6.99e-02 lr: 2.76e-05:  45%|▍| 6201/13852 [23:08<30:28,  4.18it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 2.76e-05:  45%|▍| 6202/13852 [23:08<30:33,  4.17it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 2.76e-05:  45%|▍| 6203/13852 [23:08<29:45,  4.28it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 2.76e-05:  45%|▍| 6204/13852 [23:08<29:10,  4.37it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 2.76e-05:  45%|▍| 6205/13852 [23:08<28:50,  4.42it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 2.76e-05:  45%|▍| 6206/13852 [23:09<28:37,  4.45it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 2.76e-05:  45%|▍| 6207/13852 [23:09<28:27,  4.48it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 2.76e-05:  45%|▍| 6208/13852 [23:09<28:22,  4.49it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 2.76e-05:  45%|▍| 6209/13852 [23:09<28:21,  4.49it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 2.76e-05:  45%|▍| 6210/13852 [23:10<28:20,  4.49it/s\u001b[A\n",
      "Training loss: 3.41e-02 lr: 2.76e-05:  45%|▍| 6211/13852 [23:10<28:20,  4.49it/s\u001b[A\n",
      "Training loss: 5.43e-02 lr: 2.76e-05:  45%|▍| 6212/13852 [23:10<28:42,  4.43it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 2.76e-05:  45%|▍| 6213/13852 [23:10<28:35,  4.45it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 2.76e-05:  45%|▍| 6214/13852 [23:10<28:22,  4.49it/s\u001b[A\n",
      "Training loss: 6.22e-02 lr: 2.76e-05:  45%|▍| 6215/13852 [23:11<28:08,  4.52it/s\u001b[A\n",
      "Training loss: 9.94e-02 lr: 2.76e-05:  45%|▍| 6216/13852 [23:11<28:10,  4.52it/s\u001b[A\n",
      "Training loss: 7.42e-02 lr: 2.76e-05:  45%|▍| 6217/13852 [23:11<28:10,  4.52it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 2.76e-05:  45%|▍| 6218/13852 [23:11<28:07,  4.52it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 2.76e-05:  45%|▍| 6219/13852 [23:12<28:08,  4.52it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 2.76e-05:  45%|▍| 6220/13852 [23:12<28:15,  4.50it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 2.75e-05:  45%|▍| 6221/13852 [23:12<28:16,  4.50it/s\u001b[A\n",
      "Training loss: 2.98e-02 lr: 2.75e-05:  45%|▍| 6222/13852 [23:12<28:21,  4.48it/s\u001b[A\n",
      "Training loss: 9.92e-02 lr: 2.75e-05:  45%|▍| 6223/13852 [23:12<28:18,  4.49it/s\u001b[A\n",
      "Training loss: 9.16e-02 lr: 2.75e-05:  45%|▍| 6224/13852 [23:13<28:15,  4.50it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 2.75e-05:  45%|▍| 6225/13852 [23:13<28:15,  4.50it/s\u001b[A\n",
      "Training loss: 5.68e-02 lr: 2.75e-05:  45%|▍| 6226/13852 [23:13<28:07,  4.52it/s\u001b[A\n",
      "Training loss: 4.22e-02 lr: 2.75e-05:  45%|▍| 6227/13852 [23:13<27:56,  4.55it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 2.75e-05:  45%|▍| 6228/13852 [23:14<27:50,  4.56it/s\u001b[A\n",
      "Training loss: 7.86e-02 lr: 2.75e-05:  45%|▍| 6229/13852 [23:14<28:07,  4.52it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 2.75e-05:  45%|▍| 6230/13852 [23:14<28:06,  4.52it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 2.75e-05:  45%|▍| 6231/13852 [23:14<28:05,  4.52it/s\u001b[A\n",
      "Training loss: 9.43e-02 lr: 2.75e-05:  45%|▍| 6232/13852 [23:14<28:06,  4.52it/s\u001b[A\n",
      "Training loss: 8.38e-02 lr: 2.75e-05:  45%|▍| 6233/13852 [23:15<28:07,  4.52it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 2.75e-05:  45%|▍| 6234/13852 [23:15<28:07,  4.51it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 2.75e-05:  45%|▍| 6235/13852 [23:15<28:07,  4.51it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 2.75e-05:  45%|▍| 6236/13852 [23:15<28:07,  4.51it/s\u001b[A\n",
      "Training loss: 4.86e-02 lr: 2.75e-05:  45%|▍| 6237/13852 [23:16<28:09,  4.51it/s\u001b[A\n",
      "Training loss: 3.95e-02 lr: 2.75e-05:  45%|▍| 6238/13852 [23:16<28:00,  4.53it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 2.75e-05:  45%|▍| 6239/13852 [23:16<27:53,  4.55it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 2.75e-05:  45%|▍| 6240/13852 [23:16<27:47,  4.56it/s\u001b[A\n",
      "Training loss: 8.47e-02 lr: 2.75e-05:  45%|▍| 6241/13852 [23:16<27:43,  4.58it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 2.75e-05:  45%|▍| 6242/13852 [23:17<27:57,  4.54it/s\u001b[A\n",
      "Training loss: 7.35e-02 lr: 2.75e-05:  45%|▍| 6243/13852 [23:17<28:08,  4.51it/s\u001b[A\n",
      "Training loss: 7.39e-02 lr: 2.75e-05:  45%|▍| 6244/13852 [23:17<28:08,  4.51it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 2.75e-05:  45%|▍| 6245/13852 [23:17<28:04,  4.52it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 2.75e-05:  45%|▍| 6246/13852 [23:18<28:07,  4.51it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 2.75e-05:  45%|▍| 6247/13852 [23:18<28:05,  4.51it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 2.74e-05:  45%|▍| 6248/13852 [23:18<28:11,  4.50it/s\u001b[A\n",
      "Training loss: 3.05e-02 lr: 2.74e-05:  45%|▍| 6249/13852 [23:18<28:10,  4.50it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 2.74e-05:  45%|▍| 6250/13852 [23:18<28:10,  4.50it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 2.74e-05:  45%|▍| 6251/13852 [23:19<28:00,  4.52it/s\u001b[A\n",
      "Training loss: 7.41e-02 lr: 2.74e-05:  45%|▍| 6252/13852 [23:19<27:50,  4.55it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 2.74e-05:  45%|▍| 6253/13852 [23:19<27:47,  4.56it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 2.74e-05:  45%|▍| 6254/13852 [23:19<28:01,  4.52it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 2.74e-05:  45%|▍| 6255/13852 [23:20<27:59,  4.52it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 2.74e-05:  45%|▍| 6256/13852 [23:20<28:00,  4.52it/s\u001b[A\n",
      "Training loss: 8.01e-02 lr: 2.74e-05:  45%|▍| 6257/13852 [23:20<27:58,  4.53it/s\u001b[A\n",
      "Training loss: 7.57e-02 lr: 2.74e-05:  45%|▍| 6258/13852 [23:20<28:00,  4.52it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 2.74e-05:  45%|▍| 6259/13852 [23:20<28:00,  4.52it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 2.74e-05:  45%|▍| 6260/13852 [23:21<28:03,  4.51it/s\u001b[A\n",
      "Training loss: 4.93e-02 lr: 2.74e-05:  45%|▍| 6261/13852 [23:21<28:15,  4.48it/s\u001b[A\n",
      "Training loss: 3.87e-02 lr: 2.74e-05:  45%|▍| 6262/13852 [23:21<28:11,  4.49it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 2.74e-05:  45%|▍| 6263/13852 [23:21<28:02,  4.51it/s\u001b[A\n",
      "Training loss: 3.62e-02 lr: 2.74e-05:  45%|▍| 6264/13852 [23:22<27:50,  4.54it/s\u001b[A\n",
      "Training loss: 2.99e-02 lr: 2.74e-05:  45%|▍| 6265/13852 [23:22<27:50,  4.54it/s\u001b[A\n",
      "Training loss: 6.88e-02 lr: 2.74e-05:  45%|▍| 6266/13852 [23:22<28:07,  4.50it/s\u001b[A\n",
      "Training loss: 8.89e-02 lr: 2.74e-05:  45%|▍| 6267/13852 [23:22<28:31,  4.43it/s\u001b[A\n",
      "Training loss: 7.21e-02 lr: 2.74e-05:  45%|▍| 6268/13852 [23:22<28:18,  4.47it/s\u001b[A\n",
      "Training loss: 8.89e-02 lr: 2.74e-05:  45%|▍| 6269/13852 [23:23<28:49,  4.38it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.74e-05:  45%|▍| 6270/13852 [23:23<29:32,  4.28it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 2.74e-05:  45%|▍| 6271/13852 [23:23<29:56,  4.22it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 2.74e-05:  45%|▍| 6272/13852 [23:23<29:18,  4.31it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 2.74e-05:  45%|▍| 6273/13852 [23:24<28:52,  4.38it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.74e-05:  45%|▍| 6274/13852 [23:24<28:39,  4.41it/s\u001b[A\n",
      "Training loss: 7.62e-02 lr: 2.74e-05:  45%|▍| 6275/13852 [23:24<28:25,  4.44it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 2.73e-05:  45%|▍| 6276/13852 [23:24<28:18,  4.46it/s\u001b[A\n",
      "Training loss: 5.45e-02 lr: 2.73e-05:  45%|▍| 6277/13852 [23:24<28:13,  4.47it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 2.73e-05:  45%|▍| 6278/13852 [23:25<28:12,  4.47it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 2.73e-05:  45%|▍| 6279/13852 [23:25<28:09,  4.48it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 2.73e-05:  45%|▍| 6280/13852 [23:25<28:11,  4.48it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 2.73e-05:  45%|▍| 6281/13852 [23:25<28:09,  4.48it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 2.73e-05:  45%|▍| 6282/13852 [23:26<28:15,  4.46it/s\u001b[A\n",
      "Training loss: 4.01e-02 lr: 2.73e-05:  45%|▍| 6283/13852 [23:26<28:05,  4.49it/s\u001b[A\n",
      "Training loss: 3.03e-02 lr: 2.73e-05:  45%|▍| 6284/13852 [23:26<27:53,  4.52it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 2.73e-05:  45%|▍| 6285/13852 [23:26<27:53,  4.52it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 2.73e-05:  45%|▍| 6286/13852 [23:26<27:57,  4.51it/s\u001b[A\n",
      "Training loss: 3.30e-02 lr: 2.73e-05:  45%|▍| 6287/13852 [23:27<28:00,  4.50it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 2.73e-05:  45%|▍| 6288/13852 [23:27<28:01,  4.50it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 2.73e-05:  45%|▍| 6289/13852 [23:27<28:05,  4.49it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 2.73e-05:  45%|▍| 6290/13852 [23:27<28:05,  4.49it/s\u001b[A\n",
      "Training loss: 9.54e-02 lr: 2.73e-05:  45%|▍| 6291/13852 [23:28<28:04,  4.49it/s\u001b[A\n",
      "Training loss: 8.89e-02 lr: 2.73e-05:  45%|▍| 6292/13852 [23:28<28:05,  4.48it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 2.73e-05:  45%|▍| 6293/13852 [23:28<28:11,  4.47it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 2.73e-05:  45%|▍| 6294/13852 [23:28<28:12,  4.46it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 2.73e-05:  45%|▍| 6295/13852 [23:28<28:04,  4.49it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.87e-02 lr: 2.73e-05:  45%|▍| 6296/13852 [23:29<27:56,  4.51it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 2.73e-05:  45%|▍| 6297/13852 [23:29<28:06,  4.48it/s\u001b[A\n",
      "Training loss: 9.26e-02 lr: 2.73e-05:  45%|▍| 6298/13852 [23:29<28:01,  4.49it/s\u001b[A\n",
      "Training loss: 8.34e-02 lr: 2.73e-05:  45%|▍| 6299/13852 [23:29<27:58,  4.50it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 2.73e-05:  45%|▍| 6300/13852 [23:30<27:57,  4.50it/s\u001b[A\n",
      "Training loss: 4.93e-02 lr: 2.73e-05:  45%|▍| 6301/13852 [23:30<27:59,  4.50it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 2.73e-05:  45%|▍| 6302/13852 [23:30<28:00,  4.49it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 2.73e-05:  46%|▍| 6303/13852 [23:30<28:04,  4.48it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 2.72e-05:  46%|▍| 6304/13852 [23:30<28:03,  4.48it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 2.72e-05:  46%|▍| 6305/13852 [23:31<28:05,  4.48it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 2.72e-05:  46%|▍| 6306/13852 [23:31<28:11,  4.46it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 2.72e-05:  46%|▍| 6307/13852 [23:31<27:58,  4.50it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 2.72e-05:  46%|▍| 6308/13852 [23:31<28:10,  4.46it/s\u001b[A\n",
      "Training loss: 2.77e-02 lr: 2.72e-05:  46%|▍| 6309/13852 [23:32<28:05,  4.48it/s\u001b[A\n",
      "Training loss: 8.46e-02 lr: 2.72e-05:  46%|▍| 6310/13852 [23:32<28:04,  4.48it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 2.72e-05:  46%|▍| 6311/13852 [23:32<28:02,  4.48it/s\u001b[A\n",
      "Training loss: 9.90e-02 lr: 2.72e-05:  46%|▍| 6312/13852 [23:32<28:03,  4.48it/s\u001b[A\n",
      "Training loss: 7.61e-02 lr: 2.72e-05:  46%|▍| 6313/13852 [23:32<28:01,  4.48it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 2.72e-05:  46%|▍| 6314/13852 [23:33<28:03,  4.48it/s\u001b[A\n",
      "Training loss: 4.08e-02 lr: 2.72e-05:  46%|▍| 6315/13852 [23:33<28:05,  4.47it/s\u001b[A\n",
      "Training loss: 3.17e-02 lr: 2.72e-05:  46%|▍| 6316/13852 [23:33<28:04,  4.47it/s\u001b[A\n",
      "Training loss: 3.84e-02 lr: 2.72e-05:  46%|▍| 6317/13852 [23:33<27:53,  4.50it/s\u001b[A\n",
      "Training loss: 9.47e-02 lr: 2.72e-05:  46%|▍| 6318/13852 [23:34<27:47,  4.52it/s\u001b[A\n",
      "Training loss: 8.01e-02 lr: 2.72e-05:  46%|▍| 6319/13852 [23:34<27:40,  4.54it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 2.72e-05:  46%|▍| 6320/13852 [23:34<27:39,  4.54it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 2.72e-05:  46%|▍| 6321/13852 [23:34<27:40,  4.54it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 2.72e-05:  46%|▍| 6322/13852 [23:34<27:42,  4.53it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 2.72e-05:  46%|▍| 6323/13852 [23:35<27:46,  4.52it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 2.72e-05:  46%|▍| 6324/13852 [23:35<27:49,  4.51it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 2.72e-05:  46%|▍| 6325/13852 [23:35<27:55,  4.49it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 2.72e-05:  46%|▍| 6326/13852 [23:35<27:58,  4.48it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 2.72e-05:  46%|▍| 6327/13852 [23:36<27:58,  4.48it/s\u001b[A\n",
      "Training loss: 8.34e-02 lr: 2.72e-05:  46%|▍| 6328/13852 [23:36<27:59,  4.48it/s\u001b[A\n",
      "Training loss: 9.69e-02 lr: 2.72e-05:  46%|▍| 6329/13852 [23:36<27:59,  4.48it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.72e-05:  46%|▍| 6330/13852 [23:36<27:50,  4.50it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.71e-05:  46%|▍| 6331/13852 [23:36<27:40,  4.53it/s\u001b[A\n",
      "Training loss: 8.85e-02 lr: 2.71e-05:  46%|▍| 6332/13852 [23:37<28:07,  4.46it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 2.71e-05:  46%|▍| 6333/13852 [23:37<28:28,  4.40it/s\u001b[A\n",
      "Training loss: 7.35e-02 lr: 2.71e-05:  46%|▍| 6334/13852 [23:37<28:23,  4.41it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 2.71e-05:  46%|▍| 6335/13852 [23:37<28:27,  4.40it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 2.71e-05:  46%|▍| 6336/13852 [23:38<28:18,  4.43it/s\u001b[A\n",
      "Training loss: 3.12e-02 lr: 2.71e-05:  46%|▍| 6337/13852 [23:38<28:10,  4.44it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 2.71e-05:  46%|▍| 6338/13852 [23:38<28:15,  4.43it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 2.71e-05:  46%|▍| 6339/13852 [23:38<28:02,  4.46it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 2.71e-05:  46%|▍| 6340/13852 [23:39<27:47,  4.50it/s\u001b[A\n",
      "Training loss: 4.45e-02 lr: 2.71e-05:  46%|▍| 6341/13852 [23:39<27:37,  4.53it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 2.71e-05:  46%|▍| 6342/13852 [23:39<27:49,  4.50it/s\u001b[A\n",
      "Training loss: 2.78e-02 lr: 2.71e-05:  46%|▍| 6343/13852 [23:39<27:45,  4.51it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 2.71e-05:  46%|▍| 6344/13852 [23:39<27:44,  4.51it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 2.71e-05:  46%|▍| 6345/13852 [23:40<27:43,  4.51it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 2.71e-05:  46%|▍| 6346/13852 [23:40<27:44,  4.51it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 2.71e-05:  46%|▍| 6347/13852 [23:40<27:43,  4.51it/s\u001b[A\n",
      "Training loss: 4.79e-02 lr: 2.71e-05:  46%|▍| 6348/13852 [23:40<27:54,  4.48it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 2.71e-05:  46%|▍| 6349/13852 [23:41<27:58,  4.47it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 2.71e-05:  46%|▍| 6350/13852 [23:41<27:59,  4.47it/s\u001b[A\n",
      "Training loss: 3.37e-02 lr: 2.71e-05:  46%|▍| 6351/13852 [23:41<27:54,  4.48it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 2.71e-05:  46%|▍| 6352/13852 [23:41<27:45,  4.50it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 2.71e-05:  46%|▍| 6353/13852 [23:41<27:55,  4.48it/s\u001b[A\n",
      "Training loss: 8.44e-02 lr: 2.71e-05:  46%|▍| 6354/13852 [23:42<27:53,  4.48it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 2.71e-05:  46%|▍| 6355/13852 [23:42<27:51,  4.49it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 2.71e-05:  46%|▍| 6356/13852 [23:42<27:51,  4.48it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 2.71e-05:  46%|▍| 6357/13852 [23:42<27:48,  4.49it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 2.71e-05:  46%|▍| 6358/13852 [23:43<27:47,  4.49it/s\u001b[A\n",
      "Training loss: 4.26e-02 lr: 2.70e-05:  46%|▍| 6359/13852 [23:43<27:46,  4.50it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 2.70e-05:  46%|▍| 6360/13852 [23:43<27:48,  4.49it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 2.70e-05:  46%|▍| 6361/13852 [23:43<27:47,  4.49it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 2.70e-05:  46%|▍| 6362/13852 [23:43<27:43,  4.50it/s\u001b[A\n",
      "Training loss: 3.49e-02 lr: 2.70e-05:  46%|▍| 6363/13852 [23:44<27:34,  4.53it/s\u001b[A\n",
      "Training loss: 2.67e-02 lr: 2.70e-05:  46%|▍| 6364/13852 [23:44<27:26,  4.55it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 2.70e-05:  46%|▍| 6365/13852 [23:44<27:21,  4.56it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 2.70e-05:  46%|▍| 6366/13852 [23:44<27:29,  4.54it/s\u001b[A\n",
      "Training loss: 7.64e-02 lr: 2.70e-05:  46%|▍| 6367/13852 [23:45<27:32,  4.53it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 2.70e-05:  46%|▍| 6368/13852 [23:45<27:35,  4.52it/s\u001b[A\n",
      "Training loss: 1.24e-01 lr: 2.70e-05:  46%|▍| 6369/13852 [23:45<27:34,  4.52it/s\u001b[A\n",
      "Training loss: 8.77e-02 lr: 2.70e-05:  46%|▍| 6370/13852 [23:45<27:36,  4.52it/s\u001b[A\n",
      "Training loss: 7.26e-02 lr: 2.70e-05:  46%|▍| 6371/13852 [23:45<27:37,  4.51it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 2.70e-05:  46%|▍| 6372/13852 [23:46<27:39,  4.51it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 2.70e-05:  46%|▍| 6373/13852 [23:46<27:46,  4.49it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 2.70e-05:  46%|▍| 6374/13852 [23:46<27:46,  4.49it/s\u001b[A\n",
      "Training loss: 3.34e-02 lr: 2.70e-05:  46%|▍| 6375/13852 [23:46<27:37,  4.51it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 2.70e-05:  46%|▍| 6376/13852 [23:47<27:27,  4.54it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 2.70e-05:  46%|▍| 6377/13852 [23:47<27:32,  4.52it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 2.70e-05:  46%|▍| 6378/13852 [23:47<27:41,  4.50it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 2.70e-05:  46%|▍| 6379/13852 [23:47<27:37,  4.51it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 2.70e-05:  46%|▍| 6380/13852 [23:47<27:40,  4.50it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 2.70e-05:  46%|▍| 6381/13852 [23:48<29:23,  4.24it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 2.70e-05:  46%|▍| 6382/13852 [23:48<30:35,  4.07it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 2.70e-05:  46%|▍| 6383/13852 [23:48<31:05,  4.00it/s\u001b[A\n",
      "Training loss: 3.34e-02 lr: 2.70e-05:  46%|▍| 6384/13852 [23:48<30:43,  4.05it/s\u001b[A\n",
      "Training loss: 2.50e-02 lr: 2.70e-05:  46%|▍| 6385/13852 [23:49<30:28,  4.08it/s\u001b[A\n",
      "Training loss: 2.02e-02 lr: 2.70e-05:  46%|▍| 6386/13852 [23:49<30:16,  4.11it/s\u001b[A\n",
      "Training loss: 2.96e-02 lr: 2.69e-05:  46%|▍| 6387/13852 [23:49<30:10,  4.12it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 2.69e-05:  46%|▍| 6388/13852 [23:49<29:59,  4.15it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 2.69e-05:  46%|▍| 6389/13852 [23:50<29:58,  4.15it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 2.69e-05:  46%|▍| 6390/13852 [23:50<29:52,  4.16it/s\u001b[A\n",
      "Training loss: 9.08e-02 lr: 2.69e-05:  46%|▍| 6391/13852 [23:50<29:51,  4.16it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 2.69e-05:  46%|▍| 6392/13852 [23:50<30:10,  4.12it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.88e-02 lr: 2.69e-05:  46%|▍| 6393/13852 [23:51<30:05,  4.13it/s\u001b[A\n",
      "Training loss: 4.03e-02 lr: 2.69e-05:  46%|▍| 6394/13852 [23:51<30:11,  4.12it/s\u001b[A\n",
      "Training loss: 9.30e-02 lr: 2.69e-05:  46%|▍| 6395/13852 [23:51<30:04,  4.13it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 2.69e-05:  46%|▍| 6396/13852 [23:51<29:56,  4.15it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.69e-05:  46%|▍| 6397/13852 [23:52<29:55,  4.15it/s\u001b[A\n",
      "Training loss: 4.01e-02 lr: 2.69e-05:  46%|▍| 6398/13852 [23:52<29:59,  4.14it/s\u001b[A\n",
      "Training loss: 3.59e-02 lr: 2.69e-05:  46%|▍| 6399/13852 [23:52<29:50,  4.16it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 2.69e-05:  46%|▍| 6400/13852 [23:52<29:40,  4.18it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.69e-05:  46%|▍| 6401/13852 [23:53<29:45,  4.17it/s\u001b[A\n",
      "Training loss: 3.75e-02 lr: 2.69e-05:  46%|▍| 6402/13852 [23:53<29:47,  4.17it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 2.69e-05:  46%|▍| 6403/13852 [23:53<29:48,  4.17it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 2.69e-05:  46%|▍| 6404/13852 [23:53<29:48,  4.16it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 2.69e-05:  46%|▍| 6405/13852 [23:53<29:40,  4.18it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 2.69e-05:  46%|▍| 6406/13852 [23:54<29:48,  4.16it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 2.69e-05:  46%|▍| 6407/13852 [23:54<29:45,  4.17it/s\u001b[A\n",
      "Training loss: 7.94e-02 lr: 2.69e-05:  46%|▍| 6408/13852 [23:54<29:40,  4.18it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 2.69e-05:  46%|▍| 6409/13852 [23:54<29:40,  4.18it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 2.69e-05:  46%|▍| 6410/13852 [23:55<29:42,  4.18it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 2.69e-05:  46%|▍| 6411/13852 [23:55<29:36,  4.19it/s\u001b[A\n",
      "Training loss: 4.30e-02 lr: 2.69e-05:  46%|▍| 6412/13852 [23:55<29:43,  4.17it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 2.69e-05:  46%|▍| 6413/13852 [23:55<29:44,  4.17it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 2.69e-05:  46%|▍| 6414/13852 [23:56<29:39,  4.18it/s\u001b[A\n",
      "Training loss: 1.79e-01 lr: 2.68e-05:  46%|▍| 6415/13852 [23:56<29:39,  4.18it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 2.68e-05:  46%|▍| 6416/13852 [23:56<29:44,  4.17it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.68e-05:  46%|▍| 6417/13852 [23:56<29:38,  4.18it/s\u001b[A\n",
      "Training loss: 8.22e-02 lr: 2.68e-05:  46%|▍| 6418/13852 [23:57<29:41,  4.17it/s\u001b[A\n",
      "Training loss: 8.49e-02 lr: 2.68e-05:  46%|▍| 6419/13852 [23:57<29:56,  4.14it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 2.68e-05:  46%|▍| 6420/13852 [23:57<29:52,  4.15it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 2.68e-05:  46%|▍| 6421/13852 [23:57<29:50,  4.15it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 2.68e-05:  46%|▍| 6422/13852 [23:58<29:42,  4.17it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 2.68e-05:  46%|▍| 6423/13852 [23:58<29:33,  4.19it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 2.68e-05:  46%|▍| 6424/13852 [23:58<29:29,  4.20it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 2.68e-05:  46%|▍| 6425/13852 [23:58<29:33,  4.19it/s\u001b[A\n",
      "Training loss: 5.45e-02 lr: 2.68e-05:  46%|▍| 6426/13852 [23:59<29:35,  4.18it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 2.68e-05:  46%|▍| 6427/13852 [23:59<29:37,  4.18it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 2.68e-05:  46%|▍| 6428/13852 [23:59<29:37,  4.18it/s\u001b[A\n",
      "Training loss: 3.77e-02 lr: 2.68e-05:  46%|▍| 6429/13852 [23:59<29:31,  4.19it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 2.68e-05:  46%|▍| 6430/13852 [23:59<29:35,  4.18it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 2.68e-05:  46%|▍| 6431/13852 [24:00<29:35,  4.18it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 2.68e-05:  46%|▍| 6432/13852 [24:00<29:34,  4.18it/s\u001b[A\n",
      "Training loss: 7.94e-02 lr: 2.68e-05:  46%|▍| 6433/13852 [24:00<29:41,  4.16it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 2.68e-05:  46%|▍| 6434/13852 [24:00<29:50,  4.14it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.68e-05:  46%|▍| 6435/13852 [24:01<29:43,  4.16it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 2.68e-05:  46%|▍| 6436/13852 [24:01<29:51,  4.14it/s\u001b[A\n",
      "Training loss: 7.81e-02 lr: 2.68e-05:  46%|▍| 6437/13852 [24:01<29:45,  4.15it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 2.68e-05:  46%|▍| 6438/13852 [24:01<29:42,  4.16it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 2.68e-05:  46%|▍| 6439/13852 [24:02<29:41,  4.16it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.68e-05:  46%|▍| 6440/13852 [24:02<29:40,  4.16it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 2.68e-05:  46%|▍| 6441/13852 [24:02<29:33,  4.18it/s\u001b[A\n",
      "Training loss: 3.03e-02 lr: 2.67e-05:  47%|▍| 6442/13852 [24:02<29:36,  4.17it/s\u001b[A\n",
      "Training loss: 2.59e-02 lr: 2.67e-05:  47%|▍| 6443/13852 [24:03<29:41,  4.16it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 2.67e-05:  47%|▍| 6444/13852 [24:03<29:39,  4.16it/s\u001b[A\n",
      "Training loss: 1.37e-01 lr: 2.67e-05:  47%|▍| 6445/13852 [24:03<29:50,  4.14it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 2.67e-05:  47%|▍| 6446/13852 [24:03<29:51,  4.13it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 2.67e-05:  47%|▍| 6447/13852 [24:04<29:47,  4.14it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 2.67e-05:  47%|▍| 6448/13852 [24:04<29:44,  4.15it/s\u001b[A\n",
      "Training loss: 6.17e-02 lr: 2.67e-05:  47%|▍| 6449/13852 [24:04<29:39,  4.16it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 2.67e-05:  47%|▍| 6450/13852 [24:04<29:35,  4.17it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 2.67e-05:  47%|▍| 6451/13852 [24:05<29:32,  4.18it/s\u001b[A\n",
      "Training loss: 6.02e-02 lr: 2.67e-05:  47%|▍| 6452/13852 [24:05<29:29,  4.18it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 2.67e-05:  47%|▍| 6453/13852 [24:05<29:27,  4.19it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 2.67e-05:  47%|▍| 6454/13852 [24:05<29:24,  4.19it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 2.67e-05:  47%|▍| 6455/13852 [24:05<29:20,  4.20it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 2.67e-05:  47%|▍| 6456/13852 [24:06<29:22,  4.20it/s\u001b[A\n",
      "Training loss: 8.79e-02 lr: 2.67e-05:  47%|▍| 6457/13852 [24:06<29:25,  4.19it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 2.67e-05:  47%|▍| 6458/13852 [24:06<29:19,  4.20it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 2.67e-05:  47%|▍| 6459/13852 [24:06<29:19,  4.20it/s\u001b[A\n",
      "Training loss: 9.17e-02 lr: 2.67e-05:  47%|▍| 6460/13852 [24:07<29:35,  4.16it/s\u001b[A\n",
      "Training loss: 6.78e-02 lr: 2.67e-05:  47%|▍| 6461/13852 [24:07<29:47,  4.14it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 2.67e-05:  47%|▍| 6462/13852 [24:07<29:50,  4.13it/s\u001b[A\n",
      "Training loss: 4.95e-02 lr: 2.67e-05:  47%|▍| 6463/13852 [24:07<30:03,  4.10it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 2.67e-05:  47%|▍| 6464/13852 [24:08<30:00,  4.10it/s\u001b[A\n",
      "Training loss: 9.13e-02 lr: 2.67e-05:  47%|▍| 6465/13852 [24:08<29:51,  4.12it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 2.67e-05:  47%|▍| 6466/13852 [24:08<29:48,  4.13it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.67e-05:  47%|▍| 6467/13852 [24:08<29:40,  4.15it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 2.67e-05:  47%|▍| 6468/13852 [24:09<29:37,  4.15it/s\u001b[A\n",
      "Training loss: 9.47e-02 lr: 2.67e-05:  47%|▍| 6469/13852 [24:09<29:28,  4.17it/s\u001b[A\n",
      "Training loss: 7.63e-02 lr: 2.66e-05:  47%|▍| 6470/13852 [24:09<29:25,  4.18it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 2.66e-05:  47%|▍| 6471/13852 [24:09<29:24,  4.18it/s\u001b[A\n",
      "Training loss: 4.38e-02 lr: 2.66e-05:  47%|▍| 6472/13852 [24:10<29:23,  4.18it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 2.66e-05:  47%|▍| 6473/13852 [24:10<29:24,  4.18it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 2.66e-05:  47%|▍| 6474/13852 [24:10<29:23,  4.18it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 2.66e-05:  47%|▍| 6475/13852 [24:10<29:16,  4.20it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 2.66e-05:  47%|▍| 6476/13852 [24:11<29:15,  4.20it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 2.66e-05:  47%|▍| 6477/13852 [24:11<29:24,  4.18it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 2.66e-05:  47%|▍| 6478/13852 [24:11<29:27,  4.17it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 2.66e-05:  47%|▍| 6479/13852 [24:11<29:27,  4.17it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 2.66e-05:  47%|▍| 6480/13852 [24:11<29:28,  4.17it/s\u001b[A\n",
      "Training loss: 8.18e-02 lr: 2.66e-05:  47%|▍| 6481/13852 [24:12<29:33,  4.16it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 2.66e-05:  47%|▍| 6482/13852 [24:12<29:30,  4.16it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.66e-05:  47%|▍| 6483/13852 [24:12<29:26,  4.17it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 2.66e-05:  47%|▍| 6484/13852 [24:12<29:22,  4.18it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 2.66e-05:  47%|▍| 6485/13852 [24:13<29:24,  4.18it/s\u001b[A\n",
      "Training loss: 9.35e-02 lr: 2.66e-05:  47%|▍| 6486/13852 [24:13<29:25,  4.17it/s\u001b[A\n",
      "Training loss: 7.95e-02 lr: 2.66e-05:  47%|▍| 6487/13852 [24:13<29:17,  4.19it/s\u001b[A\n",
      "Training loss: 7.00e-02 lr: 2.66e-05:  47%|▍| 6488/13852 [24:13<29:16,  4.19it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 2.66e-05:  47%|▍| 6489/13852 [24:14<29:22,  4.18it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.34e-02 lr: 2.66e-05:  47%|▍| 6490/13852 [24:14<29:18,  4.19it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 2.66e-05:  47%|▍| 6491/13852 [24:14<29:19,  4.18it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 2.66e-05:  47%|▍| 6492/13852 [24:14<29:21,  4.18it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 2.66e-05:  47%|▍| 6493/13852 [24:15<29:16,  4.19it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 2.66e-05:  47%|▍| 6494/13852 [24:15<29:14,  4.19it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 2.66e-05:  47%|▍| 6495/13852 [24:15<29:15,  4.19it/s\u001b[A\n",
      "Training loss: 9.05e-02 lr: 2.66e-05:  47%|▍| 6496/13852 [24:15<29:19,  4.18it/s\u001b[A\n",
      "Training loss: 9.13e-02 lr: 2.66e-05:  47%|▍| 6497/13852 [24:16<29:23,  4.17it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 2.65e-05:  47%|▍| 6498/13852 [24:16<29:24,  4.17it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 2.65e-05:  47%|▍| 6499/13852 [24:16<29:16,  4.19it/s\u001b[A\n",
      "Training loss: 9.21e-02 lr: 2.65e-05:  47%|▍| 6500/13852 [24:16<29:17,  4.18it/s\u001b[A\n",
      "Training loss: 7.81e-02 lr: 2.65e-05:  47%|▍| 6501/13852 [24:16<29:16,  4.18it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 2.65e-05:  47%|▍| 6502/13852 [24:17<29:29,  4.15it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.65e-05:  47%|▍| 6503/13852 [24:17<29:29,  4.15it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 2.65e-05:  47%|▍| 6504/13852 [24:17<29:29,  4.15it/s\u001b[A\n",
      "Training loss: 3.43e-02 lr: 2.65e-05:  47%|▍| 6505/13852 [24:17<29:19,  4.17it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 2.65e-05:  47%|▍| 6506/13852 [24:18<29:25,  4.16it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 2.65e-05:  47%|▍| 6507/13852 [24:18<29:22,  4.17it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.65e-05:  47%|▍| 6508/13852 [24:18<29:21,  4.17it/s\u001b[A\n",
      "Training loss: 8.92e-02 lr: 2.65e-05:  47%|▍| 6509/13852 [24:18<29:20,  4.17it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 2.65e-05:  47%|▍| 6510/13852 [24:19<29:20,  4.17it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 2.65e-05:  47%|▍| 6511/13852 [24:19<29:13,  4.19it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 2.65e-05:  47%|▍| 6512/13852 [24:19<29:14,  4.18it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 2.65e-05:  47%|▍| 6513/13852 [24:19<29:13,  4.18it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 2.65e-05:  47%|▍| 6514/13852 [24:20<29:16,  4.18it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 2.65e-05:  47%|▍| 6515/13852 [24:20<29:14,  4.18it/s\u001b[A\n",
      "Training loss: 3.80e-02 lr: 2.65e-05:  47%|▍| 6516/13852 [24:20<29:09,  4.19it/s\u001b[A\n",
      "Training loss: 3.01e-02 lr: 2.65e-05:  47%|▍| 6517/13852 [24:20<29:06,  4.20it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 2.65e-05:  47%|▍| 6518/13852 [24:21<29:14,  4.18it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 2.65e-05:  47%|▍| 6519/13852 [24:21<29:25,  4.15it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 2.65e-05:  47%|▍| 6520/13852 [24:21<29:24,  4.15it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 2.65e-05:  47%|▍| 6521/13852 [24:21<29:19,  4.17it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 2.65e-05:  47%|▍| 6522/13852 [24:22<29:10,  4.19it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 2.65e-05:  47%|▍| 6523/13852 [24:22<29:24,  4.15it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 2.65e-05:  47%|▍| 6524/13852 [24:22<29:22,  4.16it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 2.64e-05:  47%|▍| 6525/13852 [24:22<29:24,  4.15it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 2.64e-05:  47%|▍| 6526/13852 [24:22<29:25,  4.15it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 2.64e-05:  47%|▍| 6527/13852 [24:23<30:03,  4.06it/s\u001b[A\n",
      "Training loss: 4.93e-02 lr: 2.64e-05:  47%|▍| 6528/13852 [24:23<29:43,  4.11it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 2.64e-05:  47%|▍| 6529/13852 [24:23<29:33,  4.13it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 2.64e-05:  47%|▍| 6530/13852 [24:23<29:24,  4.15it/s\u001b[A\n",
      "Training loss: 9.40e-02 lr: 2.64e-05:  47%|▍| 6531/13852 [24:24<29:21,  4.16it/s\u001b[A\n",
      "Training loss: 7.20e-02 lr: 2.64e-05:  47%|▍| 6532/13852 [24:24<29:15,  4.17it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 2.64e-05:  47%|▍| 6533/13852 [24:24<29:10,  4.18it/s\u001b[A\n",
      "Training loss: 9.54e-02 lr: 2.64e-05:  47%|▍| 6534/13852 [24:24<29:03,  4.20it/s\u001b[A\n",
      "Training loss: 8.55e-02 lr: 2.64e-05:  47%|▍| 6535/13852 [24:25<29:09,  4.18it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 2.64e-05:  47%|▍| 6536/13852 [24:25<29:08,  4.18it/s\u001b[A\n",
      "Training loss: 8.66e-02 lr: 2.64e-05:  47%|▍| 6537/13852 [24:25<29:05,  4.19it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 2.64e-05:  47%|▍| 6538/13852 [24:25<29:05,  4.19it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 2.64e-05:  47%|▍| 6539/13852 [24:26<29:04,  4.19it/s\u001b[A\n",
      "Training loss: 6.42e-02 lr: 2.64e-05:  47%|▍| 6540/13852 [24:26<29:09,  4.18it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 2.64e-05:  47%|▍| 6541/13852 [24:26<29:12,  4.17it/s\u001b[A\n",
      "Training loss: 5.68e-02 lr: 2.64e-05:  47%|▍| 6542/13852 [24:26<29:09,  4.18it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 2.64e-05:  47%|▍| 6543/13852 [24:27<29:05,  4.19it/s\u001b[A\n",
      "Training loss: 7.76e-02 lr: 2.64e-05:  47%|▍| 6544/13852 [24:27<29:23,  4.15it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 2.64e-05:  47%|▍| 6545/13852 [24:27<29:15,  4.16it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 2.64e-05:  47%|▍| 6546/13852 [24:27<29:06,  4.18it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.64e-05:  47%|▍| 6547/13852 [24:28<29:06,  4.18it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 2.64e-05:  47%|▍| 6548/13852 [24:28<29:08,  4.18it/s\u001b[A\n",
      "Training loss: 8.97e-02 lr: 2.64e-05:  47%|▍| 6549/13852 [24:28<29:05,  4.18it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 2.64e-05:  47%|▍| 6550/13852 [24:28<29:05,  4.18it/s\u001b[A\n",
      "Training loss: 9.85e-02 lr: 2.64e-05:  47%|▍| 6551/13852 [24:28<29:00,  4.20it/s\u001b[A\n",
      "Training loss: 8.23e-02 lr: 2.64e-05:  47%|▍| 6552/13852 [24:29<28:53,  4.21it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 2.63e-05:  47%|▍| 6553/13852 [24:29<28:55,  4.20it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 2.63e-05:  47%|▍| 6554/13852 [24:29<28:56,  4.20it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 2.63e-05:  47%|▍| 6555/13852 [24:29<28:56,  4.20it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 2.63e-05:  47%|▍| 6556/13852 [24:30<28:55,  4.20it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 2.63e-05:  47%|▍| 6557/13852 [24:30<28:57,  4.20it/s\u001b[A\n",
      "Training loss: 4.07e-02 lr: 2.63e-05:  47%|▍| 6558/13852 [24:30<28:53,  4.21it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 2.63e-05:  47%|▍| 6559/13852 [24:30<28:59,  4.19it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 2.63e-05:  47%|▍| 6560/13852 [24:31<29:04,  4.18it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 2.63e-05:  47%|▍| 6561/13852 [24:31<29:15,  4.15it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 2.63e-05:  47%|▍| 6562/13852 [24:31<29:09,  4.17it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 2.63e-05:  47%|▍| 6563/13852 [24:31<29:07,  4.17it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 2.63e-05:  47%|▍| 6564/13852 [24:32<28:59,  4.19it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 2.63e-05:  47%|▍| 6565/13852 [24:32<29:06,  4.17it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 2.63e-05:  47%|▍| 6566/13852 [24:32<29:08,  4.17it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 2.63e-05:  47%|▍| 6567/13852 [24:32<29:04,  4.18it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 2.63e-05:  47%|▍| 6568/13852 [24:33<29:02,  4.18it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 2.63e-05:  47%|▍| 6569/13852 [24:33<29:01,  4.18it/s\u001b[A\n",
      "Training loss: 3.68e-02 lr: 2.63e-05:  47%|▍| 6570/13852 [24:33<29:13,  4.15it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 2.63e-05:  47%|▍| 6571/13852 [24:33<29:14,  4.15it/s\u001b[A\n",
      "Training loss: 8.62e-02 lr: 2.63e-05:  47%|▍| 6572/13852 [24:34<29:11,  4.16it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 2.63e-05:  47%|▍| 6573/13852 [24:34<29:06,  4.17it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.63e-05:  47%|▍| 6574/13852 [24:34<29:03,  4.17it/s\u001b[A\n",
      "Training loss: 7.72e-02 lr: 2.63e-05:  47%|▍| 6575/13852 [24:34<28:58,  4.19it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.63e-05:  47%|▍| 6576/13852 [24:34<29:01,  4.18it/s\u001b[A\n",
      "Training loss: 7.53e-02 lr: 2.63e-05:  47%|▍| 6577/13852 [24:35<28:59,  4.18it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 2.63e-05:  47%|▍| 6578/13852 [24:35<28:59,  4.18it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 2.63e-05:  47%|▍| 6579/13852 [24:35<28:57,  4.19it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 2.63e-05:  48%|▍| 6580/13852 [24:35<28:55,  4.19it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 2.62e-05:  48%|▍| 6581/13852 [24:36<28:52,  4.20it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 2.62e-05:  48%|▍| 6582/13852 [24:36<28:46,  4.21it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 2.62e-05:  48%|▍| 6583/13852 [24:36<28:50,  4.20it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.62e-05:  48%|▍| 6584/13852 [24:36<28:50,  4.20it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 2.62e-05:  48%|▍| 6585/13852 [24:37<28:48,  4.20it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 2.62e-05:  48%|▍| 6586/13852 [24:37<29:07,  4.16it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.56e-02 lr: 2.62e-05:  48%|▍| 6587/13852 [24:37<29:11,  4.15it/s\u001b[A\n",
      "Training loss: 8.93e-02 lr: 2.62e-05:  48%|▍| 6588/13852 [24:37<29:08,  4.15it/s\u001b[A\n",
      "Training loss: 7.01e-02 lr: 2.62e-05:  48%|▍| 6589/13852 [24:38<29:06,  4.16it/s\u001b[A\n",
      "Training loss: 7.53e-02 lr: 2.62e-05:  48%|▍| 6590/13852 [24:38<29:05,  4.16it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 2.62e-05:  48%|▍| 6591/13852 [24:38<29:02,  4.17it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 2.62e-05:  48%|▍| 6592/13852 [24:38<28:56,  4.18it/s\u001b[A\n",
      "Training loss: 9.72e-02 lr: 2.62e-05:  48%|▍| 6593/13852 [24:39<28:51,  4.19it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 2.62e-05:  48%|▍| 6594/13852 [24:39<28:54,  4.18it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 2.62e-05:  48%|▍| 6595/13852 [24:39<28:54,  4.18it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 2.62e-05:  48%|▍| 6596/13852 [24:39<28:51,  4.19it/s\u001b[A\n",
      "Training loss: 3.28e-02 lr: 2.62e-05:  48%|▍| 6597/13852 [24:39<28:52,  4.19it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 2.62e-05:  48%|▍| 6598/13852 [24:40<28:51,  4.19it/s\u001b[A\n",
      "Training loss: 7.68e-02 lr: 2.62e-05:  48%|▍| 6599/13852 [24:40<28:46,  4.20it/s\u001b[A\n",
      "Training loss: 9.54e-02 lr: 2.62e-05:  48%|▍| 6600/13852 [24:40<28:44,  4.20it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 2.62e-05:  48%|▍| 6601/13852 [24:40<28:46,  4.20it/s\u001b[A\n",
      "Training loss: 6.41e-02 lr: 2.62e-05:  48%|▍| 6602/13852 [24:41<29:06,  4.15it/s\u001b[A\n",
      "Training loss: 9.25e-02 lr: 2.62e-05:  48%|▍| 6603/13852 [24:41<29:15,  4.13it/s\u001b[A\n",
      "Training loss: 9.62e-02 lr: 2.62e-05:  48%|▍| 6604/13852 [24:41<29:09,  4.14it/s\u001b[A\n",
      "Training loss: 8.60e-02 lr: 2.62e-05:  48%|▍| 6605/13852 [24:41<28:57,  4.17it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 2.62e-05:  48%|▍| 6606/13852 [24:42<28:56,  4.17it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 2.62e-05:  48%|▍| 6607/13852 [24:42<28:59,  4.16it/s\u001b[A\n",
      "Training loss: 6.17e-02 lr: 2.61e-05:  48%|▍| 6608/13852 [24:42<28:58,  4.17it/s\u001b[A\n",
      "Training loss: 6.46e-02 lr: 2.61e-05:  48%|▍| 6609/13852 [24:42<28:54,  4.17it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 2.61e-05:  48%|▍| 6610/13852 [24:43<28:52,  4.18it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 2.61e-05:  48%|▍| 6611/13852 [24:43<29:01,  4.16it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 2.61e-05:  48%|▍| 6612/13852 [24:43<29:04,  4.15it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 2.61e-05:  48%|▍| 6613/13852 [24:43<29:06,  4.15it/s\u001b[A\n",
      "Training loss: 8.14e-02 lr: 2.61e-05:  48%|▍| 6614/13852 [24:44<29:01,  4.16it/s\u001b[A\n",
      "Training loss: 7.63e-02 lr: 2.61e-05:  48%|▍| 6615/13852 [24:44<28:56,  4.17it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 2.61e-05:  48%|▍| 6616/13852 [24:44<28:54,  4.17it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 2.61e-05:  48%|▍| 6617/13852 [24:44<28:48,  4.19it/s\u001b[A\n",
      "Training loss: 6.10e-02 lr: 2.61e-05:  48%|▍| 6618/13852 [24:45<28:50,  4.18it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 2.61e-05:  48%|▍| 6619/13852 [24:45<28:51,  4.18it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 2.61e-05:  48%|▍| 6620/13852 [24:45<28:48,  4.18it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.61e-05:  48%|▍| 6621/13852 [24:45<28:49,  4.18it/s\u001b[A\n",
      "Training loss: 3.90e-02 lr: 2.61e-05:  48%|▍| 6622/13852 [24:45<28:47,  4.19it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 2.61e-05:  48%|▍| 6623/13852 [24:46<28:40,  4.20it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 2.61e-05:  48%|▍| 6624/13852 [24:46<28:41,  4.20it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 2.61e-05:  48%|▍| 6625/13852 [24:46<28:42,  4.20it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 2.61e-05:  48%|▍| 6626/13852 [24:46<28:49,  4.18it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.61e-05:  48%|▍| 6627/13852 [24:47<28:56,  4.16it/s\u001b[A\n",
      "Training loss: 8.51e-02 lr: 2.61e-05:  48%|▍| 6628/13852 [24:47<28:57,  4.16it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 2.61e-05:  48%|▍| 6629/13852 [24:47<28:56,  4.16it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 2.61e-05:  48%|▍| 6630/13852 [24:47<29:02,  4.15it/s\u001b[A\n",
      "Training loss: 6.10e-02 lr: 2.61e-05:  48%|▍| 6631/13852 [24:48<29:03,  4.14it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 2.61e-05:  48%|▍| 6632/13852 [24:48<28:57,  4.16it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 2.61e-05:  48%|▍| 6633/13852 [24:48<28:56,  4.16it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 2.61e-05:  48%|▍| 6634/13852 [24:48<28:52,  4.17it/s\u001b[A\n",
      "Training loss: 2.90e-02 lr: 2.61e-05:  48%|▍| 6635/13852 [24:49<28:49,  4.17it/s\u001b[A\n",
      "Training loss: 2.89e-02 lr: 2.60e-05:  48%|▍| 6636/13852 [24:49<28:52,  4.17it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.60e-05:  48%|▍| 6637/13852 [24:49<28:46,  4.18it/s\u001b[A\n",
      "Training loss: 9.58e-02 lr: 2.60e-05:  48%|▍| 6638/13852 [24:49<28:43,  4.19it/s\u001b[A\n",
      "Training loss: 7.96e-02 lr: 2.60e-05:  48%|▍| 6639/13852 [24:50<28:45,  4.18it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 2.60e-05:  48%|▍| 6640/13852 [24:50<28:41,  4.19it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 2.60e-05:  48%|▍| 6641/13852 [24:50<28:38,  4.20it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 2.60e-05:  48%|▍| 6642/13852 [24:50<28:41,  4.19it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 2.60e-05:  48%|▍| 6643/13852 [24:51<28:41,  4.19it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 2.60e-05:  48%|▍| 6644/13852 [24:51<28:58,  4.15it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 2.60e-05:  48%|▍| 6645/13852 [24:51<28:59,  4.14it/s\u001b[A\n",
      "Training loss: 7.21e-02 lr: 2.60e-05:  48%|▍| 6646/13852 [24:51<28:55,  4.15it/s\u001b[A\n",
      "Training loss: 7.33e-02 lr: 2.60e-05:  48%|▍| 6647/13852 [24:51<28:50,  4.16it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 2.60e-05:  48%|▍| 6648/13852 [24:52<28:59,  4.14it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 2.60e-05:  48%|▍| 6649/13852 [24:52<28:52,  4.16it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 2.60e-05:  48%|▍| 6650/13852 [24:52<28:50,  4.16it/s\u001b[A\n",
      "Training loss: 3.45e-02 lr: 2.60e-05:  48%|▍| 6651/13852 [24:52<28:53,  4.15it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 2.60e-05:  48%|▍| 6652/13852 [24:53<28:43,  4.18it/s\u001b[A\n",
      "Training loss: 2.48e-02 lr: 2.60e-05:  48%|▍| 6653/13852 [24:53<28:43,  4.18it/s\u001b[A\n",
      "Training loss: 8.57e-02 lr: 2.60e-05:  48%|▍| 6654/13852 [24:53<28:42,  4.18it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 2.60e-05:  48%|▍| 6655/13852 [24:53<28:39,  4.19it/s\u001b[A\n",
      "Training loss: 6.82e-02 lr: 2.60e-05:  48%|▍| 6656/13852 [24:54<28:38,  4.19it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 2.60e-05:  48%|▍| 6657/13852 [24:54<28:36,  4.19it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.60e-05:  48%|▍| 6658/13852 [24:54<28:32,  4.20it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.60e-05:  48%|▍| 6659/13852 [24:54<28:34,  4.20it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 2.60e-05:  48%|▍| 6660/13852 [24:55<28:34,  4.19it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 2.60e-05:  48%|▍| 6661/13852 [24:55<28:33,  4.20it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 2.60e-05:  48%|▍| 6662/13852 [24:55<28:31,  4.20it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 2.60e-05:  48%|▍| 6663/13852 [24:55<28:32,  4.20it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 2.59e-05:  48%|▍| 6664/13852 [24:56<28:27,  4.21it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 2.59e-05:  48%|▍| 6665/13852 [24:56<28:27,  4.21it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 2.59e-05:  48%|▍| 6666/13852 [24:56<28:30,  4.20it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 2.59e-05:  48%|▍| 6667/13852 [24:56<28:33,  4.19it/s\u001b[A\n",
      "Training loss: 3.65e-02 lr: 2.59e-05:  48%|▍| 6668/13852 [24:56<28:34,  4.19it/s\u001b[A\n",
      "Training loss: 3.47e-02 lr: 2.59e-05:  48%|▍| 6669/13852 [24:57<28:46,  4.16it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 2.59e-05:  48%|▍| 6670/13852 [24:57<28:41,  4.17it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 2.59e-05:  48%|▍| 6671/13852 [24:57<28:35,  4.19it/s\u001b[A\n",
      "Training loss: 3.37e-02 lr: 2.59e-05:  48%|▍| 6672/13852 [24:57<28:33,  4.19it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 2.59e-05:  48%|▍| 6673/13852 [24:58<28:33,  4.19it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 2.59e-05:  48%|▍| 6674/13852 [24:58<28:32,  4.19it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 2.59e-05:  48%|▍| 6675/13852 [24:58<28:30,  4.19it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 2.59e-05:  48%|▍| 6676/13852 [24:58<28:26,  4.20it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 2.59e-05:  48%|▍| 6677/13852 [24:59<28:29,  4.20it/s\u001b[A\n",
      "Training loss: 9.83e-02 lr: 2.59e-05:  48%|▍| 6678/13852 [24:59<28:30,  4.19it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 2.59e-05:  48%|▍| 6679/13852 [24:59<28:28,  4.20it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 2.59e-05:  48%|▍| 6680/13852 [24:59<28:29,  4.20it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 2.59e-05:  48%|▍| 6681/13852 [25:00<28:31,  4.19it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 2.59e-05:  48%|▍| 6682/13852 [25:00<28:27,  4.20it/s\u001b[A\n",
      "Training loss: 4.78e-02 lr: 2.59e-05:  48%|▍| 6683/13852 [25:00<28:31,  4.19it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.07e-02 lr: 2.59e-05:  48%|▍| 6684/13852 [25:00<28:41,  4.16it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 2.59e-05:  48%|▍| 6685/13852 [25:01<28:35,  4.18it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 2.59e-05:  48%|▍| 6686/13852 [25:01<28:52,  4.14it/s\u001b[A\n",
      "Training loss: 3.17e-02 lr: 2.59e-05:  48%|▍| 6687/13852 [25:01<28:48,  4.15it/s\u001b[A\n",
      "Training loss: 4.42e-02 lr: 2.59e-05:  48%|▍| 6688/13852 [25:01<28:41,  4.16it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 2.59e-05:  48%|▍| 6689/13852 [25:02<28:37,  4.17it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 2.59e-05:  48%|▍| 6690/13852 [25:02<28:50,  4.14it/s\u001b[A\n",
      "Training loss: 4.93e-02 lr: 2.59e-05:  48%|▍| 6691/13852 [25:02<28:45,  4.15it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 2.58e-05:  48%|▍| 6692/13852 [25:02<28:40,  4.16it/s\u001b[A\n",
      "Training loss: 4.30e-02 lr: 2.58e-05:  48%|▍| 6693/13852 [25:02<28:31,  4.18it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 2.58e-05:  48%|▍| 6694/13852 [25:03<28:27,  4.19it/s\u001b[A\n",
      "Training loss: 3.89e-02 lr: 2.58e-05:  48%|▍| 6695/13852 [25:03<28:33,  4.18it/s\u001b[A\n",
      "Training loss: 2.91e-02 lr: 2.58e-05:  48%|▍| 6696/13852 [25:03<28:32,  4.18it/s\u001b[A\n",
      "Training loss: 3.44e-02 lr: 2.58e-05:  48%|▍| 6697/13852 [25:03<28:28,  4.19it/s\u001b[A\n",
      "Training loss: 3.75e-02 lr: 2.58e-05:  48%|▍| 6698/13852 [25:04<28:32,  4.18it/s\u001b[A\n",
      "Training loss: 3.52e-02 lr: 2.58e-05:  48%|▍| 6699/13852 [25:04<28:31,  4.18it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 2.58e-05:  48%|▍| 6700/13852 [25:04<28:25,  4.19it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 2.58e-05:  48%|▍| 6701/13852 [25:04<28:32,  4.17it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 2.58e-05:  48%|▍| 6702/13852 [25:05<28:32,  4.17it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 2.58e-05:  48%|▍| 6703/13852 [25:05<28:29,  4.18it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 2.58e-05:  48%|▍| 6704/13852 [25:05<28:27,  4.19it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 2.58e-05:  48%|▍| 6705/13852 [25:05<28:23,  4.20it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 2.58e-05:  48%|▍| 6706/13852 [25:06<28:19,  4.21it/s\u001b[A\n",
      "Training loss: 7.12e-02 lr: 2.58e-05:  48%|▍| 6707/13852 [25:06<28:23,  4.19it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 2.58e-05:  48%|▍| 6708/13852 [25:06<28:23,  4.19it/s\u001b[A\n",
      "Training loss: 9.48e-02 lr: 2.58e-05:  48%|▍| 6709/13852 [25:06<28:21,  4.20it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 2.58e-05:  48%|▍| 6710/13852 [25:07<28:19,  4.20it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.58e-05:  48%|▍| 6711/13852 [25:07<28:49,  4.13it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 2.58e-05:  48%|▍| 6712/13852 [25:07<28:52,  4.12it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 2.58e-05:  48%|▍| 6713/13852 [25:07<28:52,  4.12it/s\u001b[A\n",
      "Training loss: 4.38e-02 lr: 2.58e-05:  48%|▍| 6714/13852 [25:08<28:55,  4.11it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 2.58e-05:  48%|▍| 6715/13852 [25:08<28:49,  4.13it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 2.58e-05:  48%|▍| 6716/13852 [25:08<28:40,  4.15it/s\u001b[A\n",
      "Training loss: 9.67e-02 lr: 2.58e-05:  48%|▍| 6717/13852 [25:08<28:31,  4.17it/s\u001b[A\n",
      "Training loss: 6.99e-02 lr: 2.58e-05:  48%|▍| 6718/13852 [25:08<28:29,  4.17it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 2.57e-05:  49%|▍| 6719/13852 [25:09<28:26,  4.18it/s\u001b[A\n",
      "Training loss: 9.29e-02 lr: 2.57e-05:  49%|▍| 6720/13852 [25:09<28:22,  4.19it/s\u001b[A\n",
      "Training loss: 9.14e-02 lr: 2.57e-05:  49%|▍| 6721/13852 [25:09<28:21,  4.19it/s\u001b[A\n",
      "Training loss: 9.46e-02 lr: 2.57e-05:  49%|▍| 6722/13852 [25:09<28:22,  4.19it/s\u001b[A\n",
      "Training loss: 8.68e-02 lr: 2.57e-05:  49%|▍| 6723/13852 [25:10<28:17,  4.20it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 2.57e-05:  49%|▍| 6724/13852 [25:10<28:16,  4.20it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 2.57e-05:  49%|▍| 6725/13852 [25:10<28:18,  4.20it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.57e-05:  49%|▍| 6726/13852 [25:10<28:17,  4.20it/s\u001b[A\n",
      "Training loss: 7.92e-02 lr: 2.57e-05:  49%|▍| 6727/13852 [25:11<28:15,  4.20it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 2.57e-05:  49%|▍| 6728/13852 [25:11<28:39,  4.14it/s\u001b[A\n",
      "Training loss: 5.32e-02 lr: 2.57e-05:  49%|▍| 6729/13852 [25:11<28:31,  4.16it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 2.57e-05:  49%|▍| 6730/13852 [25:11<28:25,  4.18it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 2.57e-05:  49%|▍| 6731/13852 [25:12<28:28,  4.17it/s\u001b[A\n",
      "Training loss: 6.82e-02 lr: 2.57e-05:  49%|▍| 6732/13852 [25:12<28:26,  4.17it/s\u001b[A\n",
      "Training loss: 8.42e-02 lr: 2.57e-05:  49%|▍| 6733/13852 [25:12<27:46,  4.27it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.57e-05:  49%|▍| 6734/13852 [25:12<27:15,  4.35it/s\u001b[A\n",
      "Training loss: 9.57e-02 lr: 2.57e-05:  49%|▍| 6735/13852 [25:12<26:52,  4.41it/s\u001b[A\n",
      "Training loss: 9.09e-02 lr: 2.57e-05:  49%|▍| 6736/13852 [25:13<26:34,  4.46it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 2.57e-05:  49%|▍| 6737/13852 [25:13<26:17,  4.51it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 2.57e-05:  49%|▍| 6738/13852 [25:13<26:09,  4.53it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 2.57e-05:  49%|▍| 6739/13852 [25:13<26:17,  4.51it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 2.57e-05:  49%|▍| 6740/13852 [25:14<26:13,  4.52it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 2.57e-05:  49%|▍| 6741/13852 [25:14<26:12,  4.52it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 2.57e-05:  49%|▍| 6742/13852 [25:14<26:12,  4.52it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 2.57e-05:  49%|▍| 6743/13852 [25:14<26:10,  4.53it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 2.57e-05:  49%|▍| 6744/13852 [25:14<26:08,  4.53it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 2.57e-05:  49%|▍| 6745/13852 [25:15<26:06,  4.54it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 2.57e-05:  49%|▍| 6746/13852 [25:15<26:05,  4.54it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 2.56e-05:  49%|▍| 6747/13852 [25:15<26:02,  4.55it/s\u001b[A\n",
      "Training loss: 4.95e-02 lr: 2.56e-05:  49%|▍| 6748/13852 [25:15<25:59,  4.55it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 2.56e-05:  49%|▍| 6749/13852 [25:16<26:01,  4.55it/s\u001b[A\n",
      "Training loss: 3.75e-02 lr: 2.56e-05:  49%|▍| 6750/13852 [25:16<26:03,  4.54it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 2.56e-05:  49%|▍| 6751/13852 [25:16<25:58,  4.56it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 2.56e-05:  49%|▍| 6752/13852 [25:16<25:53,  4.57it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 2.56e-05:  49%|▍| 6753/13852 [25:16<25:57,  4.56it/s\u001b[A\n",
      "Training loss: 6.20e-02 lr: 2.56e-05:  49%|▍| 6754/13852 [25:17<26:05,  4.53it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 2.56e-05:  49%|▍| 6755/13852 [25:17<26:13,  4.51it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 2.56e-05:  49%|▍| 6756/13852 [25:17<26:08,  4.52it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 2.56e-05:  49%|▍| 6757/13852 [25:17<26:05,  4.53it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 2.56e-05:  49%|▍| 6758/13852 [25:18<26:05,  4.53it/s\u001b[A\n",
      "Training loss: 7.55e-02 lr: 2.56e-05:  49%|▍| 6759/13852 [25:18<26:08,  4.52it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 2.56e-05:  49%|▍| 6760/13852 [25:18<26:16,  4.50it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 2.56e-05:  49%|▍| 6761/13852 [25:18<26:12,  4.51it/s\u001b[A\n",
      "Training loss: 7.65e-02 lr: 2.56e-05:  49%|▍| 6762/13852 [25:18<26:08,  4.52it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 2.56e-05:  49%|▍| 6763/13852 [25:19<26:01,  4.54it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 2.56e-05:  49%|▍| 6764/13852 [25:19<25:55,  4.56it/s\u001b[A\n",
      "Training loss: 9.71e-02 lr: 2.56e-05:  49%|▍| 6765/13852 [25:19<25:52,  4.57it/s\u001b[A\n",
      "Training loss: 8.66e-02 lr: 2.56e-05:  49%|▍| 6766/13852 [25:19<25:57,  4.55it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.56e-05:  49%|▍| 6767/13852 [25:20<26:02,  4.53it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 2.56e-05:  49%|▍| 6768/13852 [25:20<26:02,  4.53it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 2.56e-05:  49%|▍| 6769/13852 [25:20<26:00,  4.54it/s\u001b[A\n",
      "Training loss: 4.70e-02 lr: 2.56e-05:  49%|▍| 6770/13852 [25:20<25:58,  4.54it/s\u001b[A\n",
      "Training loss: 9.91e-02 lr: 2.56e-05:  49%|▍| 6771/13852 [25:20<25:55,  4.55it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 2.56e-05:  49%|▍| 6772/13852 [25:21<25:55,  4.55it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 2.56e-05:  49%|▍| 6773/13852 [25:21<26:08,  4.51it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 2.56e-05:  49%|▍| 6774/13852 [25:21<26:05,  4.52it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 2.55e-05:  49%|▍| 6775/13852 [25:21<26:02,  4.53it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 2.55e-05:  49%|▍| 6776/13852 [25:22<26:01,  4.53it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 2.55e-05:  49%|▍| 6777/13852 [25:22<26:07,  4.51it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 2.55e-05:  49%|▍| 6778/13852 [25:22<26:00,  4.53it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 2.55e-05:  49%|▍| 6779/13852 [25:22<25:58,  4.54it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 2.55e-05:  49%|▍| 6780/13852 [25:22<25:58,  4.54it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.01e-02 lr: 2.55e-05:  49%|▍| 6781/13852 [25:23<26:00,  4.53it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 2.55e-05:  49%|▍| 6782/13852 [25:23<25:59,  4.53it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 2.55e-05:  49%|▍| 6783/13852 [25:23<25:58,  4.54it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 2.55e-05:  49%|▍| 6784/13852 [25:23<25:57,  4.54it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 2.55e-05:  49%|▍| 6785/13852 [25:23<25:56,  4.54it/s\u001b[A\n",
      "Training loss: 9.77e-02 lr: 2.55e-05:  49%|▍| 6786/13852 [25:24<25:54,  4.54it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 2.55e-05:  49%|▍| 6787/13852 [25:24<25:54,  4.54it/s\u001b[A\n",
      "Training loss: 9.36e-02 lr: 2.55e-05:  49%|▍| 6788/13852 [25:24<25:54,  4.54it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 2.55e-05:  49%|▍| 6789/13852 [25:24<25:48,  4.56it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 2.55e-05:  49%|▍| 6790/13852 [25:25<25:42,  4.58it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.55e-05:  49%|▍| 6791/13852 [25:25<25:39,  4.59it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 2.55e-05:  49%|▍| 6792/13852 [25:25<25:47,  4.56it/s\u001b[A\n",
      "Training loss: 1.54e-01 lr: 2.55e-05:  49%|▍| 6793/13852 [25:25<25:51,  4.55it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 2.55e-05:  49%|▍| 6794/13852 [25:25<25:53,  4.54it/s\u001b[A\n",
      "Training loss: 9.14e-02 lr: 2.55e-05:  49%|▍| 6795/13852 [25:26<25:54,  4.54it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 2.55e-05:  49%|▍| 6796/13852 [25:26<25:54,  4.54it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 2.55e-05:  49%|▍| 6797/13852 [25:26<25:52,  4.54it/s\u001b[A\n",
      "Training loss: 1.61e-01 lr: 2.55e-05:  49%|▍| 6798/13852 [25:26<25:52,  4.54it/s\u001b[A\n",
      "Training loss: 1.68e-01 lr: 2.55e-05:  49%|▍| 6799/13852 [25:27<25:52,  4.54it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 2.55e-05:  49%|▍| 6800/13852 [25:27<26:08,  4.50it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.55e-05:  49%|▍| 6801/13852 [25:27<26:05,  4.50it/s\u001b[A\n",
      "Training loss: 8.43e-02 lr: 2.54e-05:  49%|▍| 6802/13852 [25:27<26:02,  4.51it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 2.54e-05:  49%|▍| 6803/13852 [25:27<26:00,  4.52it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 2.54e-05:  49%|▍| 6804/13852 [25:28<25:55,  4.53it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 2.54e-05:  49%|▍| 6805/13852 [25:28<25:49,  4.55it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 2.54e-05:  49%|▍| 6806/13852 [25:28<25:51,  4.54it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 2.54e-05:  49%|▍| 6807/13852 [25:28<25:51,  4.54it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 2.54e-05:  49%|▍| 6808/13852 [25:29<25:52,  4.54it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 2.54e-05:  49%|▍| 6809/13852 [25:29<25:53,  4.53it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 2.54e-05:  49%|▍| 6810/13852 [25:29<25:56,  4.52it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.54e-05:  49%|▍| 6811/13852 [25:29<25:54,  4.53it/s\u001b[A\n",
      "Training loss: 7.58e-02 lr: 2.54e-05:  49%|▍| 6812/13852 [25:29<25:54,  4.53it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 2.54e-05:  49%|▍| 6813/13852 [25:30<25:55,  4.52it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 2.54e-05:  49%|▍| 6814/13852 [25:30<25:55,  4.53it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 2.54e-05:  49%|▍| 6815/13852 [25:30<25:55,  4.52it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 2.54e-05:  49%|▍| 6816/13852 [25:30<25:51,  4.54it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 2.54e-05:  49%|▍| 6817/13852 [25:31<25:45,  4.55it/s\u001b[A\n",
      "Training loss: 3.91e-02 lr: 2.54e-05:  49%|▍| 6818/13852 [25:31<25:59,  4.51it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 2.54e-05:  49%|▍| 6819/13852 [25:31<26:05,  4.49it/s\u001b[A\n",
      "Training loss: 3.98e-02 lr: 2.54e-05:  49%|▍| 6820/13852 [25:31<26:00,  4.51it/s\u001b[A\n",
      "Training loss: 3.86e-02 lr: 2.54e-05:  49%|▍| 6821/13852 [25:31<25:57,  4.51it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 2.54e-05:  49%|▍| 6822/13852 [25:32<26:01,  4.50it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 2.54e-05:  49%|▍| 6823/13852 [25:32<26:00,  4.50it/s\u001b[A\n",
      "Training loss: 4.60e-02 lr: 2.54e-05:  49%|▍| 6824/13852 [25:32<26:00,  4.50it/s\u001b[A\n",
      "Training loss: 7.55e-02 lr: 2.54e-05:  49%|▍| 6825/13852 [25:32<25:56,  4.51it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 2.54e-05:  49%|▍| 6826/13852 [25:33<25:54,  4.52it/s\u001b[A\n",
      "Training loss: 4.36e-02 lr: 2.54e-05:  49%|▍| 6827/13852 [25:33<25:53,  4.52it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 2.54e-05:  49%|▍| 6828/13852 [25:33<25:57,  4.51it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 2.54e-05:  49%|▍| 6829/13852 [25:33<25:50,  4.53it/s\u001b[A\n",
      "Training loss: 9.90e-02 lr: 2.53e-05:  49%|▍| 6830/13852 [25:33<25:46,  4.54it/s\u001b[A\n",
      "Training loss: 9.71e-02 lr: 2.53e-05:  49%|▍| 6831/13852 [25:34<25:46,  4.54it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 2.53e-05:  49%|▍| 6832/13852 [25:34<25:47,  4.54it/s\u001b[A\n",
      "Training loss: 5.28e-02 lr: 2.53e-05:  49%|▍| 6833/13852 [25:34<25:49,  4.53it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 2.53e-05:  49%|▍| 6834/13852 [25:34<25:47,  4.54it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 2.53e-05:  49%|▍| 6835/13852 [25:35<25:48,  4.53it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 2.53e-05:  49%|▍| 6836/13852 [25:35<25:50,  4.53it/s\u001b[A\n",
      "Training loss: 3.50e-02 lr: 2.53e-05:  49%|▍| 6837/13852 [25:35<25:49,  4.53it/s\u001b[A\n",
      "Training loss: 2.54e-02 lr: 2.53e-05:  49%|▍| 6838/13852 [25:35<25:49,  4.53it/s\u001b[A\n",
      "Training loss: 1.97e-02 lr: 2.53e-05:  49%|▍| 6839/13852 [25:35<25:51,  4.52it/s\u001b[A\n",
      "Training loss: 1.50e-02 lr: 2.53e-05:  49%|▍| 6840/13852 [25:36<25:52,  4.52it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 2.53e-05:  49%|▍| 6841/13852 [25:36<25:45,  4.54it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 2.53e-05:  49%|▍| 6842/13852 [25:36<25:40,  4.55it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 2.53e-05:  49%|▍| 6843/13852 [25:36<25:36,  4.56it/s\u001b[A\n",
      "Training loss: 4.80e-02 lr: 2.53e-05:  49%|▍| 6844/13852 [25:37<25:42,  4.54it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 2.53e-05:  49%|▍| 6845/13852 [25:37<25:56,  4.50it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 2.53e-05:  49%|▍| 6846/13852 [25:37<26:03,  4.48it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 2.53e-05:  49%|▍| 6847/13852 [25:37<26:04,  4.48it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 2.53e-05:  49%|▍| 6848/13852 [25:37<26:17,  4.44it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.53e-05:  49%|▍| 6849/13852 [25:38<26:10,  4.46it/s\u001b[A\n",
      "Training loss: 8.05e-02 lr: 2.53e-05:  49%|▍| 6850/13852 [25:38<26:02,  4.48it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 2.53e-05:  49%|▍| 6851/13852 [25:38<26:01,  4.48it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 2.53e-05:  49%|▍| 6852/13852 [25:38<25:51,  4.51it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 2.53e-05:  49%|▍| 6853/13852 [25:39<25:40,  4.54it/s\u001b[A\n",
      "Training loss: 3.20e-02 lr: 2.53e-05:  49%|▍| 6854/13852 [25:39<25:33,  4.56it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 2.53e-05:  49%|▍| 6855/13852 [25:39<25:47,  4.52it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 2.53e-05:  49%|▍| 6856/13852 [25:39<25:46,  4.52it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 2.53e-05:  50%|▍| 6857/13852 [25:39<25:46,  4.52it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 2.52e-05:  50%|▍| 6858/13852 [25:40<25:47,  4.52it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 2.52e-05:  50%|▍| 6859/13852 [25:40<25:46,  4.52it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 2.52e-05:  50%|▍| 6860/13852 [25:40<25:46,  4.52it/s\u001b[A\n",
      "Training loss: 2.63e-02 lr: 2.52e-05:  50%|▍| 6861/13852 [25:40<25:46,  4.52it/s\u001b[A\n",
      "Training loss: 9.03e-02 lr: 2.52e-05:  50%|▍| 6862/13852 [25:41<25:47,  4.52it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 2.52e-05:  50%|▍| 6863/13852 [25:41<25:50,  4.51it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 2.52e-05:  50%|▍| 6864/13852 [25:41<25:55,  4.49it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 2.52e-05:  50%|▍| 6865/13852 [25:41<25:45,  4.52it/s\u001b[A\n",
      "Training loss: 3.41e-02 lr: 2.52e-05:  50%|▍| 6866/13852 [25:41<25:35,  4.55it/s\u001b[A\n",
      "Training loss: 2.93e-02 lr: 2.52e-05:  50%|▍| 6867/13852 [25:42<25:31,  4.56it/s\u001b[A\n",
      "Training loss: 2.38e-02 lr: 2.52e-05:  50%|▍| 6868/13852 [25:42<25:47,  4.51it/s\u001b[A\n",
      "Training loss: 1.92e-02 lr: 2.52e-05:  50%|▍| 6869/13852 [25:42<25:47,  4.51it/s\u001b[A\n",
      "Training loss: 1.94e-02 lr: 2.52e-05:  50%|▍| 6870/13852 [25:42<25:45,  4.52it/s\u001b[A\n",
      "Training loss: 6.25e-02 lr: 2.52e-05:  50%|▍| 6871/13852 [25:43<25:43,  4.52it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.52e-05:  50%|▍| 6872/13852 [25:43<25:46,  4.51it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 2.52e-05:  50%|▍| 6873/13852 [25:43<25:45,  4.52it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 2.52e-05:  50%|▍| 6874/13852 [25:43<25:44,  4.52it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.52e-05:  50%|▍| 6875/13852 [25:43<25:48,  4.51it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 2.52e-05:  50%|▍| 6876/13852 [25:44<25:49,  4.50it/s\u001b[A\n",
      "Training loss: 6.09e-02 lr: 2.52e-05:  50%|▍| 6877/13852 [25:44<25:45,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.32e-02 lr: 2.52e-05:  50%|▍| 6878/13852 [25:44<25:36,  4.54it/s\u001b[A\n",
      "Training loss: 3.47e-02 lr: 2.52e-05:  50%|▍| 6879/13852 [25:44<25:29,  4.56it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 2.52e-05:  50%|▍| 6880/13852 [25:44<25:41,  4.52it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 2.52e-05:  50%|▍| 6881/13852 [25:45<25:41,  4.52it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 2.52e-05:  50%|▍| 6882/13852 [25:45<25:39,  4.53it/s\u001b[A\n",
      "Training loss: 9.15e-02 lr: 2.52e-05:  50%|▍| 6883/13852 [25:45<25:38,  4.53it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 2.52e-05:  50%|▍| 6884/13852 [25:45<25:37,  4.53it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 2.51e-05:  50%|▍| 6885/13852 [25:46<25:38,  4.53it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 2.51e-05:  50%|▍| 6886/13852 [25:46<25:40,  4.52it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.51e-05:  50%|▍| 6887/13852 [25:46<25:41,  4.52it/s\u001b[A\n",
      "Training loss: 7.66e-02 lr: 2.51e-05:  50%|▍| 6888/13852 [25:46<25:42,  4.51it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 2.51e-05:  50%|▍| 6889/13852 [25:46<25:39,  4.52it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 2.51e-05:  50%|▍| 6890/13852 [25:47<25:46,  4.50it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 2.51e-05:  50%|▍| 6891/13852 [25:47<25:41,  4.52it/s\u001b[A\n",
      "Training loss: 7.64e-02 lr: 2.51e-05:  50%|▍| 6892/13852 [25:47<25:33,  4.54it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 2.51e-05:  50%|▍| 6893/13852 [25:47<25:35,  4.53it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 2.51e-05:  50%|▍| 6894/13852 [25:48<25:36,  4.53it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 2.51e-05:  50%|▍| 6895/13852 [25:48<25:36,  4.53it/s\u001b[A\n",
      "Training loss: 4.21e-02 lr: 2.51e-05:  50%|▍| 6896/13852 [25:48<25:44,  4.50it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 2.51e-05:  50%|▍| 6897/13852 [25:48<25:43,  4.51it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 2.51e-05:  50%|▍| 6898/13852 [25:48<25:40,  4.52it/s\u001b[A\n",
      "Training loss: 6.96e-02 lr: 2.51e-05:  50%|▍| 6899/13852 [25:49<25:38,  4.52it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 2.51e-05:  50%|▍| 6900/13852 [25:49<25:39,  4.52it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 2.51e-05:  50%|▍| 6901/13852 [25:49<25:38,  4.52it/s\u001b[A\n",
      "Training loss: 9.77e-02 lr: 2.51e-05:  50%|▍| 6902/13852 [25:49<25:36,  4.52it/s\u001b[A\n",
      "Training loss: 8.75e-02 lr: 2.51e-05:  50%|▍| 6903/13852 [25:50<25:31,  4.54it/s\u001b[A\n",
      "Training loss: 9.49e-02 lr: 2.51e-05:  50%|▍| 6904/13852 [25:50<25:24,  4.56it/s\u001b[A\n",
      "Training loss: 8.31e-02 lr: 2.51e-05:  50%|▍| 6905/13852 [25:50<25:37,  4.52it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 2.51e-05:  50%|▍| 6906/13852 [25:50<25:39,  4.51it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 2.51e-05:  50%|▍| 6907/13852 [25:50<25:37,  4.52it/s\u001b[A\n",
      "Training loss: 4.78e-02 lr: 2.51e-05:  50%|▍| 6908/13852 [25:51<25:33,  4.53it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 2.51e-05:  50%|▍| 6909/13852 [25:51<25:47,  4.49it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 2.51e-05:  50%|▍| 6910/13852 [25:51<25:49,  4.48it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 2.51e-05:  50%|▍| 6911/13852 [25:51<25:44,  4.49it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 2.51e-05:  50%|▍| 6912/13852 [25:52<25:41,  4.50it/s\u001b[A\n",
      "Training loss: 3.57e-02 lr: 2.50e-05:  50%|▍| 6913/13852 [25:52<25:46,  4.49it/s\u001b[A\n",
      "Training loss: 2.73e-02 lr: 2.50e-05:  50%|▍| 6914/13852 [25:52<25:35,  4.52it/s\u001b[A\n",
      "Training loss: 7.84e-02 lr: 2.50e-05:  50%|▍| 6915/13852 [25:52<25:26,  4.54it/s\u001b[A\n",
      "Training loss: 6.75e-02 lr: 2.50e-05:  50%|▍| 6916/13852 [25:52<25:21,  4.56it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 2.50e-05:  50%|▍| 6917/13852 [25:53<25:39,  4.50it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 2.50e-05:  50%|▍| 6918/13852 [25:53<25:35,  4.52it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 2.50e-05:  50%|▍| 6919/13852 [25:53<25:34,  4.52it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 2.50e-05:  50%|▍| 6920/13852 [25:53<25:31,  4.52it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 2.50e-05:  50%|▍| 6921/13852 [25:54<25:31,  4.53it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 2.50e-05:  50%|▍| 6922/13852 [25:54<25:31,  4.52it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 2.50e-05:  50%|▍| 6923/13852 [25:54<25:32,  4.52it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 2.50e-05:  50%|▍| 6924/13852 [25:54<25:33,  4.52it/s\u001b[A\n",
      "Training loss: 6.36e-02 lr: 2.50e-05:  50%|▍| 6925/13852 [25:54<25:34,  4.52it/s\u001b[A\n",
      "Training loss: 4.60e-02 lr: 2.50e-05:  50%|▌| 6926/13852 [25:55<25:36,  4.51it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 2.50e-05:  50%|▌| 6927/13852 [25:55<25:35,  4.51it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 2.50e-05:  50%|▌| 6928/13852 [25:55<25:27,  4.53it/s\u001b[A\n",
      "Training loss: 3.48e-02 lr: 2.50e-05:  50%|▌| 6929/13852 [25:55<25:18,  4.56it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 2.50e-05:  50%|▌| 6930/13852 [25:56<25:26,  4.53it/s\u001b[A\n",
      "Training loss: 3.91e-02 lr: 2.50e-05:  50%|▌| 6931/13852 [25:56<25:27,  4.53it/s\u001b[A\n",
      "Training loss: 5.63e-02 lr: 2.50e-05:  50%|▌| 6932/13852 [25:56<25:26,  4.53it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 2.50e-05:  50%|▌| 6933/13852 [25:56<25:25,  4.53it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 2.50e-05:  50%|▌| 6934/13852 [25:56<25:28,  4.53it/s\u001b[A\n",
      "Training loss: 8.75e-02 lr: 2.50e-05:  50%|▌| 6935/13852 [25:57<25:40,  4.49it/s\u001b[A\n",
      "Training loss: 7.95e-02 lr: 2.50e-05:  50%|▌| 6936/13852 [25:57<25:41,  4.49it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 2.50e-05:  50%|▌| 6937/13852 [25:57<25:38,  4.49it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 2.50e-05:  50%|▌| 6938/13852 [25:57<25:37,  4.50it/s\u001b[A\n",
      "Training loss: 9.90e-02 lr: 2.50e-05:  50%|▌| 6939/13852 [25:58<25:32,  4.51it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 2.50e-05:  50%|▌| 6940/13852 [25:58<25:31,  4.51it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 2.49e-05:  50%|▌| 6941/13852 [25:58<25:20,  4.55it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 2.49e-05:  50%|▌| 6942/13852 [25:58<25:33,  4.50it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 2.49e-05:  50%|▌| 6943/13852 [25:58<25:30,  4.51it/s\u001b[A\n",
      "Training loss: 8.48e-02 lr: 2.49e-05:  50%|▌| 6944/13852 [25:59<25:29,  4.52it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 2.49e-05:  50%|▌| 6945/13852 [25:59<25:27,  4.52it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 2.49e-05:  50%|▌| 6946/13852 [25:59<25:28,  4.52it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 2.49e-05:  50%|▌| 6947/13852 [25:59<25:26,  4.52it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 2.49e-05:  50%|▌| 6948/13852 [26:00<25:27,  4.52it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 2.49e-05:  50%|▌| 6949/13852 [26:00<25:29,  4.51it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 2.49e-05:  50%|▌| 6950/13852 [26:00<25:30,  4.51it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 2.49e-05:  50%|▌| 6951/13852 [26:00<25:27,  4.52it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.49e-05:  50%|▌| 6952/13852 [26:00<25:21,  4.54it/s\u001b[A\n",
      "Training loss: 8.63e-02 lr: 2.49e-05:  50%|▌| 6953/13852 [26:01<25:15,  4.55it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 2.49e-05:  50%|▌| 6954/13852 [26:01<25:23,  4.53it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 2.49e-05:  50%|▌| 6955/13852 [26:01<25:29,  4.51it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.49e-05:  50%|▌| 6956/13852 [26:01<25:28,  4.51it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 2.49e-05:  50%|▌| 6957/13852 [26:02<25:25,  4.52it/s\u001b[A\n",
      "Training loss: 7.03e-02 lr: 2.49e-05:  50%|▌| 6958/13852 [26:02<25:35,  4.49it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 2.49e-05:  50%|▌| 6959/13852 [26:02<25:33,  4.49it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.49e-05:  50%|▌| 6960/13852 [26:02<25:31,  4.50it/s\u001b[A\n",
      "Training loss: 8.35e-02 lr: 2.49e-05:  50%|▌| 6961/13852 [26:02<25:28,  4.51it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 2.49e-05:  50%|▌| 6962/13852 [26:03<25:27,  4.51it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 2.49e-05:  50%|▌| 6963/13852 [26:03<25:26,  4.51it/s\u001b[A\n",
      "Training loss: 7.12e-02 lr: 2.49e-05:  50%|▌| 6964/13852 [26:03<26:02,  4.41it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 2.49e-05:  50%|▌| 6965/13852 [26:03<26:18,  4.36it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 2.49e-05:  50%|▌| 6966/13852 [26:04<26:01,  4.41it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.49e-05:  50%|▌| 6967/13852 [26:04<25:56,  4.42it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.49e-05:  50%|▌| 6968/13852 [26:04<25:51,  4.44it/s\u001b[A\n",
      "Training loss: 9.03e-02 lr: 2.48e-05:  50%|▌| 6969/13852 [26:04<25:44,  4.46it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 2.48e-05:  50%|▌| 6970/13852 [26:04<25:38,  4.47it/s\u001b[A\n",
      "Training loss: 7.28e-02 lr: 2.48e-05:  50%|▌| 6971/13852 [26:05<25:34,  4.49it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 2.48e-05:  50%|▌| 6972/13852 [26:05<25:31,  4.49it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 2.48e-05:  50%|▌| 6973/13852 [26:05<25:28,  4.50it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 2.48e-05:  50%|▌| 6974/13852 [26:05<25:20,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.00e-02 lr: 2.48e-05:  50%|▌| 6975/13852 [26:06<25:12,  4.55it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 2.48e-05:  50%|▌| 6976/13852 [26:06<25:09,  4.56it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 2.48e-05:  50%|▌| 6977/13852 [26:06<25:25,  4.51it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 2.48e-05:  50%|▌| 6978/13852 [26:06<25:22,  4.52it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.48e-05:  50%|▌| 6979/13852 [26:06<25:20,  4.52it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.48e-05:  50%|▌| 6980/13852 [26:07<25:36,  4.47it/s\u001b[A\n",
      "Training loss: 3.77e-02 lr: 2.48e-05:  50%|▌| 6981/13852 [26:07<25:40,  4.46it/s\u001b[A\n",
      "Training loss: 9.66e-02 lr: 2.48e-05:  50%|▌| 6982/13852 [26:07<25:43,  4.45it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 2.48e-05:  50%|▌| 6983/13852 [26:07<25:46,  4.44it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 2.48e-05:  50%|▌| 6984/13852 [26:08<25:42,  4.45it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 2.48e-05:  50%|▌| 6985/13852 [26:08<25:36,  4.47it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 2.48e-05:  50%|▌| 6986/13852 [26:08<25:23,  4.51it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 2.48e-05:  50%|▌| 6987/13852 [26:08<25:12,  4.54it/s\u001b[A\n",
      "Training loss: 4.29e-02 lr: 2.48e-05:  50%|▌| 6988/13852 [26:08<25:28,  4.49it/s\u001b[A\n",
      "Training loss: 3.18e-02 lr: 2.48e-05:  50%|▌| 6989/13852 [26:09<25:24,  4.50it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 2.48e-05:  50%|▌| 6990/13852 [26:09<25:21,  4.51it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 2.48e-05:  50%|▌| 6991/13852 [26:09<25:18,  4.52it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 2.48e-05:  50%|▌| 6992/13852 [26:09<25:18,  4.52it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 2.48e-05:  50%|▌| 6993/13852 [26:10<25:19,  4.51it/s\u001b[A\n",
      "Training loss: 3.34e-02 lr: 2.48e-05:  50%|▌| 6994/13852 [26:10<25:20,  4.51it/s\u001b[A\n",
      "Training loss: 3.10e-02 lr: 2.48e-05:  50%|▌| 6995/13852 [26:10<25:21,  4.51it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 2.47e-05:  51%|▌| 6996/13852 [26:10<25:22,  4.50it/s\u001b[A\n",
      "Training loss: 4.22e-02 lr: 2.47e-05:  51%|▌| 6997/13852 [26:10<25:21,  4.50it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 2.47e-05:  51%|▌| 6998/13852 [26:11<25:17,  4.52it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 2.47e-05:  51%|▌| 6999/13852 [26:11<25:19,  4.51it/s\u001b[A\n",
      "Training loss: 3.34e-02 lr: 2.47e-05:  51%|▌| 7000/13852 [26:11<25:09,  4.54it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 2.47e-05:  51%|▌| 7001/13852 [26:11<25:20,  4.51it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 2.47e-05:  51%|▌| 7002/13852 [26:12<25:18,  4.51it/s\u001b[A\n",
      "Training loss: 7.88e-02 lr: 2.47e-05:  51%|▌| 7003/13852 [26:12<25:25,  4.49it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 2.47e-05:  51%|▌| 7004/13852 [26:12<25:23,  4.50it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 2.47e-05:  51%|▌| 7005/13852 [26:12<25:22,  4.50it/s\u001b[A\n",
      "Training loss: 7.66e-02 lr: 2.47e-05:  51%|▌| 7006/13852 [26:12<25:21,  4.50it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 2.47e-05:  51%|▌| 7007/13852 [26:13<25:19,  4.50it/s\u001b[A\n",
      "Training loss: 4.95e-02 lr: 2.47e-05:  51%|▌| 7008/13852 [26:13<26:45,  4.26it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 2.47e-05:  51%|▌| 7009/13852 [26:13<26:52,  4.24it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 2.47e-05:  51%|▌| 7010/13852 [26:13<26:59,  4.22it/s\u001b[A\n",
      "Training loss: 3.38e-02 lr: 2.47e-05:  51%|▌| 7011/13852 [26:14<27:06,  4.21it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 2.47e-05:  51%|▌| 7012/13852 [26:14<27:12,  4.19it/s\u001b[A\n",
      "Training loss: 8.57e-02 lr: 2.47e-05:  51%|▌| 7013/13852 [26:14<27:18,  4.18it/s\u001b[A\n",
      "Training loss: 7.37e-02 lr: 2.47e-05:  51%|▌| 7014/13852 [26:14<27:20,  4.17it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 2.47e-05:  51%|▌| 7015/13852 [26:15<27:14,  4.18it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 2.47e-05:  51%|▌| 7016/13852 [26:15<27:15,  4.18it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 2.47e-05:  51%|▌| 7017/13852 [26:15<27:18,  4.17it/s\u001b[A\n",
      "Training loss: 4.38e-02 lr: 2.47e-05:  51%|▌| 7018/13852 [26:15<27:18,  4.17it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 2.47e-05:  51%|▌| 7019/13852 [26:16<27:19,  4.17it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 2.47e-05:  51%|▌| 7020/13852 [26:16<27:13,  4.18it/s\u001b[A\n",
      "Training loss: 3.83e-02 lr: 2.47e-05:  51%|▌| 7021/13852 [26:16<27:22,  4.16it/s\u001b[A\n",
      "Training loss: 2.77e-02 lr: 2.47e-05:  51%|▌| 7022/13852 [26:16<27:20,  4.16it/s\u001b[A\n",
      "Training loss: 3.07e-02 lr: 2.47e-05:  51%|▌| 7023/13852 [26:17<27:17,  4.17it/s\u001b[A\n",
      "Training loss: 2.39e-02 lr: 2.46e-05:  51%|▌| 7024/13852 [26:17<27:35,  4.12it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 2.46e-05:  51%|▌| 7025/13852 [26:17<27:31,  4.13it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 2.46e-05:  51%|▌| 7026/13852 [26:17<27:21,  4.16it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 2.46e-05:  51%|▌| 7027/13852 [26:17<27:17,  4.17it/s\u001b[A\n",
      "Training loss: 7.71e-02 lr: 2.46e-05:  51%|▌| 7028/13852 [26:18<27:20,  4.16it/s\u001b[A\n",
      "Training loss: 5.68e-02 lr: 2.46e-05:  51%|▌| 7029/13852 [26:18<27:31,  4.13it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 2.46e-05:  51%|▌| 7030/13852 [26:18<27:27,  4.14it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 2.46e-05:  51%|▌| 7031/13852 [26:18<27:17,  4.16it/s\u001b[A\n",
      "Training loss: 3.43e-02 lr: 2.46e-05:  51%|▌| 7032/13852 [26:19<27:07,  4.19it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 2.46e-05:  51%|▌| 7033/13852 [26:19<27:07,  4.19it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 2.46e-05:  51%|▌| 7034/13852 [26:19<27:10,  4.18it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 2.46e-05:  51%|▌| 7035/13852 [26:19<27:09,  4.18it/s\u001b[A\n",
      "Training loss: 5.28e-02 lr: 2.46e-05:  51%|▌| 7036/13852 [26:20<27:11,  4.18it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 2.46e-05:  51%|▌| 7037/13852 [26:20<27:11,  4.18it/s\u001b[A\n",
      "Training loss: 3.87e-02 lr: 2.46e-05:  51%|▌| 7038/13852 [26:20<27:06,  4.19it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 2.46e-05:  51%|▌| 7039/13852 [26:20<27:08,  4.18it/s\u001b[A\n",
      "Training loss: 3.05e-02 lr: 2.46e-05:  51%|▌| 7040/13852 [26:21<27:08,  4.18it/s\u001b[A\n",
      "Training loss: 2.46e-02 lr: 2.46e-05:  51%|▌| 7041/13852 [26:21<27:21,  4.15it/s\u001b[A\n",
      "Training loss: 1.83e-02 lr: 2.46e-05:  51%|▌| 7042/13852 [26:21<27:18,  4.16it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 2.46e-05:  51%|▌| 7043/13852 [26:21<27:27,  4.13it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 2.46e-05:  51%|▌| 7044/13852 [26:22<27:16,  4.16it/s\u001b[A\n",
      "Training loss: 3.69e-02 lr: 2.46e-05:  51%|▌| 7045/13852 [26:22<27:19,  4.15it/s\u001b[A\n",
      "Training loss: 8.69e-02 lr: 2.46e-05:  51%|▌| 7046/13852 [26:22<27:15,  4.16it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 2.46e-05:  51%|▌| 7047/13852 [26:22<27:18,  4.15it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 2.46e-05:  51%|▌| 7048/13852 [26:23<27:20,  4.15it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 2.46e-05:  51%|▌| 7049/13852 [26:23<27:11,  4.17it/s\u001b[A\n",
      "Training loss: 2.99e-02 lr: 2.46e-05:  51%|▌| 7050/13852 [26:23<27:05,  4.18it/s\u001b[A\n",
      "Training loss: 2.35e-02 lr: 2.46e-05:  51%|▌| 7051/13852 [26:23<27:05,  4.18it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 2.45e-05:  51%|▌| 7052/13852 [26:23<27:03,  4.19it/s\u001b[A\n",
      "Training loss: 4.16e-02 lr: 2.45e-05:  51%|▌| 7053/13852 [26:24<27:05,  4.18it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 2.45e-05:  51%|▌| 7054/13852 [26:24<27:08,  4.17it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 2.45e-05:  51%|▌| 7055/13852 [26:24<27:05,  4.18it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 2.45e-05:  51%|▌| 7056/13852 [26:24<27:07,  4.18it/s\u001b[A\n",
      "Training loss: 3.03e-02 lr: 2.45e-05:  51%|▌| 7057/13852 [26:25<27:04,  4.18it/s\u001b[A\n",
      "Training loss: 9.88e-02 lr: 2.45e-05:  51%|▌| 7058/13852 [26:25<27:00,  4.19it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 2.45e-05:  51%|▌| 7059/13852 [26:25<27:03,  4.19it/s\u001b[A\n",
      "Training loss: 1.34e-01 lr: 2.45e-05:  51%|▌| 7060/13852 [26:25<27:04,  4.18it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.45e-05:  51%|▌| 7061/13852 [26:26<26:58,  4.20it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 2.45e-05:  51%|▌| 7062/13852 [26:26<26:56,  4.20it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 2.45e-05:  51%|▌| 7063/13852 [26:26<26:59,  4.19it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 2.45e-05:  51%|▌| 7064/13852 [26:26<26:57,  4.20it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.45e-05:  51%|▌| 7065/13852 [26:27<26:59,  4.19it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 2.45e-05:  51%|▌| 7066/13852 [26:27<27:21,  4.13it/s\u001b[A\n",
      "Training loss: 9.46e-02 lr: 2.45e-05:  51%|▌| 7067/13852 [26:27<27:14,  4.15it/s\u001b[A\n",
      "Training loss: 9.88e-02 lr: 2.45e-05:  51%|▌| 7068/13852 [26:27<27:08,  4.17it/s\u001b[A\n",
      "Training loss: 8.25e-02 lr: 2.45e-05:  51%|▌| 7069/13852 [26:28<27:06,  4.17it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.45e-05:  51%|▌| 7070/13852 [26:28<27:10,  4.16it/s\u001b[A\n",
      "Training loss: 9.41e-02 lr: 2.45e-05:  51%|▌| 7071/13852 [26:28<27:10,  4.16it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.18e-02 lr: 2.45e-05:  51%|▌| 7072/13852 [26:28<27:09,  4.16it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.45e-05:  51%|▌| 7073/13852 [26:29<27:01,  4.18it/s\u001b[A\n",
      "Training loss: 1.37e-01 lr: 2.45e-05:  51%|▌| 7074/13852 [26:29<27:01,  4.18it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.45e-05:  51%|▌| 7075/13852 [26:29<27:00,  4.18it/s\u001b[A\n",
      "Training loss: 9.50e-02 lr: 2.45e-05:  51%|▌| 7076/13852 [26:29<26:59,  4.19it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 2.45e-05:  51%|▌| 7077/13852 [26:29<26:59,  4.18it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 2.45e-05:  51%|▌| 7078/13852 [26:30<26:59,  4.18it/s\u001b[A\n",
      "Training loss: 4.99e-02 lr: 2.44e-05:  51%|▌| 7079/13852 [26:30<26:54,  4.19it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 2.44e-05:  51%|▌| 7080/13852 [26:30<26:55,  4.19it/s\u001b[A\n",
      "Training loss: 6.55e-02 lr: 2.44e-05:  51%|▌| 7081/13852 [26:30<26:57,  4.19it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 2.44e-05:  51%|▌| 7082/13852 [26:31<26:55,  4.19it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 2.44e-05:  51%|▌| 7083/13852 [26:31<27:09,  4.16it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 2.44e-05:  51%|▌| 7084/13852 [26:31<27:01,  4.18it/s\u001b[A\n",
      "Training loss: 3.46e-02 lr: 2.44e-05:  51%|▌| 7085/13852 [26:31<27:06,  4.16it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 2.44e-05:  51%|▌| 7086/13852 [26:32<27:08,  4.15it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 2.44e-05:  51%|▌| 7087/13852 [26:32<27:05,  4.16it/s\u001b[A\n",
      "Training loss: 3.18e-02 lr: 2.44e-05:  51%|▌| 7088/13852 [26:32<27:07,  4.16it/s\u001b[A\n",
      "Training loss: 2.60e-02 lr: 2.44e-05:  51%|▌| 7089/13852 [26:32<27:03,  4.17it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 2.44e-05:  51%|▌| 7090/13852 [26:33<26:57,  4.18it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 2.44e-05:  51%|▌| 7091/13852 [26:33<26:55,  4.18it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 2.44e-05:  51%|▌| 7092/13852 [26:33<27:06,  4.16it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 2.44e-05:  51%|▌| 7093/13852 [26:33<27:02,  4.17it/s\u001b[A\n",
      "Training loss: 9.88e-02 lr: 2.44e-05:  51%|▌| 7094/13852 [26:34<27:02,  4.17it/s\u001b[A\n",
      "Training loss: 7.12e-02 lr: 2.44e-05:  51%|▌| 7095/13852 [26:34<27:01,  4.17it/s\u001b[A\n",
      "Training loss: 9.90e-02 lr: 2.44e-05:  51%|▌| 7096/13852 [26:34<26:56,  4.18it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 2.44e-05:  51%|▌| 7097/13852 [26:34<26:49,  4.20it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 2.44e-05:  51%|▌| 7098/13852 [26:35<26:52,  4.19it/s\u001b[A\n",
      "Training loss: 8.91e-02 lr: 2.44e-05:  51%|▌| 7099/13852 [26:35<26:54,  4.18it/s\u001b[A\n",
      "Training loss: 7.91e-02 lr: 2.44e-05:  51%|▌| 7100/13852 [26:35<26:54,  4.18it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 2.44e-05:  51%|▌| 7101/13852 [26:35<26:56,  4.18it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 2.44e-05:  51%|▌| 7102/13852 [26:35<26:58,  4.17it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.44e-05:  51%|▌| 7103/13852 [26:36<26:54,  4.18it/s\u001b[A\n",
      "Training loss: 9.14e-02 lr: 2.44e-05:  51%|▌| 7104/13852 [26:36<26:56,  4.17it/s\u001b[A\n",
      "Training loss: 6.56e-02 lr: 2.44e-05:  51%|▌| 7105/13852 [26:36<26:56,  4.17it/s\u001b[A\n",
      "Training loss: 4.90e-02 lr: 2.44e-05:  51%|▌| 7106/13852 [26:36<26:54,  4.18it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 2.43e-05:  51%|▌| 7107/13852 [26:37<27:09,  4.14it/s\u001b[A\n",
      "Training loss: 3.75e-02 lr: 2.43e-05:  51%|▌| 7108/13852 [26:37<27:23,  4.10it/s\u001b[A\n",
      "Training loss: 3.29e-02 lr: 2.43e-05:  51%|▌| 7109/13852 [26:37<27:25,  4.10it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 2.43e-05:  51%|▌| 7110/13852 [26:37<27:16,  4.12it/s\u001b[A\n",
      "Training loss: 2.50e-02 lr: 2.43e-05:  51%|▌| 7111/13852 [26:38<26:29,  4.24it/s\u001b[A\n",
      "Training loss: 1.84e-02 lr: 2.43e-05:  51%|▌| 7112/13852 [26:38<26:05,  4.30it/s\u001b[A\n",
      "Training loss: 3.31e-02 lr: 2.43e-05:  51%|▌| 7113/13852 [26:38<25:42,  4.37it/s\u001b[A\n",
      "Training loss: 2.75e-02 lr: 2.43e-05:  51%|▌| 7114/13852 [26:38<25:27,  4.41it/s\u001b[A\n",
      "Training loss: 3.18e-02 lr: 2.43e-05:  51%|▌| 7115/13852 [26:39<25:16,  4.44it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 2.43e-05:  51%|▌| 7116/13852 [26:39<25:00,  4.49it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 2.43e-05:  51%|▌| 7117/13852 [26:39<24:51,  4.52it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 2.43e-05:  51%|▌| 7118/13852 [26:39<24:57,  4.50it/s\u001b[A\n",
      "Training loss: 7.72e-02 lr: 2.43e-05:  51%|▌| 7119/13852 [26:39<24:54,  4.51it/s\u001b[A\n",
      "Training loss: 6.41e-02 lr: 2.43e-05:  51%|▌| 7120/13852 [26:40<24:54,  4.51it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 2.43e-05:  51%|▌| 7121/13852 [26:40<24:51,  4.51it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.43e-05:  51%|▌| 7122/13852 [26:40<24:48,  4.52it/s\u001b[A\n",
      "Training loss: 7.53e-02 lr: 2.43e-05:  51%|▌| 7123/13852 [26:40<24:50,  4.52it/s\u001b[A\n",
      "Training loss: 8.39e-02 lr: 2.43e-05:  51%|▌| 7124/13852 [26:40<24:49,  4.52it/s\u001b[A\n",
      "Training loss: 9.59e-02 lr: 2.43e-05:  51%|▌| 7125/13852 [26:41<24:51,  4.51it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 2.43e-05:  51%|▌| 7126/13852 [26:41<24:58,  4.49it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 2.43e-05:  51%|▌| 7127/13852 [26:41<24:55,  4.50it/s\u001b[A\n",
      "Training loss: 1.63e-01 lr: 2.43e-05:  51%|▌| 7128/13852 [26:41<24:51,  4.51it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 2.43e-05:  51%|▌| 7129/13852 [26:42<24:45,  4.53it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.43e-05:  51%|▌| 7130/13852 [26:42<24:43,  4.53it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 2.43e-05:  51%|▌| 7131/13852 [26:42<24:45,  4.52it/s\u001b[A\n",
      "Training loss: 9.24e-02 lr: 2.43e-05:  51%|▌| 7132/13852 [26:42<24:45,  4.52it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 2.43e-05:  51%|▌| 7133/13852 [26:42<24:44,  4.53it/s\u001b[A\n",
      "Training loss: 8.57e-02 lr: 2.43e-05:  52%|▌| 7134/13852 [26:43<24:42,  4.53it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 2.42e-05:  52%|▌| 7135/13852 [26:43<25:21,  4.41it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 2.42e-05:  52%|▌| 7136/13852 [26:43<25:11,  4.44it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 2.42e-05:  52%|▌| 7137/13852 [26:43<25:03,  4.47it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 2.42e-05:  52%|▌| 7138/13852 [26:44<24:59,  4.48it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 2.42e-05:  52%|▌| 7139/13852 [26:44<24:56,  4.49it/s\u001b[A\n",
      "Training loss: 3.96e-02 lr: 2.42e-05:  52%|▌| 7140/13852 [26:44<24:48,  4.51it/s\u001b[A\n",
      "Training loss: 3.60e-02 lr: 2.42e-05:  52%|▌| 7141/13852 [26:44<24:38,  4.54it/s\u001b[A\n",
      "Training loss: 3.07e-02 lr: 2.42e-05:  52%|▌| 7142/13852 [26:44<24:32,  4.56it/s\u001b[A\n",
      "Training loss: 2.48e-02 lr: 2.42e-05:  52%|▌| 7143/13852 [26:45<24:36,  4.54it/s\u001b[A\n",
      "Training loss: 2.09e-02 lr: 2.42e-05:  52%|▌| 7144/13852 [26:45<24:38,  4.54it/s\u001b[A\n",
      "Training loss: 1.82e-02 lr: 2.42e-05:  52%|▌| 7145/13852 [26:45<24:37,  4.54it/s\u001b[A\n",
      "Training loss: 1.63e-02 lr: 2.42e-05:  52%|▌| 7146/13852 [26:45<24:36,  4.54it/s\u001b[A\n",
      "Training loss: 1.62e-02 lr: 2.42e-05:  52%|▌| 7147/13852 [26:46<24:39,  4.53it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 2.42e-05:  52%|▌| 7148/13852 [26:46<24:39,  4.53it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 2.42e-05:  52%|▌| 7149/13852 [26:46<24:41,  4.52it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 2.42e-05:  52%|▌| 7150/13852 [26:46<24:43,  4.52it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 2.42e-05:  52%|▌| 7151/13852 [26:46<24:43,  4.52it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 2.42e-05:  52%|▌| 7152/13852 [26:47<24:49,  4.50it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 2.42e-05:  52%|▌| 7153/13852 [26:47<24:46,  4.51it/s\u001b[A\n",
      "Training loss: 8.24e-02 lr: 2.42e-05:  52%|▌| 7154/13852 [26:47<24:35,  4.54it/s\u001b[A\n",
      "Training loss: 9.34e-02 lr: 2.42e-05:  52%|▌| 7155/13852 [26:47<24:46,  4.50it/s\u001b[A\n",
      "Training loss: 6.70e-02 lr: 2.42e-05:  52%|▌| 7156/13852 [26:48<24:44,  4.51it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 2.42e-05:  52%|▌| 7157/13852 [26:48<24:41,  4.52it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 2.42e-05:  52%|▌| 7158/13852 [26:48<24:45,  4.51it/s\u001b[A\n",
      "Training loss: 3.96e-02 lr: 2.42e-05:  52%|▌| 7159/13852 [26:48<24:50,  4.49it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 2.42e-05:  52%|▌| 7160/13852 [26:48<24:49,  4.49it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 2.42e-05:  52%|▌| 7161/13852 [26:49<24:47,  4.50it/s\u001b[A\n",
      "Training loss: 7.15e-02 lr: 2.41e-05:  52%|▌| 7162/13852 [26:49<24:45,  4.50it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 2.41e-05:  52%|▌| 7163/13852 [26:49<24:44,  4.51it/s\u001b[A\n",
      "Training loss: 8.56e-02 lr: 2.41e-05:  52%|▌| 7164/13852 [26:49<24:38,  4.52it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 2.41e-05:  52%|▌| 7165/13852 [26:50<24:31,  4.54it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 2.41e-05:  52%|▌| 7166/13852 [26:50<24:25,  4.56it/s\u001b[A\n",
      "Training loss: 9.28e-02 lr: 2.41e-05:  52%|▌| 7167/13852 [26:50<24:23,  4.57it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 2.41e-05:  52%|▌| 7168/13852 [26:50<24:32,  4.54it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.37e-02 lr: 2.41e-05:  52%|▌| 7169/13852 [26:50<24:34,  4.53it/s\u001b[A\n",
      "Training loss: 6.41e-02 lr: 2.41e-05:  52%|▌| 7170/13852 [26:51<24:36,  4.52it/s\u001b[A\n",
      "Training loss: 8.24e-02 lr: 2.41e-05:  52%|▌| 7171/13852 [26:51<24:48,  4.49it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 2.41e-05:  52%|▌| 7172/13852 [26:51<24:46,  4.49it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 2.41e-05:  52%|▌| 7173/13852 [26:51<24:46,  4.49it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 2.41e-05:  52%|▌| 7174/13852 [26:52<24:49,  4.48it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 2.41e-05:  52%|▌| 7175/13852 [26:52<24:51,  4.48it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 2.41e-05:  52%|▌| 7176/13852 [26:52<24:49,  4.48it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 2.41e-05:  52%|▌| 7177/13852 [26:52<24:41,  4.51it/s\u001b[A\n",
      "Training loss: 9.73e-02 lr: 2.41e-05:  52%|▌| 7178/13852 [26:52<24:32,  4.53it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 2.41e-05:  52%|▌| 7179/13852 [26:53<24:25,  4.55it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 2.41e-05:  52%|▌| 7180/13852 [26:53<24:34,  4.52it/s\u001b[A\n",
      "Training loss: 8.03e-02 lr: 2.41e-05:  52%|▌| 7181/13852 [26:53<24:34,  4.52it/s\u001b[A\n",
      "Training loss: 7.07e-02 lr: 2.41e-05:  52%|▌| 7182/13852 [26:53<24:33,  4.53it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 2.41e-05:  52%|▌| 7183/13852 [26:54<24:33,  4.53it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 2.41e-05:  52%|▌| 7184/13852 [26:54<24:40,  4.51it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 2.41e-05:  52%|▌| 7185/13852 [26:54<24:39,  4.51it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 2.41e-05:  52%|▌| 7186/13852 [26:54<24:39,  4.51it/s\u001b[A\n",
      "Training loss: 7.63e-02 lr: 2.41e-05:  52%|▌| 7187/13852 [26:54<24:39,  4.50it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.41e-05:  52%|▌| 7188/13852 [26:55<24:40,  4.50it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 2.41e-05:  52%|▌| 7189/13852 [26:55<24:33,  4.52it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 2.40e-05:  52%|▌| 7190/13852 [26:55<24:26,  4.54it/s\u001b[A\n",
      "Training loss: 7.63e-02 lr: 2.40e-05:  52%|▌| 7191/13852 [26:55<24:18,  4.57it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 2.40e-05:  52%|▌| 7192/13852 [26:56<24:36,  4.51it/s\u001b[A\n",
      "Training loss: 5.45e-02 lr: 2.40e-05:  52%|▌| 7193/13852 [26:56<24:37,  4.51it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 2.40e-05:  52%|▌| 7194/13852 [26:56<24:35,  4.51it/s\u001b[A\n",
      "Training loss: 3.95e-02 lr: 2.40e-05:  52%|▌| 7195/13852 [26:56<24:36,  4.51it/s\u001b[A\n",
      "Training loss: 2.92e-02 lr: 2.40e-05:  52%|▌| 7196/13852 [26:56<24:37,  4.50it/s\u001b[A\n",
      "Training loss: 2.53e-02 lr: 2.40e-05:  52%|▌| 7197/13852 [26:57<24:44,  4.48it/s\u001b[A\n",
      "Training loss: 2.10e-02 lr: 2.40e-05:  52%|▌| 7198/13852 [26:57<24:50,  4.46it/s\u001b[A\n",
      "Training loss: 1.94e-02 lr: 2.40e-05:  52%|▌| 7199/13852 [26:57<24:47,  4.47it/s\u001b[A\n",
      "Training loss: 2.10e-02 lr: 2.40e-05:  52%|▌| 7200/13852 [26:57<24:41,  4.49it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 2.40e-05:  52%|▌| 7201/13852 [26:58<24:33,  4.51it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 2.40e-05:  52%|▌| 7202/13852 [26:58<24:28,  4.53it/s\u001b[A\n",
      "Training loss: 3.68e-02 lr: 2.40e-05:  52%|▌| 7203/13852 [26:58<24:24,  4.54it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 2.40e-05:  52%|▌| 7204/13852 [26:58<24:32,  4.51it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 2.40e-05:  52%|▌| 7205/13852 [26:58<24:33,  4.51it/s\u001b[A\n",
      "Training loss: 6.17e-02 lr: 2.40e-05:  52%|▌| 7206/13852 [26:59<24:33,  4.51it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 2.40e-05:  52%|▌| 7207/13852 [26:59<24:34,  4.51it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 2.40e-05:  52%|▌| 7208/13852 [26:59<24:38,  4.49it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 2.40e-05:  52%|▌| 7209/13852 [26:59<24:37,  4.50it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.40e-05:  52%|▌| 7210/13852 [27:00<24:36,  4.50it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 2.40e-05:  52%|▌| 7211/13852 [27:00<24:36,  4.50it/s\u001b[A\n",
      "Training loss: 3.33e-02 lr: 2.40e-05:  52%|▌| 7212/13852 [27:00<24:40,  4.49it/s\u001b[A\n",
      "Training loss: 2.81e-02 lr: 2.40e-05:  52%|▌| 7213/13852 [27:00<24:33,  4.51it/s\u001b[A\n",
      "Training loss: 2.71e-02 lr: 2.40e-05:  52%|▌| 7214/13852 [27:00<24:24,  4.53it/s\u001b[A\n",
      "Training loss: 2.72e-02 lr: 2.40e-05:  52%|▌| 7215/13852 [27:01<24:19,  4.55it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 2.40e-05:  52%|▌| 7216/13852 [27:01<24:47,  4.46it/s\u001b[A\n",
      "Training loss: 2.52e-02 lr: 2.40e-05:  52%|▌| 7217/13852 [27:01<24:44,  4.47it/s\u001b[A\n",
      "Training loss: 8.14e-02 lr: 2.39e-05:  52%|▌| 7218/13852 [27:01<24:42,  4.47it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 2.39e-05:  52%|▌| 7219/13852 [27:02<24:49,  4.45it/s\u001b[A\n",
      "Training loss: 6.51e-02 lr: 2.39e-05:  52%|▌| 7220/13852 [27:02<24:51,  4.45it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 2.39e-05:  52%|▌| 7221/13852 [27:02<24:48,  4.45it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.39e-05:  52%|▌| 7222/13852 [27:02<24:45,  4.46it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 2.39e-05:  52%|▌| 7223/13852 [27:02<24:42,  4.47it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 2.39e-05:  52%|▌| 7224/13852 [27:03<24:34,  4.50it/s\u001b[A\n",
      "Training loss: 5.55e-02 lr: 2.39e-05:  52%|▌| 7225/13852 [27:03<24:25,  4.52it/s\u001b[A\n",
      "Training loss: 6.19e-02 lr: 2.39e-05:  52%|▌| 7226/13852 [27:03<24:26,  4.52it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 2.39e-05:  52%|▌| 7227/13852 [27:03<24:22,  4.53it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 2.39e-05:  52%|▌| 7228/13852 [27:04<24:21,  4.53it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 2.39e-05:  52%|▌| 7229/13852 [27:04<24:22,  4.53it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 2.39e-05:  52%|▌| 7230/13852 [27:04<24:31,  4.50it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 2.39e-05:  52%|▌| 7231/13852 [27:04<24:40,  4.47it/s\u001b[A\n",
      "Training loss: 4.26e-02 lr: 2.39e-05:  52%|▌| 7232/13852 [27:04<24:37,  4.48it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 2.39e-05:  52%|▌| 7233/13852 [27:05<24:35,  4.49it/s\u001b[A\n",
      "Training loss: 8.51e-02 lr: 2.39e-05:  52%|▌| 7234/13852 [27:05<24:34,  4.49it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 2.39e-05:  52%|▌| 7235/13852 [27:05<24:32,  4.49it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 2.39e-05:  52%|▌| 7236/13852 [27:05<24:27,  4.51it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 2.39e-05:  52%|▌| 7237/13852 [27:06<24:20,  4.53it/s\u001b[A\n",
      "Training loss: 3.27e-02 lr: 2.39e-05:  52%|▌| 7238/13852 [27:06<24:14,  4.55it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 2.39e-05:  52%|▌| 7239/13852 [27:06<24:18,  4.53it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 2.39e-05:  52%|▌| 7240/13852 [27:06<24:18,  4.53it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.39e-05:  52%|▌| 7241/13852 [27:06<24:19,  4.53it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 2.39e-05:  52%|▌| 7242/13852 [27:07<24:30,  4.49it/s\u001b[A\n",
      "Training loss: 6.22e-02 lr: 2.39e-05:  52%|▌| 7243/13852 [27:07<24:39,  4.47it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 2.39e-05:  52%|▌| 7244/13852 [27:07<24:43,  4.45it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 2.39e-05:  52%|▌| 7245/13852 [27:07<24:49,  4.44it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 2.38e-05:  52%|▌| 7246/13852 [27:08<24:46,  4.45it/s\u001b[A\n",
      "Training loss: 4.07e-02 lr: 2.38e-05:  52%|▌| 7247/13852 [27:08<24:46,  4.44it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 2.38e-05:  52%|▌| 7248/13852 [27:08<24:35,  4.48it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 2.38e-05:  52%|▌| 7249/13852 [27:08<24:23,  4.51it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 2.38e-05:  52%|▌| 7250/13852 [27:08<24:28,  4.50it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 2.38e-05:  52%|▌| 7251/13852 [27:09<24:24,  4.51it/s\u001b[A\n",
      "Training loss: 4.30e-02 lr: 2.38e-05:  52%|▌| 7252/13852 [27:09<24:22,  4.51it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 2.38e-05:  52%|▌| 7253/13852 [27:09<24:17,  4.53it/s\u001b[A\n",
      "Training loss: 8.52e-02 lr: 2.38e-05:  52%|▌| 7254/13852 [27:09<24:18,  4.52it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 2.38e-05:  52%|▌| 7255/13852 [27:10<24:19,  4.52it/s\u001b[A\n",
      "Training loss: 7.19e-02 lr: 2.38e-05:  52%|▌| 7256/13852 [27:10<24:20,  4.52it/s\u001b[A\n",
      "Training loss: 1.84e-01 lr: 2.38e-05:  52%|▌| 7257/13852 [27:10<24:20,  4.52it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 2.38e-05:  52%|▌| 7258/13852 [27:10<24:22,  4.51it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.38e-05:  52%|▌| 7259/13852 [27:10<24:22,  4.51it/s\u001b[A\n",
      "Training loss: 7.68e-02 lr: 2.38e-05:  52%|▌| 7260/13852 [27:11<24:15,  4.53it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 2.38e-05:  52%|▌| 7261/13852 [27:11<24:17,  4.52it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 2.38e-05:  52%|▌| 7262/13852 [27:11<24:29,  4.49it/s\u001b[A\n",
      "Training loss: 3.50e-02 lr: 2.38e-05:  52%|▌| 7263/13852 [27:11<24:24,  4.50it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 2.38e-05:  52%|▌| 7264/13852 [27:12<24:25,  4.50it/s\u001b[A\n",
      "Training loss: 3.25e-02 lr: 2.38e-05:  52%|▌| 7265/13852 [27:12<24:29,  4.48it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.31e-02 lr: 2.38e-05:  52%|▌| 7266/13852 [27:12<24:28,  4.48it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 2.38e-05:  52%|▌| 7267/13852 [27:12<24:29,  4.48it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 2.38e-05:  52%|▌| 7268/13852 [27:12<24:27,  4.49it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 2.38e-05:  52%|▌| 7269/13852 [27:13<24:26,  4.49it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 2.38e-05:  52%|▌| 7270/13852 [27:13<24:25,  4.49it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 2.38e-05:  52%|▌| 7271/13852 [27:13<24:19,  4.51it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 2.38e-05:  52%|▌| 7272/13852 [27:13<24:10,  4.54it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 2.37e-05:  53%|▌| 7273/13852 [27:14<24:04,  4.55it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 2.37e-05:  53%|▌| 7274/13852 [27:14<24:02,  4.56it/s\u001b[A\n",
      "Training loss: 3.38e-02 lr: 2.37e-05:  53%|▌| 7275/13852 [27:14<24:07,  4.54it/s\u001b[A\n",
      "Training loss: 3.59e-02 lr: 2.37e-05:  53%|▌| 7276/13852 [27:14<24:09,  4.54it/s\u001b[A\n",
      "Training loss: 2.97e-02 lr: 2.37e-05:  53%|▌| 7277/13852 [27:14<24:15,  4.52it/s\u001b[A\n",
      "Training loss: 2.58e-02 lr: 2.37e-05:  53%|▌| 7278/13852 [27:15<24:16,  4.51it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 2.37e-05:  53%|▌| 7279/13852 [27:15<24:16,  4.51it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 2.37e-05:  53%|▌| 7280/13852 [27:15<24:17,  4.51it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 2.37e-05:  53%|▌| 7281/13852 [27:15<24:17,  4.51it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 2.37e-05:  53%|▌| 7282/13852 [27:16<24:18,  4.50it/s\u001b[A\n",
      "Training loss: 7.53e-02 lr: 2.37e-05:  53%|▌| 7283/13852 [27:16<24:20,  4.50it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 2.37e-05:  53%|▌| 7284/13852 [27:16<24:13,  4.52it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 2.37e-05:  53%|▌| 7285/13852 [27:16<24:03,  4.55it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 2.37e-05:  53%|▌| 7286/13852 [27:16<23:59,  4.56it/s\u001b[A\n",
      "Training loss: 3.04e-02 lr: 2.37e-05:  53%|▌| 7287/13852 [27:17<24:19,  4.50it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.37e-05:  53%|▌| 7288/13852 [27:17<24:24,  4.48it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 2.37e-05:  53%|▌| 7289/13852 [27:17<24:21,  4.49it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 2.37e-05:  53%|▌| 7290/13852 [27:17<24:20,  4.49it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 2.37e-05:  53%|▌| 7291/13852 [27:18<24:21,  4.49it/s\u001b[A\n",
      "Training loss: 3.47e-02 lr: 2.37e-05:  53%|▌| 7292/13852 [27:18<24:22,  4.48it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 2.37e-05:  53%|▌| 7293/13852 [27:18<24:32,  4.45it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 2.37e-05:  53%|▌| 7294/13852 [27:18<24:29,  4.46it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 2.37e-05:  53%|▌| 7295/13852 [27:18<24:20,  4.49it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 2.37e-05:  53%|▌| 7296/13852 [27:19<24:09,  4.52it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 2.37e-05:  53%|▌| 7297/13852 [27:19<24:05,  4.54it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 2.37e-05:  53%|▌| 7298/13852 [27:19<24:18,  4.49it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 2.37e-05:  53%|▌| 7299/13852 [27:19<24:17,  4.50it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 2.37e-05:  53%|▌| 7300/13852 [27:20<24:14,  4.51it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 2.36e-05:  53%|▌| 7301/13852 [27:20<24:12,  4.51it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 2.36e-05:  53%|▌| 7302/13852 [27:20<24:13,  4.51it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 2.36e-05:  53%|▌| 7303/13852 [27:20<24:14,  4.50it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 2.36e-05:  53%|▌| 7304/13852 [27:20<24:13,  4.50it/s\u001b[A\n",
      "Training loss: 4.03e-02 lr: 2.36e-05:  53%|▌| 7305/13852 [27:21<24:13,  4.50it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 2.36e-05:  53%|▌| 7306/13852 [27:21<24:23,  4.47it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 2.36e-05:  53%|▌| 7307/13852 [27:21<24:15,  4.50it/s\u001b[A\n",
      "Training loss: 3.62e-02 lr: 2.36e-05:  53%|▌| 7308/13852 [27:21<24:06,  4.53it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 2.36e-05:  53%|▌| 7309/13852 [27:22<23:59,  4.55it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 2.36e-05:  53%|▌| 7310/13852 [27:22<24:09,  4.51it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 2.36e-05:  53%|▌| 7311/13852 [27:22<24:08,  4.52it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 2.36e-05:  53%|▌| 7312/13852 [27:22<24:09,  4.51it/s\u001b[A\n",
      "Training loss: 7.21e-02 lr: 2.36e-05:  53%|▌| 7313/13852 [27:22<24:10,  4.51it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 2.36e-05:  53%|▌| 7314/13852 [27:23<24:11,  4.50it/s\u001b[A\n",
      "Training loss: 6.46e-02 lr: 2.36e-05:  53%|▌| 7315/13852 [27:23<24:16,  4.49it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 2.36e-05:  53%|▌| 7316/13852 [27:23<24:20,  4.48it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 2.36e-05:  53%|▌| 7317/13852 [27:23<24:20,  4.48it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 2.36e-05:  53%|▌| 7318/13852 [27:24<24:17,  4.48it/s\u001b[A\n",
      "Training loss: 3.46e-02 lr: 2.36e-05:  53%|▌| 7319/13852 [27:24<24:16,  4.48it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 2.36e-05:  53%|▌| 7320/13852 [27:24<24:09,  4.51it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 2.36e-05:  53%|▌| 7321/13852 [27:24<24:00,  4.53it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 2.36e-05:  53%|▌| 7322/13852 [27:24<24:03,  4.52it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 2.36e-05:  53%|▌| 7323/13852 [27:25<24:01,  4.53it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 2.36e-05:  53%|▌| 7324/13852 [27:25<24:02,  4.53it/s\u001b[A\n",
      "Training loss: 7.82e-02 lr: 2.36e-05:  53%|▌| 7325/13852 [27:25<24:03,  4.52it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 2.36e-05:  53%|▌| 7326/13852 [27:25<24:05,  4.51it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 2.36e-05:  53%|▌| 7327/13852 [27:26<24:06,  4.51it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 2.36e-05:  53%|▌| 7328/13852 [27:26<24:08,  4.51it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 2.35e-05:  53%|▌| 7329/13852 [27:26<24:08,  4.50it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 2.35e-05:  53%|▌| 7330/13852 [27:26<24:07,  4.51it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 2.35e-05:  53%|▌| 7331/13852 [27:26<24:08,  4.50it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 2.35e-05:  53%|▌| 7332/13852 [27:27<24:08,  4.50it/s\u001b[A\n",
      "Training loss: 9.37e-02 lr: 2.35e-05:  53%|▌| 7333/13852 [27:27<24:10,  4.49it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 2.35e-05:  53%|▌| 7334/13852 [27:27<24:13,  4.49it/s\u001b[A\n",
      "Training loss: 8.05e-02 lr: 2.35e-05:  53%|▌| 7335/13852 [27:27<24:09,  4.50it/s\u001b[A\n",
      "Training loss: 9.26e-02 lr: 2.35e-05:  53%|▌| 7336/13852 [27:28<24:04,  4.51it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 2.35e-05:  53%|▌| 7337/13852 [27:28<24:03,  4.51it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 2.35e-05:  53%|▌| 7338/13852 [27:28<24:03,  4.51it/s\u001b[A\n",
      "Training loss: 3.75e-02 lr: 2.35e-05:  53%|▌| 7339/13852 [27:28<24:02,  4.51it/s\u001b[A\n",
      "Training loss: 3.89e-02 lr: 2.35e-05:  53%|▌| 7340/13852 [27:28<24:03,  4.51it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 2.35e-05:  53%|▌| 7341/13852 [27:29<24:03,  4.51it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 2.35e-05:  53%|▌| 7342/13852 [27:29<24:04,  4.51it/s\u001b[A\n",
      "Training loss: 3.46e-02 lr: 2.35e-05:  53%|▌| 7343/13852 [27:29<24:02,  4.51it/s\u001b[A\n",
      "Training loss: 3.05e-02 lr: 2.35e-05:  53%|▌| 7344/13852 [27:29<23:56,  4.53it/s\u001b[A\n",
      "Training loss: 3.01e-02 lr: 2.35e-05:  53%|▌| 7345/13852 [27:30<23:51,  4.55it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 2.35e-05:  53%|▌| 7346/13852 [27:30<24:07,  4.50it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 2.35e-05:  53%|▌| 7347/13852 [27:30<24:03,  4.51it/s\u001b[A\n",
      "Training loss: 4.78e-02 lr: 2.35e-05:  53%|▌| 7348/13852 [27:30<24:02,  4.51it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 2.35e-05:  53%|▌| 7349/13852 [27:30<24:00,  4.51it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 2.35e-05:  53%|▌| 7350/13852 [27:31<24:02,  4.51it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 2.35e-05:  53%|▌| 7351/13852 [27:31<24:12,  4.48it/s\u001b[A\n",
      "Training loss: 3.09e-02 lr: 2.35e-05:  53%|▌| 7352/13852 [27:31<24:10,  4.48it/s\u001b[A\n",
      "Training loss: 3.48e-02 lr: 2.35e-05:  53%|▌| 7353/13852 [27:31<24:08,  4.49it/s\u001b[A\n",
      "Training loss: 9.01e-02 lr: 2.35e-05:  53%|▌| 7354/13852 [27:32<24:07,  4.49it/s\u001b[A\n",
      "Training loss: 8.13e-02 lr: 2.35e-05:  53%|▌| 7355/13852 [27:32<24:15,  4.46it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 2.34e-05:  53%|▌| 7356/13852 [27:32<24:02,  4.50it/s\u001b[A\n",
      "Training loss: 7.13e-02 lr: 2.34e-05:  53%|▌| 7357/13852 [27:32<23:55,  4.52it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 2.34e-05:  53%|▌| 7358/13852 [27:32<23:54,  4.53it/s\u001b[A\n",
      "Training loss: 6.36e-02 lr: 2.34e-05:  53%|▌| 7359/13852 [27:33<23:55,  4.52it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 2.34e-05:  53%|▌| 7360/13852 [27:33<23:57,  4.52it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 2.34e-05:  53%|▌| 7361/13852 [27:33<24:04,  4.49it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 2.34e-05:  53%|▌| 7362/13852 [27:33<24:05,  4.49it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.18e-02 lr: 2.34e-05:  53%|▌| 7363/13852 [27:34<24:04,  4.49it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 2.34e-05:  53%|▌| 7364/13852 [27:34<24:02,  4.50it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.34e-05:  53%|▌| 7365/13852 [27:34<24:03,  4.49it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.34e-05:  53%|▌| 7366/13852 [27:34<24:04,  4.49it/s\u001b[A\n",
      "Training loss: 7.88e-02 lr: 2.34e-05:  53%|▌| 7367/13852 [27:34<24:01,  4.50it/s\u001b[A\n",
      "Training loss: 6.25e-02 lr: 2.34e-05:  53%|▌| 7368/13852 [27:35<23:53,  4.52it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 2.34e-05:  53%|▌| 7369/13852 [27:35<23:47,  4.54it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 2.34e-05:  53%|▌| 7370/13852 [27:35<23:57,  4.51it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 2.34e-05:  53%|▌| 7371/13852 [27:35<23:56,  4.51it/s\u001b[A\n",
      "Training loss: 8.37e-02 lr: 2.34e-05:  53%|▌| 7372/13852 [27:36<23:56,  4.51it/s\u001b[A\n",
      "Training loss: 8.42e-02 lr: 2.34e-05:  53%|▌| 7373/13852 [27:36<23:53,  4.52it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 2.34e-05:  53%|▌| 7374/13852 [27:36<23:56,  4.51it/s\u001b[A\n",
      "Training loss: 7.58e-02 lr: 2.34e-05:  53%|▌| 7375/13852 [27:36<23:54,  4.51it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 2.34e-05:  53%|▌| 7376/13852 [27:36<23:55,  4.51it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 2.34e-05:  53%|▌| 7377/13852 [27:37<24:05,  4.48it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 2.34e-05:  53%|▌| 7378/13852 [27:37<24:13,  4.45it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 2.34e-05:  53%|▌| 7379/13852 [27:37<24:43,  4.36it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 2.34e-05:  53%|▌| 7380/13852 [27:37<25:10,  4.28it/s\u001b[A\n",
      "Training loss: 3.22e-02 lr: 2.34e-05:  53%|▌| 7381/13852 [27:38<25:15,  4.27it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 2.34e-05:  53%|▌| 7382/13852 [27:38<24:50,  4.34it/s\u001b[A\n",
      "Training loss: 4.05e-02 lr: 2.34e-05:  53%|▌| 7383/13852 [27:38<24:35,  4.38it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 2.33e-05:  53%|▌| 7384/13852 [27:38<24:23,  4.42it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 2.33e-05:  53%|▌| 7385/13852 [27:38<24:15,  4.44it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.33e-05:  53%|▌| 7386/13852 [27:39<24:13,  4.45it/s\u001b[A\n",
      "Training loss: 8.97e-02 lr: 2.33e-05:  53%|▌| 7387/13852 [27:39<24:07,  4.47it/s\u001b[A\n",
      "Training loss: 6.36e-02 lr: 2.33e-05:  53%|▌| 7388/13852 [27:39<23:55,  4.50it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 2.33e-05:  53%|▌| 7389/13852 [27:39<23:48,  4.53it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 2.33e-05:  53%|▌| 7390/13852 [27:40<24:04,  4.47it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 2.33e-05:  53%|▌| 7391/13852 [27:40<24:00,  4.48it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 2.33e-05:  53%|▌| 7392/13852 [27:40<23:56,  4.50it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 2.33e-05:  53%|▌| 7393/13852 [27:40<23:54,  4.50it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 2.33e-05:  53%|▌| 7394/13852 [27:40<23:53,  4.51it/s\u001b[A\n",
      "Training loss: 5.09e-02 lr: 2.33e-05:  53%|▌| 7395/13852 [27:41<23:52,  4.51it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 2.33e-05:  53%|▌| 7396/13852 [27:41<23:58,  4.49it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 2.33e-05:  53%|▌| 7397/13852 [27:41<23:57,  4.49it/s\u001b[A\n",
      "Training loss: 3.50e-02 lr: 2.33e-05:  53%|▌| 7398/13852 [27:41<23:55,  4.50it/s\u001b[A\n",
      "Training loss: 2.90e-02 lr: 2.33e-05:  53%|▌| 7399/13852 [27:42<23:57,  4.49it/s\u001b[A\n",
      "Training loss: 3.84e-02 lr: 2.33e-05:  53%|▌| 7400/13852 [27:42<23:54,  4.50it/s\u001b[A\n",
      "Training loss: 1.36e-01 lr: 2.33e-05:  53%|▌| 7401/13852 [27:42<23:45,  4.53it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.33e-05:  53%|▌| 7402/13852 [27:42<23:38,  4.55it/s\u001b[A\n",
      "Training loss: 7.99e-02 lr: 2.33e-05:  53%|▌| 7403/13852 [27:42<23:37,  4.55it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 2.33e-05:  53%|▌| 7404/13852 [27:43<23:39,  4.54it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 2.33e-05:  53%|▌| 7405/13852 [27:43<23:40,  4.54it/s\u001b[A\n",
      "Training loss: 3.83e-02 lr: 2.33e-05:  53%|▌| 7406/13852 [27:43<23:43,  4.53it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 2.33e-05:  53%|▌| 7407/13852 [27:43<23:44,  4.53it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 2.33e-05:  53%|▌| 7408/13852 [27:44<23:43,  4.53it/s\u001b[A\n",
      "Training loss: 6.12e-02 lr: 2.33e-05:  53%|▌| 7409/13852 [27:44<23:43,  4.52it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 2.33e-05:  53%|▌| 7410/13852 [27:44<23:44,  4.52it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.33e-05:  54%|▌| 7411/13852 [27:44<23:45,  4.52it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 2.32e-05:  54%|▌| 7412/13852 [27:44<23:46,  4.51it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 2.32e-05:  54%|▌| 7413/13852 [27:45<23:40,  4.53it/s\u001b[A\n",
      "Training loss: 9.69e-02 lr: 2.32e-05:  54%|▌| 7414/13852 [27:45<23:49,  4.50it/s\u001b[A\n",
      "Training loss: 8.42e-02 lr: 2.32e-05:  54%|▌| 7415/13852 [27:45<23:49,  4.50it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 2.32e-05:  54%|▌| 7416/13852 [27:45<23:48,  4.51it/s\u001b[A\n",
      "Training loss: 9.60e-02 lr: 2.32e-05:  54%|▌| 7417/13852 [27:46<23:45,  4.51it/s\u001b[A\n",
      "Training loss: 7.68e-02 lr: 2.32e-05:  54%|▌| 7418/13852 [27:46<23:44,  4.52it/s\u001b[A\n",
      "Training loss: 5.57e-02 lr: 2.32e-05:  54%|▌| 7419/13852 [27:46<23:42,  4.52it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 2.32e-05:  54%|▌| 7420/13852 [27:46<23:41,  4.53it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 2.32e-05:  54%|▌| 7421/13852 [27:46<23:41,  4.52it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 2.32e-05:  54%|▌| 7422/13852 [27:47<23:48,  4.50it/s\u001b[A\n",
      "Training loss: 8.69e-02 lr: 2.32e-05:  54%|▌| 7423/13852 [27:47<23:49,  4.50it/s\u001b[A\n",
      "Training loss: 6.68e-02 lr: 2.32e-05:  54%|▌| 7424/13852 [27:47<23:41,  4.52it/s\u001b[A\n",
      "Training loss: 7.87e-02 lr: 2.32e-05:  54%|▌| 7425/13852 [27:47<23:32,  4.55it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 2.32e-05:  54%|▌| 7426/13852 [27:48<23:27,  4.56it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 2.32e-05:  54%|▌| 7427/13852 [27:48<24:05,  4.45it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 2.32e-05:  54%|▌| 7428/13852 [27:48<24:44,  4.33it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 2.32e-05:  54%|▌| 7429/13852 [27:48<25:16,  4.24it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 2.32e-05:  54%|▌| 7430/13852 [27:49<25:27,  4.21it/s\u001b[A\n",
      "Training loss: 3.77e-02 lr: 2.32e-05:  54%|▌| 7431/13852 [27:49<25:01,  4.28it/s\u001b[A\n",
      "Training loss: 3.12e-02 lr: 2.32e-05:  54%|▌| 7432/13852 [27:49<24:34,  4.36it/s\u001b[A\n",
      "Training loss: 2.87e-02 lr: 2.32e-05:  54%|▌| 7433/13852 [27:49<24:16,  4.41it/s\u001b[A\n",
      "Training loss: 2.59e-02 lr: 2.32e-05:  54%|▌| 7434/13852 [27:49<24:10,  4.42it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.32e-05:  54%|▌| 7435/13852 [27:50<24:08,  4.43it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.32e-05:  54%|▌| 7436/13852 [27:50<24:00,  4.45it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 2.32e-05:  54%|▌| 7437/13852 [27:50<24:04,  4.44it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 2.32e-05:  54%|▌| 7438/13852 [27:50<23:57,  4.46it/s\u001b[A\n",
      "Training loss: 8.01e-02 lr: 2.31e-05:  54%|▌| 7439/13852 [27:51<23:53,  4.48it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 2.31e-05:  54%|▌| 7440/13852 [27:51<23:58,  4.46it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 2.31e-05:  54%|▌| 7441/13852 [27:51<23:56,  4.46it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 2.31e-05:  54%|▌| 7442/13852 [27:51<23:52,  4.47it/s\u001b[A\n",
      "Training loss: 7.49e-02 lr: 2.31e-05:  54%|▌| 7443/13852 [27:51<23:43,  4.50it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 2.31e-05:  54%|▌| 7444/13852 [27:52<23:39,  4.52it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 2.31e-05:  54%|▌| 7445/13852 [27:52<23:32,  4.54it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 2.31e-05:  54%|▌| 7446/13852 [27:52<23:29,  4.55it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 2.31e-05:  54%|▌| 7447/13852 [27:52<23:30,  4.54it/s\u001b[A\n",
      "Training loss: 7.85e-02 lr: 2.31e-05:  54%|▌| 7448/13852 [27:53<23:38,  4.51it/s\u001b[A\n",
      "Training loss: 7.79e-02 lr: 2.31e-05:  54%|▌| 7449/13852 [27:53<23:35,  4.52it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 2.31e-05:  54%|▌| 7450/13852 [27:53<23:37,  4.52it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 2.31e-05:  54%|▌| 7451/13852 [27:53<23:44,  4.49it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 2.31e-05:  54%|▌| 7452/13852 [27:53<23:42,  4.50it/s\u001b[A\n",
      "Training loss: 7.21e-02 lr: 2.31e-05:  54%|▌| 7453/13852 [27:54<23:41,  4.50it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 2.31e-05:  54%|▌| 7454/13852 [27:54<23:39,  4.51it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 2.31e-05:  54%|▌| 7455/13852 [27:54<23:45,  4.49it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 2.31e-05:  54%|▌| 7456/13852 [27:54<23:37,  4.51it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 2.31e-05:  54%|▌| 7457/13852 [27:55<23:27,  4.54it/s\u001b[A\n",
      "Training loss: 3.03e-02 lr: 2.31e-05:  54%|▌| 7458/13852 [27:55<23:28,  4.54it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 2.31e-05:  54%|▌| 7459/13852 [27:55<23:30,  4.53it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.14e-02 lr: 2.31e-05:  54%|▌| 7460/13852 [27:55<23:30,  4.53it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 2.31e-05:  54%|▌| 7461/13852 [27:55<23:31,  4.53it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 2.31e-05:  54%|▌| 7462/13852 [27:56<23:34,  4.52it/s\u001b[A\n",
      "Training loss: 8.48e-02 lr: 2.31e-05:  54%|▌| 7463/13852 [27:56<23:33,  4.52it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 2.31e-05:  54%|▌| 7464/13852 [27:56<23:36,  4.51it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 2.31e-05:  54%|▌| 7465/13852 [27:56<23:39,  4.50it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 2.31e-05:  54%|▌| 7466/13852 [27:57<23:42,  4.49it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 2.30e-05:  54%|▌| 7467/13852 [27:57<23:49,  4.47it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.30e-05:  54%|▌| 7468/13852 [27:57<23:43,  4.49it/s\u001b[A\n",
      "Training loss: 8.06e-02 lr: 2.30e-05:  54%|▌| 7469/13852 [27:57<23:33,  4.52it/s\u001b[A\n",
      "Training loss: 7.21e-02 lr: 2.30e-05:  54%|▌| 7470/13852 [27:57<23:42,  4.49it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 2.30e-05:  54%|▌| 7471/13852 [27:58<23:38,  4.50it/s\u001b[A\n",
      "Training loss: 8.17e-02 lr: 2.30e-05:  54%|▌| 7472/13852 [27:58<23:37,  4.50it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.30e-05:  54%|▌| 7473/13852 [27:58<23:39,  4.49it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.30e-05:  54%|▌| 7474/13852 [27:58<23:37,  4.50it/s\u001b[A\n",
      "Training loss: 9.09e-02 lr: 2.30e-05:  54%|▌| 7475/13852 [27:59<23:34,  4.51it/s\u001b[A\n",
      "Training loss: 6.96e-02 lr: 2.30e-05:  54%|▌| 7476/13852 [27:59<23:34,  4.51it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 2.30e-05:  54%|▌| 7477/13852 [27:59<23:33,  4.51it/s\u001b[A\n",
      "Training loss: 1.76e-01 lr: 2.30e-05:  54%|▌| 7478/13852 [27:59<23:37,  4.50it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 2.30e-05:  54%|▌| 7479/13852 [27:59<23:29,  4.52it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 2.30e-05:  54%|▌| 7480/13852 [28:00<23:20,  4.55it/s\u001b[A\n",
      "Training loss: 8.96e-02 lr: 2.30e-05:  54%|▌| 7481/13852 [28:00<23:22,  4.54it/s\u001b[A\n",
      "Training loss: 7.42e-02 lr: 2.30e-05:  54%|▌| 7482/13852 [28:00<23:20,  4.55it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 2.30e-05:  54%|▌| 7483/13852 [28:00<23:24,  4.54it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 2.30e-05:  54%|▌| 7484/13852 [28:01<23:24,  4.53it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 2.30e-05:  54%|▌| 7485/13852 [28:01<23:28,  4.52it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 2.30e-05:  54%|▌| 7486/13852 [28:01<24:16,  4.37it/s\u001b[A\n",
      "Training loss: 4.82e-02 lr: 2.30e-05:  54%|▌| 7487/13852 [28:01<24:03,  4.41it/s\u001b[A\n",
      "Training loss: 6.18e-02 lr: 2.30e-05:  54%|▌| 7488/13852 [28:01<23:52,  4.44it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.30e-05:  54%|▌| 7489/13852 [28:02<23:48,  4.46it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 2.30e-05:  54%|▌| 7490/13852 [28:02<23:44,  4.47it/s\u001b[A\n",
      "Training loss: 6.79e-02 lr: 2.30e-05:  54%|▌| 7491/13852 [28:02<23:38,  4.48it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 2.30e-05:  54%|▌| 7492/13852 [28:02<23:28,  4.52it/s\u001b[A\n",
      "Training loss: 4.38e-02 lr: 2.30e-05:  54%|▌| 7493/13852 [28:03<23:19,  4.54it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 2.30e-05:  54%|▌| 7494/13852 [28:03<23:24,  4.53it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 2.29e-05:  54%|▌| 7495/13852 [28:03<23:31,  4.50it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 2.29e-05:  54%|▌| 7496/13852 [28:03<23:28,  4.51it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 2.29e-05:  54%|▌| 7497/13852 [28:03<23:26,  4.52it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 2.29e-05:  54%|▌| 7498/13852 [28:04<23:27,  4.51it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 2.29e-05:  54%|▌| 7499/13852 [28:04<23:25,  4.52it/s\u001b[A\n",
      "Training loss: 7.33e-02 lr: 2.29e-05:  54%|▌| 7500/13852 [28:04<23:26,  4.52it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 2.29e-05:  54%|▌| 7501/13852 [28:04<23:36,  4.49it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 2.29e-05:  54%|▌| 7502/13852 [28:05<23:39,  4.47it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 2.29e-05:  54%|▌| 7503/13852 [28:05<23:31,  4.50it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 2.29e-05:  54%|▌| 7504/13852 [28:05<23:21,  4.53it/s\u001b[A\n",
      "Training loss: 8.50e-02 lr: 2.29e-05:  54%|▌| 7505/13852 [28:05<23:14,  4.55it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 2.29e-05:  54%|▌| 7506/13852 [28:05<23:26,  4.51it/s\u001b[A\n",
      "Training loss: 8.20e-02 lr: 2.29e-05:  54%|▌| 7507/13852 [28:06<23:25,  4.51it/s\u001b[A\n",
      "Training loss: 9.82e-02 lr: 2.29e-05:  54%|▌| 7508/13852 [28:06<23:23,  4.52it/s\u001b[A\n",
      "Training loss: 8.49e-02 lr: 2.29e-05:  54%|▌| 7509/13852 [28:06<23:26,  4.51it/s\u001b[A\n",
      "Training loss: 7.37e-02 lr: 2.29e-05:  54%|▌| 7510/13852 [28:06<23:27,  4.51it/s\u001b[A\n",
      "Training loss: 6.34e-02 lr: 2.29e-05:  54%|▌| 7511/13852 [28:07<23:26,  4.51it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 2.29e-05:  54%|▌| 7512/13852 [28:07<23:35,  4.48it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 2.29e-05:  54%|▌| 7513/13852 [28:07<24:14,  4.36it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 2.29e-05:  54%|▌| 7514/13852 [28:07<24:32,  4.31it/s\u001b[A\n",
      "Training loss: 3.89e-02 lr: 2.29e-05:  54%|▌| 7515/13852 [28:07<24:58,  4.23it/s\u001b[A\n",
      "Training loss: 3.47e-02 lr: 2.29e-05:  54%|▌| 7516/13852 [28:08<24:29,  4.31it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 2.29e-05:  54%|▌| 7517/13852 [28:08<24:11,  4.37it/s\u001b[A\n",
      "Training loss: 2.35e-02 lr: 2.29e-05:  54%|▌| 7518/13852 [28:08<24:01,  4.40it/s\u001b[A\n",
      "Training loss: 2.15e-02 lr: 2.29e-05:  54%|▌| 7519/13852 [28:08<23:52,  4.42it/s\u001b[A\n",
      "Training loss: 1.66e-02 lr: 2.29e-05:  54%|▌| 7520/13852 [28:09<23:48,  4.43it/s\u001b[A\n",
      "Training loss: 1.79e-02 lr: 2.29e-05:  54%|▌| 7521/13852 [28:09<23:42,  4.45it/s\u001b[A\n",
      "Training loss: 3.09e-02 lr: 2.29e-05:  54%|▌| 7522/13852 [28:09<23:41,  4.45it/s\u001b[A\n",
      "Training loss: 2.29e-02 lr: 2.28e-05:  54%|▌| 7523/13852 [28:09<23:34,  4.48it/s\u001b[A\n",
      "Training loss: 2.77e-02 lr: 2.28e-05:  54%|▌| 7524/13852 [28:09<23:25,  4.50it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.28e-05:  54%|▌| 7525/13852 [28:10<23:17,  4.53it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 2.28e-05:  54%|▌| 7526/13852 [28:10<23:15,  4.53it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 2.28e-05:  54%|▌| 7527/13852 [28:10<23:16,  4.53it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 2.28e-05:  54%|▌| 7528/13852 [28:10<23:17,  4.53it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 2.28e-05:  54%|▌| 7529/13852 [28:11<23:21,  4.51it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 2.28e-05:  54%|▌| 7530/13852 [28:11<23:31,  4.48it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 2.28e-05:  54%|▌| 7531/13852 [28:11<23:34,  4.47it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 2.28e-05:  54%|▌| 7532/13852 [28:11<23:33,  4.47it/s\u001b[A\n",
      "Training loss: 3.91e-02 lr: 2.28e-05:  54%|▌| 7533/13852 [28:11<23:32,  4.47it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 2.28e-05:  54%|▌| 7534/13852 [28:12<23:27,  4.49it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 2.28e-05:  54%|▌| 7535/13852 [28:12<23:18,  4.52it/s\u001b[A\n",
      "Training loss: 4.60e-02 lr: 2.28e-05:  54%|▌| 7536/13852 [28:12<23:30,  4.48it/s\u001b[A\n",
      "Training loss: 3.69e-02 lr: 2.28e-05:  54%|▌| 7537/13852 [28:12<23:20,  4.51it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 2.28e-05:  54%|▌| 7538/13852 [28:13<23:22,  4.50it/s\u001b[A\n",
      "Training loss: 2.48e-02 lr: 2.28e-05:  54%|▌| 7539/13852 [28:13<23:22,  4.50it/s\u001b[A\n",
      "Training loss: 2.01e-02 lr: 2.28e-05:  54%|▌| 7540/13852 [28:13<23:24,  4.49it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 2.28e-05:  54%|▌| 7541/13852 [28:13<23:25,  4.49it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 2.28e-05:  54%|▌| 7542/13852 [28:13<23:27,  4.48it/s\u001b[A\n",
      "Training loss: 3.56e-02 lr: 2.28e-05:  54%|▌| 7543/13852 [28:14<23:26,  4.49it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 2.28e-05:  54%|▌| 7544/13852 [28:14<23:25,  4.49it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 2.28e-05:  54%|▌| 7545/13852 [28:14<23:26,  4.48it/s\u001b[A\n",
      "Training loss: 2.91e-02 lr: 2.28e-05:  54%|▌| 7546/13852 [28:14<23:27,  4.48it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 2.28e-05:  54%|▌| 7547/13852 [28:15<23:19,  4.51it/s\u001b[A\n",
      "Training loss: 9.28e-02 lr: 2.28e-05:  54%|▌| 7548/13852 [28:15<23:13,  4.53it/s\u001b[A\n",
      "Training loss: 6.59e-02 lr: 2.28e-05:  54%|▌| 7549/13852 [28:15<23:19,  4.50it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 2.27e-05:  55%|▌| 7550/13852 [28:15<23:17,  4.51it/s\u001b[A\n",
      "Training loss: 3.73e-02 lr: 2.27e-05:  55%|▌| 7551/13852 [28:15<23:17,  4.51it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 2.27e-05:  55%|▌| 7552/13852 [28:16<23:17,  4.51it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 2.27e-05:  55%|▌| 7553/13852 [28:16<23:18,  4.50it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 2.27e-05:  55%|▌| 7554/13852 [28:16<23:18,  4.50it/s\u001b[A\n",
      "Training loss: 3.46e-02 lr: 2.27e-05:  55%|▌| 7555/13852 [28:16<23:19,  4.50it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 2.27e-05:  55%|▌| 7556/13852 [28:17<23:18,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.59e-02 lr: 2.27e-05:  55%|▌| 7557/13852 [28:17<23:28,  4.47it/s\u001b[A\n",
      "Training loss: 1.60e-01 lr: 2.27e-05:  55%|▌| 7558/13852 [28:17<23:21,  4.49it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 2.27e-05:  55%|▌| 7559/13852 [28:17<23:10,  4.53it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 2.27e-05:  55%|▌| 7560/13852 [28:17<23:02,  4.55it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 2.27e-05:  55%|▌| 7561/13852 [28:18<23:17,  4.50it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 2.27e-05:  55%|▌| 7562/13852 [28:18<23:18,  4.50it/s\u001b[A\n",
      "Training loss: 4.16e-02 lr: 2.27e-05:  55%|▌| 7563/13852 [28:18<23:16,  4.50it/s\u001b[A\n",
      "Training loss: 3.13e-02 lr: 2.27e-05:  55%|▌| 7564/13852 [28:18<23:16,  4.50it/s\u001b[A\n",
      "Training loss: 2.37e-02 lr: 2.27e-05:  55%|▌| 7565/13852 [28:19<23:17,  4.50it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 2.27e-05:  55%|▌| 7566/13852 [28:19<23:19,  4.49it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 2.27e-05:  55%|▌| 7567/13852 [28:19<23:20,  4.49it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 2.27e-05:  55%|▌| 7568/13852 [28:19<23:20,  4.49it/s\u001b[A\n",
      "Training loss: 2.96e-02 lr: 2.27e-05:  55%|▌| 7569/13852 [28:19<23:19,  4.49it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 2.27e-05:  55%|▌| 7570/13852 [28:20<23:15,  4.50it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 2.27e-05:  55%|▌| 7571/13852 [28:20<23:06,  4.53it/s\u001b[A\n",
      "Training loss: 4.57e-02 lr: 2.27e-05:  55%|▌| 7572/13852 [28:20<23:01,  4.55it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 2.27e-05:  55%|▌| 7573/13852 [28:20<22:56,  4.56it/s\u001b[A\n",
      "Training loss: 2.94e-02 lr: 2.27e-05:  55%|▌| 7574/13852 [28:21<23:02,  4.54it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 2.27e-05:  55%|▌| 7575/13852 [28:21<23:12,  4.51it/s\u001b[A\n",
      "Training loss: 4.38e-02 lr: 2.27e-05:  55%|▌| 7576/13852 [28:21<23:15,  4.50it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 2.27e-05:  55%|▌| 7577/13852 [28:21<23:17,  4.49it/s\u001b[A\n",
      "Training loss: 9.71e-02 lr: 2.26e-05:  55%|▌| 7578/13852 [28:21<23:17,  4.49it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 2.26e-05:  55%|▌| 7579/13852 [28:22<23:18,  4.49it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 2.26e-05:  55%|▌| 7580/13852 [28:22<23:18,  4.48it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 2.26e-05:  55%|▌| 7581/13852 [28:22<23:31,  4.44it/s\u001b[A\n",
      "Training loss: 9.20e-02 lr: 2.26e-05:  55%|▌| 7582/13852 [28:22<23:20,  4.48it/s\u001b[A\n",
      "Training loss: 7.98e-02 lr: 2.26e-05:  55%|▌| 7583/13852 [28:23<23:08,  4.51it/s\u001b[A\n",
      "Training loss: 8.93e-02 lr: 2.26e-05:  55%|▌| 7584/13852 [28:23<23:04,  4.53it/s\u001b[A\n",
      "Training loss: 6.93e-02 lr: 2.26e-05:  55%|▌| 7585/13852 [28:23<24:31,  4.26it/s\u001b[A\n",
      "Training loss: 5.32e-02 lr: 2.26e-05:  55%|▌| 7586/13852 [28:23<24:39,  4.23it/s\u001b[A\n",
      "Training loss: 3.86e-02 lr: 2.26e-05:  55%|▌| 7587/13852 [28:24<24:47,  4.21it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 2.26e-05:  55%|▌| 7588/13852 [28:24<24:52,  4.20it/s\u001b[A\n",
      "Training loss: 6.25e-02 lr: 2.26e-05:  55%|▌| 7589/13852 [28:24<24:52,  4.20it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 2.26e-05:  55%|▌| 7590/13852 [28:24<25:00,  4.17it/s\u001b[A\n",
      "Training loss: 3.73e-02 lr: 2.26e-05:  55%|▌| 7591/13852 [28:25<25:13,  4.14it/s\u001b[A\n",
      "Training loss: 7.21e-02 lr: 2.26e-05:  55%|▌| 7592/13852 [28:25<25:31,  4.09it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 2.26e-05:  55%|▌| 7593/13852 [28:25<25:22,  4.11it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 2.26e-05:  55%|▌| 7594/13852 [28:25<24:45,  4.21it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 2.26e-05:  55%|▌| 7595/13852 [28:25<24:20,  4.28it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 2.26e-05:  55%|▌| 7596/13852 [28:26<24:10,  4.31it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 2.26e-05:  55%|▌| 7597/13852 [28:26<23:54,  4.36it/s\u001b[A\n",
      "Training loss: 6.52e-02 lr: 2.26e-05:  55%|▌| 7598/13852 [28:26<23:45,  4.39it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 2.26e-05:  55%|▌| 7599/13852 [28:26<23:41,  4.40it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 2.26e-05:  55%|▌| 7600/13852 [28:27<24:16,  4.29it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 2.26e-05:  55%|▌| 7601/13852 [28:27<24:33,  4.24it/s\u001b[A\n",
      "Training loss: 4.99e-02 lr: 2.26e-05:  55%|▌| 7602/13852 [28:27<24:05,  4.32it/s\u001b[A\n",
      "Training loss: 5.40e-02 lr: 2.26e-05:  55%|▌| 7603/13852 [28:27<23:45,  4.38it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 2.26e-05:  55%|▌| 7604/13852 [28:27<23:25,  4.45it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 2.26e-05:  55%|▌| 7605/13852 [28:28<23:28,  4.43it/s\u001b[A\n",
      "Training loss: 6.12e-02 lr: 2.25e-05:  55%|▌| 7606/13852 [28:28<23:25,  4.44it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 2.25e-05:  55%|▌| 7607/13852 [28:28<23:22,  4.45it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 2.25e-05:  55%|▌| 7608/13852 [28:28<23:19,  4.46it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 2.25e-05:  55%|▌| 7609/13852 [28:29<23:17,  4.47it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 2.25e-05:  55%|▌| 7610/13852 [28:29<23:15,  4.47it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 2.25e-05:  55%|▌| 7611/13852 [28:29<23:13,  4.48it/s\u001b[A\n",
      "Training loss: 2.60e-02 lr: 2.25e-05:  55%|▌| 7612/13852 [28:29<23:13,  4.48it/s\u001b[A\n",
      "Training loss: 2.11e-02 lr: 2.25e-05:  55%|▌| 7613/13852 [28:30<23:16,  4.47it/s\u001b[A\n",
      "Training loss: 2.42e-02 lr: 2.25e-05:  55%|▌| 7614/13852 [28:30<23:09,  4.49it/s\u001b[A\n",
      "Training loss: 1.86e-02 lr: 2.25e-05:  55%|▌| 7615/13852 [28:30<22:58,  4.53it/s\u001b[A\n",
      "Training loss: 2.91e-02 lr: 2.25e-05:  55%|▌| 7616/13852 [28:30<22:59,  4.52it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 2.25e-05:  55%|▌| 7617/13852 [28:30<23:05,  4.50it/s\u001b[A\n",
      "Training loss: 3.80e-02 lr: 2.25e-05:  55%|▌| 7618/13852 [28:31<23:05,  4.50it/s\u001b[A\n",
      "Training loss: 2.95e-02 lr: 2.25e-05:  55%|▌| 7619/13852 [28:31<23:14,  4.47it/s\u001b[A\n",
      "Training loss: 2.82e-02 lr: 2.25e-05:  55%|▌| 7620/13852 [28:31<23:16,  4.46it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 2.25e-05:  55%|▌| 7621/13852 [28:31<23:14,  4.47it/s\u001b[A\n",
      "Training loss: 8.31e-02 lr: 2.25e-05:  55%|▌| 7622/13852 [28:32<23:12,  4.47it/s\u001b[A\n",
      "Training loss: 7.13e-02 lr: 2.25e-05:  55%|▌| 7623/13852 [28:32<23:19,  4.45it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 2.25e-05:  55%|▌| 7624/13852 [28:32<23:14,  4.47it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 2.25e-05:  55%|▌| 7625/13852 [28:32<23:16,  4.46it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 2.25e-05:  55%|▌| 7626/13852 [28:32<23:04,  4.50it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 2.25e-05:  55%|▌| 7627/13852 [28:33<22:55,  4.53it/s\u001b[A\n",
      "Training loss: 2.71e-02 lr: 2.25e-05:  55%|▌| 7628/13852 [28:33<23:00,  4.51it/s\u001b[A\n",
      "Training loss: 1.98e-02 lr: 2.25e-05:  55%|▌| 7629/13852 [28:33<23:05,  4.49it/s\u001b[A\n",
      "Training loss: 1.56e-02 lr: 2.25e-05:  55%|▌| 7630/13852 [28:33<23:12,  4.47it/s\u001b[A\n",
      "Training loss: 2.75e-02 lr: 2.25e-05:  55%|▌| 7631/13852 [28:34<23:08,  4.48it/s\u001b[A\n",
      "Training loss: 6.75e-02 lr: 2.25e-05:  55%|▌| 7632/13852 [28:34<23:06,  4.49it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 2.24e-05:  55%|▌| 7633/13852 [28:34<23:04,  4.49it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 2.24e-05:  55%|▌| 7634/13852 [28:34<23:05,  4.49it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 2.24e-05:  55%|▌| 7635/13852 [28:34<23:05,  4.49it/s\u001b[A\n",
      "Training loss: 6.34e-02 lr: 2.24e-05:  55%|▌| 7636/13852 [28:35<23:03,  4.49it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 2.24e-05:  55%|▌| 7637/13852 [28:35<22:56,  4.51it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 2.24e-05:  55%|▌| 7638/13852 [28:35<22:54,  4.52it/s\u001b[A\n",
      "Training loss: 3.31e-02 lr: 2.24e-05:  55%|▌| 7639/13852 [28:35<23:01,  4.50it/s\u001b[A\n",
      "Training loss: 2.44e-02 lr: 2.24e-05:  55%|▌| 7640/13852 [28:36<23:00,  4.50it/s\u001b[A\n",
      "Training loss: 2.89e-02 lr: 2.24e-05:  55%|▌| 7641/13852 [28:36<23:01,  4.50it/s\u001b[A\n",
      "Training loss: 2.12e-02 lr: 2.24e-05:  55%|▌| 7642/13852 [28:36<23:00,  4.50it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 2.24e-05:  55%|▌| 7643/13852 [28:36<23:00,  4.50it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 2.24e-05:  55%|▌| 7644/13852 [28:36<23:00,  4.50it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 2.24e-05:  55%|▌| 7645/13852 [28:37<23:06,  4.48it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 2.24e-05:  55%|▌| 7646/13852 [28:37<23:20,  4.43it/s\u001b[A\n",
      "Training loss: 8.14e-02 lr: 2.24e-05:  55%|▌| 7647/13852 [28:37<23:19,  4.44it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 2.24e-05:  55%|▌| 7648/13852 [28:37<23:13,  4.45it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 2.24e-05:  55%|▌| 7649/13852 [28:38<23:11,  4.46it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 2.24e-05:  55%|▌| 7650/13852 [28:38<23:07,  4.47it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 2.24e-05:  55%|▌| 7651/13852 [28:38<23:02,  4.48it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 2.24e-05:  55%|▌| 7652/13852 [28:38<23:02,  4.49it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 2.24e-05:  55%|▌| 7653/13852 [28:38<22:58,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.73e-02 lr: 2.24e-05:  55%|▌| 7654/13852 [28:39<23:03,  4.48it/s\u001b[A\n",
      "Training loss: 6.52e-02 lr: 2.24e-05:  55%|▌| 7655/13852 [28:39<23:01,  4.49it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 2.24e-05:  55%|▌| 7656/13852 [28:39<22:59,  4.49it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 2.24e-05:  55%|▌| 7657/13852 [28:39<23:00,  4.49it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 2.24e-05:  55%|▌| 7658/13852 [28:40<22:59,  4.49it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 2.24e-05:  55%|▌| 7659/13852 [28:40<22:55,  4.50it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 2.24e-05:  55%|▌| 7660/13852 [28:40<22:47,  4.53it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 2.23e-05:  55%|▌| 7661/13852 [28:40<22:42,  4.54it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 2.23e-05:  55%|▌| 7662/13852 [28:40<22:51,  4.51it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.23e-05:  55%|▌| 7663/13852 [28:41<22:51,  4.51it/s\u001b[A\n",
      "Training loss: 3.65e-02 lr: 2.23e-05:  55%|▌| 7664/13852 [28:41<23:03,  4.47it/s\u001b[A\n",
      "Training loss: 2.95e-02 lr: 2.23e-05:  55%|▌| 7665/13852 [28:41<23:01,  4.48it/s\u001b[A\n",
      "Training loss: 2.31e-02 lr: 2.23e-05:  55%|▌| 7666/13852 [28:41<23:02,  4.47it/s\u001b[A\n",
      "Training loss: 1.71e-02 lr: 2.23e-05:  55%|▌| 7667/13852 [28:42<23:00,  4.48it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 2.23e-05:  55%|▌| 7668/13852 [28:42<23:07,  4.46it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.23e-05:  55%|▌| 7669/13852 [28:42<23:05,  4.46it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 2.23e-05:  55%|▌| 7670/13852 [28:42<23:12,  4.44it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 2.23e-05:  55%|▌| 7671/13852 [28:42<23:07,  4.46it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.23e-05:  55%|▌| 7672/13852 [28:43<23:06,  4.46it/s\u001b[A\n",
      "Training loss: 8.86e-02 lr: 2.23e-05:  55%|▌| 7673/13852 [28:43<23:01,  4.47it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 2.23e-05:  55%|▌| 7674/13852 [28:43<22:57,  4.48it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 2.23e-05:  55%|▌| 7675/13852 [28:43<22:56,  4.49it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 2.23e-05:  55%|▌| 7676/13852 [28:44<22:54,  4.49it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 2.23e-05:  55%|▌| 7677/13852 [28:44<22:54,  4.49it/s\u001b[A\n",
      "Training loss: 3.46e-02 lr: 2.23e-05:  55%|▌| 7678/13852 [28:44<22:53,  4.49it/s\u001b[A\n",
      "Training loss: 3.19e-02 lr: 2.23e-05:  55%|▌| 7679/13852 [28:44<22:53,  4.50it/s\u001b[A\n",
      "Training loss: 2.61e-02 lr: 2.23e-05:  55%|▌| 7680/13852 [28:44<22:53,  4.50it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 2.23e-05:  55%|▌| 7681/13852 [28:45<22:49,  4.51it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 2.23e-05:  55%|▌| 7682/13852 [28:45<22:40,  4.54it/s\u001b[A\n",
      "Training loss: 7.47e-02 lr: 2.23e-05:  55%|▌| 7683/13852 [28:45<22:35,  4.55it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.23e-05:  55%|▌| 7684/13852 [28:45<22:49,  4.50it/s\u001b[A\n",
      "Training loss: 4.22e-02 lr: 2.23e-05:  55%|▌| 7685/13852 [28:46<22:46,  4.51it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 2.23e-05:  55%|▌| 7686/13852 [28:46<22:50,  4.50it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 2.23e-05:  55%|▌| 7687/13852 [28:46<22:48,  4.50it/s\u001b[A\n",
      "Training loss: 4.80e-02 lr: 2.23e-05:  56%|▌| 7688/13852 [28:46<22:47,  4.51it/s\u001b[A\n",
      "Training loss: 6.75e-02 lr: 2.22e-05:  56%|▌| 7689/13852 [28:46<22:48,  4.50it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 2.22e-05:  56%|▌| 7690/13852 [28:47<22:53,  4.49it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 2.22e-05:  56%|▌| 7691/13852 [28:47<23:00,  4.46it/s\u001b[A\n",
      "Training loss: 9.37e-02 lr: 2.22e-05:  56%|▌| 7692/13852 [28:47<22:57,  4.47it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 2.22e-05:  56%|▌| 7693/13852 [28:47<22:56,  4.47it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 2.22e-05:  56%|▌| 7694/13852 [28:48<22:48,  4.50it/s\u001b[A\n",
      "Training loss: 8.93e-02 lr: 2.22e-05:  56%|▌| 7695/13852 [28:48<22:40,  4.53it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 2.22e-05:  56%|▌| 7696/13852 [28:48<22:57,  4.47it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 2.22e-05:  56%|▌| 7697/13852 [28:48<22:54,  4.48it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 2.22e-05:  56%|▌| 7698/13852 [28:48<22:52,  4.48it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.22e-05:  56%|▌| 7699/13852 [28:49<22:48,  4.50it/s\u001b[A\n",
      "Training loss: 8.10e-02 lr: 2.22e-05:  56%|▌| 7700/13852 [28:49<22:50,  4.49it/s\u001b[A\n",
      "Training loss: 9.74e-02 lr: 2.22e-05:  56%|▌| 7701/13852 [28:49<22:51,  4.49it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 2.22e-05:  56%|▌| 7702/13852 [28:49<22:52,  4.48it/s\u001b[A\n",
      "Training loss: 7.24e-02 lr: 2.22e-05:  56%|▌| 7703/13852 [28:50<22:50,  4.49it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 2.22e-05:  56%|▌| 7704/13852 [28:50<22:50,  4.49it/s\u001b[A\n",
      "Training loss: 4.78e-02 lr: 2.22e-05:  56%|▌| 7705/13852 [28:50<22:43,  4.51it/s\u001b[A\n",
      "Training loss: 9.51e-02 lr: 2.22e-05:  56%|▌| 7706/13852 [28:50<22:36,  4.53it/s\u001b[A\n",
      "Training loss: 7.80e-02 lr: 2.22e-05:  56%|▌| 7707/13852 [28:50<22:32,  4.54it/s\u001b[A\n",
      "Training loss: 8.22e-02 lr: 2.22e-05:  56%|▌| 7708/13852 [28:51<22:39,  4.52it/s\u001b[A\n",
      "Training loss: 7.37e-02 lr: 2.22e-05:  56%|▌| 7709/13852 [28:51<22:46,  4.49it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 2.22e-05:  56%|▌| 7710/13852 [28:51<22:49,  4.48it/s\u001b[A\n",
      "Training loss: 4.29e-02 lr: 2.22e-05:  56%|▌| 7711/13852 [28:51<22:48,  4.49it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 2.22e-05:  56%|▌| 7712/13852 [28:52<22:49,  4.48it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 2.22e-05:  56%|▌| 7713/13852 [28:52<22:56,  4.46it/s\u001b[A\n",
      "Training loss: 3.30e-02 lr: 2.22e-05:  56%|▌| 7714/13852 [28:52<22:52,  4.47it/s\u001b[A\n",
      "Training loss: 3.69e-02 lr: 2.22e-05:  56%|▌| 7715/13852 [28:52<22:51,  4.48it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 2.22e-05:  56%|▌| 7716/13852 [28:52<22:44,  4.50it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 2.21e-05:  56%|▌| 7717/13852 [28:53<22:35,  4.53it/s\u001b[A\n",
      "Training loss: 3.31e-02 lr: 2.21e-05:  56%|▌| 7718/13852 [28:53<22:31,  4.54it/s\u001b[A\n",
      "Training loss: 2.54e-02 lr: 2.21e-05:  56%|▌| 7719/13852 [28:53<22:45,  4.49it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 2.21e-05:  56%|▌| 7720/13852 [28:53<22:44,  4.49it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 2.21e-05:  56%|▌| 7721/13852 [28:54<22:40,  4.51it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 2.21e-05:  56%|▌| 7722/13852 [28:54<22:40,  4.51it/s\u001b[A\n",
      "Training loss: 3.52e-02 lr: 2.21e-05:  56%|▌| 7723/13852 [28:54<22:40,  4.50it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 2.21e-05:  56%|▌| 7724/13852 [28:54<22:43,  4.49it/s\u001b[A\n",
      "Training loss: 2.31e-02 lr: 2.21e-05:  56%|▌| 7725/13852 [28:54<22:42,  4.50it/s\u001b[A\n",
      "Training loss: 2.32e-02 lr: 2.21e-05:  56%|▌| 7726/13852 [28:55<22:42,  4.50it/s\u001b[A\n",
      "Training loss: 2.09e-02 lr: 2.21e-05:  56%|▌| 7727/13852 [28:55<22:42,  4.50it/s\u001b[A\n",
      "Training loss: 2.55e-02 lr: 2.21e-05:  56%|▌| 7728/13852 [28:55<22:38,  4.51it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 2.21e-05:  56%|▌| 7729/13852 [28:55<22:31,  4.53it/s\u001b[A\n",
      "Training loss: 8.82e-02 lr: 2.21e-05:  56%|▌| 7730/13852 [28:56<22:26,  4.55it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 2.21e-05:  56%|▌| 7731/13852 [28:56<22:20,  4.57it/s\u001b[A\n",
      "Training loss: 8.59e-02 lr: 2.21e-05:  56%|▌| 7732/13852 [28:56<22:27,  4.54it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 2.21e-05:  56%|▌| 7733/13852 [28:56<22:30,  4.53it/s\u001b[A\n",
      "Training loss: 8.77e-02 lr: 2.21e-05:  56%|▌| 7734/13852 [28:56<22:32,  4.52it/s\u001b[A\n",
      "Training loss: 7.66e-02 lr: 2.21e-05:  56%|▌| 7735/13852 [28:57<22:40,  4.50it/s\u001b[A\n",
      "Training loss: 7.95e-02 lr: 2.21e-05:  56%|▌| 7736/13852 [28:57<22:44,  4.48it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 2.21e-05:  56%|▌| 7737/13852 [28:57<22:46,  4.47it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 2.21e-05:  56%|▌| 7738/13852 [28:57<22:46,  4.47it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 2.21e-05:  56%|▌| 7739/13852 [28:58<22:52,  4.46it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.21e-05:  56%|▌| 7740/13852 [28:58<22:48,  4.47it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 2.21e-05:  56%|▌| 7741/13852 [28:58<22:39,  4.49it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.21e-05:  56%|▌| 7742/13852 [28:58<22:32,  4.52it/s\u001b[A\n",
      "Training loss: 8.27e-02 lr: 2.21e-05:  56%|▌| 7743/13852 [28:58<22:37,  4.50it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 2.20e-05:  56%|▌| 7744/13852 [28:59<22:36,  4.50it/s\u001b[A\n",
      "Training loss: 8.31e-02 lr: 2.20e-05:  56%|▌| 7745/13852 [28:59<22:35,  4.50it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 2.20e-05:  56%|▌| 7746/13852 [28:59<22:36,  4.50it/s\u001b[A\n",
      "Training loss: 7.88e-02 lr: 2.20e-05:  56%|▌| 7747/13852 [28:59<22:37,  4.50it/s\u001b[A\n",
      "Training loss: 8.64e-02 lr: 2.20e-05:  56%|▌| 7748/13852 [29:00<22:37,  4.50it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 2.20e-05:  56%|▌| 7749/13852 [29:00<22:37,  4.50it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 2.20e-05:  56%|▌| 7750/13852 [29:00<22:39,  4.49it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.61e-02 lr: 2.20e-05:  56%|▌| 7751/13852 [29:00<22:40,  4.49it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 2.20e-05:  56%|▌| 7752/13852 [29:00<22:37,  4.49it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 2.20e-05:  56%|▌| 7753/13852 [29:01<22:36,  4.50it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 2.20e-05:  56%|▌| 7754/13852 [29:01<22:50,  4.45it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 2.20e-05:  56%|▌| 7755/13852 [29:01<22:44,  4.47it/s\u001b[A\n",
      "Training loss: 7.84e-02 lr: 2.20e-05:  56%|▌| 7756/13852 [29:01<22:40,  4.48it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 2.20e-05:  56%|▌| 7757/13852 [29:02<22:38,  4.49it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 2.20e-05:  56%|▌| 7758/13852 [29:02<22:45,  4.46it/s\u001b[A\n",
      "Training loss: 5.68e-02 lr: 2.20e-05:  56%|▌| 7759/13852 [29:02<22:43,  4.47it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 2.20e-05:  56%|▌| 7760/13852 [29:02<22:41,  4.47it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 2.20e-05:  56%|▌| 7761/13852 [29:02<22:47,  4.45it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 2.20e-05:  56%|▌| 7762/13852 [29:03<22:42,  4.47it/s\u001b[A\n",
      "Training loss: 7.08e-02 lr: 2.20e-05:  56%|▌| 7763/13852 [29:03<22:32,  4.50it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 2.20e-05:  56%|▌| 7764/13852 [29:03<22:26,  4.52it/s\u001b[A\n",
      "Training loss: 8.93e-02 lr: 2.20e-05:  56%|▌| 7765/13852 [29:03<22:41,  4.47it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.20e-05:  56%|▌| 7766/13852 [29:04<22:36,  4.49it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 2.20e-05:  56%|▌| 7767/13852 [29:04<22:31,  4.50it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 2.20e-05:  56%|▌| 7768/13852 [29:04<22:30,  4.50it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.20e-05:  56%|▌| 7769/13852 [29:04<22:31,  4.50it/s\u001b[A\n",
      "Training loss: 3.70e-02 lr: 2.20e-05:  56%|▌| 7770/13852 [29:04<22:31,  4.50it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 2.20e-05:  56%|▌| 7771/13852 [29:05<22:35,  4.49it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 2.19e-05:  56%|▌| 7772/13852 [29:05<22:34,  4.49it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 2.19e-05:  56%|▌| 7773/13852 [29:05<22:34,  4.49it/s\u001b[A\n",
      "Training loss: 3.01e-02 lr: 2.19e-05:  56%|▌| 7774/13852 [29:05<22:28,  4.51it/s\u001b[A\n",
      "Training loss: 2.27e-02 lr: 2.19e-05:  56%|▌| 7775/13852 [29:06<22:19,  4.54it/s\u001b[A\n",
      "Training loss: 2.74e-02 lr: 2.19e-05:  56%|▌| 7776/13852 [29:06<22:13,  4.56it/s\u001b[A\n",
      "Training loss: 2.27e-02 lr: 2.19e-05:  56%|▌| 7777/13852 [29:06<22:08,  4.57it/s\u001b[A\n",
      "Training loss: 2.35e-02 lr: 2.19e-05:  56%|▌| 7778/13852 [29:06<22:19,  4.53it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 2.19e-05:  56%|▌| 7779/13852 [29:06<22:19,  4.53it/s\u001b[A\n",
      "Training loss: 3.49e-02 lr: 2.19e-05:  56%|▌| 7780/13852 [29:07<22:28,  4.50it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 2.19e-05:  56%|▌| 7781/13852 [29:07<22:36,  4.48it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 2.19e-05:  56%|▌| 7782/13852 [29:07<22:40,  4.46it/s\u001b[A\n",
      "Training loss: 2.74e-02 lr: 2.19e-05:  56%|▌| 7783/13852 [29:07<22:46,  4.44it/s\u001b[A\n",
      "Training loss: 2.59e-02 lr: 2.19e-05:  56%|▌| 7784/13852 [29:08<22:43,  4.45it/s\u001b[A\n",
      "Training loss: 3.34e-02 lr: 2.19e-05:  56%|▌| 7785/13852 [29:08<22:40,  4.46it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 2.19e-05:  56%|▌| 7786/13852 [29:08<22:32,  4.48it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 2.19e-05:  56%|▌| 7787/13852 [29:08<22:24,  4.51it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 2.19e-05:  56%|▌| 7788/13852 [29:08<22:18,  4.53it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 2.19e-05:  56%|▌| 7789/13852 [29:09<22:28,  4.50it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 2.19e-05:  56%|▌| 7790/13852 [29:09<22:25,  4.51it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 2.19e-05:  56%|▌| 7791/13852 [29:09<22:26,  4.50it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 2.19e-05:  56%|▌| 7792/13852 [29:09<22:24,  4.51it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 2.19e-05:  56%|▌| 7793/13852 [29:10<22:25,  4.50it/s\u001b[A\n",
      "Training loss: 7.82e-02 lr: 2.19e-05:  56%|▌| 7794/13852 [29:10<22:25,  4.50it/s\u001b[A\n",
      "Training loss: 7.57e-02 lr: 2.19e-05:  56%|▌| 7795/13852 [29:10<22:24,  4.51it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 2.19e-05:  56%|▌| 7796/13852 [29:10<22:25,  4.50it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 2.19e-05:  56%|▌| 7797/13852 [29:10<22:29,  4.49it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 2.19e-05:  56%|▌| 7798/13852 [29:11<22:23,  4.51it/s\u001b[A\n",
      "Training loss: 8.46e-02 lr: 2.19e-05:  56%|▌| 7799/13852 [29:11<22:21,  4.51it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 2.18e-05:  56%|▌| 7800/13852 [29:11<22:17,  4.52it/s\u001b[A\n",
      "Training loss: 7.05e-02 lr: 2.18e-05:  56%|▌| 7801/13852 [29:11<22:25,  4.50it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 2.18e-05:  56%|▌| 7802/13852 [29:12<22:26,  4.49it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 2.18e-05:  56%|▌| 7803/13852 [29:12<22:33,  4.47it/s\u001b[A\n",
      "Training loss: 3.69e-02 lr: 2.18e-05:  56%|▌| 7804/13852 [29:12<22:29,  4.48it/s\u001b[A\n",
      "Training loss: 2.67e-02 lr: 2.18e-05:  56%|▌| 7805/13852 [29:12<22:29,  4.48it/s\u001b[A\n",
      "Training loss: 1.90e-02 lr: 2.18e-05:  56%|▌| 7806/13852 [29:12<22:36,  4.46it/s\u001b[A\n",
      "Training loss: 2.24e-02 lr: 2.18e-05:  56%|▌| 7807/13852 [29:13<22:33,  4.47it/s\u001b[A\n",
      "Training loss: 1.75e-02 lr: 2.18e-05:  56%|▌| 7808/13852 [29:13<22:36,  4.46it/s\u001b[A\n",
      "Training loss: 2.48e-02 lr: 2.18e-05:  56%|▌| 7809/13852 [29:13<22:57,  4.39it/s\u001b[A\n",
      "Training loss: 2.22e-02 lr: 2.18e-05:  56%|▌| 7810/13852 [29:13<23:34,  4.27it/s\u001b[A\n",
      "Training loss: 1.71e-02 lr: 2.18e-05:  56%|▌| 7811/13852 [29:14<23:57,  4.20it/s\u001b[A\n",
      "Training loss: 1.25e-02 lr: 2.18e-05:  56%|▌| 7812/13852 [29:14<23:57,  4.20it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 2.18e-05:  56%|▌| 7813/13852 [29:14<23:37,  4.26it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 2.18e-05:  56%|▌| 7814/13852 [29:14<23:21,  4.31it/s\u001b[A\n",
      "Training loss: 3.13e-02 lr: 2.18e-05:  56%|▌| 7815/13852 [29:15<23:08,  4.35it/s\u001b[A\n",
      "Training loss: 8.96e-02 lr: 2.18e-05:  56%|▌| 7816/13852 [29:15<22:54,  4.39it/s\u001b[A\n",
      "Training loss: 9.36e-02 lr: 2.18e-05:  56%|▌| 7817/13852 [29:15<22:49,  4.41it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 2.18e-05:  56%|▌| 7818/13852 [29:15<23:16,  4.32it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 2.18e-05:  56%|▌| 7819/13852 [29:15<22:59,  4.37it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 2.18e-05:  56%|▌| 7820/13852 [29:16<22:47,  4.41it/s\u001b[A\n",
      "Training loss: 3.73e-02 lr: 2.18e-05:  56%|▌| 7821/13852 [29:16<22:41,  4.43it/s\u001b[A\n",
      "Training loss: 3.91e-02 lr: 2.18e-05:  56%|▌| 7822/13852 [29:16<22:40,  4.43it/s\u001b[A\n",
      "Training loss: 3.80e-02 lr: 2.18e-05:  56%|▌| 7823/13852 [29:16<22:34,  4.45it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 2.18e-05:  56%|▌| 7824/13852 [29:17<22:32,  4.46it/s\u001b[A\n",
      "Training loss: 3.56e-02 lr: 2.18e-05:  56%|▌| 7825/13852 [29:17<22:37,  4.44it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 2.18e-05:  56%|▌| 7826/13852 [29:17<22:30,  4.46it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 2.17e-05:  57%|▌| 7827/13852 [29:17<22:17,  4.50it/s\u001b[A\n",
      "Training loss: 3.33e-02 lr: 2.17e-05:  57%|▌| 7828/13852 [29:17<22:26,  4.47it/s\u001b[A\n",
      "Training loss: 3.90e-02 lr: 2.17e-05:  57%|▌| 7829/13852 [29:18<22:27,  4.47it/s\u001b[A\n",
      "Training loss: 3.70e-02 lr: 2.17e-05:  57%|▌| 7830/13852 [29:18<22:21,  4.49it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 2.17e-05:  57%|▌| 7831/13852 [29:18<22:21,  4.49it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 2.17e-05:  57%|▌| 7832/13852 [29:18<22:21,  4.49it/s\u001b[A\n",
      "Training loss: 8.24e-02 lr: 2.17e-05:  57%|▌| 7833/13852 [29:19<22:25,  4.47it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 2.17e-05:  57%|▌| 7834/13852 [29:19<22:24,  4.48it/s\u001b[A\n",
      "Training loss: 4.70e-02 lr: 2.17e-05:  57%|▌| 7835/13852 [29:19<22:21,  4.49it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 2.17e-05:  57%|▌| 7836/13852 [29:19<22:22,  4.48it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 2.17e-05:  57%|▌| 7837/13852 [29:19<22:16,  4.50it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 2.17e-05:  57%|▌| 7838/13852 [29:20<22:09,  4.52it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 2.17e-05:  57%|▌| 7839/13852 [29:20<22:03,  4.54it/s\u001b[A\n",
      "Training loss: 2.36e-02 lr: 2.17e-05:  57%|▌| 7840/13852 [29:20<22:10,  4.52it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 2.17e-05:  57%|▌| 7841/13852 [29:20<22:10,  4.52it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 2.17e-05:  57%|▌| 7842/13852 [29:21<22:08,  4.52it/s\u001b[A\n",
      "Training loss: 4.95e-02 lr: 2.17e-05:  57%|▌| 7843/13852 [29:21<22:12,  4.51it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 2.17e-05:  57%|▌| 7844/13852 [29:21<22:14,  4.50it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.17e-05:  57%|▌| 7845/13852 [29:21<22:18,  4.49it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 2.17e-05:  57%|▌| 7846/13852 [29:21<22:16,  4.49it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 2.17e-05:  57%|▌| 7847/13852 [29:22<22:23,  4.47it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.24e-01 lr: 2.17e-05:  57%|▌| 7848/13852 [29:22<22:23,  4.47it/s\u001b[A\n",
      "Training loss: 9.39e-02 lr: 2.17e-05:  57%|▌| 7849/13852 [29:22<22:19,  4.48it/s\u001b[A\n",
      "Training loss: 7.72e-02 lr: 2.17e-05:  57%|▌| 7850/13852 [29:22<22:11,  4.51it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 2.17e-05:  57%|▌| 7851/13852 [29:23<22:23,  4.47it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 2.17e-05:  57%|▌| 7852/13852 [29:23<22:20,  4.48it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 2.17e-05:  57%|▌| 7853/13852 [29:23<22:19,  4.48it/s\u001b[A\n",
      "Training loss: 2.63e-02 lr: 2.17e-05:  57%|▌| 7854/13852 [29:23<22:15,  4.49it/s\u001b[A\n",
      "Training loss: 2.39e-02 lr: 2.16e-05:  57%|▌| 7855/13852 [29:23<22:13,  4.50it/s\u001b[A\n",
      "Training loss: 2.43e-02 lr: 2.16e-05:  57%|▌| 7856/13852 [29:24<22:14,  4.49it/s\u001b[A\n",
      "Training loss: 2.26e-02 lr: 2.16e-05:  57%|▌| 7857/13852 [29:24<22:13,  4.50it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 2.16e-05:  57%|▌| 7858/13852 [29:24<22:11,  4.50it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 2.16e-05:  57%|▌| 7859/13852 [29:24<22:11,  4.50it/s\u001b[A\n",
      "Training loss: 9.29e-02 lr: 2.16e-05:  57%|▌| 7860/13852 [29:25<22:05,  4.52it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 2.16e-05:  57%|▌| 7861/13852 [29:25<22:03,  4.53it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 2.16e-05:  57%|▌| 7862/13852 [29:25<21:55,  4.55it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 2.16e-05:  57%|▌| 7863/13852 [29:25<22:12,  4.50it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 2.16e-05:  57%|▌| 7864/13852 [29:25<22:10,  4.50it/s\u001b[A\n",
      "Training loss: 1.37e-01 lr: 2.16e-05:  57%|▌| 7865/13852 [29:26<22:08,  4.51it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.16e-05:  57%|▌| 7866/13852 [29:26<22:08,  4.50it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 2.16e-05:  57%|▌| 7867/13852 [29:26<22:10,  4.50it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 2.16e-05:  57%|▌| 7868/13852 [29:26<22:09,  4.50it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 2.16e-05:  57%|▌| 7869/13852 [29:27<22:12,  4.49it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 2.16e-05:  57%|▌| 7870/13852 [29:27<22:20,  4.46it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 2.16e-05:  57%|▌| 7871/13852 [29:27<22:18,  4.47it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 2.16e-05:  57%|▌| 7872/13852 [29:27<22:12,  4.49it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 2.16e-05:  57%|▌| 7873/13852 [29:27<22:04,  4.51it/s\u001b[A\n",
      "Training loss: 7.28e-02 lr: 2.16e-05:  57%|▌| 7874/13852 [29:28<21:59,  4.53it/s\u001b[A\n",
      "Training loss: 7.30e-02 lr: 2.16e-05:  57%|▌| 7875/13852 [29:28<22:04,  4.51it/s\u001b[A\n",
      "Training loss: 8.64e-02 lr: 2.16e-05:  57%|▌| 7876/13852 [29:28<22:04,  4.51it/s\u001b[A\n",
      "Training loss: 8.02e-02 lr: 2.16e-05:  57%|▌| 7877/13852 [29:28<22:09,  4.50it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 2.16e-05:  57%|▌| 7878/13852 [29:29<22:10,  4.49it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 2.16e-05:  57%|▌| 7879/13852 [29:29<22:12,  4.48it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 2.16e-05:  57%|▌| 7880/13852 [29:29<22:09,  4.49it/s\u001b[A\n",
      "Training loss: 9.73e-02 lr: 2.16e-05:  57%|▌| 7881/13852 [29:29<22:09,  4.49it/s\u001b[A\n",
      "Training loss: 9.92e-02 lr: 2.16e-05:  57%|▌| 7882/13852 [29:29<22:08,  4.50it/s\u001b[A\n",
      "Training loss: 9.12e-02 lr: 2.15e-05:  57%|▌| 7883/13852 [29:30<22:08,  4.49it/s\u001b[A\n",
      "Training loss: 7.20e-02 lr: 2.15e-05:  57%|▌| 7884/13852 [29:30<22:08,  4.49it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 2.15e-05:  57%|▌| 7885/13852 [29:30<22:03,  4.51it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 2.15e-05:  57%|▌| 7886/13852 [29:30<22:00,  4.52it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 2.15e-05:  57%|▌| 7887/13852 [29:31<22:00,  4.52it/s\u001b[A\n",
      "Training loss: 4.70e-02 lr: 2.15e-05:  57%|▌| 7888/13852 [29:31<22:08,  4.49it/s\u001b[A\n",
      "Training loss: 3.65e-02 lr: 2.15e-05:  57%|▌| 7889/13852 [29:31<22:10,  4.48it/s\u001b[A\n",
      "Training loss: 3.31e-02 lr: 2.15e-05:  57%|▌| 7890/13852 [29:31<22:08,  4.49it/s\u001b[A\n",
      "Training loss: 6.05e-02 lr: 2.15e-05:  57%|▌| 7891/13852 [29:31<22:07,  4.49it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 2.15e-05:  57%|▌| 7892/13852 [29:32<22:08,  4.49it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 2.15e-05:  57%|▌| 7893/13852 [29:32<22:08,  4.49it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 2.15e-05:  57%|▌| 7894/13852 [29:32<22:07,  4.49it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 2.15e-05:  57%|▌| 7895/13852 [29:32<22:00,  4.51it/s\u001b[A\n",
      "Training loss: 3.94e-02 lr: 2.15e-05:  57%|▌| 7896/13852 [29:33<22:00,  4.51it/s\u001b[A\n",
      "Training loss: 2.87e-02 lr: 2.15e-05:  57%|▌| 7897/13852 [29:33<21:53,  4.53it/s\u001b[A\n",
      "Training loss: 2.14e-02 lr: 2.15e-05:  57%|▌| 7898/13852 [29:33<22:13,  4.47it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.15e-05:  57%|▌| 7899/13852 [29:33<22:09,  4.48it/s\u001b[A\n",
      "Training loss: 4.03e-02 lr: 2.15e-05:  57%|▌| 7900/13852 [29:33<22:04,  4.49it/s\u001b[A\n",
      "Training loss: 3.48e-02 lr: 2.15e-05:  57%|▌| 7901/13852 [29:34<22:02,  4.50it/s\u001b[A\n",
      "Training loss: 3.42e-02 lr: 2.15e-05:  57%|▌| 7902/13852 [29:34<22:05,  4.49it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 2.15e-05:  57%|▌| 7903/13852 [29:34<22:03,  4.50it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 2.15e-05:  57%|▌| 7904/13852 [29:34<22:03,  4.50it/s\u001b[A\n",
      "Training loss: 9.29e-02 lr: 2.15e-05:  57%|▌| 7905/13852 [29:35<22:01,  4.50it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 2.15e-05:  57%|▌| 7906/13852 [29:35<22:02,  4.50it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 2.15e-05:  57%|▌| 7907/13852 [29:35<21:55,  4.52it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 2.15e-05:  57%|▌| 7908/13852 [29:35<21:49,  4.54it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 2.15e-05:  57%|▌| 7909/13852 [29:35<21:43,  4.56it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 2.14e-05:  57%|▌| 7910/13852 [29:36<21:40,  4.57it/s\u001b[A\n",
      "Training loss: 7.05e-02 lr: 2.14e-05:  57%|▌| 7911/13852 [29:36<21:47,  4.54it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 2.14e-05:  57%|▌| 7912/13852 [29:36<21:49,  4.54it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 2.14e-05:  57%|▌| 7913/13852 [29:36<21:50,  4.53it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 2.14e-05:  57%|▌| 7914/13852 [29:37<21:51,  4.53it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 2.14e-05:  57%|▌| 7915/13852 [29:37<22:22,  4.42it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 2.14e-05:  57%|▌| 7916/13852 [29:37<22:54,  4.32it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.14e-05:  57%|▌| 7917/13852 [29:37<23:13,  4.26it/s\u001b[A\n",
      "Training loss: 8.80e-02 lr: 2.14e-05:  57%|▌| 7918/13852 [29:38<22:53,  4.32it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 2.14e-05:  57%|▌| 7919/13852 [29:38<22:29,  4.40it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 2.14e-05:  57%|▌| 7920/13852 [29:38<22:17,  4.43it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 2.14e-05:  57%|▌| 7921/13852 [29:38<22:09,  4.46it/s\u001b[A\n",
      "Training loss: 8.50e-02 lr: 2.14e-05:  57%|▌| 7922/13852 [29:38<22:04,  4.48it/s\u001b[A\n",
      "Training loss: 9.17e-02 lr: 2.14e-05:  57%|▌| 7923/13852 [29:39<22:01,  4.49it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 2.14e-05:  57%|▌| 7924/13852 [29:39<21:59,  4.49it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 2.14e-05:  57%|▌| 7925/13852 [29:39<21:58,  4.50it/s\u001b[A\n",
      "Training loss: 6.12e-02 lr: 2.14e-05:  57%|▌| 7926/13852 [29:39<21:57,  4.50it/s\u001b[A\n",
      "Training loss: 5.13e-02 lr: 2.14e-05:  57%|▌| 7927/13852 [29:40<22:04,  4.47it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.14e-05:  57%|▌| 7928/13852 [29:40<22:03,  4.47it/s\u001b[A\n",
      "Training loss: 4.30e-02 lr: 2.14e-05:  57%|▌| 7929/13852 [29:40<21:54,  4.51it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 2.14e-05:  57%|▌| 7930/13852 [29:40<21:46,  4.53it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 2.14e-05:  57%|▌| 7931/13852 [29:40<21:38,  4.56it/s\u001b[A\n",
      "Training loss: 3.96e-02 lr: 2.14e-05:  57%|▌| 7932/13852 [29:41<21:46,  4.53it/s\u001b[A\n",
      "Training loss: 9.62e-02 lr: 2.14e-05:  57%|▌| 7933/13852 [29:41<21:55,  4.50it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 2.14e-05:  57%|▌| 7934/13852 [29:41<21:56,  4.49it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 2.14e-05:  57%|▌| 7935/13852 [29:41<21:56,  4.49it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 2.14e-05:  57%|▌| 7936/13852 [29:42<21:55,  4.50it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 2.14e-05:  57%|▌| 7937/13852 [29:42<22:07,  4.45it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 2.13e-05:  57%|▌| 7938/13852 [29:42<22:04,  4.46it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 2.13e-05:  57%|▌| 7939/13852 [29:42<22:01,  4.47it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 2.13e-05:  57%|▌| 7940/13852 [29:42<21:55,  4.50it/s\u001b[A\n",
      "Training loss: 7.65e-02 lr: 2.13e-05:  57%|▌| 7941/13852 [29:43<21:47,  4.52it/s\u001b[A\n",
      "Training loss: 6.42e-02 lr: 2.13e-05:  57%|▌| 7942/13852 [29:43<21:42,  4.54it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 2.13e-05:  57%|▌| 7943/13852 [29:43<21:51,  4.50it/s\u001b[A\n",
      "Training loss: 3.43e-02 lr: 2.13e-05:  57%|▌| 7944/13852 [29:43<21:51,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.32e-02 lr: 2.13e-05:  57%|▌| 7945/13852 [29:44<21:46,  4.52it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 2.13e-05:  57%|▌| 7946/13852 [29:44<21:48,  4.51it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 2.13e-05:  57%|▌| 7947/13852 [29:44<21:46,  4.52it/s\u001b[A\n",
      "Training loss: 8.75e-02 lr: 2.13e-05:  57%|▌| 7948/13852 [29:44<21:47,  4.52it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 2.13e-05:  57%|▌| 7949/13852 [29:44<21:47,  4.51it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 2.13e-05:  57%|▌| 7950/13852 [29:45<21:49,  4.51it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 2.13e-05:  57%|▌| 7951/13852 [29:45<21:50,  4.50it/s\u001b[A\n",
      "Training loss: 5.43e-02 lr: 2.13e-05:  57%|▌| 7952/13852 [29:45<21:52,  4.50it/s\u001b[A\n",
      "Training loss: 3.98e-02 lr: 2.13e-05:  57%|▌| 7953/13852 [29:45<21:43,  4.53it/s\u001b[A\n",
      "Training loss: 3.18e-02 lr: 2.13e-05:  57%|▌| 7954/13852 [29:46<21:34,  4.55it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 2.13e-05:  57%|▌| 7955/13852 [29:46<21:32,  4.56it/s\u001b[A\n",
      "Training loss: 3.44e-02 lr: 2.13e-05:  57%|▌| 7956/13852 [29:46<21:37,  4.54it/s\u001b[A\n",
      "Training loss: 3.75e-02 lr: 2.13e-05:  57%|▌| 7957/13852 [29:46<21:39,  4.54it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 2.13e-05:  57%|▌| 7958/13852 [29:46<21:41,  4.53it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 2.13e-05:  57%|▌| 7959/13852 [29:47<21:47,  4.51it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 2.13e-05:  57%|▌| 7960/13852 [29:47<21:56,  4.47it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 2.13e-05:  57%|▌| 7961/13852 [29:47<21:56,  4.48it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 2.13e-05:  57%|▌| 7962/13852 [29:47<21:53,  4.48it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 2.13e-05:  57%|▌| 7963/13852 [29:48<21:52,  4.49it/s\u001b[A\n",
      "Training loss: 3.83e-02 lr: 2.13e-05:  57%|▌| 7964/13852 [29:48<21:51,  4.49it/s\u001b[A\n",
      "Training loss: 3.30e-02 lr: 2.13e-05:  58%|▌| 7965/13852 [29:48<21:47,  4.50it/s\u001b[A\n",
      "Training loss: 3.38e-02 lr: 2.12e-05:  58%|▌| 7966/13852 [29:48<21:43,  4.52it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 2.12e-05:  58%|▌| 7967/13852 [29:48<21:36,  4.54it/s\u001b[A\n",
      "Training loss: 2.34e-02 lr: 2.12e-05:  58%|▌| 7968/13852 [29:49<21:41,  4.52it/s\u001b[A\n",
      "Training loss: 1.71e-02 lr: 2.12e-05:  58%|▌| 7969/13852 [29:49<21:40,  4.53it/s\u001b[A\n",
      "Training loss: 2.11e-02 lr: 2.12e-05:  58%|▌| 7970/13852 [29:49<21:44,  4.51it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 2.12e-05:  58%|▌| 7971/13852 [29:49<21:46,  4.50it/s\u001b[A\n",
      "Training loss: 4.86e-02 lr: 2.12e-05:  58%|▌| 7972/13852 [29:50<21:46,  4.50it/s\u001b[A\n",
      "Training loss: 8.16e-02 lr: 2.12e-05:  58%|▌| 7973/13852 [29:50<21:47,  4.50it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 2.12e-05:  58%|▌| 7974/13852 [29:50<21:47,  4.50it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 2.12e-05:  58%|▌| 7975/13852 [29:50<21:47,  4.50it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 2.12e-05:  58%|▌| 7976/13852 [29:50<21:48,  4.49it/s\u001b[A\n",
      "Training loss: 3.68e-02 lr: 2.12e-05:  58%|▌| 7977/13852 [29:51<21:40,  4.52it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 2.12e-05:  58%|▌| 7978/13852 [29:51<21:42,  4.51it/s\u001b[A\n",
      "Training loss: 3.45e-02 lr: 2.12e-05:  58%|▌| 7979/13852 [29:51<21:51,  4.48it/s\u001b[A\n",
      "Training loss: 2.81e-02 lr: 2.12e-05:  58%|▌| 7980/13852 [29:51<21:52,  4.47it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 2.12e-05:  58%|▌| 7981/13852 [29:52<21:47,  4.49it/s\u001b[A\n",
      "Training loss: 4.61e-02 lr: 2.12e-05:  58%|▌| 7982/13852 [29:52<21:58,  4.45it/s\u001b[A\n",
      "Training loss: 3.47e-02 lr: 2.12e-05:  58%|▌| 7983/13852 [29:52<21:55,  4.46it/s\u001b[A\n",
      "Training loss: 2.72e-02 lr: 2.12e-05:  58%|▌| 7984/13852 [29:52<21:52,  4.47it/s\u001b[A\n",
      "Training loss: 2.03e-02 lr: 2.12e-05:  58%|▌| 7985/13852 [29:52<21:50,  4.48it/s\u001b[A\n",
      "Training loss: 1.81e-02 lr: 2.12e-05:  58%|▌| 7986/13852 [29:53<21:48,  4.48it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 2.12e-05:  58%|▌| 7987/13852 [29:53<21:50,  4.47it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 2.12e-05:  58%|▌| 7988/13852 [29:53<21:44,  4.49it/s\u001b[A\n",
      "Training loss: 8.12e-02 lr: 2.12e-05:  58%|▌| 7989/13852 [29:53<21:38,  4.51it/s\u001b[A\n",
      "Training loss: 7.76e-02 lr: 2.12e-05:  58%|▌| 7990/13852 [29:54<21:49,  4.48it/s\u001b[A\n",
      "Training loss: 7.82e-02 lr: 2.12e-05:  58%|▌| 7991/13852 [29:54<21:44,  4.49it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 2.12e-05:  58%|▌| 7992/13852 [29:54<21:42,  4.50it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 2.12e-05:  58%|▌| 7993/13852 [29:54<21:41,  4.50it/s\u001b[A\n",
      "Training loss: 7.48e-02 lr: 2.11e-05:  58%|▌| 7994/13852 [29:54<21:41,  4.50it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 2.11e-05:  58%|▌| 7995/13852 [29:55<21:41,  4.50it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 2.11e-05:  58%|▌| 7996/13852 [29:55<21:42,  4.49it/s\u001b[A\n",
      "Training loss: 3.28e-02 lr: 2.11e-05:  58%|▌| 7997/13852 [29:55<21:44,  4.49it/s\u001b[A\n",
      "Training loss: 2.63e-02 lr: 2.11e-05:  58%|▌| 7998/13852 [29:55<21:46,  4.48it/s\u001b[A\n",
      "Training loss: 1.94e-02 lr: 2.11e-05:  58%|▌| 7999/13852 [29:56<21:40,  4.50it/s\u001b[A\n",
      "Training loss: 1.57e-02 lr: 2.11e-05:  58%|▌| 8000/13852 [29:56<21:32,  4.53it/s\u001b[A\n",
      "Training loss: 2.08e-02 lr: 2.11e-05:  58%|▌| 8001/13852 [29:56<21:26,  4.55it/s\u001b[A\n",
      "Training loss: 1.64e-02 lr: 2.11e-05:  58%|▌| 8002/13852 [29:56<21:26,  4.55it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 2.11e-05:  58%|▌| 8003/13852 [29:56<21:32,  4.52it/s\u001b[A\n",
      "Training loss: 7.07e-02 lr: 2.11e-05:  58%|▌| 8004/13852 [29:57<21:38,  4.50it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 2.11e-05:  58%|▌| 8005/13852 [29:57<21:47,  4.47it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 2.11e-05:  58%|▌| 8006/13852 [29:57<21:47,  4.47it/s\u001b[A\n",
      "Training loss: 4.21e-02 lr: 2.11e-05:  58%|▌| 8007/13852 [29:57<21:45,  4.48it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 2.11e-05:  58%|▌| 8008/13852 [29:58<21:42,  4.49it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 2.11e-05:  58%|▌| 8009/13852 [29:58<21:41,  4.49it/s\u001b[A\n",
      "Training loss: 4.72e-02 lr: 2.11e-05:  58%|▌| 8010/13852 [29:58<21:40,  4.49it/s\u001b[A\n",
      "Training loss: 3.44e-02 lr: 2.11e-05:  58%|▌| 8011/13852 [29:58<21:38,  4.50it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 2.11e-05:  58%|▌| 8012/13852 [29:58<21:31,  4.52it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 2.11e-05:  58%|▌| 8013/13852 [29:59<21:24,  4.55it/s\u001b[A\n",
      "Training loss: 6.19e-02 lr: 2.11e-05:  58%|▌| 8014/13852 [29:59<21:37,  4.50it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 2.11e-05:  58%|▌| 8015/13852 [29:59<21:33,  4.51it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 2.11e-05:  58%|▌| 8016/13852 [29:59<21:30,  4.52it/s\u001b[A\n",
      "Training loss: 3.40e-02 lr: 2.11e-05:  58%|▌| 8017/13852 [30:00<21:30,  4.52it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 2.11e-05:  58%|▌| 8018/13852 [30:00<21:32,  4.51it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 2.11e-05:  58%|▌| 8019/13852 [30:00<21:31,  4.52it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 2.11e-05:  58%|▌| 8020/13852 [30:00<22:06,  4.40it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 2.10e-05:  58%|▌| 8021/13852 [30:00<21:55,  4.43it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 2.10e-05:  58%|▌| 8022/13852 [30:01<21:44,  4.47it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 2.10e-05:  58%|▌| 8023/13852 [30:01<21:42,  4.47it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 2.10e-05:  58%|▌| 8024/13852 [30:01<21:31,  4.51it/s\u001b[A\n",
      "Training loss: 7.02e-02 lr: 2.10e-05:  58%|▌| 8025/13852 [30:01<21:26,  4.53it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 2.10e-05:  58%|▌| 8026/13852 [30:02<21:28,  4.52it/s\u001b[A\n",
      "Training loss: 7.03e-02 lr: 2.10e-05:  58%|▌| 8027/13852 [30:02<21:32,  4.51it/s\u001b[A\n",
      "Training loss: 7.42e-02 lr: 2.10e-05:  58%|▌| 8028/13852 [30:02<21:33,  4.50it/s\u001b[A\n",
      "Training loss: 8.85e-02 lr: 2.10e-05:  58%|▌| 8029/13852 [30:02<21:31,  4.51it/s\u001b[A\n",
      "Training loss: 8.45e-02 lr: 2.10e-05:  58%|▌| 8030/13852 [30:02<21:31,  4.51it/s\u001b[A\n",
      "Training loss: 6.25e-02 lr: 2.10e-05:  58%|▌| 8031/13852 [30:03<21:31,  4.51it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 2.10e-05:  58%|▌| 8032/13852 [30:03<21:36,  4.49it/s\u001b[A\n",
      "Training loss: 3.90e-02 lr: 2.10e-05:  58%|▌| 8033/13852 [30:03<21:42,  4.47it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 2.10e-05:  58%|▌| 8034/13852 [30:03<21:41,  4.47it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 2.10e-05:  58%|▌| 8035/13852 [30:04<21:33,  4.50it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 2.10e-05:  58%|▌| 8036/13852 [30:04<21:23,  4.53it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 2.10e-05:  58%|▌| 8037/13852 [30:04<21:16,  4.56it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 2.10e-05:  58%|▌| 8038/13852 [30:04<21:22,  4.53it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 2.10e-05:  58%|▌| 8039/13852 [30:04<21:22,  4.53it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 2.10e-05:  58%|▌| 8040/13852 [30:05<21:23,  4.53it/s\u001b[A\n",
      "Training loss: 8.20e-02 lr: 2.10e-05:  58%|▌| 8041/13852 [30:05<21:30,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.94e-02 lr: 2.10e-05:  58%|▌| 8042/13852 [30:05<21:33,  4.49it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 2.10e-05:  58%|▌| 8043/13852 [30:05<21:34,  4.49it/s\u001b[A\n",
      "Training loss: 3.83e-02 lr: 2.10e-05:  58%|▌| 8044/13852 [30:06<21:33,  4.49it/s\u001b[A\n",
      "Training loss: 7.01e-02 lr: 2.10e-05:  58%|▌| 8045/13852 [30:06<21:32,  4.49it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 2.10e-05:  58%|▌| 8046/13852 [30:06<21:32,  4.49it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 2.10e-05:  58%|▌| 8047/13852 [30:06<21:25,  4.51it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 2.10e-05:  58%|▌| 8048/13852 [30:06<21:18,  4.54it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 2.09e-05:  58%|▌| 8049/13852 [30:07<21:12,  4.56it/s\u001b[A\n",
      "Training loss: 3.65e-02 lr: 2.09e-05:  58%|▌| 8050/13852 [30:07<21:32,  4.49it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.09e-05:  58%|▌| 8051/13852 [30:07<21:33,  4.48it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 2.09e-05:  58%|▌| 8052/13852 [30:07<21:39,  4.46it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 2.09e-05:  58%|▌| 8053/13852 [30:08<21:39,  4.46it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 2.09e-05:  58%|▌| 8054/13852 [30:08<21:37,  4.47it/s\u001b[A\n",
      "Training loss: 8.73e-02 lr: 2.09e-05:  58%|▌| 8055/13852 [30:08<21:34,  4.48it/s\u001b[A\n",
      "Training loss: 8.58e-02 lr: 2.09e-05:  58%|▌| 8056/13852 [30:08<22:09,  4.36it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 2.09e-05:  58%|▌| 8057/13852 [30:08<22:23,  4.31it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 2.09e-05:  58%|▌| 8058/13852 [30:09<23:18,  4.14it/s\u001b[A\n",
      "Training loss: 8.84e-02 lr: 2.09e-05:  58%|▌| 8059/13852 [30:09<23:14,  4.15it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 2.09e-05:  58%|▌| 8060/13852 [30:09<23:13,  4.16it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 2.09e-05:  58%|▌| 8061/13852 [30:09<23:13,  4.15it/s\u001b[A\n",
      "Training loss: 8.73e-02 lr: 2.09e-05:  58%|▌| 8062/13852 [30:10<23:15,  4.15it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 2.09e-05:  58%|▌| 8063/13852 [30:10<23:09,  4.17it/s\u001b[A\n",
      "Training loss: 5.84e-02 lr: 2.09e-05:  58%|▌| 8064/13852 [30:10<23:09,  4.17it/s\u001b[A\n",
      "Training loss: 4.43e-02 lr: 2.09e-05:  58%|▌| 8065/13852 [30:10<23:08,  4.17it/s\u001b[A\n",
      "Training loss: 3.19e-02 lr: 2.09e-05:  58%|▌| 8066/13852 [30:11<23:10,  4.16it/s\u001b[A\n",
      "Training loss: 3.02e-02 lr: 2.09e-05:  58%|▌| 8067/13852 [30:11<23:29,  4.11it/s\u001b[A\n",
      "Training loss: 2.69e-02 lr: 2.09e-05:  58%|▌| 8068/13852 [30:11<23:19,  4.13it/s\u001b[A\n",
      "Training loss: 2.10e-02 lr: 2.09e-05:  58%|▌| 8069/13852 [30:11<23:09,  4.16it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 2.09e-05:  58%|▌| 8070/13852 [30:12<23:06,  4.17it/s\u001b[A\n",
      "Training loss: 2.65e-02 lr: 2.09e-05:  58%|▌| 8071/13852 [30:12<23:08,  4.16it/s\u001b[A\n",
      "Training loss: 2.06e-02 lr: 2.09e-05:  58%|▌| 8072/13852 [30:12<23:09,  4.16it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 2.09e-05:  58%|▌| 8073/13852 [30:12<23:08,  4.16it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 2.09e-05:  58%|▌| 8074/13852 [30:13<23:01,  4.18it/s\u001b[A\n",
      "Training loss: 6.78e-02 lr: 2.09e-05:  58%|▌| 8075/13852 [30:13<23:06,  4.17it/s\u001b[A\n",
      "Training loss: 8.25e-02 lr: 2.09e-05:  58%|▌| 8076/13852 [30:13<23:10,  4.16it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 2.08e-05:  58%|▌| 8077/13852 [30:13<23:06,  4.17it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 2.08e-05:  58%|▌| 8078/13852 [30:14<23:04,  4.17it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 2.08e-05:  58%|▌| 8079/13852 [30:14<23:04,  4.17it/s\u001b[A\n",
      "Training loss: 2.99e-02 lr: 2.08e-05:  58%|▌| 8080/13852 [30:14<22:57,  4.19it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 2.08e-05:  58%|▌| 8081/13852 [30:14<22:59,  4.18it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 2.08e-05:  58%|▌| 8082/13852 [30:14<23:00,  4.18it/s\u001b[A\n",
      "Training loss: 4.72e-02 lr: 2.08e-05:  58%|▌| 8083/13852 [30:15<22:59,  4.18it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 2.08e-05:  58%|▌| 8084/13852 [30:15<23:00,  4.18it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 2.08e-05:  58%|▌| 8085/13852 [30:15<23:01,  4.17it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 2.08e-05:  58%|▌| 8086/13852 [30:15<22:58,  4.18it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 2.08e-05:  58%|▌| 8087/13852 [30:16<22:58,  4.18it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 2.08e-05:  58%|▌| 8088/13852 [30:16<22:57,  4.18it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 2.08e-05:  58%|▌| 8089/13852 [30:16<22:57,  4.18it/s\u001b[A\n",
      "Training loss: 2.70e-02 lr: 2.08e-05:  58%|▌| 8090/13852 [30:16<23:01,  4.17it/s\u001b[A\n",
      "Training loss: 2.36e-02 lr: 2.08e-05:  58%|▌| 8091/13852 [30:17<23:04,  4.16it/s\u001b[A\n",
      "Training loss: 1.95e-02 lr: 2.08e-05:  58%|▌| 8092/13852 [30:17<23:13,  4.13it/s\u001b[A\n",
      "Training loss: 2.44e-02 lr: 2.08e-05:  58%|▌| 8093/13852 [30:17<23:10,  4.14it/s\u001b[A\n",
      "Training loss: 2.34e-02 lr: 2.08e-05:  58%|▌| 8094/13852 [30:17<23:07,  4.15it/s\u001b[A\n",
      "Training loss: 2.12e-02 lr: 2.08e-05:  58%|▌| 8095/13852 [30:18<23:06,  4.15it/s\u001b[A\n",
      "Training loss: 3.84e-02 lr: 2.08e-05:  58%|▌| 8096/13852 [30:18<23:04,  4.16it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 2.08e-05:  58%|▌| 8097/13852 [30:18<23:06,  4.15it/s\u001b[A\n",
      "Training loss: 7.71e-02 lr: 2.08e-05:  58%|▌| 8098/13852 [30:18<23:02,  4.16it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 2.08e-05:  58%|▌| 8099/13852 [30:19<22:59,  4.17it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 2.08e-05:  58%|▌| 8100/13852 [30:19<22:58,  4.17it/s\u001b[A\n",
      "Training loss: 3.16e-02 lr: 2.08e-05:  58%|▌| 8101/13852 [30:19<22:57,  4.18it/s\u001b[A\n",
      "Training loss: 2.39e-02 lr: 2.08e-05:  58%|▌| 8102/13852 [30:19<22:56,  4.18it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 2.08e-05:  58%|▌| 8103/13852 [30:20<22:52,  4.19it/s\u001b[A\n",
      "Training loss: 3.30e-02 lr: 2.07e-05:  59%|▌| 8104/13852 [30:20<22:47,  4.20it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 2.07e-05:  59%|▌| 8105/13852 [30:20<22:50,  4.19it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 2.07e-05:  59%|▌| 8106/13852 [30:20<22:50,  4.19it/s\u001b[A\n",
      "Training loss: 7.95e-02 lr: 2.07e-05:  59%|▌| 8107/13852 [30:20<22:52,  4.19it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 2.07e-05:  59%|▌| 8108/13852 [30:21<22:56,  4.17it/s\u001b[A\n",
      "Training loss: 1.41e-01 lr: 2.07e-05:  59%|▌| 8109/13852 [30:21<23:03,  4.15it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.07e-05:  59%|▌| 8110/13852 [30:21<22:53,  4.18it/s\u001b[A\n",
      "Training loss: 9.33e-02 lr: 2.07e-05:  59%|▌| 8111/13852 [30:21<22:54,  4.18it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 2.07e-05:  59%|▌| 8112/13852 [30:22<22:59,  4.16it/s\u001b[A\n",
      "Training loss: 7.16e-02 lr: 2.07e-05:  59%|▌| 8113/13852 [30:22<22:58,  4.16it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 2.07e-05:  59%|▌| 8114/13852 [30:22<22:58,  4.16it/s\u001b[A\n",
      "Training loss: 9.51e-02 lr: 2.07e-05:  59%|▌| 8115/13852 [30:22<22:53,  4.18it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 2.07e-05:  59%|▌| 8116/13852 [30:23<22:57,  4.17it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.07e-05:  59%|▌| 8117/13852 [30:23<22:57,  4.16it/s\u001b[A\n",
      "Training loss: 8.24e-02 lr: 2.07e-05:  59%|▌| 8118/13852 [30:23<22:59,  4.16it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 2.07e-05:  59%|▌| 8119/13852 [30:23<23:02,  4.15it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 2.07e-05:  59%|▌| 8120/13852 [30:24<23:00,  4.15it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 2.07e-05:  59%|▌| 8121/13852 [30:24<22:54,  4.17it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 2.07e-05:  59%|▌| 8122/13852 [30:24<22:51,  4.18it/s\u001b[A\n",
      "Training loss: 7.86e-02 lr: 2.07e-05:  59%|▌| 8123/13852 [30:24<22:48,  4.19it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 2.07e-05:  59%|▌| 8124/13852 [30:25<22:46,  4.19it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 2.07e-05:  59%|▌| 8125/13852 [30:25<22:46,  4.19it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 2.07e-05:  59%|▌| 8126/13852 [30:25<22:47,  4.19it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 2.07e-05:  59%|▌| 8127/13852 [30:25<22:43,  4.20it/s\u001b[A\n",
      "Training loss: 4.86e-02 lr: 2.07e-05:  59%|▌| 8128/13852 [30:25<22:41,  4.20it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 2.07e-05:  59%|▌| 8129/13852 [30:26<22:43,  4.20it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 2.07e-05:  59%|▌| 8130/13852 [30:26<22:42,  4.20it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 2.07e-05:  59%|▌| 8131/13852 [30:26<22:42,  4.20it/s\u001b[A\n",
      "Training loss: 4.21e-02 lr: 2.06e-05:  59%|▌| 8132/13852 [30:26<22:43,  4.19it/s\u001b[A\n",
      "Training loss: 3.49e-02 lr: 2.06e-05:  59%|▌| 8133/13852 [30:27<22:49,  4.18it/s\u001b[A\n",
      "Training loss: 3.28e-02 lr: 2.06e-05:  59%|▌| 8134/13852 [30:27<22:52,  4.17it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 2.06e-05:  59%|▌| 8135/13852 [30:27<22:49,  4.17it/s\u001b[A\n",
      "Training loss: 9.23e-02 lr: 2.06e-05:  59%|▌| 8136/13852 [30:27<22:46,  4.18it/s\u001b[A\n",
      "Training loss: 7.39e-02 lr: 2.06e-05:  59%|▌| 8137/13852 [30:28<22:49,  4.17it/s\u001b[A\n",
      "Training loss: 7.29e-02 lr: 2.06e-05:  59%|▌| 8138/13852 [30:28<22:49,  4.17it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.10e-02 lr: 2.06e-05:  59%|▌| 8139/13852 [30:28<22:43,  4.19it/s\u001b[A\n",
      "Training loss: 6.22e-02 lr: 2.06e-05:  59%|▌| 8140/13852 [30:28<22:45,  4.18it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 2.06e-05:  59%|▌| 8141/13852 [30:29<22:43,  4.19it/s\u001b[A\n",
      "Training loss: 3.95e-02 lr: 2.06e-05:  59%|▌| 8142/13852 [30:29<22:42,  4.19it/s\u001b[A\n",
      "Training loss: 3.03e-02 lr: 2.06e-05:  59%|▌| 8143/13852 [30:29<22:42,  4.19it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 2.06e-05:  59%|▌| 8144/13852 [30:29<22:45,  4.18it/s\u001b[A\n",
      "Training loss: 3.44e-02 lr: 2.06e-05:  59%|▌| 8145/13852 [30:30<22:41,  4.19it/s\u001b[A\n",
      "Training loss: 2.81e-02 lr: 2.06e-05:  59%|▌| 8146/13852 [30:30<22:42,  4.19it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 2.06e-05:  59%|▌| 8147/13852 [30:30<22:41,  4.19it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 2.06e-05:  59%|▌| 8148/13852 [30:30<22:43,  4.18it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 2.06e-05:  59%|▌| 8149/13852 [30:31<22:46,  4.17it/s\u001b[A\n",
      "Training loss: 9.62e-02 lr: 2.06e-05:  59%|▌| 8150/13852 [30:31<22:55,  4.14it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 2.06e-05:  59%|▌| 8151/13852 [30:31<22:53,  4.15it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 2.06e-05:  59%|▌| 8152/13852 [30:31<22:50,  4.16it/s\u001b[A\n",
      "Training loss: 9.98e-02 lr: 2.06e-05:  59%|▌| 8153/13852 [30:31<22:48,  4.16it/s\u001b[A\n",
      "Training loss: 8.26e-02 lr: 2.06e-05:  59%|▌| 8154/13852 [30:32<22:52,  4.15it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 2.06e-05:  59%|▌| 8155/13852 [30:32<22:51,  4.15it/s\u001b[A\n",
      "Training loss: 6.00e-02 lr: 2.06e-05:  59%|▌| 8156/13852 [30:32<22:48,  4.16it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 2.06e-05:  59%|▌| 8157/13852 [30:32<22:42,  4.18it/s\u001b[A\n",
      "Training loss: 6.75e-02 lr: 2.06e-05:  59%|▌| 8158/13852 [30:33<22:41,  4.18it/s\u001b[A\n",
      "Training loss: 9.05e-02 lr: 2.06e-05:  59%|▌| 8159/13852 [30:33<22:41,  4.18it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 2.05e-05:  59%|▌| 8160/13852 [30:33<22:43,  4.17it/s\u001b[A\n",
      "Training loss: 6.96e-02 lr: 2.05e-05:  59%|▌| 8161/13852 [30:33<22:44,  4.17it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 2.05e-05:  59%|▌| 8162/13852 [30:34<22:44,  4.17it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 2.05e-05:  59%|▌| 8163/13852 [30:34<22:40,  4.18it/s\u001b[A\n",
      "Training loss: 3.19e-02 lr: 2.05e-05:  59%|▌| 8164/13852 [30:34<22:41,  4.18it/s\u001b[A\n",
      "Training loss: 3.07e-02 lr: 2.05e-05:  59%|▌| 8165/13852 [30:34<22:41,  4.18it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 2.05e-05:  59%|▌| 8166/13852 [30:35<22:40,  4.18it/s\u001b[A\n",
      "Training loss: 3.98e-02 lr: 2.05e-05:  59%|▌| 8167/13852 [30:35<22:41,  4.18it/s\u001b[A\n",
      "Training loss: 3.50e-02 lr: 2.05e-05:  59%|▌| 8168/13852 [30:35<22:37,  4.19it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 2.05e-05:  59%|▌| 8169/13852 [30:35<22:41,  4.18it/s\u001b[A\n",
      "Training loss: 4.21e-02 lr: 2.05e-05:  59%|▌| 8170/13852 [30:36<22:39,  4.18it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 2.05e-05:  59%|▌| 8171/13852 [30:36<22:37,  4.18it/s\u001b[A\n",
      "Training loss: 2.96e-02 lr: 2.05e-05:  59%|▌| 8172/13852 [30:36<22:38,  4.18it/s\u001b[A\n",
      "Training loss: 2.21e-02 lr: 2.05e-05:  59%|▌| 8173/13852 [30:36<22:38,  4.18it/s\u001b[A\n",
      "Training loss: 3.30e-02 lr: 2.05e-05:  59%|▌| 8174/13852 [30:37<22:32,  4.20it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 2.05e-05:  59%|▌| 8175/13852 [30:37<22:40,  4.17it/s\u001b[A\n",
      "Training loss: 3.57e-02 lr: 2.05e-05:  59%|▌| 8176/13852 [30:37<22:47,  4.15it/s\u001b[A\n",
      "Training loss: 7.57e-02 lr: 2.05e-05:  59%|▌| 8177/13852 [30:37<22:49,  4.14it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 2.05e-05:  59%|▌| 8178/13852 [30:37<22:52,  4.13it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 2.05e-05:  59%|▌| 8179/13852 [30:38<22:49,  4.14it/s\u001b[A\n",
      "Training loss: 8.41e-02 lr: 2.05e-05:  59%|▌| 8180/13852 [30:38<22:43,  4.16it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 2.05e-05:  59%|▌| 8181/13852 [30:38<22:16,  4.24it/s\u001b[A\n",
      "Training loss: 1.42e-01 lr: 2.05e-05:  59%|▌| 8182/13852 [30:38<22:29,  4.20it/s\u001b[A\n",
      "Training loss: 1.28e-01 lr: 2.05e-05:  59%|▌| 8183/13852 [30:39<22:36,  4.18it/s\u001b[A\n",
      "Training loss: 2.00e-01 lr: 2.05e-05:  59%|▌| 8184/13852 [30:39<22:40,  4.17it/s\u001b[A\n",
      "Training loss: 1.54e-01 lr: 2.05e-05:  59%|▌| 8185/13852 [30:39<22:10,  4.26it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 2.05e-05:  59%|▌| 8186/13852 [30:39<21:44,  4.34it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.04e-05:  59%|▌| 8187/13852 [30:40<21:23,  4.42it/s\u001b[A\n",
      "Training loss: 7.61e-02 lr: 2.04e-05:  59%|▌| 8188/13852 [30:40<21:08,  4.47it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 2.04e-05:  59%|▌| 8189/13852 [30:40<20:56,  4.51it/s\u001b[A\n",
      "Training loss: 8.02e-02 lr: 2.04e-05:  59%|▌| 8190/13852 [30:40<20:57,  4.50it/s\u001b[A\n",
      "Training loss: 7.06e-02 lr: 2.04e-05:  59%|▌| 8191/13852 [30:40<20:57,  4.50it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 2.04e-05:  59%|▌| 8192/13852 [30:41<20:57,  4.50it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 2.04e-05:  59%|▌| 8193/13852 [30:41<21:04,  4.48it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 2.04e-05:  59%|▌| 8194/13852 [30:41<21:02,  4.48it/s\u001b[A\n",
      "Training loss: 8.43e-02 lr: 2.04e-05:  59%|▌| 8195/13852 [30:41<21:01,  4.48it/s\u001b[A\n",
      "Training loss: 8.80e-02 lr: 2.04e-05:  59%|▌| 8196/13852 [30:42<21:00,  4.49it/s\u001b[A\n",
      "Training loss: 6.47e-02 lr: 2.04e-05:  59%|▌| 8197/13852 [30:42<21:05,  4.47it/s\u001b[A\n",
      "Training loss: 8.75e-02 lr: 2.04e-05:  59%|▌| 8198/13852 [30:42<21:04,  4.47it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 2.04e-05:  59%|▌| 8199/13852 [30:42<20:57,  4.49it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 2.04e-05:  59%|▌| 8200/13852 [30:42<20:51,  4.52it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 2.04e-05:  59%|▌| 8201/13852 [30:43<20:52,  4.51it/s\u001b[A\n",
      "Training loss: 3.38e-02 lr: 2.04e-05:  59%|▌| 8202/13852 [30:43<20:52,  4.51it/s\u001b[A\n",
      "Training loss: 4.45e-02 lr: 2.04e-05:  59%|▌| 8203/13852 [30:43<21:03,  4.47it/s\u001b[A\n",
      "Training loss: 4.93e-02 lr: 2.04e-05:  59%|▌| 8204/13852 [30:43<20:58,  4.49it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 2.04e-05:  59%|▌| 8205/13852 [30:44<21:02,  4.47it/s\u001b[A\n",
      "Training loss: 4.08e-02 lr: 2.04e-05:  59%|▌| 8206/13852 [30:44<20:59,  4.48it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 2.04e-05:  59%|▌| 8207/13852 [30:44<20:56,  4.49it/s\u001b[A\n",
      "Training loss: 7.26e-02 lr: 2.04e-05:  59%|▌| 8208/13852 [30:44<20:56,  4.49it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 2.04e-05:  59%|▌| 8209/13852 [30:44<21:01,  4.47it/s\u001b[A\n",
      "Training loss: 8.14e-02 lr: 2.04e-05:  59%|▌| 8210/13852 [30:45<20:53,  4.50it/s\u001b[A\n",
      "Training loss: 6.46e-02 lr: 2.04e-05:  59%|▌| 8211/13852 [30:45<20:46,  4.53it/s\u001b[A\n",
      "Training loss: 9.23e-02 lr: 2.04e-05:  59%|▌| 8212/13852 [30:45<20:44,  4.53it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.04e-05:  59%|▌| 8213/13852 [30:45<20:51,  4.51it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 2.04e-05:  59%|▌| 8214/13852 [30:46<20:51,  4.51it/s\u001b[A\n",
      "Training loss: 8.41e-02 lr: 2.03e-05:  59%|▌| 8215/13852 [30:46<20:48,  4.51it/s\u001b[A\n",
      "Training loss: 9.08e-02 lr: 2.03e-05:  59%|▌| 8216/13852 [30:46<20:48,  4.51it/s\u001b[A\n",
      "Training loss: 7.69e-02 lr: 2.03e-05:  59%|▌| 8217/13852 [30:46<20:50,  4.51it/s\u001b[A\n",
      "Training loss: 6.25e-02 lr: 2.03e-05:  59%|▌| 8218/13852 [30:46<20:51,  4.50it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 2.03e-05:  59%|▌| 8219/13852 [30:47<20:54,  4.49it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 2.03e-05:  59%|▌| 8220/13852 [30:47<20:56,  4.48it/s\u001b[A\n",
      "Training loss: 9.34e-02 lr: 2.03e-05:  59%|▌| 8221/13852 [30:47<20:55,  4.48it/s\u001b[A\n",
      "Training loss: 7.66e-02 lr: 2.03e-05:  59%|▌| 8222/13852 [30:47<20:49,  4.51it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 2.03e-05:  59%|▌| 8223/13852 [30:48<20:42,  4.53it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 2.03e-05:  59%|▌| 8224/13852 [30:48<20:42,  4.53it/s\u001b[A\n",
      "Training loss: 8.76e-02 lr: 2.03e-05:  59%|▌| 8225/13852 [30:48<20:59,  4.47it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 2.03e-05:  59%|▌| 8226/13852 [30:48<22:17,  4.21it/s\u001b[A\n",
      "Training loss: 8.53e-02 lr: 2.03e-05:  59%|▌| 8227/13852 [30:49<22:56,  4.09it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 2.03e-05:  59%|▌| 8228/13852 [30:49<22:48,  4.11it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 2.03e-05:  59%|▌| 8229/13852 [30:49<22:36,  4.15it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 2.03e-05:  59%|▌| 8230/13852 [30:49<22:33,  4.15it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 2.03e-05:  59%|▌| 8231/13852 [30:50<22:32,  4.16it/s\u001b[A\n",
      "Training loss: 6.59e-02 lr: 2.03e-05:  59%|▌| 8232/13852 [30:50<22:36,  4.14it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 2.03e-05:  59%|▌| 8233/13852 [30:50<22:34,  4.15it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 2.03e-05:  59%|▌| 8234/13852 [30:50<22:32,  4.15it/s\u001b[A\n",
      "Training loss: 5.09e-02 lr: 2.03e-05:  59%|▌| 8235/13852 [30:50<22:26,  4.17it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.01e-02 lr: 2.03e-05:  59%|▌| 8236/13852 [30:51<22:26,  4.17it/s\u001b[A\n",
      "Training loss: 9.95e-02 lr: 2.03e-05:  59%|▌| 8237/13852 [30:51<22:31,  4.16it/s\u001b[A\n",
      "Training loss: 9.47e-02 lr: 2.03e-05:  59%|▌| 8238/13852 [30:51<22:30,  4.16it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 2.03e-05:  59%|▌| 8239/13852 [30:51<22:34,  4.14it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.03e-05:  59%|▌| 8240/13852 [30:52<22:34,  4.14it/s\u001b[A\n",
      "Training loss: 3.90e-02 lr: 2.03e-05:  59%|▌| 8241/13852 [30:52<22:36,  4.14it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 2.03e-05:  60%|▌| 8242/13852 [30:52<22:31,  4.15it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 2.02e-05:  60%|▌| 8243/13852 [30:52<22:27,  4.16it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 2.02e-05:  60%|▌| 8244/13852 [30:53<22:26,  4.17it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 2.02e-05:  60%|▌| 8245/13852 [30:53<22:25,  4.17it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 2.02e-05:  60%|▌| 8246/13852 [30:53<22:29,  4.15it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 2.02e-05:  60%|▌| 8247/13852 [30:53<22:29,  4.15it/s\u001b[A\n",
      "Training loss: 3.16e-02 lr: 2.02e-05:  60%|▌| 8248/13852 [30:54<22:24,  4.17it/s\u001b[A\n",
      "Training loss: 3.16e-02 lr: 2.02e-05:  60%|▌| 8249/13852 [30:54<22:23,  4.17it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 2.02e-05:  60%|▌| 8250/13852 [30:54<22:25,  4.16it/s\u001b[A\n",
      "Training loss: 7.73e-02 lr: 2.02e-05:  60%|▌| 8251/13852 [30:54<22:25,  4.16it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 2.02e-05:  60%|▌| 8252/13852 [30:55<22:19,  4.18it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 2.02e-05:  60%|▌| 8253/13852 [30:55<22:17,  4.18it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 2.02e-05:  60%|▌| 8254/13852 [30:55<22:17,  4.18it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 2.02e-05:  60%|▌| 8255/13852 [30:55<22:16,  4.19it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 2.02e-05:  60%|▌| 8256/13852 [30:56<22:20,  4.17it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 2.02e-05:  60%|▌| 8257/13852 [30:56<22:22,  4.17it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 2.02e-05:  60%|▌| 8258/13852 [30:56<22:16,  4.18it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 2.02e-05:  60%|▌| 8259/13852 [30:56<22:14,  4.19it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 2.02e-05:  60%|▌| 8260/13852 [30:56<22:17,  4.18it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 2.02e-05:  60%|▌| 8261/13852 [30:57<22:28,  4.15it/s\u001b[A\n",
      "Training loss: 9.34e-02 lr: 2.02e-05:  60%|▌| 8262/13852 [30:57<22:33,  4.13it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 2.02e-05:  60%|▌| 8263/13852 [30:57<22:23,  4.16it/s\u001b[A\n",
      "Training loss: 8.62e-02 lr: 2.02e-05:  60%|▌| 8264/13852 [30:57<22:14,  4.19it/s\u001b[A\n",
      "Training loss: 9.57e-02 lr: 2.02e-05:  60%|▌| 8265/13852 [30:58<22:17,  4.18it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 2.02e-05:  60%|▌| 8266/13852 [30:58<22:15,  4.18it/s\u001b[A\n",
      "Training loss: 9.54e-02 lr: 2.02e-05:  60%|▌| 8267/13852 [30:58<22:21,  4.16it/s\u001b[A\n",
      "Training loss: 9.14e-02 lr: 2.02e-05:  60%|▌| 8268/13852 [30:58<22:20,  4.17it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 2.02e-05:  60%|▌| 8269/13852 [30:59<22:21,  4.16it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 2.02e-05:  60%|▌| 8270/13852 [30:59<22:16,  4.18it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 2.01e-05:  60%|▌| 8271/13852 [30:59<22:15,  4.18it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 2.01e-05:  60%|▌| 8272/13852 [30:59<22:15,  4.18it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 2.01e-05:  60%|▌| 8273/13852 [31:00<22:14,  4.18it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 2.01e-05:  60%|▌| 8274/13852 [31:00<22:18,  4.17it/s\u001b[A\n",
      "Training loss: 5.09e-02 lr: 2.01e-05:  60%|▌| 8275/13852 [31:00<22:13,  4.18it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 2.01e-05:  60%|▌| 8276/13852 [31:00<22:11,  4.19it/s\u001b[A\n",
      "Training loss: 6.36e-02 lr: 2.01e-05:  60%|▌| 8277/13852 [31:01<22:14,  4.18it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 2.01e-05:  60%|▌| 8278/13852 [31:01<22:20,  4.16it/s\u001b[A\n",
      "Training loss: 3.70e-02 lr: 2.01e-05:  60%|▌| 8279/13852 [31:01<22:20,  4.16it/s\u001b[A\n",
      "Training loss: 8.07e-02 lr: 2.01e-05:  60%|▌| 8280/13852 [31:01<22:21,  4.15it/s\u001b[A\n",
      "Training loss: 7.77e-02 lr: 2.01e-05:  60%|▌| 8281/13852 [31:02<22:15,  4.17it/s\u001b[A\n",
      "Training loss: 6.02e-02 lr: 2.01e-05:  60%|▌| 8282/13852 [31:02<22:28,  4.13it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 2.01e-05:  60%|▌| 8283/13852 [31:02<22:24,  4.14it/s\u001b[A\n",
      "Training loss: 7.63e-02 lr: 2.01e-05:  60%|▌| 8284/13852 [31:02<22:19,  4.16it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 2.01e-05:  60%|▌| 8285/13852 [31:02<22:18,  4.16it/s\u001b[A\n",
      "Training loss: 4.79e-02 lr: 2.01e-05:  60%|▌| 8286/13852 [31:03<22:17,  4.16it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 2.01e-05:  60%|▌| 8287/13852 [31:03<22:20,  4.15it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 2.01e-05:  60%|▌| 8288/13852 [31:03<22:24,  4.14it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 2.01e-05:  60%|▌| 8289/13852 [31:03<22:20,  4.15it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.01e-05:  60%|▌| 8290/13852 [31:04<22:19,  4.15it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 2.01e-05:  60%|▌| 8291/13852 [31:04<22:16,  4.16it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 2.01e-05:  60%|▌| 8292/13852 [31:04<22:16,  4.16it/s\u001b[A\n",
      "Training loss: 4.30e-02 lr: 2.01e-05:  60%|▌| 8293/13852 [31:04<22:11,  4.18it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 2.01e-05:  60%|▌| 8294/13852 [31:05<22:11,  4.17it/s\u001b[A\n",
      "Training loss: 1.16e-01 lr: 2.01e-05:  60%|▌| 8295/13852 [31:05<22:14,  4.17it/s\u001b[A\n",
      "Training loss: 8.23e-02 lr: 2.01e-05:  60%|▌| 8296/13852 [31:05<22:21,  4.14it/s\u001b[A\n",
      "Training loss: 8.81e-02 lr: 2.01e-05:  60%|▌| 8297/13852 [31:05<22:20,  4.14it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 2.00e-05:  60%|▌| 8298/13852 [31:06<22:14,  4.16it/s\u001b[A\n",
      "Training loss: 8.42e-02 lr: 2.00e-05:  60%|▌| 8299/13852 [31:06<22:18,  4.15it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 2.00e-05:  60%|▌| 8300/13852 [31:06<22:16,  4.15it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 2.00e-05:  60%|▌| 8301/13852 [31:06<22:12,  4.17it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 2.00e-05:  60%|▌| 8302/13852 [31:07<22:11,  4.17it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 2.00e-05:  60%|▌| 8303/13852 [31:07<22:39,  4.08it/s\u001b[A\n",
      "Training loss: 3.47e-02 lr: 2.00e-05:  60%|▌| 8304/13852 [31:07<22:35,  4.09it/s\u001b[A\n",
      "Training loss: 3.22e-02 lr: 2.00e-05:  60%|▌| 8305/13852 [31:07<22:32,  4.10it/s\u001b[A\n",
      "Training loss: 3.54e-02 lr: 2.00e-05:  60%|▌| 8306/13852 [31:08<22:30,  4.11it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 2.00e-05:  60%|▌| 8307/13852 [31:08<22:28,  4.11it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 2.00e-05:  60%|▌| 8308/13852 [31:08<21:52,  4.22it/s\u001b[A\n",
      "Training loss: 3.77e-02 lr: 2.00e-05:  60%|▌| 8309/13852 [31:08<21:27,  4.31it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 2.00e-05:  60%|▌| 8310/13852 [31:08<21:05,  4.38it/s\u001b[A\n",
      "Training loss: 3.49e-02 lr: 2.00e-05:  60%|▌| 8311/13852 [31:09<20:46,  4.44it/s\u001b[A\n",
      "Training loss: 3.20e-02 lr: 2.00e-05:  60%|▌| 8312/13852 [31:09<20:33,  4.49it/s\u001b[A\n",
      "Training loss: 2.72e-02 lr: 2.00e-05:  60%|▌| 8313/13852 [31:09<20:32,  4.49it/s\u001b[A\n",
      "Training loss: 5.57e-02 lr: 2.00e-05:  60%|▌| 8314/13852 [31:09<20:29,  4.50it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 2.00e-05:  60%|▌| 8315/13852 [31:10<20:26,  4.51it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 2.00e-05:  60%|▌| 8316/13852 [31:10<20:25,  4.52it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 2.00e-05:  60%|▌| 8317/13852 [31:10<20:26,  4.51it/s\u001b[A\n",
      "Training loss: 2.69e-02 lr: 2.00e-05:  60%|▌| 8318/13852 [31:10<20:24,  4.52it/s\u001b[A\n",
      "Training loss: 2.05e-02 lr: 2.00e-05:  60%|▌| 8319/13852 [31:10<20:25,  4.52it/s\u001b[A\n",
      "Training loss: 3.20e-02 lr: 2.00e-05:  60%|▌| 8320/13852 [31:11<20:25,  4.51it/s\u001b[A\n",
      "Training loss: 4.29e-02 lr: 2.00e-05:  60%|▌| 8321/13852 [31:11<20:35,  4.48it/s\u001b[A\n",
      "Training loss: 8.13e-02 lr: 2.00e-05:  60%|▌| 8322/13852 [31:11<20:28,  4.50it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 2.00e-05:  60%|▌| 8323/13852 [31:11<20:21,  4.53it/s\u001b[A\n",
      "Training loss: 9.58e-02 lr: 2.00e-05:  60%|▌| 8324/13852 [31:12<20:18,  4.54it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 2.00e-05:  60%|▌| 8325/13852 [31:12<20:36,  4.47it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 1.99e-05:  60%|▌| 8326/13852 [31:12<20:38,  4.46it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 1.99e-05:  60%|▌| 8327/13852 [31:12<20:33,  4.48it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 1.99e-05:  60%|▌| 8328/13852 [31:12<20:30,  4.49it/s\u001b[A\n",
      "Training loss: 4.36e-02 lr: 1.99e-05:  60%|▌| 8329/13852 [31:13<20:29,  4.49it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 1.99e-05:  60%|▌| 8330/13852 [31:13<20:27,  4.50it/s\u001b[A\n",
      "Training loss: 5.57e-02 lr: 1.99e-05:  60%|▌| 8331/13852 [31:13<20:30,  4.49it/s\u001b[A\n",
      "Training loss: 4.70e-02 lr: 1.99e-05:  60%|▌| 8332/13852 [31:13<20:36,  4.47it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.96e-02 lr: 1.99e-05:  60%|▌| 8333/13852 [31:14<20:27,  4.49it/s\u001b[A\n",
      "Training loss: 8.63e-02 lr: 1.99e-05:  60%|▌| 8334/13852 [31:14<20:19,  4.52it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 1.99e-05:  60%|▌| 8335/13852 [31:14<20:15,  4.54it/s\u001b[A\n",
      "Training loss: 8.30e-02 lr: 1.99e-05:  60%|▌| 8336/13852 [31:14<20:28,  4.49it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 1.99e-05:  60%|▌| 8337/13852 [31:14<20:25,  4.50it/s\u001b[A\n",
      "Training loss: 7.49e-02 lr: 1.99e-05:  60%|▌| 8338/13852 [31:15<20:23,  4.51it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 1.99e-05:  60%|▌| 8339/13852 [31:15<20:22,  4.51it/s\u001b[A\n",
      "Training loss: 4.57e-02 lr: 1.99e-05:  60%|▌| 8340/13852 [31:15<20:22,  4.51it/s\u001b[A\n",
      "Training loss: 6.34e-02 lr: 1.99e-05:  60%|▌| 8341/13852 [31:15<20:20,  4.52it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 1.99e-05:  60%|▌| 8342/13852 [31:16<20:19,  4.52it/s\u001b[A\n",
      "Training loss: 8.00e-02 lr: 1.99e-05:  60%|▌| 8343/13852 [31:16<20:20,  4.51it/s\u001b[A\n",
      "Training loss: 6.64e-02 lr: 1.99e-05:  60%|▌| 8344/13852 [31:16<20:21,  4.51it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 1.99e-05:  60%|▌| 8345/13852 [31:16<20:23,  4.50it/s\u001b[A\n",
      "Training loss: 7.86e-02 lr: 1.99e-05:  60%|▌| 8346/13852 [31:16<20:21,  4.51it/s\u001b[A\n",
      "Training loss: 5.86e-02 lr: 1.99e-05:  60%|▌| 8347/13852 [31:17<20:16,  4.53it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 1.99e-05:  60%|▌| 8348/13852 [31:17<20:17,  4.52it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 1.99e-05:  60%|▌| 8349/13852 [31:17<20:19,  4.51it/s\u001b[A\n",
      "Training loss: 7.92e-02 lr: 1.99e-05:  60%|▌| 8350/13852 [31:17<20:19,  4.51it/s\u001b[A\n",
      "Training loss: 6.71e-02 lr: 1.99e-05:  60%|▌| 8351/13852 [31:18<20:19,  4.51it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.99e-05:  60%|▌| 8352/13852 [31:18<20:17,  4.52it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 1.99e-05:  60%|▌| 8353/13852 [31:18<20:28,  4.48it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 1.98e-05:  60%|▌| 8354/13852 [31:18<20:26,  4.48it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 1.98e-05:  60%|▌| 8355/13852 [31:18<20:24,  4.49it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 1.98e-05:  60%|▌| 8356/13852 [31:19<20:24,  4.49it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 1.98e-05:  60%|▌| 8357/13852 [31:19<20:23,  4.49it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.98e-05:  60%|▌| 8358/13852 [31:19<20:17,  4.51it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 1.98e-05:  60%|▌| 8359/13852 [31:19<20:11,  4.54it/s\u001b[A\n",
      "Training loss: 3.08e-02 lr: 1.98e-05:  60%|▌| 8360/13852 [31:20<20:05,  4.55it/s\u001b[A\n",
      "Training loss: 2.71e-02 lr: 1.98e-05:  60%|▌| 8361/13852 [31:20<20:11,  4.53it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 1.98e-05:  60%|▌| 8362/13852 [31:20<20:11,  4.53it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 1.98e-05:  60%|▌| 8363/13852 [31:20<20:11,  4.53it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 1.98e-05:  60%|▌| 8364/13852 [31:20<20:12,  4.53it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 1.98e-05:  60%|▌| 8365/13852 [31:21<20:15,  4.51it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 1.98e-05:  60%|▌| 8366/13852 [31:21<20:25,  4.48it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 1.98e-05:  60%|▌| 8367/13852 [31:21<20:24,  4.48it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 1.98e-05:  60%|▌| 8368/13852 [31:21<20:22,  4.49it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 1.98e-05:  60%|▌| 8369/13852 [31:22<20:23,  4.48it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 1.98e-05:  60%|▌| 8370/13852 [31:22<20:25,  4.47it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 1.98e-05:  60%|▌| 8371/13852 [31:22<20:16,  4.50it/s\u001b[A\n",
      "Training loss: 8.25e-02 lr: 1.98e-05:  60%|▌| 8372/13852 [31:22<20:26,  4.47it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 1.98e-05:  60%|▌| 8373/13852 [31:22<20:23,  4.48it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 1.98e-05:  60%|▌| 8374/13852 [31:23<20:22,  4.48it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 1.98e-05:  60%|▌| 8375/13852 [31:23<20:18,  4.49it/s\u001b[A\n",
      "Training loss: 8.07e-02 lr: 1.98e-05:  60%|▌| 8376/13852 [31:23<20:22,  4.48it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 1.98e-05:  60%|▌| 8377/13852 [31:23<20:36,  4.43it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 1.98e-05:  60%|▌| 8378/13852 [31:24<20:30,  4.45it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 1.98e-05:  60%|▌| 8379/13852 [31:24<20:27,  4.46it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 1.98e-05:  60%|▌| 8380/13852 [31:24<20:18,  4.49it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 1.97e-05:  61%|▌| 8381/13852 [31:24<20:08,  4.53it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 1.97e-05:  61%|▌| 8382/13852 [31:24<20:04,  4.54it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 1.97e-05:  61%|▌| 8383/13852 [31:25<20:00,  4.56it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 1.97e-05:  61%|▌| 8384/13852 [31:25<19:58,  4.56it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 1.97e-05:  61%|▌| 8385/13852 [31:25<19:59,  4.56it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 1.97e-05:  61%|▌| 8386/13852 [31:25<20:01,  4.55it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 1.97e-05:  61%|▌| 8387/13852 [31:26<20:05,  4.53it/s\u001b[A\n",
      "Training loss: 9.22e-02 lr: 1.97e-05:  61%|▌| 8388/13852 [31:26<20:07,  4.52it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 1.97e-05:  61%|▌| 8389/13852 [31:26<20:10,  4.51it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 1.97e-05:  61%|▌| 8390/13852 [31:26<20:13,  4.50it/s\u001b[A\n",
      "Training loss: 8.91e-02 lr: 1.97e-05:  61%|▌| 8391/13852 [31:26<20:13,  4.50it/s\u001b[A\n",
      "Training loss: 7.80e-02 lr: 1.97e-05:  61%|▌| 8392/13852 [31:27<20:17,  4.49it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 1.97e-05:  61%|▌| 8393/13852 [31:27<20:23,  4.46it/s\u001b[A\n",
      "Training loss: 1.52e-01 lr: 1.97e-05:  61%|▌| 8394/13852 [31:27<20:17,  4.48it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 1.97e-05:  61%|▌| 8395/13852 [31:27<20:10,  4.51it/s\u001b[A\n",
      "Training loss: 8.79e-02 lr: 1.97e-05:  61%|▌| 8396/13852 [31:28<20:15,  4.49it/s\u001b[A\n",
      "Training loss: 8.33e-02 lr: 1.97e-05:  61%|▌| 8397/13852 [31:28<20:13,  4.50it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 1.97e-05:  61%|▌| 8398/13852 [31:28<20:11,  4.50it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 1.97e-05:  61%|▌| 8399/13852 [31:28<20:10,  4.51it/s\u001b[A\n",
      "Training loss: 6.85e-02 lr: 1.97e-05:  61%|▌| 8400/13852 [31:28<20:10,  4.50it/s\u001b[A\n",
      "Training loss: 9.42e-02 lr: 1.97e-05:  61%|▌| 8401/13852 [31:29<20:12,  4.50it/s\u001b[A\n",
      "Training loss: 7.99e-02 lr: 1.97e-05:  61%|▌| 8402/13852 [31:29<20:13,  4.49it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 1.97e-05:  61%|▌| 8403/13852 [31:29<20:12,  4.49it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 1.97e-05:  61%|▌| 8404/13852 [31:29<20:13,  4.49it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 1.97e-05:  61%|▌| 8405/13852 [31:30<20:11,  4.50it/s\u001b[A\n",
      "Training loss: 6.34e-02 lr: 1.97e-05:  61%|▌| 8406/13852 [31:30<20:04,  4.52it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 1.97e-05:  61%|▌| 8407/13852 [31:30<19:59,  4.54it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 1.97e-05:  61%|▌| 8408/13852 [31:30<20:10,  4.50it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 1.96e-05:  61%|▌| 8409/13852 [31:30<20:09,  4.50it/s\u001b[A\n",
      "Training loss: 3.86e-02 lr: 1.96e-05:  61%|▌| 8410/13852 [31:31<20:09,  4.50it/s\u001b[A\n",
      "Training loss: 3.36e-02 lr: 1.96e-05:  61%|▌| 8411/13852 [31:31<20:22,  4.45it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 1.96e-05:  61%|▌| 8412/13852 [31:31<20:21,  4.46it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 1.96e-05:  61%|▌| 8413/13852 [31:31<20:16,  4.47it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 1.96e-05:  61%|▌| 8414/13852 [31:32<20:16,  4.47it/s\u001b[A\n",
      "Training loss: 3.98e-02 lr: 1.96e-05:  61%|▌| 8415/13852 [31:32<20:22,  4.45it/s\u001b[A\n",
      "Training loss: 4.26e-02 lr: 1.96e-05:  61%|▌| 8416/13852 [31:32<20:14,  4.48it/s\u001b[A\n",
      "Training loss: 3.22e-02 lr: 1.96e-05:  61%|▌| 8417/13852 [31:32<20:06,  4.51it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.96e-05:  61%|▌| 8418/13852 [31:32<19:59,  4.53it/s\u001b[A\n",
      "Training loss: 3.01e-02 lr: 1.96e-05:  61%|▌| 8419/13852 [31:33<19:54,  4.55it/s\u001b[A\n",
      "Training loss: 3.40e-02 lr: 1.96e-05:  61%|▌| 8420/13852 [31:33<19:57,  4.54it/s\u001b[A\n",
      "Training loss: 2.62e-02 lr: 1.96e-05:  61%|▌| 8421/13852 [31:33<20:01,  4.52it/s\u001b[A\n",
      "Training loss: 3.42e-02 lr: 1.96e-05:  61%|▌| 8422/13852 [31:33<20:03,  4.51it/s\u001b[A\n",
      "Training loss: 8.55e-02 lr: 1.96e-05:  61%|▌| 8423/13852 [31:34<20:10,  4.49it/s\u001b[A\n",
      "Training loss: 9.19e-02 lr: 1.96e-05:  61%|▌| 8424/13852 [31:34<20:11,  4.48it/s\u001b[A\n",
      "Training loss: 6.87e-02 lr: 1.96e-05:  61%|▌| 8425/13852 [31:34<20:11,  4.48it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 1.96e-05:  61%|▌| 8426/13852 [31:34<20:11,  4.48it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 1.96e-05:  61%|▌| 8427/13852 [31:34<20:12,  4.47it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 1.96e-05:  61%|▌| 8428/13852 [31:35<20:10,  4.48it/s\u001b[A\n",
      "Training loss: 3.27e-02 lr: 1.96e-05:  61%|▌| 8429/13852 [31:35<20:03,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.48e-02 lr: 1.96e-05:  61%|▌| 8430/13852 [31:35<19:59,  4.52it/s\u001b[A\n",
      "Training loss: 1.04e-01 lr: 1.96e-05:  61%|▌| 8431/13852 [31:35<20:04,  4.50it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 1.96e-05:  61%|▌| 8432/13852 [31:36<20:12,  4.47it/s\u001b[A\n",
      "Training loss: 9.23e-02 lr: 1.96e-05:  61%|▌| 8433/13852 [31:36<20:15,  4.46it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 1.96e-05:  61%|▌| 8434/13852 [31:36<20:13,  4.46it/s\u001b[A\n",
      "Training loss: 4.86e-02 lr: 1.96e-05:  61%|▌| 8435/13852 [31:36<20:13,  4.47it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 1.96e-05:  61%|▌| 8436/13852 [31:36<20:12,  4.47it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 1.95e-05:  61%|▌| 8437/13852 [31:37<20:14,  4.46it/s\u001b[A\n",
      "Training loss: 3.36e-02 lr: 1.95e-05:  61%|▌| 8438/13852 [31:37<20:22,  4.43it/s\u001b[A\n",
      "Training loss: 2.66e-02 lr: 1.95e-05:  61%|▌| 8439/13852 [31:37<20:14,  4.46it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 1.95e-05:  61%|▌| 8440/13852 [31:37<20:06,  4.49it/s\u001b[A\n",
      "Training loss: 4.22e-02 lr: 1.95e-05:  61%|▌| 8441/13852 [31:38<20:35,  4.38it/s\u001b[A\n",
      "Training loss: 3.12e-02 lr: 1.95e-05:  61%|▌| 8442/13852 [31:38<21:05,  4.28it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 1.95e-05:  61%|▌| 8443/13852 [31:38<21:21,  4.22it/s\u001b[A\n",
      "Training loss: 6.09e-02 lr: 1.95e-05:  61%|▌| 8444/13852 [31:38<21:30,  4.19it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 1.95e-05:  61%|▌| 8445/13852 [31:39<20:59,  4.29it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.95e-05:  61%|▌| 8446/13852 [31:39<20:35,  4.38it/s\u001b[A\n",
      "Training loss: 3.96e-02 lr: 1.95e-05:  61%|▌| 8447/13852 [31:39<20:19,  4.43it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 1.95e-05:  61%|▌| 8448/13852 [31:39<20:08,  4.47it/s\u001b[A\n",
      "Training loss: 2.32e-02 lr: 1.95e-05:  61%|▌| 8449/13852 [31:39<20:10,  4.46it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 1.95e-05:  61%|▌| 8450/13852 [31:40<20:05,  4.48it/s\u001b[A\n",
      "Training loss: 2.39e-02 lr: 1.95e-05:  61%|▌| 8451/13852 [31:40<20:05,  4.48it/s\u001b[A\n",
      "Training loss: 2.11e-02 lr: 1.95e-05:  61%|▌| 8452/13852 [31:40<20:06,  4.47it/s\u001b[A\n",
      "Training loss: 3.10e-02 lr: 1.95e-05:  61%|▌| 8453/13852 [31:40<20:05,  4.48it/s\u001b[A\n",
      "Training loss: 2.98e-02 lr: 1.95e-05:  61%|▌| 8454/13852 [31:41<20:09,  4.46it/s\u001b[A\n",
      "Training loss: 2.14e-02 lr: 1.95e-05:  61%|▌| 8455/13852 [31:41<20:12,  4.45it/s\u001b[A\n",
      "Training loss: 3.03e-02 lr: 1.95e-05:  61%|▌| 8456/13852 [31:41<21:30,  4.18it/s\u001b[A\n",
      "Training loss: 9.53e-02 lr: 1.95e-05:  61%|▌| 8457/13852 [31:41<22:17,  4.03it/s\u001b[A\n",
      "Training loss: 9.77e-02 lr: 1.95e-05:  61%|▌| 8458/13852 [31:42<22:06,  4.07it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 1.95e-05:  61%|▌| 8459/13852 [31:42<22:06,  4.07it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.95e-05:  61%|▌| 8460/13852 [31:42<21:58,  4.09it/s\u001b[A\n",
      "Training loss: 7.90e-02 lr: 1.95e-05:  61%|▌| 8461/13852 [31:42<21:50,  4.11it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 1.95e-05:  61%|▌| 8462/13852 [31:43<21:49,  4.12it/s\u001b[A\n",
      "Training loss: 4.16e-02 lr: 1.95e-05:  61%|▌| 8463/13852 [31:43<21:43,  4.13it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 1.94e-05:  61%|▌| 8464/13852 [31:43<21:41,  4.14it/s\u001b[A\n",
      "Training loss: 3.49e-02 lr: 1.94e-05:  61%|▌| 8465/13852 [31:43<21:40,  4.14it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 1.94e-05:  61%|▌| 8466/13852 [31:43<21:47,  4.12it/s\u001b[A\n",
      "Training loss: 2.25e-02 lr: 1.94e-05:  61%|▌| 8467/13852 [31:44<21:40,  4.14it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 1.94e-05:  61%|▌| 8468/13852 [31:44<21:46,  4.12it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.94e-05:  61%|▌| 8469/13852 [31:44<21:40,  4.14it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 1.94e-05:  61%|▌| 8470/13852 [31:44<21:40,  4.14it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 1.94e-05:  61%|▌| 8471/13852 [31:45<21:37,  4.15it/s\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.94e-05:  61%|▌| 8472/13852 [31:45<21:29,  4.17it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.94e-05:  61%|▌| 8473/13852 [31:45<21:21,  4.20it/s\u001b[A\n",
      "Training loss: 2.47e-02 lr: 1.94e-05:  61%|▌| 8474/13852 [31:45<21:26,  4.18it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 1.94e-05:  61%|▌| 8475/13852 [31:46<21:25,  4.18it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 1.94e-05:  61%|▌| 8476/13852 [31:46<21:27,  4.18it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 1.94e-05:  61%|▌| 8477/13852 [31:46<21:30,  4.17it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 1.94e-05:  61%|▌| 8478/13852 [31:46<21:26,  4.18it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 1.94e-05:  61%|▌| 8479/13852 [31:47<21:21,  4.19it/s\u001b[A\n",
      "Training loss: 2.35e-02 lr: 1.94e-05:  61%|▌| 8480/13852 [31:47<21:44,  4.12it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 1.94e-05:  61%|▌| 8481/13852 [31:47<21:38,  4.14it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 1.94e-05:  61%|▌| 8482/13852 [31:47<21:41,  4.13it/s\u001b[A\n",
      "Training loss: 2.09e-02 lr: 1.94e-05:  61%|▌| 8483/13852 [31:48<21:37,  4.14it/s\u001b[A\n",
      "Training loss: 1.65e-02 lr: 1.94e-05:  61%|▌| 8484/13852 [31:48<21:30,  4.16it/s\u001b[A\n",
      "Training loss: 2.04e-02 lr: 1.94e-05:  61%|▌| 8485/13852 [31:48<21:39,  4.13it/s\u001b[A\n",
      "Training loss: 1.59e-02 lr: 1.94e-05:  61%|▌| 8486/13852 [31:48<21:38,  4.13it/s\u001b[A\n",
      "Training loss: 1.17e-02 lr: 1.94e-05:  61%|▌| 8487/13852 [31:49<21:35,  4.14it/s\u001b[A\n",
      "Training loss: 1.54e-02 lr: 1.94e-05:  61%|▌| 8488/13852 [31:49<21:31,  4.15it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 1.94e-05:  61%|▌| 8489/13852 [31:49<21:32,  4.15it/s\u001b[A\n",
      "Training loss: 4.42e-02 lr: 1.94e-05:  61%|▌| 8490/13852 [31:49<21:25,  4.17it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.94e-05:  61%|▌| 8491/13852 [31:49<21:25,  4.17it/s\u001b[A\n",
      "Training loss: 2.70e-02 lr: 1.93e-05:  61%|▌| 8492/13852 [31:50<21:27,  4.16it/s\u001b[A\n",
      "Training loss: 2.08e-02 lr: 1.93e-05:  61%|▌| 8493/13852 [31:50<21:26,  4.17it/s\u001b[A\n",
      "Training loss: 1.86e-02 lr: 1.93e-05:  61%|▌| 8494/13852 [31:50<21:24,  4.17it/s\u001b[A\n",
      "Training loss: 1.72e-02 lr: 1.93e-05:  61%|▌| 8495/13852 [31:50<21:21,  4.18it/s\u001b[A\n",
      "Training loss: 1.33e-02 lr: 1.93e-05:  61%|▌| 8496/13852 [31:51<21:32,  4.14it/s\u001b[A\n",
      "Training loss: 1.76e-02 lr: 1.93e-05:  61%|▌| 8497/13852 [31:51<21:39,  4.12it/s\u001b[A\n",
      "Training loss: 6.93e-02 lr: 1.93e-05:  61%|▌| 8498/13852 [31:51<21:34,  4.14it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 1.93e-05:  61%|▌| 8499/13852 [31:51<21:31,  4.15it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.93e-05:  61%|▌| 8500/13852 [31:52<21:33,  4.14it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 1.93e-05:  61%|▌| 8501/13852 [31:52<21:27,  4.16it/s\u001b[A\n",
      "Training loss: 3.18e-02 lr: 1.93e-05:  61%|▌| 8502/13852 [31:52<21:26,  4.16it/s\u001b[A\n",
      "Training loss: 2.44e-02 lr: 1.93e-05:  61%|▌| 8503/13852 [31:52<21:26,  4.16it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 1.93e-05:  61%|▌| 8504/13852 [31:53<21:26,  4.16it/s\u001b[A\n",
      "Training loss: 3.86e-02 lr: 1.93e-05:  61%|▌| 8505/13852 [31:53<21:26,  4.16it/s\u001b[A\n",
      "Training loss: 2.85e-02 lr: 1.93e-05:  61%|▌| 8506/13852 [31:53<21:27,  4.15it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 1.93e-05:  61%|▌| 8507/13852 [31:53<21:25,  4.16it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 1.93e-05:  61%|▌| 8508/13852 [31:54<21:47,  4.09it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 1.93e-05:  61%|▌| 8509/13852 [31:54<21:39,  4.11it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 1.93e-05:  61%|▌| 8510/13852 [31:54<21:36,  4.12it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 1.93e-05:  61%|▌| 8511/13852 [31:54<21:30,  4.14it/s\u001b[A\n",
      "Training loss: 6.16e-02 lr: 1.93e-05:  61%|▌| 8512/13852 [31:55<21:26,  4.15it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 1.93e-05:  61%|▌| 8513/13852 [31:55<21:24,  4.16it/s\u001b[A\n",
      "Training loss: 3.59e-02 lr: 1.93e-05:  61%|▌| 8514/13852 [31:55<21:23,  4.16it/s\u001b[A\n",
      "Training loss: 2.81e-02 lr: 1.93e-05:  61%|▌| 8515/13852 [31:55<21:21,  4.16it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 1.93e-05:  61%|▌| 8516/13852 [31:56<21:21,  4.16it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 1.93e-05:  61%|▌| 8517/13852 [31:56<21:20,  4.17it/s\u001b[A\n",
      "Training loss: 3.99e-02 lr: 1.93e-05:  61%|▌| 8518/13852 [31:56<21:16,  4.18it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.93e-05:  62%|▌| 8519/13852 [31:56<21:24,  4.15it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 1.92e-05:  62%|▌| 8520/13852 [31:56<21:23,  4.15it/s\u001b[A\n",
      "Training loss: 1.72e-01 lr: 1.92e-05:  62%|▌| 8521/13852 [31:57<21:22,  4.16it/s\u001b[A\n",
      "Training loss: 1.21e-01 lr: 1.92e-05:  62%|▌| 8522/13852 [31:57<21:23,  4.15it/s\u001b[A\n",
      "Training loss: 9.24e-02 lr: 1.92e-05:  62%|▌| 8523/13852 [31:57<21:20,  4.16it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 1.92e-05:  62%|▌| 8524/13852 [31:57<21:15,  4.18it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 1.92e-05:  62%|▌| 8525/13852 [31:58<21:17,  4.17it/s\u001b[A\n",
      "Training loss: 9.01e-02 lr: 1.92e-05:  62%|▌| 8526/13852 [31:58<21:15,  4.17it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.79e-01 lr: 1.92e-05:  62%|▌| 8527/13852 [31:58<21:20,  4.16it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 1.92e-05:  62%|▌| 8528/13852 [31:58<21:16,  4.17it/s\u001b[A\n",
      "Training loss: 9.08e-02 lr: 1.92e-05:  62%|▌| 8529/13852 [31:59<21:13,  4.18it/s\u001b[A\n",
      "Training loss: 1.35e-01 lr: 1.92e-05:  62%|▌| 8530/13852 [31:59<21:23,  4.15it/s\u001b[A\n",
      "Training loss: 9.74e-02 lr: 1.92e-05:  62%|▌| 8531/13852 [31:59<21:20,  4.16it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 1.92e-05:  62%|▌| 8532/13852 [31:59<21:18,  4.16it/s\u001b[A\n",
      "Training loss: 9.32e-02 lr: 1.92e-05:  62%|▌| 8533/13852 [32:00<21:19,  4.16it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.92e-05:  62%|▌| 8534/13852 [32:00<21:17,  4.16it/s\u001b[A\n",
      "Training loss: 8.59e-02 lr: 1.92e-05:  62%|▌| 8535/13852 [32:00<21:16,  4.17it/s\u001b[A\n",
      "Training loss: 8.11e-02 lr: 1.92e-05:  62%|▌| 8536/13852 [32:00<21:16,  4.16it/s\u001b[A\n",
      "Training loss: 8.38e-02 lr: 1.92e-05:  62%|▌| 8537/13852 [32:01<21:17,  4.16it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 1.92e-05:  62%|▌| 8538/13852 [32:01<21:19,  4.15it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 1.92e-05:  62%|▌| 8539/13852 [32:01<21:17,  4.16it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 1.92e-05:  62%|▌| 8540/13852 [32:01<21:16,  4.16it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 1.92e-05:  62%|▌| 8541/13852 [32:02<21:10,  4.18it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 1.92e-05:  62%|▌| 8542/13852 [32:02<21:19,  4.15it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 1.92e-05:  62%|▌| 8543/13852 [32:02<21:19,  4.15it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 1.92e-05:  62%|▌| 8544/13852 [32:02<21:17,  4.16it/s\u001b[A\n",
      "Training loss: 4.45e-02 lr: 1.92e-05:  62%|▌| 8545/13852 [32:02<21:12,  4.17it/s\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.92e-05:  62%|▌| 8546/13852 [32:03<21:10,  4.18it/s\u001b[A\n",
      "Training loss: 2.99e-02 lr: 1.92e-05:  62%|▌| 8547/13852 [32:03<21:09,  4.18it/s\u001b[A\n",
      "Training loss: 2.51e-02 lr: 1.91e-05:  62%|▌| 8548/13852 [32:03<21:15,  4.16it/s\u001b[A\n",
      "Training loss: 3.38e-02 lr: 1.91e-05:  62%|▌| 8549/13852 [32:03<21:13,  4.16it/s\u001b[A\n",
      "Training loss: 3.46e-02 lr: 1.91e-05:  62%|▌| 8550/13852 [32:04<21:25,  4.12it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 1.91e-05:  62%|▌| 8551/13852 [32:04<21:19,  4.14it/s\u001b[A\n",
      "Training loss: 9.16e-02 lr: 1.91e-05:  62%|▌| 8552/13852 [32:04<21:13,  4.16it/s\u001b[A\n",
      "Training loss: 8.36e-02 lr: 1.91e-05:  62%|▌| 8553/13852 [32:04<21:10,  4.17it/s\u001b[A\n",
      "Training loss: 8.92e-02 lr: 1.91e-05:  62%|▌| 8554/13852 [32:05<21:10,  4.17it/s\u001b[A\n",
      "Training loss: 6.79e-02 lr: 1.91e-05:  62%|▌| 8555/13852 [32:05<21:09,  4.17it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 1.91e-05:  62%|▌| 8556/13852 [32:05<21:06,  4.18it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 1.91e-05:  62%|▌| 8557/13852 [32:05<21:15,  4.15it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 1.91e-05:  62%|▌| 8558/13852 [32:06<21:11,  4.16it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 1.91e-05:  62%|▌| 8559/13852 [32:06<21:06,  4.18it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 1.91e-05:  62%|▌| 8560/13852 [32:06<21:06,  4.18it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 1.91e-05:  62%|▌| 8561/13852 [32:06<21:08,  4.17it/s\u001b[A\n",
      "Training loss: 9.49e-02 lr: 1.91e-05:  62%|▌| 8562/13852 [32:07<21:06,  4.18it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 1.91e-05:  62%|▌| 8563/13852 [32:07<21:21,  4.13it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 1.91e-05:  62%|▌| 8564/13852 [32:07<21:22,  4.12it/s\u001b[A\n",
      "Training loss: 7.27e-02 lr: 1.91e-05:  62%|▌| 8565/13852 [32:07<21:24,  4.12it/s\u001b[A\n",
      "Training loss: 5.43e-02 lr: 1.91e-05:  62%|▌| 8566/13852 [32:08<21:21,  4.13it/s\u001b[A\n",
      "Training loss: 8.43e-02 lr: 1.91e-05:  62%|▌| 8567/13852 [32:08<21:15,  4.14it/s\u001b[A\n",
      "Training loss: 7.80e-02 lr: 1.91e-05:  62%|▌| 8568/13852 [32:08<21:10,  4.16it/s\u001b[A\n",
      "Training loss: 6.31e-02 lr: 1.91e-05:  62%|▌| 8569/13852 [32:08<21:06,  4.17it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 1.91e-05:  62%|▌| 8570/13852 [32:08<21:01,  4.19it/s\u001b[A\n",
      "Training loss: 3.87e-02 lr: 1.91e-05:  62%|▌| 8571/13852 [32:09<21:02,  4.18it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 1.91e-05:  62%|▌| 8572/13852 [32:09<21:01,  4.18it/s\u001b[A\n",
      "Training loss: 3.70e-02 lr: 1.91e-05:  62%|▌| 8573/13852 [32:09<21:00,  4.19it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 1.91e-05:  62%|▌| 8574/13852 [32:09<20:59,  4.19it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 1.90e-05:  62%|▌| 8575/13852 [32:10<21:01,  4.18it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 1.90e-05:  62%|▌| 8576/13852 [32:10<20:59,  4.19it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 1.90e-05:  62%|▌| 8577/13852 [32:10<21:00,  4.19it/s\u001b[A\n",
      "Training loss: 2.97e-02 lr: 1.90e-05:  62%|▌| 8578/13852 [32:10<21:00,  4.18it/s\u001b[A\n",
      "Training loss: 3.13e-02 lr: 1.90e-05:  62%|▌| 8579/13852 [32:11<20:59,  4.19it/s\u001b[A\n",
      "Training loss: 2.27e-02 lr: 1.90e-05:  62%|▌| 8580/13852 [32:11<21:09,  4.15it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 1.90e-05:  62%|▌| 8581/13852 [32:11<21:04,  4.17it/s\u001b[A\n",
      "Training loss: 2.94e-02 lr: 1.90e-05:  62%|▌| 8582/13852 [32:11<20:59,  4.19it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 1.90e-05:  62%|▌| 8583/13852 [32:12<21:00,  4.18it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 1.90e-05:  62%|▌| 8584/13852 [32:12<21:04,  4.17it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 1.90e-05:  62%|▌| 8585/13852 [32:12<21:05,  4.16it/s\u001b[A\n",
      "Training loss: 4.43e-02 lr: 1.90e-05:  62%|▌| 8586/13852 [32:12<21:03,  4.17it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 1.90e-05:  62%|▌| 8587/13852 [32:13<20:58,  4.18it/s\u001b[A\n",
      "Training loss: 2.81e-02 lr: 1.90e-05:  62%|▌| 8588/13852 [32:13<20:57,  4.18it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 1.90e-05:  62%|▌| 8589/13852 [32:13<21:04,  4.16it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 1.90e-05:  62%|▌| 8590/13852 [32:13<21:03,  4.16it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 1.90e-05:  62%|▌| 8591/13852 [32:14<21:01,  4.17it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 1.90e-05:  62%|▌| 8592/13852 [32:14<21:10,  4.14it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 1.90e-05:  62%|▌| 8593/13852 [32:14<21:03,  4.16it/s\u001b[A\n",
      "Training loss: 6.88e-02 lr: 1.90e-05:  62%|▌| 8594/13852 [32:14<20:59,  4.17it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 1.90e-05:  62%|▌| 8595/13852 [32:14<21:06,  4.15it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 1.90e-05:  62%|▌| 8596/13852 [32:15<21:02,  4.16it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 1.90e-05:  62%|▌| 8597/13852 [32:15<21:00,  4.17it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 1.90e-05:  62%|▌| 8598/13852 [32:15<21:00,  4.17it/s\u001b[A\n",
      "Training loss: 8.09e-02 lr: 1.90e-05:  62%|▌| 8599/13852 [32:15<21:02,  4.16it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 1.90e-05:  62%|▌| 8600/13852 [32:16<21:04,  4.15it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 1.90e-05:  62%|▌| 8601/13852 [32:16<21:13,  4.12it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 1.90e-05:  62%|▌| 8602/13852 [32:16<21:19,  4.10it/s\u001b[A\n",
      "Training loss: 7.71e-02 lr: 1.89e-05:  62%|▌| 8603/13852 [32:16<20:49,  4.20it/s\u001b[A\n",
      "Training loss: 6.10e-02 lr: 1.89e-05:  62%|▌| 8604/13852 [32:17<20:42,  4.22it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 1.89e-05:  62%|▌| 8605/13852 [32:17<20:48,  4.20it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 1.89e-05:  62%|▌| 8606/13852 [32:17<20:53,  4.18it/s\u001b[A\n",
      "Training loss: 9.62e-02 lr: 1.89e-05:  62%|▌| 8607/13852 [32:17<20:28,  4.27it/s\u001b[A\n",
      "Training loss: 7.68e-02 lr: 1.89e-05:  62%|▌| 8608/13852 [32:18<20:04,  4.35it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 1.89e-05:  62%|▌| 8609/13852 [32:18<19:52,  4.40it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 1.89e-05:  62%|▌| 8610/13852 [32:18<19:46,  4.42it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 1.89e-05:  62%|▌| 8611/13852 [32:18<19:36,  4.46it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 1.89e-05:  62%|▌| 8612/13852 [32:18<19:30,  4.48it/s\u001b[A\n",
      "Training loss: 4.36e-02 lr: 1.89e-05:  62%|▌| 8613/13852 [32:19<19:29,  4.48it/s\u001b[A\n",
      "Training loss: 8.40e-02 lr: 1.89e-05:  62%|▌| 8614/13852 [32:19<19:23,  4.50it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 1.89e-05:  62%|▌| 8615/13852 [32:19<19:17,  4.52it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 1.89e-05:  62%|▌| 8616/13852 [32:19<19:13,  4.54it/s\u001b[A\n",
      "Training loss: 7.89e-02 lr: 1.89e-05:  62%|▌| 8617/13852 [32:20<19:16,  4.53it/s\u001b[A\n",
      "Training loss: 9.25e-02 lr: 1.89e-05:  62%|▌| 8618/13852 [32:20<19:16,  4.53it/s\u001b[A\n",
      "Training loss: 9.13e-02 lr: 1.89e-05:  62%|▌| 8619/13852 [32:20<19:16,  4.52it/s\u001b[A\n",
      "Training loss: 7.26e-02 lr: 1.89e-05:  62%|▌| 8620/13852 [32:20<19:18,  4.52it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 1.89e-05:  62%|▌| 8621/13852 [32:20<19:16,  4.52it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 1.89e-05:  62%|▌| 8622/13852 [32:21<19:15,  4.52it/s\u001b[A\n",
      "Training loss: 7.42e-02 lr: 1.89e-05:  62%|▌| 8623/13852 [32:21<19:19,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.37e-02 lr: 1.89e-05:  62%|▌| 8624/13852 [32:21<19:18,  4.51it/s\u001b[A\n",
      "Training loss: 7.70e-02 lr: 1.89e-05:  62%|▌| 8625/13852 [32:21<19:16,  4.52it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 1.89e-05:  62%|▌| 8626/13852 [32:22<19:17,  4.52it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 1.89e-05:  62%|▌| 8627/13852 [32:22<19:18,  4.51it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 1.89e-05:  62%|▌| 8628/13852 [32:22<19:15,  4.52it/s\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.89e-05:  62%|▌| 8629/13852 [32:22<19:17,  4.51it/s\u001b[A\n",
      "Training loss: 2.91e-02 lr: 1.89e-05:  62%|▌| 8630/13852 [32:22<19:18,  4.51it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.88e-05:  62%|▌| 8631/13852 [32:23<19:21,  4.50it/s\u001b[A\n",
      "Training loss: 3.08e-02 lr: 1.88e-05:  62%|▌| 8632/13852 [32:23<19:17,  4.51it/s\u001b[A\n",
      "Training loss: 2.43e-02 lr: 1.88e-05:  62%|▌| 8633/13852 [32:23<19:16,  4.51it/s\u001b[A\n",
      "Training loss: 2.30e-02 lr: 1.88e-05:  62%|▌| 8634/13852 [32:23<19:13,  4.52it/s\u001b[A\n",
      "Training loss: 3.00e-02 lr: 1.88e-05:  62%|▌| 8635/13852 [32:24<19:10,  4.53it/s\u001b[A\n",
      "Training loss: 2.66e-02 lr: 1.88e-05:  62%|▌| 8636/13852 [32:24<19:16,  4.51it/s\u001b[A\n",
      "Training loss: 2.59e-02 lr: 1.88e-05:  62%|▌| 8637/13852 [32:24<19:13,  4.52it/s\u001b[A\n",
      "Training loss: 2.40e-02 lr: 1.88e-05:  62%|▌| 8638/13852 [32:24<19:12,  4.52it/s\u001b[A\n",
      "Training loss: 2.72e-02 lr: 1.88e-05:  62%|▌| 8639/13852 [32:24<19:10,  4.53it/s\u001b[A\n",
      "Training loss: 2.46e-02 lr: 1.88e-05:  62%|▌| 8640/13852 [32:25<19:06,  4.55it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 1.88e-05:  62%|▌| 8641/13852 [32:25<19:05,  4.55it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.88e-05:  62%|▌| 8642/13852 [32:25<19:05,  4.55it/s\u001b[A\n",
      "Training loss: 3.08e-02 lr: 1.88e-05:  62%|▌| 8643/13852 [32:25<19:06,  4.54it/s\u001b[A\n",
      "Training loss: 3.12e-02 lr: 1.88e-05:  62%|▌| 8644/13852 [32:26<19:06,  4.54it/s\u001b[A\n",
      "Training loss: 3.65e-02 lr: 1.88e-05:  62%|▌| 8645/13852 [32:26<19:06,  4.54it/s\u001b[A\n",
      "Training loss: 3.46e-02 lr: 1.88e-05:  62%|▌| 8646/13852 [32:26<19:06,  4.54it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 1.88e-05:  62%|▌| 8647/13852 [32:26<19:06,  4.54it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 1.88e-05:  62%|▌| 8648/13852 [32:26<19:04,  4.55it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 1.88e-05:  62%|▌| 8649/13852 [32:27<19:07,  4.54it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 1.88e-05:  62%|▌| 8650/13852 [32:27<19:13,  4.51it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.88e-05:  62%|▌| 8651/13852 [32:27<19:12,  4.51it/s\u001b[A\n",
      "Training loss: 3.30e-02 lr: 1.88e-05:  62%|▌| 8652/13852 [32:27<19:07,  4.53it/s\u001b[A\n",
      "Training loss: 2.34e-02 lr: 1.88e-05:  62%|▌| 8653/13852 [32:27<19:00,  4.56it/s\u001b[A\n",
      "Training loss: 1.90e-02 lr: 1.88e-05:  62%|▌| 8654/13852 [32:28<18:57,  4.57it/s\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.88e-05:  62%|▌| 8655/13852 [32:28<19:02,  4.55it/s\u001b[A\n",
      "Training loss: 7.03e-02 lr: 1.88e-05:  62%|▌| 8656/13852 [32:28<19:06,  4.53it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 1.88e-05:  62%|▌| 8657/13852 [32:28<19:06,  4.53it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 1.87e-05:  63%|▋| 8658/13852 [32:29<19:07,  4.53it/s\u001b[A\n",
      "Training loss: 6.04e-02 lr: 1.87e-05:  63%|▋| 8659/13852 [32:29<19:06,  4.53it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 1.87e-05:  63%|▋| 8660/13852 [32:29<19:07,  4.53it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 1.87e-05:  63%|▋| 8661/13852 [32:29<19:05,  4.53it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 1.87e-05:  63%|▋| 8662/13852 [32:29<19:03,  4.54it/s\u001b[A\n",
      "Training loss: 4.96e-02 lr: 1.87e-05:  63%|▋| 8663/13852 [32:30<19:02,  4.54it/s\u001b[A\n",
      "Training loss: 4.57e-02 lr: 1.87e-05:  63%|▋| 8664/13852 [32:30<19:06,  4.53it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 1.87e-05:  63%|▋| 8665/13852 [32:30<19:04,  4.53it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 1.87e-05:  63%|▋| 8666/13852 [32:30<19:01,  4.54it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 1.87e-05:  63%|▋| 8667/13852 [32:31<18:56,  4.56it/s\u001b[A\n",
      "Training loss: 4.53e-02 lr: 1.87e-05:  63%|▋| 8668/13852 [32:31<19:09,  4.51it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 1.87e-05:  63%|▋| 8669/13852 [32:31<19:20,  4.47it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 1.87e-05:  63%|▋| 8670/13852 [32:31<19:16,  4.48it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 1.87e-05:  63%|▋| 8671/13852 [32:31<19:12,  4.50it/s\u001b[A\n",
      "Training loss: 3.18e-02 lr: 1.87e-05:  63%|▋| 8672/13852 [32:32<19:14,  4.49it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 1.87e-05:  63%|▋| 8673/13852 [32:32<19:09,  4.51it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.87e-05:  63%|▋| 8674/13852 [32:32<19:08,  4.51it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 1.87e-05:  63%|▋| 8675/13852 [32:32<19:06,  4.51it/s\u001b[A\n",
      "Training loss: 3.05e-02 lr: 1.87e-05:  63%|▋| 8676/13852 [32:33<19:06,  4.52it/s\u001b[A\n",
      "Training loss: 3.75e-02 lr: 1.87e-05:  63%|▋| 8677/13852 [32:33<19:06,  4.51it/s\u001b[A\n",
      "Training loss: 3.04e-02 lr: 1.87e-05:  63%|▋| 8678/13852 [32:33<19:09,  4.50it/s\u001b[A\n",
      "Training loss: 7.71e-02 lr: 1.87e-05:  63%|▋| 8679/13852 [32:33<19:02,  4.53it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 1.87e-05:  63%|▋| 8680/13852 [32:33<19:04,  4.52it/s\u001b[A\n",
      "Training loss: 3.94e-02 lr: 1.87e-05:  63%|▋| 8681/13852 [32:34<19:05,  4.52it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 1.87e-05:  63%|▋| 8682/13852 [32:34<19:12,  4.49it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 1.87e-05:  63%|▋| 8683/13852 [32:34<19:08,  4.50it/s\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.87e-05:  63%|▋| 8684/13852 [32:34<19:05,  4.51it/s\u001b[A\n",
      "Training loss: 3.84e-02 lr: 1.87e-05:  63%|▋| 8685/13852 [32:35<19:02,  4.52it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.86e-05:  63%|▋| 8686/13852 [32:35<19:01,  4.53it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 1.86e-05:  63%|▋| 8687/13852 [32:35<18:59,  4.53it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 1.86e-05:  63%|▋| 8688/13852 [32:35<19:01,  4.53it/s\u001b[A\n",
      "Training loss: 3.04e-02 lr: 1.86e-05:  63%|▋| 8689/13852 [32:35<18:59,  4.53it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 1.86e-05:  63%|▋| 8690/13852 [32:36<18:57,  4.54it/s\u001b[A\n",
      "Training loss: 9.76e-02 lr: 1.86e-05:  63%|▋| 8691/13852 [32:36<18:53,  4.55it/s\u001b[A\n",
      "Training loss: 8.60e-02 lr: 1.86e-05:  63%|▋| 8692/13852 [32:36<19:01,  4.52it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 1.86e-05:  63%|▋| 8693/13852 [32:36<18:57,  4.53it/s\u001b[A\n",
      "Training loss: 8.87e-02 lr: 1.86e-05:  63%|▋| 8694/13852 [32:37<18:57,  4.53it/s\u001b[A\n",
      "Training loss: 8.13e-02 lr: 1.86e-05:  63%|▋| 8695/13852 [32:37<19:10,  4.48it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 1.86e-05:  63%|▋| 8696/13852 [32:37<19:07,  4.49it/s\u001b[A\n",
      "Training loss: 5.91e-02 lr: 1.86e-05:  63%|▋| 8697/13852 [32:37<19:06,  4.50it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 1.86e-05:  63%|▋| 8698/13852 [32:37<19:26,  4.42it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 1.86e-05:  63%|▋| 8699/13852 [32:38<19:18,  4.45it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 1.86e-05:  63%|▋| 8700/13852 [32:38<19:10,  4.48it/s\u001b[A\n",
      "Training loss: 3.42e-02 lr: 1.86e-05:  63%|▋| 8701/13852 [32:38<19:06,  4.49it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 1.86e-05:  63%|▋| 8702/13852 [32:38<19:00,  4.52it/s\u001b[A\n",
      "Training loss: 3.84e-02 lr: 1.86e-05:  63%|▋| 8703/13852 [32:39<18:55,  4.54it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 1.86e-05:  63%|▋| 8704/13852 [32:39<18:56,  4.53it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 1.86e-05:  63%|▋| 8705/13852 [32:39<18:56,  4.53it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 1.86e-05:  63%|▋| 8706/13852 [32:39<18:57,  4.52it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.86e-05:  63%|▋| 8707/13852 [32:39<18:56,  4.53it/s\u001b[A\n",
      "Training loss: 5.33e-02 lr: 1.86e-05:  63%|▋| 8708/13852 [32:40<18:57,  4.52it/s\u001b[A\n",
      "Training loss: 3.83e-02 lr: 1.86e-05:  63%|▋| 8709/13852 [32:40<18:57,  4.52it/s\u001b[A\n",
      "Training loss: 3.99e-02 lr: 1.86e-05:  63%|▋| 8710/13852 [32:40<18:57,  4.52it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 1.86e-05:  63%|▋| 8711/13852 [32:40<18:56,  4.52it/s\u001b[A\n",
      "Training loss: 9.81e-02 lr: 1.86e-05:  63%|▋| 8712/13852 [32:41<18:56,  4.52it/s\u001b[A\n",
      "Training loss: 7.95e-02 lr: 1.86e-05:  63%|▋| 8713/13852 [32:41<18:58,  4.51it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 1.85e-05:  63%|▋| 8714/13852 [32:41<18:56,  4.52it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 1.85e-05:  63%|▋| 8715/13852 [32:41<18:51,  4.54it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.85e-05:  63%|▋| 8716/13852 [32:41<18:45,  4.56it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 1.85e-05:  63%|▋| 8717/13852 [32:42<18:56,  4.52it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 1.85e-05:  63%|▋| 8718/13852 [32:42<18:56,  4.52it/s\u001b[A\n",
      "Training loss: 2.37e-02 lr: 1.85e-05:  63%|▋| 8719/13852 [32:42<18:56,  4.51it/s\u001b[A\n",
      "Training loss: 2.45e-02 lr: 1.85e-05:  63%|▋| 8720/13852 [32:42<18:57,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.87e-02 lr: 1.85e-05:  63%|▋| 8721/13852 [32:43<18:56,  4.52it/s\u001b[A\n",
      "Training loss: 3.12e-02 lr: 1.85e-05:  63%|▋| 8722/13852 [32:43<18:53,  4.52it/s\u001b[A\n",
      "Training loss: 2.40e-02 lr: 1.85e-05:  63%|▋| 8723/13852 [32:43<18:52,  4.53it/s\u001b[A\n",
      "Training loss: 1.87e-02 lr: 1.85e-05:  63%|▋| 8724/13852 [32:43<18:54,  4.52it/s\u001b[A\n",
      "Training loss: 3.07e-02 lr: 1.85e-05:  63%|▋| 8725/13852 [32:43<18:53,  4.52it/s\u001b[A\n",
      "Training loss: 3.17e-02 lr: 1.85e-05:  63%|▋| 8726/13852 [32:44<18:50,  4.53it/s\u001b[A\n",
      "Training loss: 2.45e-02 lr: 1.85e-05:  63%|▋| 8727/13852 [32:44<18:48,  4.54it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 1.85e-05:  63%|▋| 8728/13852 [32:44<18:45,  4.55it/s\u001b[A\n",
      "Training loss: 7.78e-02 lr: 1.85e-05:  63%|▋| 8729/13852 [32:44<18:55,  4.51it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 1.85e-05:  63%|▋| 8730/13852 [32:45<18:53,  4.52it/s\u001b[A\n",
      "Training loss: 4.01e-02 lr: 1.85e-05:  63%|▋| 8731/13852 [32:45<18:52,  4.52it/s\u001b[A\n",
      "Training loss: 3.56e-02 lr: 1.85e-05:  63%|▋| 8732/13852 [32:45<18:51,  4.52it/s\u001b[A\n",
      "Training loss: 5.60e-02 lr: 1.85e-05:  63%|▋| 8733/13852 [32:45<18:50,  4.53it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 1.85e-05:  63%|▋| 8734/13852 [32:45<18:54,  4.51it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 1.85e-05:  63%|▋| 8735/13852 [32:46<18:51,  4.52it/s\u001b[A\n",
      "Training loss: 4.05e-02 lr: 1.85e-05:  63%|▋| 8736/13852 [32:46<18:56,  4.50it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 1.85e-05:  63%|▋| 8737/13852 [32:46<18:55,  4.50it/s\u001b[A\n",
      "Training loss: 9.55e-02 lr: 1.85e-05:  63%|▋| 8738/13852 [32:46<18:55,  4.50it/s\u001b[A\n",
      "Training loss: 6.89e-02 lr: 1.85e-05:  63%|▋| 8739/13852 [32:47<18:54,  4.51it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 1.85e-05:  63%|▋| 8740/13852 [32:47<18:55,  4.50it/s\u001b[A\n",
      "Training loss: 6.44e-02 lr: 1.84e-05:  63%|▋| 8741/13852 [32:47<18:49,  4.53it/s\u001b[A\n",
      "Training loss: 6.38e-02 lr: 1.84e-05:  63%|▋| 8742/13852 [32:47<18:49,  4.52it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 1.84e-05:  63%|▋| 8743/13852 [32:47<18:49,  4.52it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 1.84e-05:  63%|▋| 8744/13852 [32:48<18:48,  4.52it/s\u001b[A\n",
      "Training loss: 9.60e-02 lr: 1.84e-05:  63%|▋| 8745/13852 [32:48<18:46,  4.54it/s\u001b[A\n",
      "Training loss: 9.73e-02 lr: 1.84e-05:  63%|▋| 8746/13852 [32:48<18:51,  4.51it/s\u001b[A\n",
      "Training loss: 8.62e-02 lr: 1.84e-05:  63%|▋| 8747/13852 [32:48<18:49,  4.52it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 1.84e-05:  63%|▋| 8748/13852 [32:49<18:49,  4.52it/s\u001b[A\n",
      "Training loss: 4.86e-02 lr: 1.84e-05:  63%|▋| 8749/13852 [32:49<18:50,  4.51it/s\u001b[A\n",
      "Training loss: 3.80e-02 lr: 1.84e-05:  63%|▋| 8750/13852 [32:49<19:31,  4.35it/s\u001b[A\n",
      "Training loss: 2.98e-02 lr: 1.84e-05:  63%|▋| 8751/13852 [32:49<19:53,  4.27it/s\u001b[A\n",
      "Training loss: 2.53e-02 lr: 1.84e-05:  63%|▋| 8752/13852 [32:49<20:09,  4.22it/s\u001b[A\n",
      "Training loss: 2.75e-02 lr: 1.84e-05:  63%|▋| 8753/13852 [32:50<19:46,  4.30it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 1.84e-05:  63%|▋| 8754/13852 [32:50<19:47,  4.29it/s\u001b[A\n",
      "Training loss: 3.43e-02 lr: 1.84e-05:  63%|▋| 8755/13852 [32:50<19:31,  4.35it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 1.84e-05:  63%|▋| 8756/13852 [32:50<19:20,  4.39it/s\u001b[A\n",
      "Training loss: 3.49e-02 lr: 1.84e-05:  63%|▋| 8757/13852 [32:51<19:11,  4.42it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 1.84e-05:  63%|▋| 8758/13852 [32:51<19:19,  4.39it/s\u001b[A\n",
      "Training loss: 2.94e-02 lr: 1.84e-05:  63%|▋| 8759/13852 [32:51<19:07,  4.44it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 1.84e-05:  63%|▋| 8760/13852 [32:51<19:06,  4.44it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 1.84e-05:  63%|▋| 8761/13852 [32:52<19:07,  4.44it/s\u001b[A\n",
      "Training loss: 9.97e-02 lr: 1.84e-05:  63%|▋| 8762/13852 [32:52<19:09,  4.43it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 1.84e-05:  63%|▋| 8763/13852 [32:52<19:03,  4.45it/s\u001b[A\n",
      "Training loss: 9.37e-02 lr: 1.84e-05:  63%|▋| 8764/13852 [32:52<18:57,  4.47it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 1.84e-05:  63%|▋| 8765/13852 [32:52<18:54,  4.48it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 1.84e-05:  63%|▋| 8766/13852 [32:53<18:52,  4.49it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 1.84e-05:  63%|▋| 8767/13852 [32:53<18:53,  4.49it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.84e-05:  63%|▋| 8768/13852 [32:53<18:49,  4.50it/s\u001b[A\n",
      "Training loss: 9.95e-02 lr: 1.83e-05:  63%|▋| 8769/13852 [32:53<18:47,  4.51it/s\u001b[A\n",
      "Training loss: 9.49e-02 lr: 1.83e-05:  63%|▋| 8770/13852 [32:54<18:39,  4.54it/s\u001b[A\n",
      "Training loss: 8.12e-02 lr: 1.83e-05:  63%|▋| 8771/13852 [32:54<18:41,  4.53it/s\u001b[A\n",
      "Training loss: 6.12e-02 lr: 1.83e-05:  63%|▋| 8772/13852 [32:54<19:03,  4.44it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 1.83e-05:  63%|▋| 8773/13852 [32:54<18:57,  4.47it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 1.83e-05:  63%|▋| 8774/13852 [32:54<18:51,  4.49it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 1.83e-05:  63%|▋| 8775/13852 [32:55<18:52,  4.48it/s\u001b[A\n",
      "Training loss: 8.98e-02 lr: 1.83e-05:  63%|▋| 8776/13852 [32:55<18:49,  4.49it/s\u001b[A\n",
      "Training loss: 7.28e-02 lr: 1.83e-05:  63%|▋| 8777/13852 [32:55<18:49,  4.49it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 1.83e-05:  63%|▋| 8778/13852 [32:55<18:48,  4.50it/s\u001b[A\n",
      "Training loss: 8.98e-02 lr: 1.83e-05:  63%|▋| 8779/13852 [32:56<18:45,  4.51it/s\u001b[A\n",
      "Training loss: 7.22e-02 lr: 1.83e-05:  63%|▋| 8780/13852 [32:56<18:47,  4.50it/s\u001b[A\n",
      "Training loss: 6.35e-02 lr: 1.83e-05:  63%|▋| 8781/13852 [32:56<18:40,  4.52it/s\u001b[A\n",
      "Training loss: 6.19e-02 lr: 1.83e-05:  63%|▋| 8782/13852 [32:56<18:36,  4.54it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 1.83e-05:  63%|▋| 8783/13852 [32:56<18:45,  4.50it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 1.83e-05:  63%|▋| 8784/13852 [32:57<18:44,  4.51it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 1.83e-05:  63%|▋| 8785/13852 [32:57<18:52,  4.47it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 1.83e-05:  63%|▋| 8786/13852 [32:57<18:49,  4.48it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.83e-05:  63%|▋| 8787/13852 [32:57<18:46,  4.49it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 1.83e-05:  63%|▋| 8788/13852 [32:58<18:48,  4.49it/s\u001b[A\n",
      "Training loss: 7.18e-02 lr: 1.83e-05:  63%|▋| 8789/13852 [32:58<18:46,  4.50it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 1.83e-05:  63%|▋| 8790/13852 [32:58<18:43,  4.51it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 1.83e-05:  63%|▋| 8791/13852 [32:58<18:42,  4.51it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 1.83e-05:  63%|▋| 8792/13852 [32:58<18:41,  4.51it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 1.83e-05:  63%|▋| 8793/13852 [32:59<18:36,  4.53it/s\u001b[A\n",
      "Training loss: 9.73e-02 lr: 1.83e-05:  63%|▋| 8794/13852 [32:59<18:32,  4.55it/s\u001b[A\n",
      "Training loss: 7.05e-02 lr: 1.83e-05:  63%|▋| 8795/13852 [32:59<18:30,  4.56it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 1.83e-05:  63%|▋| 8796/13852 [32:59<18:34,  4.54it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 1.82e-05:  64%|▋| 8797/13852 [33:00<18:34,  4.53it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 1.82e-05:  64%|▋| 8798/13852 [33:00<18:35,  4.53it/s\u001b[A\n",
      "Training loss: 1.17e-01 lr: 1.82e-05:  64%|▋| 8799/13852 [33:00<18:33,  4.54it/s\u001b[A\n",
      "Training loss: 1.71e-01 lr: 1.82e-05:  64%|▋| 8800/13852 [33:00<18:35,  4.53it/s\u001b[A\n",
      "Training loss: 1.25e-01 lr: 1.82e-05:  64%|▋| 8801/13852 [33:00<18:42,  4.50it/s\u001b[A\n",
      "Training loss: 1.39e-01 lr: 1.82e-05:  64%|▋| 8802/13852 [33:01<18:41,  4.50it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 1.82e-05:  64%|▋| 8803/13852 [33:01<18:49,  4.47it/s\u001b[A\n",
      "Training loss: 8.36e-02 lr: 1.82e-05:  64%|▋| 8804/13852 [33:01<18:50,  4.47it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 1.82e-05:  64%|▋| 8805/13852 [33:01<18:42,  4.50it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 1.82e-05:  64%|▋| 8806/13852 [33:02<18:34,  4.53it/s\u001b[A\n",
      "Training loss: 4.29e-02 lr: 1.82e-05:  64%|▋| 8807/13852 [33:02<18:35,  4.52it/s\u001b[A\n",
      "Training loss: 3.78e-02 lr: 1.82e-05:  64%|▋| 8808/13852 [33:02<18:40,  4.50it/s\u001b[A\n",
      "Training loss: 2.94e-02 lr: 1.82e-05:  64%|▋| 8809/13852 [33:02<18:38,  4.51it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 1.82e-05:  64%|▋| 8810/13852 [33:02<18:37,  4.51it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.82e-05:  64%|▋| 8811/13852 [33:03<18:35,  4.52it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 1.82e-05:  64%|▋| 8812/13852 [33:03<18:41,  4.49it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 1.82e-05:  64%|▋| 8813/13852 [33:03<18:44,  4.48it/s\u001b[A\n",
      "Training loss: 5.01e-02 lr: 1.82e-05:  64%|▋| 8814/13852 [33:03<18:42,  4.49it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 1.82e-05:  64%|▋| 8815/13852 [33:04<18:40,  4.50it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 1.82e-05:  64%|▋| 8816/13852 [33:04<18:38,  4.50it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 1.82e-05:  64%|▋| 8817/13852 [33:04<18:33,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.07e-02 lr: 1.82e-05:  64%|▋| 8818/13852 [33:04<19:03,  4.40it/s\u001b[A\n",
      "Training loss: 7.76e-02 lr: 1.82e-05:  64%|▋| 8819/13852 [33:04<19:33,  4.29it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 1.82e-05:  64%|▋| 8820/13852 [33:05<19:59,  4.20it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 1.82e-05:  64%|▋| 8821/13852 [33:05<19:46,  4.24it/s\u001b[A\n",
      "Training loss: 4.74e-02 lr: 1.82e-05:  64%|▋| 8822/13852 [33:05<19:29,  4.30it/s\u001b[A\n",
      "Training loss: 3.62e-02 lr: 1.82e-05:  64%|▋| 8823/13852 [33:05<19:12,  4.36it/s\u001b[A\n",
      "Training loss: 9.48e-02 lr: 1.82e-05:  64%|▋| 8824/13852 [33:06<19:07,  4.38it/s\u001b[A\n",
      "Training loss: 7.19e-02 lr: 1.81e-05:  64%|▋| 8825/13852 [33:06<18:56,  4.42it/s\u001b[A\n",
      "Training loss: 8.03e-02 lr: 1.81e-05:  64%|▋| 8826/13852 [33:06<18:49,  4.45it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 1.81e-05:  64%|▋| 8827/13852 [33:06<18:44,  4.47it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 1.81e-05:  64%|▋| 8828/13852 [33:06<18:39,  4.49it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 1.81e-05:  64%|▋| 8829/13852 [33:07<18:45,  4.46it/s\u001b[A\n",
      "Training loss: 4.57e-02 lr: 1.81e-05:  64%|▋| 8830/13852 [33:07<19:14,  4.35it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 1.81e-05:  64%|▋| 8831/13852 [33:07<19:39,  4.26it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.81e-05:  64%|▋| 8832/13852 [33:07<19:47,  4.23it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 1.81e-05:  64%|▋| 8833/13852 [33:08<19:19,  4.33it/s\u001b[A\n",
      "Training loss: 4.55e-02 lr: 1.81e-05:  64%|▋| 8834/13852 [33:08<18:57,  4.41it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 1.81e-05:  64%|▋| 8835/13852 [33:08<18:57,  4.41it/s\u001b[A\n",
      "Training loss: 7.93e-02 lr: 1.81e-05:  64%|▋| 8836/13852 [33:08<18:48,  4.44it/s\u001b[A\n",
      "Training loss: 9.17e-02 lr: 1.81e-05:  64%|▋| 8837/13852 [33:09<18:40,  4.48it/s\u001b[A\n",
      "Training loss: 7.04e-02 lr: 1.81e-05:  64%|▋| 8838/13852 [33:09<18:34,  4.50it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 1.81e-05:  64%|▋| 8839/13852 [33:09<18:36,  4.49it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 1.81e-05:  64%|▋| 8840/13852 [33:09<18:31,  4.51it/s\u001b[A\n",
      "Training loss: 3.17e-02 lr: 1.81e-05:  64%|▋| 8841/13852 [33:09<18:30,  4.51it/s\u001b[A\n",
      "Training loss: 2.77e-02 lr: 1.81e-05:  64%|▋| 8842/13852 [33:10<18:29,  4.51it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 1.81e-05:  64%|▋| 8843/13852 [33:10<18:30,  4.51it/s\u001b[A\n",
      "Training loss: 5.09e-02 lr: 1.81e-05:  64%|▋| 8844/13852 [33:10<18:29,  4.51it/s\u001b[A\n",
      "Training loss: 4.03e-02 lr: 1.81e-05:  64%|▋| 8845/13852 [33:10<18:23,  4.54it/s\u001b[A\n",
      "Training loss: 3.30e-02 lr: 1.81e-05:  64%|▋| 8846/13852 [33:11<18:18,  4.56it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 1.81e-05:  64%|▋| 8847/13852 [33:11<18:21,  4.55it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 1.81e-05:  64%|▋| 8848/13852 [33:11<18:27,  4.52it/s\u001b[A\n",
      "Training loss: 3.54e-02 lr: 1.81e-05:  64%|▋| 8849/13852 [33:11<18:26,  4.52it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 1.81e-05:  64%|▋| 8850/13852 [33:11<18:27,  4.52it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 1.81e-05:  64%|▋| 8851/13852 [33:12<18:24,  4.53it/s\u001b[A\n",
      "Training loss: 8.30e-02 lr: 1.80e-05:  64%|▋| 8852/13852 [33:12<18:30,  4.50it/s\u001b[A\n",
      "Training loss: 6.36e-02 lr: 1.80e-05:  64%|▋| 8853/13852 [33:12<18:31,  4.50it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 1.80e-05:  64%|▋| 8854/13852 [33:12<18:29,  4.50it/s\u001b[A\n",
      "Training loss: 6.90e-02 lr: 1.80e-05:  64%|▋| 8855/13852 [33:13<18:28,  4.51it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.80e-05:  64%|▋| 8856/13852 [33:13<18:28,  4.51it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.80e-05:  64%|▋| 8857/13852 [33:13<18:27,  4.51it/s\u001b[A\n",
      "Training loss: 8.95e-02 lr: 1.80e-05:  64%|▋| 8858/13852 [33:13<18:21,  4.54it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 1.80e-05:  64%|▋| 8859/13852 [33:13<18:17,  4.55it/s\u001b[A\n",
      "Training loss: 4.90e-02 lr: 1.80e-05:  64%|▋| 8860/13852 [33:14<18:22,  4.53it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 1.80e-05:  64%|▋| 8861/13852 [33:14<18:22,  4.53it/s\u001b[A\n",
      "Training loss: 3.50e-02 lr: 1.80e-05:  64%|▋| 8862/13852 [33:14<18:22,  4.52it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.80e-05:  64%|▋| 8863/13852 [33:14<18:51,  4.41it/s\u001b[A\n",
      "Training loss: 4.66e-02 lr: 1.80e-05:  64%|▋| 8864/13852 [33:15<19:05,  4.35it/s\u001b[A\n",
      "Training loss: 9.20e-02 lr: 1.80e-05:  64%|▋| 8865/13852 [33:15<18:52,  4.40it/s\u001b[A\n",
      "Training loss: 6.69e-02 lr: 1.80e-05:  64%|▋| 8866/13852 [33:15<18:43,  4.44it/s\u001b[A\n",
      "Training loss: 7.30e-02 lr: 1.80e-05:  64%|▋| 8867/13852 [33:15<18:38,  4.46it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 1.80e-05:  64%|▋| 8868/13852 [33:15<18:33,  4.48it/s\u001b[A\n",
      "Training loss: 5.96e-02 lr: 1.80e-05:  64%|▋| 8869/13852 [33:16<18:25,  4.51it/s\u001b[A\n",
      "Training loss: 4.22e-02 lr: 1.80e-05:  64%|▋| 8870/13852 [33:16<18:27,  4.50it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 1.80e-05:  64%|▋| 8871/13852 [33:16<18:26,  4.50it/s\u001b[A\n",
      "Training loss: 3.36e-02 lr: 1.80e-05:  64%|▋| 8872/13852 [33:16<18:23,  4.51it/s\u001b[A\n",
      "Training loss: 3.25e-02 lr: 1.80e-05:  64%|▋| 8873/13852 [33:17<18:21,  4.52it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 1.80e-05:  64%|▋| 8874/13852 [33:17<18:26,  4.50it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 1.80e-05:  64%|▋| 8875/13852 [33:17<18:24,  4.51it/s\u001b[A\n",
      "Training loss: 5.76e-02 lr: 1.80e-05:  64%|▋| 8876/13852 [33:17<18:25,  4.50it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 1.80e-05:  64%|▋| 8877/13852 [33:17<18:23,  4.51it/s\u001b[A\n",
      "Training loss: 4.05e-02 lr: 1.80e-05:  64%|▋| 8878/13852 [33:18<18:22,  4.51it/s\u001b[A\n",
      "Training loss: 4.57e-02 lr: 1.80e-05:  64%|▋| 8879/13852 [33:18<18:22,  4.51it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 1.79e-05:  64%|▋| 8880/13852 [33:18<18:18,  4.52it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 1.79e-05:  64%|▋| 8881/13852 [33:18<18:12,  4.55it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 1.79e-05:  64%|▋| 8882/13852 [33:19<18:07,  4.57it/s\u001b[A\n",
      "Training loss: 8.10e-02 lr: 1.79e-05:  64%|▋| 8883/13852 [33:19<18:03,  4.59it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 1.79e-05:  64%|▋| 8884/13852 [33:19<18:08,  4.56it/s\u001b[A\n",
      "Training loss: 7.15e-02 lr: 1.79e-05:  64%|▋| 8885/13852 [33:19<18:11,  4.55it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 1.79e-05:  64%|▋| 8886/13852 [33:19<18:12,  4.55it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 1.79e-05:  64%|▋| 8887/13852 [33:20<18:11,  4.55it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.79e-05:  64%|▋| 8888/13852 [33:20<18:14,  4.54it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 1.79e-05:  64%|▋| 8889/13852 [33:20<18:15,  4.53it/s\u001b[A\n",
      "Training loss: 3.68e-02 lr: 1.79e-05:  64%|▋| 8890/13852 [33:20<18:17,  4.52it/s\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.79e-05:  64%|▋| 8891/13852 [33:20<18:17,  4.52it/s\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.79e-05:  64%|▋| 8892/13852 [33:21<18:19,  4.51it/s\u001b[A\n",
      "Training loss: 3.33e-02 lr: 1.79e-05:  64%|▋| 8893/13852 [33:21<18:22,  4.50it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 1.79e-05:  64%|▋| 8894/13852 [33:21<18:15,  4.52it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 1.79e-05:  64%|▋| 8895/13852 [33:21<18:12,  4.54it/s\u001b[A\n",
      "Training loss: 3.90e-02 lr: 1.79e-05:  64%|▋| 8896/13852 [33:22<18:18,  4.51it/s\u001b[A\n",
      "Training loss: 3.56e-02 lr: 1.79e-05:  64%|▋| 8897/13852 [33:22<18:21,  4.50it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 1.79e-05:  64%|▋| 8898/13852 [33:22<18:18,  4.51it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 1.79e-05:  64%|▋| 8899/13852 [33:22<18:16,  4.52it/s\u001b[A\n",
      "Training loss: 5.14e-02 lr: 1.79e-05:  64%|▋| 8900/13852 [33:22<18:16,  4.52it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 1.79e-05:  64%|▋| 8901/13852 [33:23<18:15,  4.52it/s\u001b[A\n",
      "Training loss: 3.69e-02 lr: 1.79e-05:  64%|▋| 8902/13852 [33:23<18:15,  4.52it/s\u001b[A\n",
      "Training loss: 3.14e-02 lr: 1.79e-05:  64%|▋| 8903/13852 [33:23<18:15,  4.52it/s\u001b[A\n",
      "Training loss: 4.60e-02 lr: 1.79e-05:  64%|▋| 8904/13852 [33:23<18:15,  4.52it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 1.79e-05:  64%|▋| 8905/13852 [33:24<18:12,  4.53it/s\u001b[A\n",
      "Training loss: 7.44e-02 lr: 1.79e-05:  64%|▋| 8906/13852 [33:24<18:08,  4.54it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 1.79e-05:  64%|▋| 8907/13852 [33:24<18:04,  4.56it/s\u001b[A\n",
      "Training loss: 8.98e-02 lr: 1.78e-05:  64%|▋| 8908/13852 [33:24<18:03,  4.56it/s\u001b[A\n",
      "Training loss: 6.84e-02 lr: 1.78e-05:  64%|▋| 8909/13852 [33:24<18:03,  4.56it/s\u001b[A\n",
      "Training loss: 5.64e-02 lr: 1.78e-05:  64%|▋| 8910/13852 [33:25<18:06,  4.55it/s\u001b[A\n",
      "Training loss: 4.22e-02 lr: 1.78e-05:  64%|▋| 8911/13852 [33:25<18:09,  4.53it/s\u001b[A\n",
      "Training loss: 3.22e-02 lr: 1.78e-05:  64%|▋| 8912/13852 [33:25<18:11,  4.52it/s\u001b[A\n",
      "Training loss: 2.63e-02 lr: 1.78e-05:  64%|▋| 8913/13852 [33:25<18:13,  4.52it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.78e-05:  64%|▋| 8914/13852 [33:26<18:14,  4.51it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.26e-02 lr: 1.78e-05:  64%|▋| 8915/13852 [33:26<18:15,  4.51it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 1.78e-05:  64%|▋| 8916/13852 [33:26<18:15,  4.51it/s\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.78e-05:  64%|▋| 8917/13852 [33:26<18:15,  4.51it/s\u001b[A\n",
      "Training loss: 3.02e-02 lr: 1.78e-05:  64%|▋| 8918/13852 [33:26<18:15,  4.50it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 1.78e-05:  64%|▋| 8919/13852 [33:27<18:11,  4.52it/s\u001b[A\n",
      "Training loss: 2.60e-02 lr: 1.78e-05:  64%|▋| 8920/13852 [33:27<18:06,  4.54it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 1.78e-05:  64%|▋| 8921/13852 [33:27<18:02,  4.56it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 1.78e-05:  64%|▋| 8922/13852 [33:27<18:07,  4.53it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 1.78e-05:  64%|▋| 8923/13852 [33:28<18:06,  4.53it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 1.78e-05:  64%|▋| 8924/13852 [33:28<18:09,  4.52it/s\u001b[A\n",
      "Training loss: 6.21e-02 lr: 1.78e-05:  64%|▋| 8925/13852 [33:28<18:10,  4.52it/s\u001b[A\n",
      "Training loss: 7.26e-02 lr: 1.78e-05:  64%|▋| 8926/13852 [33:28<18:37,  4.41it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 1.78e-05:  64%|▋| 8927/13852 [33:28<19:06,  4.30it/s\u001b[A\n",
      "Training loss: 4.03e-02 lr: 1.78e-05:  64%|▋| 8928/13852 [33:29<19:24,  4.23it/s\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.78e-05:  64%|▋| 8929/13852 [33:29<19:23,  4.23it/s\u001b[A\n",
      "Training loss: 2.53e-02 lr: 1.78e-05:  64%|▋| 8930/13852 [33:29<19:03,  4.30it/s\u001b[A\n",
      "Training loss: 1.95e-02 lr: 1.78e-05:  64%|▋| 8931/13852 [33:29<18:47,  4.37it/s\u001b[A\n",
      "Training loss: 2.32e-02 lr: 1.78e-05:  64%|▋| 8932/13852 [33:30<18:34,  4.41it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 1.78e-05:  64%|▋| 8933/13852 [33:30<18:32,  4.42it/s\u001b[A\n",
      "Training loss: 4.26e-02 lr: 1.78e-05:  64%|▋| 8934/13852 [33:30<18:31,  4.43it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 1.77e-05:  65%|▋| 8935/13852 [33:30<18:27,  4.44it/s\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.77e-05:  65%|▋| 8936/13852 [33:31<18:28,  4.43it/s\u001b[A\n",
      "Training loss: 3.04e-02 lr: 1.77e-05:  65%|▋| 8937/13852 [33:31<18:25,  4.45it/s\u001b[A\n",
      "Training loss: 2.22e-02 lr: 1.77e-05:  65%|▋| 8938/13852 [33:31<18:23,  4.45it/s\u001b[A\n",
      "Training loss: 1.76e-02 lr: 1.77e-05:  65%|▋| 8939/13852 [33:31<18:14,  4.49it/s\u001b[A\n",
      "Training loss: 7.32e-02 lr: 1.77e-05:  65%|▋| 8940/13852 [33:31<18:21,  4.46it/s\u001b[A\n",
      "Training loss: 9.69e-02 lr: 1.77e-05:  65%|▋| 8941/13852 [33:32<18:18,  4.47it/s\u001b[A\n",
      "Training loss: 7.87e-02 lr: 1.77e-05:  65%|▋| 8942/13852 [33:32<18:15,  4.48it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 1.77e-05:  65%|▋| 8943/13852 [33:32<18:16,  4.48it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 1.77e-05:  65%|▋| 8944/13852 [33:32<18:14,  4.48it/s\u001b[A\n",
      "Training loss: 4.38e-02 lr: 1.77e-05:  65%|▋| 8945/13852 [33:33<18:12,  4.49it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 1.77e-05:  65%|▋| 8946/13852 [33:33<18:11,  4.49it/s\u001b[A\n",
      "Training loss: 2.81e-02 lr: 1.77e-05:  65%|▋| 8947/13852 [33:33<18:19,  4.46it/s\u001b[A\n",
      "Training loss: 2.18e-02 lr: 1.77e-05:  65%|▋| 8948/13852 [33:33<18:21,  4.45it/s\u001b[A\n",
      "Training loss: 2.33e-02 lr: 1.77e-05:  65%|▋| 8949/13852 [33:33<18:13,  4.48it/s\u001b[A\n",
      "Training loss: 6.28e-02 lr: 1.77e-05:  65%|▋| 8950/13852 [33:34<18:05,  4.51it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 1.77e-05:  65%|▋| 8951/13852 [33:34<18:09,  4.50it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 1.77e-05:  65%|▋| 8952/13852 [33:34<18:10,  4.49it/s\u001b[A\n",
      "Training loss: 3.05e-02 lr: 1.77e-05:  65%|▋| 8953/13852 [33:34<18:13,  4.48it/s\u001b[A\n",
      "Training loss: 3.73e-02 lr: 1.77e-05:  65%|▋| 8954/13852 [33:35<18:09,  4.50it/s\u001b[A\n",
      "Training loss: 5.93e-02 lr: 1.77e-05:  65%|▋| 8955/13852 [33:35<18:12,  4.48it/s\u001b[A\n",
      "Training loss: 4.79e-02 lr: 1.77e-05:  65%|▋| 8956/13852 [33:35<18:10,  4.49it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 1.77e-05:  65%|▋| 8957/13852 [33:35<18:09,  4.49it/s\u001b[A\n",
      "Training loss: 7.41e-02 lr: 1.77e-05:  65%|▋| 8958/13852 [33:35<18:09,  4.49it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 1.77e-05:  65%|▋| 8959/13852 [33:36<18:13,  4.47it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 1.77e-05:  65%|▋| 8960/13852 [33:36<18:07,  4.50it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 1.77e-05:  65%|▋| 8961/13852 [33:36<18:00,  4.52it/s\u001b[A\n",
      "Training loss: 2.94e-02 lr: 1.77e-05:  65%|▋| 8962/13852 [33:36<17:56,  4.54it/s\u001b[A\n",
      "Training loss: 2.41e-02 lr: 1.76e-05:  65%|▋| 8963/13852 [33:37<18:06,  4.50it/s\u001b[A\n",
      "Training loss: 1.88e-02 lr: 1.76e-05:  65%|▋| 8964/13852 [33:37<18:16,  4.46it/s\u001b[A\n",
      "Training loss: 4.45e-02 lr: 1.76e-05:  65%|▋| 8965/13852 [33:37<18:17,  4.45it/s\u001b[A\n",
      "Training loss: 4.21e-02 lr: 1.76e-05:  65%|▋| 8966/13852 [33:37<18:17,  4.45it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 1.76e-05:  65%|▋| 8967/13852 [33:37<18:21,  4.44it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 1.76e-05:  65%|▋| 8968/13852 [33:38<18:16,  4.45it/s\u001b[A\n",
      "Training loss: 9.10e-02 lr: 1.76e-05:  65%|▋| 8969/13852 [33:38<18:12,  4.47it/s\u001b[A\n",
      "Training loss: 7.28e-02 lr: 1.76e-05:  65%|▋| 8970/13852 [33:38<18:11,  4.47it/s\u001b[A\n",
      "Training loss: 6.82e-02 lr: 1.76e-05:  65%|▋| 8971/13852 [33:38<18:08,  4.48it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 1.76e-05:  65%|▋| 8972/13852 [33:39<18:00,  4.52it/s\u001b[A\n",
      "Training loss: 3.98e-02 lr: 1.76e-05:  65%|▋| 8973/13852 [33:39<17:54,  4.54it/s\u001b[A\n",
      "Training loss: 6.37e-02 lr: 1.76e-05:  65%|▋| 8974/13852 [33:39<17:50,  4.56it/s\u001b[A\n",
      "Training loss: 8.47e-02 lr: 1.76e-05:  65%|▋| 8975/13852 [33:39<17:53,  4.54it/s\u001b[A\n",
      "Training loss: 6.01e-02 lr: 1.76e-05:  65%|▋| 8976/13852 [33:39<17:55,  4.53it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 1.76e-05:  65%|▋| 8977/13852 [33:40<17:56,  4.53it/s\u001b[A\n",
      "Training loss: 3.25e-02 lr: 1.76e-05:  65%|▋| 8978/13852 [33:40<17:57,  4.52it/s\u001b[A\n",
      "Training loss: 2.65e-02 lr: 1.76e-05:  65%|▋| 8979/13852 [33:40<18:02,  4.50it/s\u001b[A\n",
      "Training loss: 4.06e-02 lr: 1.76e-05:  65%|▋| 8980/13852 [33:40<18:00,  4.51it/s\u001b[A\n",
      "Training loss: 3.42e-02 lr: 1.76e-05:  65%|▋| 8981/13852 [33:41<18:00,  4.51it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 1.76e-05:  65%|▋| 8982/13852 [33:41<18:02,  4.50it/s\u001b[A\n",
      "Training loss: 2.99e-02 lr: 1.76e-05:  65%|▋| 8983/13852 [33:41<18:02,  4.50it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 1.76e-05:  65%|▋| 8984/13852 [33:41<17:58,  4.52it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 1.76e-05:  65%|▋| 8985/13852 [33:41<17:53,  4.54it/s\u001b[A\n",
      "Training loss: 9.96e-02 lr: 1.76e-05:  65%|▋| 8986/13852 [33:42<17:49,  4.55it/s\u001b[A\n",
      "Training loss: 1.45e-01 lr: 1.76e-05:  65%|▋| 8987/13852 [33:42<17:59,  4.51it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 1.76e-05:  65%|▋| 8988/13852 [33:42<17:59,  4.50it/s\u001b[A\n",
      "Training loss: 1.70e-01 lr: 1.76e-05:  65%|▋| 8989/13852 [33:42<17:58,  4.51it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 1.76e-05:  65%|▋| 8990/13852 [33:43<17:58,  4.51it/s\u001b[A\n",
      "Training loss: 1.49e-01 lr: 1.75e-05:  65%|▋| 8991/13852 [33:43<17:59,  4.50it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.75e-05:  65%|▋| 8992/13852 [33:43<17:59,  4.50it/s\u001b[A\n",
      "Training loss: 9.49e-02 lr: 1.75e-05:  65%|▋| 8993/13852 [33:43<18:00,  4.50it/s\u001b[A\n",
      "Training loss: 9.21e-02 lr: 1.75e-05:  65%|▋| 8994/13852 [33:43<18:02,  4.49it/s\u001b[A\n",
      "Training loss: 6.91e-02 lr: 1.75e-05:  65%|▋| 8995/13852 [33:44<18:03,  4.48it/s\u001b[A\n",
      "Training loss: 6.38e-02 lr: 1.75e-05:  65%|▋| 8996/13852 [33:44<17:59,  4.50it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 1.75e-05:  65%|▋| 8997/13852 [33:44<17:54,  4.52it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 1.75e-05:  65%|▋| 8998/13852 [33:44<18:08,  4.46it/s\u001b[A\n",
      "Training loss: 4.72e-02 lr: 1.75e-05:  65%|▋| 8999/13852 [33:45<18:02,  4.48it/s\u001b[A\n",
      "Training loss: 3.46e-02 lr: 1.75e-05:  65%|▋| 9000/13852 [33:45<17:59,  4.50it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 1.75e-05:  65%|▋| 9001/13852 [33:45<17:56,  4.51it/s\u001b[A\n",
      "Training loss: 8.55e-02 lr: 1.75e-05:  65%|▋| 9002/13852 [33:45<17:55,  4.51it/s\u001b[A\n",
      "Training loss: 6.46e-02 lr: 1.75e-05:  65%|▋| 9003/13852 [33:45<17:56,  4.50it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 1.75e-05:  65%|▋| 9004/13852 [33:46<17:56,  4.50it/s\u001b[A\n",
      "Training loss: 4.29e-02 lr: 1.75e-05:  65%|▋| 9005/13852 [33:46<17:56,  4.50it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 1.75e-05:  65%|▋| 9006/13852 [33:46<17:57,  4.50it/s\u001b[A\n",
      "Training loss: 3.45e-02 lr: 1.75e-05:  65%|▋| 9007/13852 [33:46<17:53,  4.51it/s\u001b[A\n",
      "Training loss: 2.59e-02 lr: 1.75e-05:  65%|▋| 9008/13852 [33:47<17:51,  4.52it/s\u001b[A\n",
      "Training loss: 2.13e-02 lr: 1.75e-05:  65%|▋| 9009/13852 [33:47<17:54,  4.51it/s\u001b[A\n",
      "Training loss: 1.59e-02 lr: 1.75e-05:  65%|▋| 9010/13852 [33:47<17:48,  4.53it/s\u001b[A\n",
      "Training loss: 1.76e-02 lr: 1.75e-05:  65%|▋| 9011/13852 [33:47<17:47,  4.53it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.68e-02 lr: 1.75e-05:  65%|▋| 9012/13852 [33:47<17:48,  4.53it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 1.75e-05:  65%|▋| 9013/13852 [33:48<17:49,  4.52it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 1.75e-05:  65%|▋| 9014/13852 [33:48<17:51,  4.52it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 1.75e-05:  65%|▋| 9015/13852 [33:48<17:58,  4.49it/s\u001b[A\n",
      "Training loss: 3.77e-02 lr: 1.75e-05:  65%|▋| 9016/13852 [33:48<17:57,  4.49it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 1.75e-05:  65%|▋| 9017/13852 [33:49<17:57,  4.49it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 1.75e-05:  65%|▋| 9018/13852 [33:49<17:56,  4.49it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 1.74e-05:  65%|▋| 9019/13852 [33:49<17:59,  4.48it/s\u001b[A\n",
      "Training loss: 2.65e-02 lr: 1.74e-05:  65%|▋| 9020/13852 [33:49<17:53,  4.50it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 1.74e-05:  65%|▋| 9021/13852 [33:49<17:46,  4.53it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 1.74e-05:  65%|▋| 9022/13852 [33:50<17:45,  4.53it/s\u001b[A\n",
      "Training loss: 3.16e-02 lr: 1.74e-05:  65%|▋| 9023/13852 [33:50<17:46,  4.53it/s\u001b[A\n",
      "Training loss: 2.97e-02 lr: 1.74e-05:  65%|▋| 9024/13852 [33:50<17:50,  4.51it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 1.74e-05:  65%|▋| 9025/13852 [33:50<17:52,  4.50it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 1.74e-05:  65%|▋| 9026/13852 [33:51<17:51,  4.51it/s\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.74e-05:  65%|▋| 9027/13852 [33:51<17:54,  4.49it/s\u001b[A\n",
      "Training loss: 5.38e-02 lr: 1.74e-05:  65%|▋| 9028/13852 [33:51<17:57,  4.48it/s\u001b[A\n",
      "Training loss: 3.83e-02 lr: 1.74e-05:  65%|▋| 9029/13852 [33:51<17:54,  4.49it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 1.74e-05:  65%|▋| 9030/13852 [33:51<17:54,  4.49it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 1.74e-05:  65%|▋| 9031/13852 [33:52<17:54,  4.49it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 1.74e-05:  65%|▋| 9032/13852 [33:52<17:50,  4.50it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 1.74e-05:  65%|▋| 9033/13852 [33:52<17:45,  4.52it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 1.74e-05:  65%|▋| 9034/13852 [33:52<17:52,  4.49it/s\u001b[A\n",
      "Training loss: 5.98e-02 lr: 1.74e-05:  65%|▋| 9035/13852 [33:53<17:52,  4.49it/s\u001b[A\n",
      "Training loss: 7.01e-02 lr: 1.74e-05:  65%|▋| 9036/13852 [33:53<17:50,  4.50it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 1.74e-05:  65%|▋| 9037/13852 [33:53<17:50,  4.50it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 1.74e-05:  65%|▋| 9038/13852 [33:53<17:51,  4.49it/s\u001b[A\n",
      "Training loss: 2.95e-02 lr: 1.74e-05:  65%|▋| 9039/13852 [33:53<17:50,  4.50it/s\u001b[A\n",
      "Training loss: 2.95e-02 lr: 1.74e-05:  65%|▋| 9040/13852 [33:54<17:49,  4.50it/s\u001b[A\n",
      "Training loss: 2.44e-02 lr: 1.74e-05:  65%|▋| 9041/13852 [33:54<17:50,  4.49it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 1.74e-05:  65%|▋| 9042/13852 [33:54<17:51,  4.49it/s\u001b[A\n",
      "Training loss: 7.09e-02 lr: 1.74e-05:  65%|▋| 9043/13852 [33:54<17:46,  4.51it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 1.74e-05:  65%|▋| 9044/13852 [33:55<17:41,  4.53it/s\u001b[A\n",
      "Training loss: 4.90e-02 lr: 1.74e-05:  65%|▋| 9045/13852 [33:55<17:37,  4.54it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.73e-05:  65%|▋| 9046/13852 [33:55<17:36,  4.55it/s\u001b[A\n",
      "Training loss: 1.44e-01 lr: 1.73e-05:  65%|▋| 9047/13852 [33:55<17:37,  4.54it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 1.73e-05:  65%|▋| 9048/13852 [33:55<17:38,  4.54it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 1.73e-05:  65%|▋| 9049/13852 [33:56<17:41,  4.53it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 1.73e-05:  65%|▋| 9050/13852 [33:56<17:42,  4.52it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 1.73e-05:  65%|▋| 9051/13852 [33:56<17:46,  4.50it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 1.73e-05:  65%|▋| 9052/13852 [33:56<17:47,  4.50it/s\u001b[A\n",
      "Training loss: 4.30e-02 lr: 1.73e-05:  65%|▋| 9053/13852 [33:57<17:47,  4.49it/s\u001b[A\n",
      "Training loss: 6.88e-02 lr: 1.73e-05:  65%|▋| 9054/13852 [33:57<17:55,  4.46it/s\u001b[A\n",
      "Training loss: 1.33e-01 lr: 1.73e-05:  65%|▋| 9055/13852 [33:57<17:53,  4.47it/s\u001b[A\n",
      "Training loss: 9.70e-02 lr: 1.73e-05:  65%|▋| 9056/13852 [33:57<17:45,  4.50it/s\u001b[A\n",
      "Training loss: 7.12e-02 lr: 1.73e-05:  65%|▋| 9057/13852 [33:57<17:38,  4.53it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 1.73e-05:  65%|▋| 9058/13852 [33:58<17:44,  4.50it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 1.73e-05:  65%|▋| 9059/13852 [33:58<17:42,  4.51it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 1.73e-05:  65%|▋| 9060/13852 [33:58<17:42,  4.51it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 1.73e-05:  65%|▋| 9061/13852 [33:58<17:40,  4.52it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 1.73e-05:  65%|▋| 9062/13852 [33:59<17:42,  4.51it/s\u001b[A\n",
      "Training loss: 3.86e-02 lr: 1.73e-05:  65%|▋| 9063/13852 [33:59<17:42,  4.51it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 1.73e-05:  65%|▋| 9064/13852 [33:59<17:42,  4.51it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 1.73e-05:  65%|▋| 9065/13852 [33:59<17:42,  4.50it/s\u001b[A\n",
      "Training loss: 3.77e-02 lr: 1.73e-05:  65%|▋| 9066/13852 [33:59<17:43,  4.50it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 1.73e-05:  65%|▋| 9067/13852 [34:00<17:39,  4.52it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 1.73e-05:  65%|▋| 9068/13852 [34:00<17:34,  4.54it/s\u001b[A\n",
      "Training loss: 3.80e-02 lr: 1.73e-05:  65%|▋| 9069/13852 [34:00<17:31,  4.55it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 1.73e-05:  65%|▋| 9070/13852 [34:00<17:42,  4.50it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 1.73e-05:  65%|▋| 9071/13852 [34:01<17:41,  4.51it/s\u001b[A\n",
      "Training loss: 7.49e-02 lr: 1.73e-05:  65%|▋| 9072/13852 [34:01<17:45,  4.49it/s\u001b[A\n",
      "Training loss: 5.39e-02 lr: 1.73e-05:  65%|▋| 9073/13852 [34:01<17:48,  4.47it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 1.72e-05:  66%|▋| 9074/13852 [34:01<17:47,  4.48it/s\u001b[A\n",
      "Training loss: 5.72e-02 lr: 1.72e-05:  66%|▋| 9075/13852 [34:01<17:45,  4.48it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 1.72e-05:  66%|▋| 9076/13852 [34:02<17:48,  4.47it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 1.72e-05:  66%|▋| 9077/13852 [34:02<17:48,  4.47it/s\u001b[A\n",
      "Training loss: 3.36e-02 lr: 1.72e-05:  66%|▋| 9078/13852 [34:02<17:52,  4.45it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 1.72e-05:  66%|▋| 9079/13852 [34:02<17:45,  4.48it/s\u001b[A\n",
      "Training loss: 3.44e-02 lr: 1.72e-05:  66%|▋| 9080/13852 [34:03<17:34,  4.52it/s\u001b[A\n",
      "Training loss: 7.01e-02 lr: 1.72e-05:  66%|▋| 9081/13852 [34:03<17:30,  4.54it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 1.72e-05:  66%|▋| 9082/13852 [34:03<17:40,  4.50it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 1.72e-05:  66%|▋| 9083/13852 [34:03<17:38,  4.51it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 1.72e-05:  66%|▋| 9084/13852 [34:03<17:38,  4.50it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 1.72e-05:  66%|▋| 9085/13852 [34:04<17:36,  4.51it/s\u001b[A\n",
      "Training loss: 8.05e-02 lr: 1.72e-05:  66%|▋| 9086/13852 [34:04<17:36,  4.51it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 1.72e-05:  66%|▋| 9087/13852 [34:04<17:38,  4.50it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 1.72e-05:  66%|▋| 9088/13852 [34:04<17:38,  4.50it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 1.72e-05:  66%|▋| 9089/13852 [34:05<17:45,  4.47it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 1.72e-05:  66%|▋| 9090/13852 [34:05<17:45,  4.47it/s\u001b[A\n",
      "Training loss: 3.87e-02 lr: 1.72e-05:  66%|▋| 9091/13852 [34:05<17:38,  4.50it/s\u001b[A\n",
      "Training loss: 5.54e-02 lr: 1.72e-05:  66%|▋| 9092/13852 [34:05<17:31,  4.53it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 1.72e-05:  66%|▋| 9093/13852 [34:05<17:26,  4.55it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 1.72e-05:  66%|▋| 9094/13852 [34:06<17:31,  4.53it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 1.72e-05:  66%|▋| 9095/13852 [34:06<17:38,  4.49it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 1.72e-05:  66%|▋| 9096/13852 [34:06<17:40,  4.48it/s\u001b[A\n",
      "Training loss: 4.69e-02 lr: 1.72e-05:  66%|▋| 9097/13852 [34:06<17:38,  4.49it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 1.72e-05:  66%|▋| 9098/13852 [34:07<17:38,  4.49it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 1.72e-05:  66%|▋| 9099/13852 [34:07<17:48,  4.45it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 1.72e-05:  66%|▋| 9100/13852 [34:07<17:48,  4.45it/s\u001b[A\n",
      "Training loss: 7.51e-02 lr: 1.72e-05:  66%|▋| 9101/13852 [34:07<17:45,  4.46it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 1.71e-05:  66%|▋| 9102/13852 [34:07<17:45,  4.46it/s\u001b[A\n",
      "Training loss: 7.59e-02 lr: 1.71e-05:  66%|▋| 9103/13852 [34:08<17:38,  4.49it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 1.71e-05:  66%|▋| 9104/13852 [34:08<17:39,  4.48it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 1.71e-05:  66%|▋| 9105/13852 [34:08<17:38,  4.48it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 1.71e-05:  66%|▋| 9106/13852 [34:08<17:36,  4.49it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 1.71e-05:  66%|▋| 9107/13852 [34:09<17:33,  4.50it/s\u001b[A\n",
      "Training loss: 8.50e-02 lr: 1.71e-05:  66%|▋| 9108/13852 [34:09<17:35,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.72e-02 lr: 1.71e-05:  66%|▋| 9109/13852 [34:09<17:35,  4.50it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 1.71e-05:  66%|▋| 9110/13852 [34:09<17:36,  4.49it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 1.71e-05:  66%|▋| 9111/13852 [34:09<17:34,  4.50it/s\u001b[A\n",
      "Training loss: 3.13e-02 lr: 1.71e-05:  66%|▋| 9112/13852 [34:10<17:34,  4.49it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 1.71e-05:  66%|▋| 9113/13852 [34:10<17:33,  4.50it/s\u001b[A\n",
      "Training loss: 1.56e-01 lr: 1.71e-05:  66%|▋| 9114/13852 [34:10<17:28,  4.52it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 1.71e-05:  66%|▋| 9115/13852 [34:10<17:24,  4.54it/s\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.71e-05:  66%|▋| 9116/13852 [34:11<17:35,  4.49it/s\u001b[A\n",
      "Training loss: 8.37e-02 lr: 1.71e-05:  66%|▋| 9117/13852 [34:11<17:39,  4.47it/s\u001b[A\n",
      "Training loss: 8.37e-02 lr: 1.71e-05:  66%|▋| 9118/13852 [34:11<17:38,  4.47it/s\u001b[A\n",
      "Training loss: 6.08e-02 lr: 1.71e-05:  66%|▋| 9119/13852 [34:11<17:36,  4.48it/s\u001b[A\n",
      "Training loss: 6.38e-02 lr: 1.71e-05:  66%|▋| 9120/13852 [34:11<17:34,  4.49it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 1.71e-05:  66%|▋| 9121/13852 [34:12<17:38,  4.47it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 1.71e-05:  66%|▋| 9122/13852 [34:12<17:36,  4.48it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 1.71e-05:  66%|▋| 9123/13852 [34:12<17:35,  4.48it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 1.71e-05:  66%|▋| 9124/13852 [34:12<17:33,  4.49it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 1.71e-05:  66%|▋| 9125/13852 [34:13<17:30,  4.50it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 1.71e-05:  66%|▋| 9126/13852 [34:13<17:25,  4.52it/s\u001b[A\n",
      "Training loss: 4.82e-02 lr: 1.71e-05:  66%|▋| 9127/13852 [34:13<17:20,  4.54it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 1.71e-05:  66%|▋| 9128/13852 [34:13<17:25,  4.52it/s\u001b[A\n",
      "Training loss: 7.79e-02 lr: 1.70e-05:  66%|▋| 9129/13852 [34:13<17:26,  4.51it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 1.70e-05:  66%|▋| 9130/13852 [34:14<17:52,  4.40it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 1.70e-05:  66%|▋| 9131/13852 [34:14<18:08,  4.34it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 1.70e-05:  66%|▋| 9132/13852 [34:14<18:22,  4.28it/s\u001b[A\n",
      "Training loss: 5.52e-02 lr: 1.70e-05:  66%|▋| 9133/13852 [34:14<18:31,  4.25it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 1.70e-05:  66%|▋| 9134/13852 [34:15<18:36,  4.22it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 1.70e-05:  66%|▋| 9135/13852 [34:15<18:39,  4.21it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 1.70e-05:  66%|▋| 9136/13852 [34:15<18:43,  4.20it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 1.70e-05:  66%|▋| 9137/13852 [34:15<18:45,  4.19it/s\u001b[A\n",
      "Training loss: 4.36e-02 lr: 1.70e-05:  66%|▋| 9138/13852 [34:16<18:47,  4.18it/s\u001b[A\n",
      "Training loss: 5.57e-02 lr: 1.70e-05:  66%|▋| 9139/13852 [34:16<18:48,  4.18it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 1.70e-05:  66%|▋| 9140/13852 [34:16<18:46,  4.18it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 1.70e-05:  66%|▋| 9141/13852 [34:16<18:50,  4.17it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 1.70e-05:  66%|▋| 9142/13852 [34:17<18:49,  4.17it/s\u001b[A\n",
      "Training loss: 8.60e-02 lr: 1.70e-05:  66%|▋| 9143/13852 [34:17<18:59,  4.13it/s\u001b[A\n",
      "Training loss: 7.25e-02 lr: 1.70e-05:  66%|▋| 9144/13852 [34:17<18:58,  4.14it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 1.70e-05:  66%|▋| 9145/13852 [34:17<18:52,  4.16it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 1.70e-05:  66%|▋| 9146/13852 [34:18<18:44,  4.19it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 1.70e-05:  66%|▋| 9147/13852 [34:18<18:46,  4.18it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 1.70e-05:  66%|▋| 9148/13852 [34:18<18:57,  4.14it/s\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.70e-05:  66%|▋| 9149/13852 [34:18<18:55,  4.14it/s\u001b[A\n",
      "Training loss: 5.63e-02 lr: 1.70e-05:  66%|▋| 9150/13852 [34:18<18:53,  4.15it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 1.70e-05:  66%|▋| 9151/13852 [34:19<18:46,  4.17it/s\u001b[A\n",
      "Training loss: 7.12e-02 lr: 1.70e-05:  66%|▋| 9152/13852 [34:19<18:39,  4.20it/s\u001b[A\n",
      "Training loss: 6.99e-02 lr: 1.70e-05:  66%|▋| 9153/13852 [34:19<18:41,  4.19it/s\u001b[A\n",
      "Training loss: 5.85e-02 lr: 1.70e-05:  66%|▋| 9154/13852 [34:19<18:43,  4.18it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 1.70e-05:  66%|▋| 9155/13852 [34:20<18:44,  4.18it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 1.70e-05:  66%|▋| 9156/13852 [34:20<18:44,  4.18it/s\u001b[A\n",
      "Training loss: 3.31e-02 lr: 1.69e-05:  66%|▋| 9157/13852 [34:20<18:40,  4.19it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 1.69e-05:  66%|▋| 9158/13852 [34:20<18:45,  4.17it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 1.69e-05:  66%|▋| 9159/13852 [34:21<18:43,  4.18it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 1.69e-05:  66%|▋| 9160/13852 [34:21<18:46,  4.16it/s\u001b[A\n",
      "Training loss: 8.83e-02 lr: 1.69e-05:  66%|▋| 9161/13852 [34:21<18:45,  4.17it/s\u001b[A\n",
      "Training loss: 6.30e-02 lr: 1.69e-05:  66%|▋| 9162/13852 [34:21<18:44,  4.17it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 1.69e-05:  66%|▋| 9163/13852 [34:22<18:39,  4.19it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.69e-05:  66%|▋| 9164/13852 [34:22<18:41,  4.18it/s\u001b[A\n",
      "Training loss: 9.35e-02 lr: 1.69e-05:  66%|▋| 9165/13852 [34:22<18:43,  4.17it/s\u001b[A\n",
      "Training loss: 7.72e-02 lr: 1.69e-05:  66%|▋| 9166/13852 [34:22<18:41,  4.18it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 1.69e-05:  66%|▋| 9167/13852 [34:23<18:42,  4.17it/s\u001b[A\n",
      "Training loss: 6.30e-02 lr: 1.69e-05:  66%|▋| 9168/13852 [34:23<18:43,  4.17it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 1.69e-05:  66%|▋| 9169/13852 [34:23<18:40,  4.18it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 1.69e-05:  66%|▋| 9170/13852 [34:23<18:41,  4.18it/s\u001b[A\n",
      "Training loss: 3.67e-02 lr: 1.69e-05:  66%|▋| 9171/13852 [34:24<18:39,  4.18it/s\u001b[A\n",
      "Training loss: 3.08e-02 lr: 1.69e-05:  66%|▋| 9172/13852 [34:24<18:40,  4.18it/s\u001b[A\n",
      "Training loss: 2.71e-02 lr: 1.69e-05:  66%|▋| 9173/13852 [34:24<18:40,  4.18it/s\u001b[A\n",
      "Training loss: 2.97e-02 lr: 1.69e-05:  66%|▋| 9174/13852 [34:24<18:39,  4.18it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 1.69e-05:  66%|▋| 9175/13852 [34:24<18:34,  4.20it/s\u001b[A\n",
      "Training loss: 2.96e-02 lr: 1.69e-05:  66%|▋| 9176/13852 [34:25<18:37,  4.18it/s\u001b[A\n",
      "Training loss: 5.32e-02 lr: 1.69e-05:  66%|▋| 9177/13852 [34:25<18:36,  4.19it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 1.69e-05:  66%|▋| 9178/13852 [34:25<18:35,  4.19it/s\u001b[A\n",
      "Training loss: 3.14e-02 lr: 1.69e-05:  66%|▋| 9179/13852 [34:25<18:35,  4.19it/s\u001b[A\n",
      "Training loss: 2.85e-02 lr: 1.69e-05:  66%|▋| 9180/13852 [34:26<18:34,  4.19it/s\u001b[A\n",
      "Training loss: 2.55e-02 lr: 1.69e-05:  66%|▋| 9181/13852 [34:26<18:31,  4.20it/s\u001b[A\n",
      "Training loss: 2.12e-02 lr: 1.69e-05:  66%|▋| 9182/13852 [34:26<18:36,  4.18it/s\u001b[A\n",
      "Training loss: 1.67e-02 lr: 1.69e-05:  66%|▋| 9183/13852 [34:26<18:35,  4.18it/s\u001b[A\n",
      "Training loss: 2.27e-02 lr: 1.69e-05:  66%|▋| 9184/13852 [34:27<18:33,  4.19it/s\u001b[A\n",
      "Training loss: 4.75e-02 lr: 1.68e-05:  66%|▋| 9185/13852 [34:27<18:44,  4.15it/s\u001b[A\n",
      "Training loss: 5.45e-02 lr: 1.68e-05:  66%|▋| 9186/13852 [34:27<18:39,  4.17it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 1.68e-05:  66%|▋| 9187/13852 [34:27<18:33,  4.19it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 1.68e-05:  66%|▋| 9188/13852 [34:28<18:31,  4.20it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 1.68e-05:  66%|▋| 9189/13852 [34:28<18:33,  4.19it/s\u001b[A\n",
      "Training loss: 2.53e-02 lr: 1.68e-05:  66%|▋| 9190/13852 [34:28<18:33,  4.19it/s\u001b[A\n",
      "Training loss: 2.33e-02 lr: 1.68e-05:  66%|▋| 9191/13852 [34:28<18:35,  4.18it/s\u001b[A\n",
      "Training loss: 1.76e-02 lr: 1.68e-05:  66%|▋| 9192/13852 [34:29<18:35,  4.18it/s\u001b[A\n",
      "Training loss: 1.34e-02 lr: 1.68e-05:  66%|▋| 9193/13852 [34:29<18:33,  4.19it/s\u001b[A\n",
      "Training loss: 2.73e-02 lr: 1.68e-05:  66%|▋| 9194/13852 [34:29<18:33,  4.18it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 1.68e-05:  66%|▋| 9195/13852 [34:29<18:33,  4.18it/s\u001b[A\n",
      "Training loss: 2.79e-02 lr: 1.68e-05:  66%|▋| 9196/13852 [34:29<18:34,  4.18it/s\u001b[A\n",
      "Training loss: 7.10e-02 lr: 1.68e-05:  66%|▋| 9197/13852 [34:30<18:33,  4.18it/s\u001b[A\n",
      "Training loss: 7.72e-02 lr: 1.68e-05:  66%|▋| 9198/13852 [34:30<18:33,  4.18it/s\u001b[A\n",
      "Training loss: 5.50e-02 lr: 1.68e-05:  66%|▋| 9199/13852 [34:30<18:29,  4.19it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 1.68e-05:  66%|▋| 9200/13852 [34:30<18:29,  4.19it/s\u001b[A\n",
      "Training loss: 3.27e-02 lr: 1.68e-05:  66%|▋| 9201/13852 [34:31<18:34,  4.17it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 1.68e-05:  66%|▋| 9202/13852 [34:31<18:40,  4.15it/s\u001b[A\n",
      "Training loss: 7.96e-02 lr: 1.68e-05:  66%|▋| 9203/13852 [34:31<18:42,  4.14it/s\u001b[A\n",
      "Training loss: 5.82e-02 lr: 1.68e-05:  66%|▋| 9204/13852 [34:31<18:39,  4.15it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 1.68e-05:  66%|▋| 9205/13852 [34:32<18:36,  4.16it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.07e-02 lr: 1.68e-05:  66%|▋| 9206/13852 [34:32<18:37,  4.16it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 1.68e-05:  66%|▋| 9207/13852 [34:32<18:37,  4.16it/s\u001b[A\n",
      "Training loss: 5.66e-02 lr: 1.68e-05:  66%|▋| 9208/13852 [34:32<18:33,  4.17it/s\u001b[A\n",
      "Training loss: 4.62e-02 lr: 1.68e-05:  66%|▋| 9209/13852 [34:33<18:31,  4.18it/s\u001b[A\n",
      "Training loss: 3.87e-02 lr: 1.68e-05:  66%|▋| 9210/13852 [34:33<18:27,  4.19it/s\u001b[A\n",
      "Training loss: 2.82e-02 lr: 1.68e-05:  66%|▋| 9211/13852 [34:33<18:33,  4.17it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 1.67e-05:  67%|▋| 9212/13852 [34:33<18:37,  4.15it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 1.67e-05:  67%|▋| 9213/13852 [34:34<18:34,  4.16it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 1.67e-05:  67%|▋| 9214/13852 [34:34<18:33,  4.17it/s\u001b[A\n",
      "Training loss: 5.26e-02 lr: 1.67e-05:  67%|▋| 9215/13852 [34:34<18:31,  4.17it/s\u001b[A\n",
      "Training loss: 7.85e-02 lr: 1.67e-05:  67%|▋| 9216/13852 [34:34<18:28,  4.18it/s\u001b[A\n",
      "Training loss: 5.59e-02 lr: 1.67e-05:  67%|▋| 9217/13852 [34:35<18:30,  4.17it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 1.67e-05:  67%|▋| 9218/13852 [34:35<18:38,  4.14it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 1.67e-05:  67%|▋| 9219/13852 [34:35<18:34,  4.16it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 1.67e-05:  67%|▋| 9220/13852 [34:35<18:31,  4.17it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 1.67e-05:  67%|▋| 9221/13852 [34:35<18:29,  4.17it/s\u001b[A\n",
      "Training loss: 2.69e-02 lr: 1.67e-05:  67%|▋| 9222/13852 [34:36<18:26,  4.19it/s\u001b[A\n",
      "Training loss: 1.98e-02 lr: 1.67e-05:  67%|▋| 9223/13852 [34:36<18:25,  4.19it/s\u001b[A\n",
      "Training loss: 1.51e-02 lr: 1.67e-05:  67%|▋| 9224/13852 [34:36<18:25,  4.19it/s\u001b[A\n",
      "Training loss: 3.90e-02 lr: 1.67e-05:  67%|▋| 9225/13852 [34:36<18:25,  4.19it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 1.67e-05:  67%|▋| 9226/13852 [34:37<18:32,  4.16it/s\u001b[A\n",
      "Training loss: 2.27e-02 lr: 1.67e-05:  67%|▋| 9227/13852 [34:37<18:32,  4.16it/s\u001b[A\n",
      "Training loss: 2.50e-02 lr: 1.67e-05:  67%|▋| 9228/13852 [34:37<18:28,  4.17it/s\u001b[A\n",
      "Training loss: 2.00e-02 lr: 1.67e-05:  67%|▋| 9229/13852 [34:37<18:04,  4.26it/s\u001b[A\n",
      "Training loss: 1.80e-02 lr: 1.67e-05:  67%|▋| 9230/13852 [34:38<17:46,  4.33it/s\u001b[A\n",
      "Training loss: 2.44e-02 lr: 1.67e-05:  67%|▋| 9231/13852 [34:38<17:34,  4.38it/s\u001b[A\n",
      "Training loss: 3.48e-02 lr: 1.67e-05:  67%|▋| 9232/13852 [34:38<17:22,  4.43it/s\u001b[A\n",
      "Training loss: 5.65e-02 lr: 1.67e-05:  67%|▋| 9233/13852 [34:38<17:14,  4.46it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 1.67e-05:  67%|▋| 9234/13852 [34:38<17:09,  4.48it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 1.67e-05:  67%|▋| 9235/13852 [34:39<17:07,  4.50it/s\u001b[A\n",
      "Training loss: 3.31e-02 lr: 1.67e-05:  67%|▋| 9236/13852 [34:39<17:03,  4.51it/s\u001b[A\n",
      "Training loss: 2.42e-02 lr: 1.67e-05:  67%|▋| 9237/13852 [34:39<17:00,  4.52it/s\u001b[A\n",
      "Training loss: 8.15e-02 lr: 1.67e-05:  67%|▋| 9238/13852 [34:39<17:00,  4.52it/s\u001b[A\n",
      "Training loss: 5.87e-02 lr: 1.67e-05:  67%|▋| 9239/13852 [34:40<16:55,  4.54it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 1.66e-05:  67%|▋| 9240/13852 [34:40<16:52,  4.56it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 1.66e-05:  67%|▋| 9241/13852 [34:40<16:48,  4.57it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 1.66e-05:  67%|▋| 9242/13852 [34:40<16:53,  4.55it/s\u001b[A\n",
      "Training loss: 1.20e-01 lr: 1.66e-05:  67%|▋| 9243/13852 [34:40<16:54,  4.54it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.66e-05:  67%|▋| 9244/13852 [34:41<16:54,  4.54it/s\u001b[A\n",
      "Training loss: 9.04e-02 lr: 1.66e-05:  67%|▋| 9245/13852 [34:41<16:58,  4.52it/s\u001b[A\n",
      "Training loss: 6.40e-02 lr: 1.66e-05:  67%|▋| 9246/13852 [34:41<16:57,  4.53it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 1.66e-05:  67%|▋| 9247/13852 [34:41<16:56,  4.53it/s\u001b[A\n",
      "Training loss: 4.30e-02 lr: 1.66e-05:  67%|▋| 9248/13852 [34:42<16:56,  4.53it/s\u001b[A\n",
      "Training loss: 3.19e-02 lr: 1.66e-05:  67%|▋| 9249/13852 [34:42<16:58,  4.52it/s\u001b[A\n",
      "Training loss: 2.81e-02 lr: 1.66e-05:  67%|▋| 9250/13852 [34:42<16:59,  4.52it/s\u001b[A\n",
      "Training loss: 2.59e-02 lr: 1.66e-05:  67%|▋| 9251/13852 [34:42<16:58,  4.52it/s\u001b[A\n",
      "Training loss: 3.91e-02 lr: 1.66e-05:  67%|▋| 9252/13852 [34:42<16:54,  4.53it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 1.66e-05:  67%|▋| 9253/13852 [34:43<16:50,  4.55it/s\u001b[A\n",
      "Training loss: 7.29e-02 lr: 1.66e-05:  67%|▋| 9254/13852 [34:43<16:47,  4.57it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 1.66e-05:  67%|▋| 9255/13852 [34:43<16:43,  4.58it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.66e-05:  67%|▋| 9256/13852 [34:43<16:48,  4.56it/s\u001b[A\n",
      "Training loss: 6.41e-02 lr: 1.66e-05:  67%|▋| 9257/13852 [34:44<16:50,  4.55it/s\u001b[A\n",
      "Training loss: 5.27e-02 lr: 1.66e-05:  67%|▋| 9258/13852 [34:44<16:51,  4.54it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.66e-05:  67%|▋| 9259/13852 [34:44<16:50,  4.55it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.66e-05:  67%|▋| 9260/13852 [34:44<16:51,  4.54it/s\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.66e-05:  67%|▋| 9261/13852 [34:44<16:55,  4.52it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 1.66e-05:  67%|▋| 9262/13852 [34:45<16:54,  4.52it/s\u001b[A\n",
      "Training loss: 2.38e-02 lr: 1.66e-05:  67%|▋| 9263/13852 [34:45<16:56,  4.52it/s\u001b[A\n",
      "Training loss: 1.83e-02 lr: 1.66e-05:  67%|▋| 9264/13852 [34:45<16:55,  4.52it/s\u001b[A\n",
      "Training loss: 1.59e-02 lr: 1.66e-05:  67%|▋| 9265/13852 [34:45<16:53,  4.53it/s\u001b[A\n",
      "Training loss: 2.11e-02 lr: 1.66e-05:  67%|▋| 9266/13852 [34:46<16:49,  4.54it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 1.66e-05:  67%|▋| 9267/13852 [34:46<16:47,  4.55it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 1.65e-05:  67%|▋| 9268/13852 [34:46<16:51,  4.53it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 1.65e-05:  67%|▋| 9269/13852 [34:46<16:51,  4.53it/s\u001b[A\n",
      "Training loss: 4.01e-02 lr: 1.65e-05:  67%|▋| 9270/13852 [34:46<16:51,  4.53it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 1.65e-05:  67%|▋| 9271/13852 [34:47<16:52,  4.53it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 1.65e-05:  67%|▋| 9272/13852 [34:47<17:01,  4.49it/s\u001b[A\n",
      "Training loss: 4.77e-02 lr: 1.65e-05:  67%|▋| 9273/13852 [34:47<17:02,  4.48it/s\u001b[A\n",
      "Training loss: 4.80e-02 lr: 1.65e-05:  67%|▋| 9274/13852 [34:47<16:57,  4.50it/s\u001b[A\n",
      "Training loss: 9.40e-02 lr: 1.65e-05:  67%|▋| 9275/13852 [34:48<16:55,  4.51it/s\u001b[A\n",
      "Training loss: 6.73e-02 lr: 1.65e-05:  67%|▋| 9276/13852 [34:48<16:54,  4.51it/s\u001b[A\n",
      "Training loss: 6.78e-02 lr: 1.65e-05:  67%|▋| 9277/13852 [34:48<16:53,  4.51it/s\u001b[A\n",
      "Training loss: 7.61e-02 lr: 1.65e-05:  67%|▋| 9278/13852 [34:48<16:52,  4.52it/s\u001b[A\n",
      "Training loss: 1.38e-01 lr: 1.65e-05:  67%|▋| 9279/13852 [34:48<16:46,  4.54it/s\u001b[A\n",
      "Training loss: 1.53e-01 lr: 1.65e-05:  67%|▋| 9280/13852 [34:49<16:53,  4.51it/s\u001b[A\n",
      "Training loss: 1.30e-01 lr: 1.65e-05:  67%|▋| 9281/13852 [34:49<16:52,  4.51it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 1.65e-05:  67%|▋| 9282/13852 [34:49<16:51,  4.52it/s\u001b[A\n",
      "Training loss: 7.67e-02 lr: 1.65e-05:  67%|▋| 9283/13852 [34:49<16:50,  4.52it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 1.65e-05:  67%|▋| 9284/13852 [34:50<16:46,  4.54it/s\u001b[A\n",
      "Training loss: 4.11e-02 lr: 1.65e-05:  67%|▋| 9285/13852 [34:50<16:46,  4.54it/s\u001b[A\n",
      "Training loss: 4.40e-02 lr: 1.65e-05:  67%|▋| 9286/13852 [34:50<16:49,  4.52it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 1.65e-05:  67%|▋| 9287/13852 [34:50<16:48,  4.53it/s\u001b[A\n",
      "Training loss: 3.28e-02 lr: 1.65e-05:  67%|▋| 9288/13852 [34:50<16:48,  4.53it/s\u001b[A\n",
      "Training loss: 2.87e-02 lr: 1.65e-05:  67%|▋| 9289/13852 [34:51<16:47,  4.53it/s\u001b[A\n",
      "Training loss: 2.33e-02 lr: 1.65e-05:  67%|▋| 9290/13852 [34:51<16:58,  4.48it/s\u001b[A\n",
      "Training loss: 2.58e-02 lr: 1.65e-05:  67%|▋| 9291/13852 [34:51<16:51,  4.51it/s\u001b[A\n",
      "Training loss: 3.44e-02 lr: 1.65e-05:  67%|▋| 9292/13852 [34:51<16:45,  4.53it/s\u001b[A\n",
      "Training loss: 4.17e-02 lr: 1.65e-05:  67%|▋| 9293/13852 [34:52<16:47,  4.53it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.65e-05:  67%|▋| 9294/13852 [34:52<16:50,  4.51it/s\u001b[A\n",
      "Training loss: 3.32e-02 lr: 1.65e-05:  67%|▋| 9295/13852 [34:52<16:47,  4.52it/s\u001b[A\n",
      "Training loss: 2.85e-02 lr: 1.64e-05:  67%|▋| 9296/13852 [34:52<16:44,  4.53it/s\u001b[A\n",
      "Training loss: 2.24e-02 lr: 1.64e-05:  67%|▋| 9297/13852 [34:52<16:47,  4.52it/s\u001b[A\n",
      "Training loss: 1.68e-02 lr: 1.64e-05:  67%|▋| 9298/13852 [34:53<16:45,  4.53it/s\u001b[A\n",
      "Training loss: 3.13e-02 lr: 1.64e-05:  67%|▋| 9299/13852 [34:53<16:46,  4.52it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 1.64e-05:  67%|▋| 9300/13852 [34:53<16:47,  4.52it/s\u001b[A\n",
      "Training loss: 4.05e-02 lr: 1.64e-05:  67%|▋| 9301/13852 [34:53<16:46,  4.52it/s\u001b[A\n",
      "Training loss: 3.06e-02 lr: 1.64e-05:  67%|▋| 9302/13852 [34:54<16:45,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.99e-02 lr: 1.64e-05:  67%|▋| 9303/13852 [34:54<16:41,  4.54it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 1.64e-05:  67%|▋| 9304/13852 [34:54<16:36,  4.56it/s\u001b[A\n",
      "Training loss: 3.10e-02 lr: 1.64e-05:  67%|▋| 9305/13852 [34:54<16:32,  4.58it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 1.64e-05:  67%|▋| 9306/13852 [34:54<16:40,  4.54it/s\u001b[A\n",
      "Training loss: 3.95e-02 lr: 1.64e-05:  67%|▋| 9307/13852 [34:55<16:40,  4.54it/s\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.64e-05:  67%|▋| 9308/13852 [34:55<16:47,  4.51it/s\u001b[A\n",
      "Training loss: 2.56e-02 lr: 1.64e-05:  67%|▋| 9309/13852 [34:55<16:45,  4.52it/s\u001b[A\n",
      "Training loss: 2.25e-02 lr: 1.64e-05:  67%|▋| 9310/13852 [34:55<16:46,  4.51it/s\u001b[A\n",
      "Training loss: 2.10e-02 lr: 1.64e-05:  67%|▋| 9311/13852 [34:55<16:43,  4.52it/s\u001b[A\n",
      "Training loss: 1.62e-02 lr: 1.64e-05:  67%|▋| 9312/13852 [34:56<16:43,  4.52it/s\u001b[A\n",
      "Training loss: 4.26e-02 lr: 1.64e-05:  67%|▋| 9313/13852 [34:56<16:42,  4.53it/s\u001b[A\n",
      "Training loss: 3.35e-02 lr: 1.64e-05:  67%|▋| 9314/13852 [34:56<16:42,  4.53it/s\u001b[A\n",
      "Training loss: 3.98e-02 lr: 1.64e-05:  67%|▋| 9315/13852 [34:56<16:41,  4.53it/s\u001b[A\n",
      "Training loss: 3.03e-02 lr: 1.64e-05:  67%|▋| 9316/13852 [34:57<16:35,  4.55it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 1.64e-05:  67%|▋| 9317/13852 [34:57<16:40,  4.53it/s\u001b[A\n",
      "Training loss: 9.78e-02 lr: 1.64e-05:  67%|▋| 9318/13852 [34:57<16:47,  4.50it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 1.64e-05:  67%|▋| 9319/13852 [34:57<16:47,  4.50it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 1.64e-05:  67%|▋| 9320/13852 [34:57<16:45,  4.51it/s\u001b[A\n",
      "Training loss: 3.99e-02 lr: 1.64e-05:  67%|▋| 9321/13852 [34:58<16:42,  4.52it/s\u001b[A\n",
      "Training loss: 4.52e-02 lr: 1.64e-05:  67%|▋| 9322/13852 [34:58<16:42,  4.52it/s\u001b[A\n",
      "Training loss: 3.45e-02 lr: 1.63e-05:  67%|▋| 9323/13852 [34:58<16:41,  4.52it/s\u001b[A\n",
      "Training loss: 2.59e-02 lr: 1.63e-05:  67%|▋| 9324/13852 [34:58<16:41,  4.52it/s\u001b[A\n",
      "Training loss: 2.66e-02 lr: 1.63e-05:  67%|▋| 9325/13852 [34:59<16:40,  4.52it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 1.63e-05:  67%|▋| 9326/13852 [34:59<16:43,  4.51it/s\u001b[A\n",
      "Training loss: 4.70e-02 lr: 1.63e-05:  67%|▋| 9327/13852 [34:59<16:43,  4.51it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 1.63e-05:  67%|▋| 9328/13852 [34:59<16:41,  4.52it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 1.63e-05:  67%|▋| 9329/13852 [34:59<16:37,  4.54it/s\u001b[A\n",
      "Training loss: 3.15e-02 lr: 1.63e-05:  67%|▋| 9330/13852 [35:00<16:32,  4.55it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 1.63e-05:  67%|▋| 9331/13852 [35:00<16:36,  4.54it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.63e-05:  67%|▋| 9332/13852 [35:00<16:37,  4.53it/s\u001b[A\n",
      "Training loss: 7.20e-02 lr: 1.63e-05:  67%|▋| 9333/13852 [35:00<16:38,  4.52it/s\u001b[A\n",
      "Training loss: 5.32e-02 lr: 1.63e-05:  67%|▋| 9334/13852 [35:01<16:39,  4.52it/s\u001b[A\n",
      "Training loss: 4.08e-02 lr: 1.63e-05:  67%|▋| 9335/13852 [35:01<16:42,  4.50it/s\u001b[A\n",
      "Training loss: 3.25e-02 lr: 1.63e-05:  67%|▋| 9336/13852 [35:01<16:41,  4.51it/s\u001b[A\n",
      "Training loss: 3.51e-02 lr: 1.63e-05:  67%|▋| 9337/13852 [35:01<16:40,  4.51it/s\u001b[A\n",
      "Training loss: 2.57e-02 lr: 1.63e-05:  67%|▋| 9338/13852 [35:01<16:41,  4.51it/s\u001b[A\n",
      "Training loss: 1.98e-02 lr: 1.63e-05:  67%|▋| 9339/13852 [35:02<16:47,  4.48it/s\u001b[A\n",
      "Training loss: 2.46e-02 lr: 1.63e-05:  67%|▋| 9340/13852 [35:02<16:40,  4.51it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 1.63e-05:  67%|▋| 9341/13852 [35:02<16:35,  4.53it/s\u001b[A\n",
      "Training loss: 3.10e-02 lr: 1.63e-05:  67%|▋| 9342/13852 [35:02<16:30,  4.55it/s\u001b[A\n",
      "Training loss: 3.61e-02 lr: 1.63e-05:  67%|▋| 9343/13852 [35:03<16:38,  4.52it/s\u001b[A\n",
      "Training loss: 9.27e-02 lr: 1.63e-05:  67%|▋| 9344/13852 [35:03<16:38,  4.52it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.63e-05:  67%|▋| 9345/13852 [35:03<16:44,  4.49it/s\u001b[A\n",
      "Training loss: 8.66e-02 lr: 1.63e-05:  67%|▋| 9346/13852 [35:03<16:41,  4.50it/s\u001b[A\n",
      "Training loss: 7.73e-02 lr: 1.63e-05:  67%|▋| 9347/13852 [35:03<16:40,  4.50it/s\u001b[A\n",
      "Training loss: 5.94e-02 lr: 1.63e-05:  67%|▋| 9348/13852 [35:04<16:40,  4.50it/s\u001b[A\n",
      "Training loss: 5.97e-02 lr: 1.63e-05:  67%|▋| 9349/13852 [35:04<16:38,  4.51it/s\u001b[A\n",
      "Training loss: 4.57e-02 lr: 1.63e-05:  67%|▋| 9350/13852 [35:04<16:39,  4.51it/s\u001b[A\n",
      "Training loss: 3.39e-02 lr: 1.62e-05:  68%|▋| 9351/13852 [35:04<16:38,  4.51it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 1.62e-05:  68%|▋| 9352/13852 [35:05<16:33,  4.53it/s\u001b[A\n",
      "Training loss: 7.60e-02 lr: 1.62e-05:  68%|▋| 9353/13852 [35:05<16:29,  4.55it/s\u001b[A\n",
      "Training loss: 6.22e-02 lr: 1.62e-05:  68%|▋| 9354/13852 [35:05<16:26,  4.56it/s\u001b[A\n",
      "Training loss: 4.42e-02 lr: 1.62e-05:  68%|▋| 9355/13852 [35:05<16:25,  4.56it/s\u001b[A\n",
      "Training loss: 3.44e-02 lr: 1.62e-05:  68%|▋| 9356/13852 [35:05<16:28,  4.55it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 1.62e-05:  68%|▋| 9357/13852 [35:06<16:29,  4.54it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 1.62e-05:  68%|▋| 9358/13852 [35:06<16:30,  4.54it/s\u001b[A\n",
      "Training loss: 5.37e-02 lr: 1.62e-05:  68%|▋| 9359/13852 [35:06<16:39,  4.50it/s\u001b[A\n",
      "Training loss: 1.46e-01 lr: 1.62e-05:  68%|▋| 9360/13852 [35:06<16:39,  4.49it/s\u001b[A\n",
      "Training loss: 1.22e-01 lr: 1.62e-05:  68%|▋| 9361/13852 [35:07<16:37,  4.50it/s\u001b[A\n",
      "Training loss: 1.49e-01 lr: 1.62e-05:  68%|▋| 9362/13852 [35:07<16:51,  4.44it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 1.62e-05:  68%|▋| 9363/13852 [35:07<16:48,  4.45it/s\u001b[A\n",
      "Training loss: 8.33e-02 lr: 1.62e-05:  68%|▋| 9364/13852 [35:07<16:48,  4.45it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 1.62e-05:  68%|▋| 9365/13852 [35:07<16:44,  4.46it/s\u001b[A\n",
      "Training loss: 5.77e-02 lr: 1.62e-05:  68%|▋| 9366/13852 [35:08<16:37,  4.50it/s\u001b[A\n",
      "Training loss: 4.21e-02 lr: 1.62e-05:  68%|▋| 9367/13852 [35:08<16:38,  4.49it/s\u001b[A\n",
      "Training loss: 5.35e-02 lr: 1.62e-05:  68%|▋| 9368/13852 [35:08<16:37,  4.50it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 1.62e-05:  68%|▋| 9369/13852 [35:08<16:38,  4.49it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 1.62e-05:  68%|▋| 9370/13852 [35:09<16:34,  4.51it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 1.62e-05:  68%|▋| 9371/13852 [35:09<16:33,  4.51it/s\u001b[A\n",
      "Training loss: 4.13e-02 lr: 1.62e-05:  68%|▋| 9372/13852 [35:09<16:32,  4.51it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 1.62e-05:  68%|▋| 9373/13852 [35:09<16:32,  4.51it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 1.62e-05:  68%|▋| 9374/13852 [35:09<16:32,  4.51it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 1.62e-05:  68%|▋| 9375/13852 [35:10<16:34,  4.50it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 1.62e-05:  68%|▋| 9376/13852 [35:10<16:31,  4.51it/s\u001b[A\n",
      "Training loss: 9.29e-02 lr: 1.62e-05:  68%|▋| 9377/13852 [35:10<16:27,  4.53it/s\u001b[A\n",
      "Training loss: 7.05e-02 lr: 1.62e-05:  68%|▋| 9378/13852 [35:10<16:27,  4.53it/s\u001b[A\n",
      "Training loss: 5.49e-02 lr: 1.61e-05:  68%|▋| 9379/13852 [35:11<16:33,  4.50it/s\u001b[A\n",
      "Training loss: 9.14e-02 lr: 1.61e-05:  68%|▋| 9380/13852 [35:11<16:35,  4.49it/s\u001b[A\n",
      "Training loss: 8.42e-02 lr: 1.61e-05:  68%|▋| 9381/13852 [35:11<16:34,  4.50it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 1.61e-05:  68%|▋| 9382/13852 [35:11<16:33,  4.50it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.61e-05:  68%|▋| 9383/13852 [35:11<16:33,  4.50it/s\u001b[A\n",
      "Training loss: 6.09e-02 lr: 1.61e-05:  68%|▋| 9384/13852 [35:12<16:39,  4.47it/s\u001b[A\n",
      "Training loss: 6.68e-02 lr: 1.61e-05:  68%|▋| 9385/13852 [35:12<16:38,  4.47it/s\u001b[A\n",
      "Training loss: 5.03e-02 lr: 1.61e-05:  68%|▋| 9386/13852 [35:12<16:39,  4.47it/s\u001b[A\n",
      "Training loss: 3.99e-02 lr: 1.61e-05:  68%|▋| 9387/13852 [35:12<16:37,  4.48it/s\u001b[A\n",
      "Training loss: 3.01e-02 lr: 1.61e-05:  68%|▋| 9388/13852 [35:13<16:30,  4.51it/s\u001b[A\n",
      "Training loss: 2.35e-02 lr: 1.61e-05:  68%|▋| 9389/13852 [35:13<16:24,  4.53it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.61e-05:  68%|▋| 9390/13852 [35:13<16:20,  4.55it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 1.61e-05:  68%|▋| 9391/13852 [35:13<16:19,  4.56it/s\u001b[A\n",
      "Training loss: 2.83e-02 lr: 1.61e-05:  68%|▋| 9392/13852 [35:13<16:44,  4.44it/s\u001b[A\n",
      "Training loss: 4.26e-02 lr: 1.61e-05:  68%|▋| 9393/13852 [35:14<17:00,  4.37it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 1.61e-05:  68%|▋| 9394/13852 [35:14<16:50,  4.41it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 1.61e-05:  68%|▋| 9395/13852 [35:14<16:43,  4.44it/s\u001b[A\n",
      "Training loss: 3.09e-02 lr: 1.61e-05:  68%|▋| 9396/13852 [35:14<16:39,  4.46it/s\u001b[A\n",
      "Training loss: 2.75e-02 lr: 1.61e-05:  68%|▋| 9397/13852 [35:15<16:35,  4.48it/s\u001b[A\n",
      "Training loss: 8.19e-02 lr: 1.61e-05:  68%|▋| 9398/13852 [35:15<16:33,  4.48it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 1.61e-05:  68%|▋| 9399/13852 [35:15<16:28,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.81e-02 lr: 1.61e-05:  68%|▋| 9400/13852 [35:15<16:22,  4.53it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.61e-05:  68%|▋| 9401/13852 [35:15<16:18,  4.55it/s\u001b[A\n",
      "Training loss: 6.57e-02 lr: 1.61e-05:  68%|▋| 9402/13852 [35:16<16:25,  4.51it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 1.61e-05:  68%|▋| 9403/13852 [35:16<16:24,  4.52it/s\u001b[A\n",
      "Training loss: 3.91e-02 lr: 1.61e-05:  68%|▋| 9404/13852 [35:16<16:25,  4.52it/s\u001b[A\n",
      "Training loss: 3.04e-02 lr: 1.61e-05:  68%|▋| 9405/13852 [35:16<16:24,  4.52it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 1.60e-05:  68%|▋| 9406/13852 [35:17<16:25,  4.51it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 1.60e-05:  68%|▋| 9407/13852 [35:17<16:29,  4.49it/s\u001b[A\n",
      "Training loss: 7.34e-02 lr: 1.60e-05:  68%|▋| 9408/13852 [35:17<16:28,  4.49it/s\u001b[A\n",
      "Training loss: 9.09e-02 lr: 1.60e-05:  68%|▋| 9409/13852 [35:17<16:28,  4.50it/s\u001b[A\n",
      "Training loss: 9.46e-02 lr: 1.60e-05:  68%|▋| 9410/13852 [35:17<16:27,  4.50it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 1.60e-05:  68%|▋| 9411/13852 [35:18<16:22,  4.52it/s\u001b[A\n",
      "Training loss: 8.67e-02 lr: 1.60e-05:  68%|▋| 9412/13852 [35:18<16:16,  4.55it/s\u001b[A\n",
      "Training loss: 9.99e-02 lr: 1.60e-05:  68%|▋| 9413/13852 [35:18<16:19,  4.53it/s\u001b[A\n",
      "Training loss: 8.90e-02 lr: 1.60e-05:  68%|▋| 9414/13852 [35:18<16:25,  4.50it/s\u001b[A\n",
      "Training loss: 8.25e-02 lr: 1.60e-05:  68%|▋| 9415/13852 [35:19<16:23,  4.51it/s\u001b[A\n",
      "Training loss: 7.84e-02 lr: 1.60e-05:  68%|▋| 9416/13852 [35:19<16:21,  4.52it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 1.60e-05:  68%|▋| 9417/13852 [35:19<16:19,  4.53it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 1.60e-05:  68%|▋| 9418/13852 [35:19<16:20,  4.52it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 1.60e-05:  68%|▋| 9419/13852 [35:19<16:20,  4.52it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 1.60e-05:  68%|▋| 9420/13852 [35:20<16:21,  4.52it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 1.60e-05:  68%|▋| 9421/13852 [35:20<16:20,  4.52it/s\u001b[A\n",
      "Training loss: 5.53e-02 lr: 1.60e-05:  68%|▋| 9422/13852 [35:20<16:23,  4.51it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 1.60e-05:  68%|▋| 9423/13852 [35:20<16:21,  4.51it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 1.60e-05:  68%|▋| 9424/13852 [35:21<16:34,  4.45it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 1.60e-05:  68%|▋| 9425/13852 [35:21<17:37,  4.19it/s\u001b[A\n",
      "Training loss: 2.98e-02 lr: 1.60e-05:  68%|▋| 9426/13852 [35:21<18:10,  4.06it/s\u001b[A\n",
      "Training loss: 2.71e-02 lr: 1.60e-05:  68%|▋| 9427/13852 [35:21<18:02,  4.09it/s\u001b[A\n",
      "Training loss: 3.18e-02 lr: 1.60e-05:  68%|▋| 9428/13852 [35:22<17:56,  4.11it/s\u001b[A\n",
      "Training loss: 5.30e-02 lr: 1.60e-05:  68%|▋| 9429/13852 [35:22<17:53,  4.12it/s\u001b[A\n",
      "Training loss: 4.56e-02 lr: 1.60e-05:  68%|▋| 9430/13852 [35:22<17:48,  4.14it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 1.60e-05:  68%|▋| 9431/13852 [35:22<17:45,  4.15it/s\u001b[A\n",
      "Training loss: 3.27e-02 lr: 1.60e-05:  68%|▋| 9432/13852 [35:23<17:41,  4.16it/s\u001b[A\n",
      "Training loss: 2.73e-02 lr: 1.60e-05:  68%|▋| 9433/13852 [35:23<17:41,  4.16it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 1.59e-05:  68%|▋| 9434/13852 [35:23<17:42,  4.16it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.59e-05:  68%|▋| 9435/13852 [35:23<17:38,  4.17it/s\u001b[A\n",
      "Training loss: 6.46e-02 lr: 1.59e-05:  68%|▋| 9436/13852 [35:23<17:38,  4.17it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 1.59e-05:  68%|▋| 9437/13852 [35:24<17:37,  4.18it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 1.59e-05:  68%|▋| 9438/13852 [35:24<17:36,  4.18it/s\u001b[A\n",
      "Training loss: 4.35e-02 lr: 1.59e-05:  68%|▋| 9439/13852 [35:24<17:40,  4.16it/s\u001b[A\n",
      "Training loss: 5.34e-02 lr: 1.59e-05:  68%|▋| 9440/13852 [35:24<17:35,  4.18it/s\u001b[A\n",
      "Training loss: 4.20e-02 lr: 1.59e-05:  68%|▋| 9441/13852 [35:25<17:40,  4.16it/s\u001b[A\n",
      "Training loss: 4.05e-02 lr: 1.59e-05:  68%|▋| 9442/13852 [35:25<17:42,  4.15it/s\u001b[A\n",
      "Training loss: 2.89e-02 lr: 1.59e-05:  68%|▋| 9443/13852 [35:25<17:40,  4.16it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 1.59e-05:  68%|▋| 9444/13852 [35:25<17:42,  4.15it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 1.59e-05:  68%|▋| 9445/13852 [35:26<17:41,  4.15it/s\u001b[A\n",
      "Training loss: 3.38e-02 lr: 1.59e-05:  68%|▋| 9446/13852 [35:26<17:37,  4.17it/s\u001b[A\n",
      "Training loss: 2.47e-02 lr: 1.59e-05:  68%|▋| 9447/13852 [35:26<17:37,  4.17it/s\u001b[A\n",
      "Training loss: 2.11e-02 lr: 1.59e-05:  68%|▋| 9448/13852 [35:26<17:36,  4.17it/s\u001b[A\n",
      "Training loss: 2.99e-02 lr: 1.59e-05:  68%|▋| 9449/13852 [35:27<17:35,  4.17it/s\u001b[A\n",
      "Training loss: 9.25e-02 lr: 1.59e-05:  68%|▋| 9450/13852 [35:27<17:41,  4.15it/s\u001b[A\n",
      "Training loss: 6.80e-02 lr: 1.59e-05:  68%|▋| 9451/13852 [35:27<17:41,  4.15it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 1.59e-05:  68%|▋| 9452/13852 [35:27<17:34,  4.17it/s\u001b[A\n",
      "Training loss: 5.61e-02 lr: 1.59e-05:  68%|▋| 9453/13852 [35:28<17:35,  4.17it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.59e-05:  68%|▋| 9454/13852 [35:28<17:36,  4.16it/s\u001b[A\n",
      "Training loss: 3.70e-02 lr: 1.59e-05:  68%|▋| 9455/13852 [35:28<17:36,  4.16it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.59e-05:  68%|▋| 9456/13852 [35:28<17:34,  4.17it/s\u001b[A\n",
      "Training loss: 3.55e-02 lr: 1.59e-05:  68%|▋| 9457/13852 [35:29<17:31,  4.18it/s\u001b[A\n",
      "Training loss: 2.93e-02 lr: 1.59e-05:  68%|▋| 9458/13852 [35:29<17:26,  4.20it/s\u001b[A\n",
      "Training loss: 2.18e-02 lr: 1.59e-05:  68%|▋| 9459/13852 [35:29<17:29,  4.19it/s\u001b[A\n",
      "Training loss: 1.58e-02 lr: 1.59e-05:  68%|▋| 9460/13852 [35:29<17:33,  4.17it/s\u001b[A\n",
      "Training loss: 1.21e-02 lr: 1.59e-05:  68%|▋| 9461/13852 [35:29<17:32,  4.17it/s\u001b[A\n",
      "Training loss: 1.15e-02 lr: 1.58e-05:  68%|▋| 9462/13852 [35:30<17:31,  4.18it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 1.58e-05:  68%|▋| 9463/13852 [35:30<17:31,  4.17it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 1.58e-05:  68%|▋| 9464/13852 [35:30<17:29,  4.18it/s\u001b[A\n",
      "Training loss: 3.11e-02 lr: 1.58e-05:  68%|▋| 9465/13852 [35:30<17:29,  4.18it/s\u001b[A\n",
      "Training loss: 7.23e-02 lr: 1.58e-05:  68%|▋| 9466/13852 [35:31<17:30,  4.18it/s\u001b[A\n",
      "Training loss: 5.15e-02 lr: 1.58e-05:  68%|▋| 9467/13852 [35:31<17:34,  4.16it/s\u001b[A\n",
      "Training loss: 6.14e-02 lr: 1.58e-05:  68%|▋| 9468/13852 [35:31<17:32,  4.17it/s\u001b[A\n",
      "Training loss: 4.72e-02 lr: 1.58e-05:  68%|▋| 9469/13852 [35:31<17:30,  4.17it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 1.58e-05:  68%|▋| 9470/13852 [35:32<17:34,  4.16it/s\u001b[A\n",
      "Training loss: 2.73e-02 lr: 1.58e-05:  68%|▋| 9471/13852 [35:32<17:32,  4.16it/s\u001b[A\n",
      "Training loss: 2.87e-02 lr: 1.58e-05:  68%|▋| 9472/13852 [35:32<17:31,  4.17it/s\u001b[A\n",
      "Training loss: 1.23e-01 lr: 1.58e-05:  68%|▋| 9473/13852 [35:32<17:27,  4.18it/s\u001b[A\n",
      "Training loss: 1.61e-01 lr: 1.58e-05:  68%|▋| 9474/13852 [35:33<17:25,  4.19it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 1.58e-05:  68%|▋| 9475/13852 [35:33<17:24,  4.19it/s\u001b[A\n",
      "Training loss: 8.04e-02 lr: 1.58e-05:  68%|▋| 9476/13852 [35:33<17:30,  4.16it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 1.58e-05:  68%|▋| 9477/13852 [35:33<17:29,  4.17it/s\u001b[A\n",
      "Training loss: 5.11e-02 lr: 1.58e-05:  68%|▋| 9478/13852 [35:34<17:31,  4.16it/s\u001b[A\n",
      "Training loss: 4.30e-02 lr: 1.58e-05:  68%|▋| 9479/13852 [35:34<17:29,  4.17it/s\u001b[A\n",
      "Training loss: 5.09e-02 lr: 1.58e-05:  68%|▋| 9480/13852 [35:34<17:27,  4.17it/s\u001b[A\n",
      "Training loss: 7.62e-02 lr: 1.58e-05:  68%|▋| 9481/13852 [35:34<17:26,  4.18it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 1.58e-05:  68%|▋| 9482/13852 [35:35<17:27,  4.17it/s\u001b[A\n",
      "Training loss: 4.02e-02 lr: 1.58e-05:  68%|▋| 9483/13852 [35:35<17:26,  4.18it/s\u001b[A\n",
      "Training loss: 4.18e-02 lr: 1.58e-05:  68%|▋| 9484/13852 [35:35<17:23,  4.19it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 1.58e-05:  68%|▋| 9485/13852 [35:35<17:23,  4.18it/s\u001b[A\n",
      "Training loss: 2.90e-02 lr: 1.58e-05:  68%|▋| 9486/13852 [35:35<17:22,  4.19it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 1.58e-05:  68%|▋| 9487/13852 [35:36<17:19,  4.20it/s\u001b[A\n",
      "Training loss: 3.09e-02 lr: 1.58e-05:  68%|▋| 9488/13852 [35:36<17:17,  4.21it/s\u001b[A\n",
      "Training loss: 3.22e-02 lr: 1.57e-05:  69%|▋| 9489/13852 [35:36<17:23,  4.18it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 1.57e-05:  69%|▋| 9490/13852 [35:36<17:21,  4.19it/s\u001b[A\n",
      "Training loss: 5.02e-02 lr: 1.57e-05:  69%|▋| 9491/13852 [35:37<17:29,  4.15it/s\u001b[A\n",
      "Training loss: 6.76e-02 lr: 1.57e-05:  69%|▋| 9492/13852 [35:37<17:28,  4.16it/s\u001b[A\n",
      "Training loss: 4.85e-02 lr: 1.57e-05:  69%|▋| 9493/13852 [35:37<17:27,  4.16it/s\u001b[A\n",
      "Training loss: 5.28e-02 lr: 1.57e-05:  69%|▋| 9494/13852 [35:37<17:28,  4.16it/s\u001b[A\n",
      "Training loss: 8.88e-02 lr: 1.57e-05:  69%|▋| 9495/13852 [35:38<17:28,  4.16it/s\u001b[A\n",
      "Training loss: 6.57e-02 lr: 1.57e-05:  69%|▋| 9496/13852 [35:38<17:29,  4.15it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.98e-02 lr: 1.57e-05:  69%|▋| 9497/13852 [35:38<17:01,  4.26it/s\u001b[A\n",
      "Training loss: 1.47e-01 lr: 1.57e-05:  69%|▋| 9498/13852 [35:38<16:42,  4.34it/s\u001b[A\n",
      "Training loss: 1.07e-01 lr: 1.57e-05:  69%|▋| 9499/13852 [35:39<16:28,  4.40it/s\u001b[A\n",
      "Training loss: 8.33e-02 lr: 1.57e-05:  69%|▋| 9500/13852 [35:39<16:15,  4.46it/s\u001b[A\n",
      "Training loss: 7.93e-02 lr: 1.57e-05:  69%|▋| 9501/13852 [35:39<16:06,  4.50it/s\u001b[A\n",
      "Training loss: 1.29e-01 lr: 1.57e-05:  69%|▋| 9502/13852 [35:39<15:59,  4.53it/s\u001b[A\n",
      "Training loss: 9.46e-02 lr: 1.57e-05:  69%|▋| 9503/13852 [35:39<15:55,  4.55it/s\u001b[A\n",
      "Training loss: 1.31e-01 lr: 1.57e-05:  69%|▋| 9504/13852 [35:40<15:55,  4.55it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 1.57e-05:  69%|▋| 9505/13852 [35:40<15:55,  4.55it/s\u001b[A\n",
      "Training loss: 9.13e-02 lr: 1.57e-05:  69%|▋| 9506/13852 [35:40<15:56,  4.54it/s\u001b[A\n",
      "Training loss: 6.59e-02 lr: 1.57e-05:  69%|▋| 9507/13852 [35:40<15:55,  4.55it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 1.57e-05:  69%|▋| 9508/13852 [35:41<15:55,  4.55it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 1.57e-05:  69%|▋| 9509/13852 [35:41<15:58,  4.53it/s\u001b[A\n",
      "Training loss: 5.80e-02 lr: 1.57e-05:  69%|▋| 9510/13852 [35:41<16:01,  4.52it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 1.57e-05:  69%|▋| 9511/13852 [35:41<16:02,  4.51it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 1.57e-05:  69%|▋| 9512/13852 [35:41<15:59,  4.52it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 1.57e-05:  69%|▋| 9513/13852 [35:42<15:58,  4.53it/s\u001b[A\n",
      "Training loss: 3.65e-02 lr: 1.57e-05:  69%|▋| 9514/13852 [35:42<15:56,  4.54it/s\u001b[A\n",
      "Training loss: 2.95e-02 lr: 1.57e-05:  69%|▋| 9515/13852 [35:42<15:51,  4.56it/s\u001b[A\n",
      "Training loss: 4.05e-02 lr: 1.57e-05:  69%|▋| 9516/13852 [35:42<15:49,  4.57it/s\u001b[A\n",
      "Training loss: 6.39e-02 lr: 1.56e-05:  69%|▋| 9517/13852 [35:42<15:51,  4.56it/s\u001b[A\n",
      "Training loss: 6.15e-02 lr: 1.56e-05:  69%|▋| 9518/13852 [35:43<15:52,  4.55it/s\u001b[A\n",
      "Training loss: 5.12e-02 lr: 1.56e-05:  69%|▋| 9519/13852 [35:43<15:53,  4.54it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 1.56e-05:  69%|▋| 9520/13852 [35:43<15:54,  4.54it/s\u001b[A\n",
      "Training loss: 9.69e-02 lr: 1.56e-05:  69%|▋| 9521/13852 [35:43<15:55,  4.54it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 1.56e-05:  69%|▋| 9522/13852 [35:44<15:54,  4.54it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 1.56e-05:  69%|▋| 9523/13852 [35:44<15:53,  4.54it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.56e-05:  69%|▋| 9524/13852 [35:44<15:53,  4.54it/s\u001b[A\n",
      "Training loss: 3.36e-02 lr: 1.56e-05:  69%|▋| 9525/13852 [35:44<15:54,  4.53it/s\u001b[A\n",
      "Training loss: 5.20e-02 lr: 1.56e-05:  69%|▋| 9526/13852 [35:44<15:53,  4.54it/s\u001b[A\n",
      "Training loss: 4.63e-02 lr: 1.56e-05:  69%|▋| 9527/13852 [35:45<15:49,  4.55it/s\u001b[A\n",
      "Training loss: 3.94e-02 lr: 1.56e-05:  69%|▋| 9528/13852 [35:45<15:46,  4.57it/s\u001b[A\n",
      "Training loss: 2.98e-02 lr: 1.56e-05:  69%|▋| 9529/13852 [35:45<15:53,  4.54it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 1.56e-05:  69%|▋| 9530/13852 [35:45<15:57,  4.52it/s\u001b[A\n",
      "Training loss: 4.59e-02 lr: 1.56e-05:  69%|▋| 9531/13852 [35:46<15:56,  4.52it/s\u001b[A\n",
      "Training loss: 5.29e-02 lr: 1.56e-05:  69%|▋| 9532/13852 [35:46<15:56,  4.52it/s\u001b[A\n",
      "Training loss: 3.85e-02 lr: 1.56e-05:  69%|▋| 9533/13852 [35:46<15:55,  4.52it/s\u001b[A\n",
      "Training loss: 4.65e-02 lr: 1.56e-05:  69%|▋| 9534/13852 [35:46<15:54,  4.52it/s\u001b[A\n",
      "Training loss: 6.48e-02 lr: 1.56e-05:  69%|▋| 9535/13852 [35:46<15:53,  4.53it/s\u001b[A\n",
      "Training loss: 5.42e-02 lr: 1.56e-05:  69%|▋| 9536/13852 [35:47<15:56,  4.51it/s\u001b[A\n",
      "Training loss: 5.10e-02 lr: 1.56e-05:  69%|▋| 9537/13852 [35:47<15:55,  4.52it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 1.56e-05:  69%|▋| 9538/13852 [35:47<15:53,  4.52it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 1.56e-05:  69%|▋| 9539/13852 [35:47<15:52,  4.53it/s\u001b[A\n",
      "Training loss: 3.53e-02 lr: 1.56e-05:  69%|▋| 9540/13852 [35:48<15:51,  4.53it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 1.56e-05:  69%|▋| 9541/13852 [35:48<15:51,  4.53it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 1.56e-05:  69%|▋| 9542/13852 [35:48<16:15,  4.42it/s\u001b[A\n",
      "Training loss: 3.03e-02 lr: 1.56e-05:  69%|▋| 9543/13852 [35:48<16:42,  4.30it/s\u001b[A\n",
      "Training loss: 2.94e-02 lr: 1.56e-05:  69%|▋| 9544/13852 [35:49<17:00,  4.22it/s\u001b[A\n",
      "Training loss: 2.38e-02 lr: 1.55e-05:  69%|▋| 9545/13852 [35:49<16:45,  4.28it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 1.55e-05:  69%|▋| 9546/13852 [35:49<16:31,  4.34it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 1.55e-05:  69%|▋| 9547/13852 [35:49<16:20,  4.39it/s\u001b[A\n",
      "Training loss: 7.64e-02 lr: 1.55e-05:  69%|▋| 9548/13852 [35:49<16:08,  4.44it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 1.55e-05:  69%|▋| 9549/13852 [35:50<15:59,  4.48it/s\u001b[A\n",
      "Training loss: 5.90e-02 lr: 1.55e-05:  69%|▋| 9550/13852 [35:50<15:52,  4.52it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 1.55e-05:  69%|▋| 9551/13852 [35:50<15:51,  4.52it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 1.55e-05:  69%|▋| 9552/13852 [35:50<15:51,  4.52it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 1.55e-05:  69%|▋| 9553/13852 [35:51<15:50,  4.52it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 1.55e-05:  69%|▋| 9554/13852 [35:51<15:51,  4.52it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.55e-05:  69%|▋| 9555/13852 [35:51<15:56,  4.49it/s\u001b[A\n",
      "Training loss: 3.38e-02 lr: 1.55e-05:  69%|▋| 9556/13852 [35:51<15:56,  4.49it/s\u001b[A\n",
      "Training loss: 4.31e-02 lr: 1.55e-05:  69%|▋| 9557/13852 [35:51<15:55,  4.50it/s\u001b[A\n",
      "Training loss: 6.23e-02 lr: 1.55e-05:  69%|▋| 9558/13852 [35:52<15:55,  4.49it/s\u001b[A\n",
      "Training loss: 5.31e-02 lr: 1.55e-05:  69%|▋| 9559/13852 [35:52<15:59,  4.47it/s\u001b[A\n",
      "Training loss: 6.54e-02 lr: 1.55e-05:  69%|▋| 9560/13852 [35:52<15:59,  4.47it/s\u001b[A\n",
      "Training loss: 5.74e-02 lr: 1.55e-05:  69%|▋| 9561/13852 [35:52<15:54,  4.49it/s\u001b[A\n",
      "Training loss: 1.18e-01 lr: 1.55e-05:  69%|▋| 9562/13852 [35:53<15:48,  4.52it/s\u001b[A\n",
      "Training loss: 8.51e-02 lr: 1.55e-05:  69%|▋| 9563/13852 [35:53<15:55,  4.49it/s\u001b[A\n",
      "Training loss: 7.53e-02 lr: 1.55e-05:  69%|▋| 9564/13852 [35:53<15:54,  4.49it/s\u001b[A\n",
      "Training loss: 5.88e-02 lr: 1.55e-05:  69%|▋| 9565/13852 [35:53<15:51,  4.50it/s\u001b[A\n",
      "Training loss: 7.31e-02 lr: 1.55e-05:  69%|▋| 9566/13852 [35:53<15:53,  4.50it/s\u001b[A\n",
      "Training loss: 5.62e-02 lr: 1.55e-05:  69%|▋| 9567/13852 [35:54<15:52,  4.50it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 1.55e-05:  69%|▋| 9568/13852 [35:54<15:51,  4.50it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 1.55e-05:  69%|▋| 9569/13852 [35:54<15:51,  4.50it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 1.55e-05:  69%|▋| 9570/13852 [35:54<15:54,  4.48it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 1.55e-05:  69%|▋| 9571/13852 [35:55<15:53,  4.49it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 1.55e-05:  69%|▋| 9572/13852 [35:55<15:48,  4.51it/s\u001b[A\n",
      "Training loss: 7.85e-02 lr: 1.54e-05:  69%|▋| 9573/13852 [35:55<15:42,  4.54it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 1.54e-05:  69%|▋| 9574/13852 [35:55<15:44,  4.53it/s\u001b[A\n",
      "Training loss: 5.56e-02 lr: 1.54e-05:  69%|▋| 9575/13852 [35:55<15:49,  4.50it/s\u001b[A\n",
      "Training loss: 6.86e-02 lr: 1.54e-05:  69%|▋| 9576/13852 [35:56<15:49,  4.50it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 1.54e-05:  69%|▋| 9577/13852 [35:56<15:46,  4.51it/s\u001b[A\n",
      "Training loss: 4.88e-02 lr: 1.54e-05:  69%|▋| 9578/13852 [35:56<15:47,  4.51it/s\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.54e-05:  69%|▋| 9579/13852 [35:56<15:48,  4.50it/s\u001b[A\n",
      "Training loss: 3.80e-02 lr: 1.54e-05:  69%|▋| 9580/13852 [35:57<15:48,  4.51it/s\u001b[A\n",
      "Training loss: 2.94e-02 lr: 1.54e-05:  69%|▋| 9581/13852 [35:57<15:56,  4.46it/s\u001b[A\n",
      "Training loss: 7.30e-02 lr: 1.54e-05:  69%|▋| 9582/13852 [35:57<15:55,  4.47it/s\u001b[A\n",
      "Training loss: 5.40e-02 lr: 1.54e-05:  69%|▋| 9583/13852 [35:57<15:55,  4.47it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 1.54e-05:  69%|▋| 9584/13852 [35:57<15:48,  4.50it/s\u001b[A\n",
      "Training loss: 4.81e-02 lr: 1.54e-05:  69%|▋| 9585/13852 [35:58<15:43,  4.52it/s\u001b[A\n",
      "Training loss: 3.93e-02 lr: 1.54e-05:  69%|▋| 9586/13852 [35:58<15:43,  4.52it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 1.54e-05:  69%|▋| 9587/13852 [35:58<15:44,  4.51it/s\u001b[A\n",
      "Training loss: 4.51e-02 lr: 1.54e-05:  69%|▋| 9588/13852 [35:58<15:44,  4.52it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 1.54e-05:  69%|▋| 9589/13852 [35:59<15:44,  4.51it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 1.54e-05:  69%|▋| 9590/13852 [35:59<15:43,  4.52it/s\u001b[A\n",
      "Training loss: 2.87e-02 lr: 1.54e-05:  69%|▋| 9591/13852 [35:59<15:43,  4.51it/s\u001b[A\n",
      "Training loss: 2.18e-02 lr: 1.54e-05:  69%|▋| 9592/13852 [35:59<15:42,  4.52it/s\u001b[A\n",
      "Training loss: 3.07e-02 lr: 1.54e-05:  69%|▋| 9593/13852 [35:59<15:43,  4.52it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.39e-02 lr: 1.54e-05:  69%|▋| 9594/13852 [36:00<15:44,  4.51it/s\u001b[A\n",
      "Training loss: 3.37e-02 lr: 1.54e-05:  69%|▋| 9595/13852 [36:00<15:44,  4.51it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 1.54e-05:  69%|▋| 9596/13852 [36:00<15:43,  4.51it/s\u001b[A\n",
      "Training loss: 8.54e-02 lr: 1.54e-05:  69%|▋| 9597/13852 [36:00<15:39,  4.53it/s\u001b[A\n",
      "Training loss: 8.75e-02 lr: 1.54e-05:  69%|▋| 9598/13852 [36:01<15:36,  4.54it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 1.54e-05:  69%|▋| 9599/13852 [36:01<15:42,  4.51it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 1.53e-05:  69%|▋| 9600/13852 [36:01<15:46,  4.49it/s\u001b[A\n",
      "Training loss: 8.59e-02 lr: 1.53e-05:  69%|▋| 9601/13852 [36:01<15:43,  4.51it/s\u001b[A\n",
      "Training loss: 8.55e-02 lr: 1.53e-05:  69%|▋| 9602/13852 [36:01<15:47,  4.49it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 1.53e-05:  69%|▋| 9603/13852 [36:02<15:46,  4.49it/s\u001b[A\n",
      "Training loss: 5.08e-02 lr: 1.53e-05:  69%|▋| 9604/13852 [36:02<15:46,  4.49it/s\u001b[A\n",
      "Training loss: 5.16e-02 lr: 1.53e-05:  69%|▋| 9605/13852 [36:02<15:46,  4.48it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 1.53e-05:  69%|▋| 9606/13852 [36:02<15:46,  4.49it/s\u001b[A\n",
      "Training loss: 2.92e-02 lr: 1.53e-05:  69%|▋| 9607/13852 [36:03<15:46,  4.49it/s\u001b[A\n",
      "Training loss: 2.44e-02 lr: 1.53e-05:  69%|▋| 9608/13852 [36:03<15:41,  4.51it/s\u001b[A\n",
      "Training loss: 3.90e-02 lr: 1.53e-05:  69%|▋| 9609/13852 [36:03<15:43,  4.49it/s\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.53e-05:  69%|▋| 9610/13852 [36:03<15:46,  4.48it/s\u001b[A\n",
      "Training loss: 2.09e-02 lr: 1.53e-05:  69%|▋| 9611/13852 [36:03<15:46,  4.48it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 1.53e-05:  69%|▋| 9612/13852 [36:04<15:44,  4.49it/s\u001b[A\n",
      "Training loss: 4.32e-02 lr: 1.53e-05:  69%|▋| 9613/13852 [36:04<15:41,  4.50it/s\u001b[A\n",
      "Training loss: 4.28e-02 lr: 1.53e-05:  69%|▋| 9614/13852 [36:04<15:40,  4.50it/s\u001b[A\n",
      "Training loss: 3.74e-02 lr: 1.53e-05:  69%|▋| 9615/13852 [36:04<15:39,  4.51it/s\u001b[A\n",
      "Training loss: 3.80e-02 lr: 1.53e-05:  69%|▋| 9616/13852 [36:05<15:38,  4.51it/s\u001b[A\n",
      "Training loss: 3.12e-02 lr: 1.53e-05:  69%|▋| 9617/13852 [36:05<15:38,  4.51it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 1.53e-05:  69%|▋| 9618/13852 [36:05<15:41,  4.50it/s\u001b[A\n",
      "Training loss: 2.73e-02 lr: 1.53e-05:  69%|▋| 9619/13852 [36:05<15:40,  4.50it/s\u001b[A\n",
      "Training loss: 2.28e-02 lr: 1.53e-05:  69%|▋| 9620/13852 [36:05<15:38,  4.51it/s\u001b[A\n",
      "Training loss: 2.83e-02 lr: 1.53e-05:  69%|▋| 9621/13852 [36:06<15:33,  4.53it/s\u001b[A\n",
      "Training loss: 4.08e-02 lr: 1.53e-05:  69%|▋| 9622/13852 [36:06<15:29,  4.55it/s\u001b[A\n",
      "Training loss: 3.19e-02 lr: 1.53e-05:  69%|▋| 9623/13852 [36:06<15:32,  4.53it/s\u001b[A\n",
      "Training loss: 2.57e-02 lr: 1.53e-05:  69%|▋| 9624/13852 [36:06<15:36,  4.52it/s\u001b[A\n",
      "Training loss: 2.88e-02 lr: 1.53e-05:  69%|▋| 9625/13852 [36:07<15:42,  4.48it/s\u001b[A\n",
      "Training loss: 7.75e-02 lr: 1.53e-05:  69%|▋| 9626/13852 [36:07<15:53,  4.43it/s\u001b[A\n",
      "Training loss: 1.00e-01 lr: 1.53e-05:  69%|▋| 9627/13852 [36:07<15:53,  4.43it/s\u001b[A\n",
      "Training loss: 9.56e-02 lr: 1.52e-05:  70%|▋| 9628/13852 [36:07<15:50,  4.44it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.52e-05:  70%|▋| 9629/13852 [36:07<15:51,  4.44it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 1.52e-05:  70%|▋| 9630/13852 [36:08<15:49,  4.45it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.52e-05:  70%|▋| 9631/13852 [36:08<15:45,  4.46it/s\u001b[A\n",
      "Training loss: 9.81e-02 lr: 1.52e-05:  70%|▋| 9632/13852 [36:08<15:39,  4.49it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 1.52e-05:  70%|▋| 9633/13852 [36:08<15:41,  4.48it/s\u001b[A\n",
      "Training loss: 5.44e-02 lr: 1.52e-05:  70%|▋| 9634/13852 [36:09<15:39,  4.49it/s\u001b[A\n",
      "Training loss: 3.98e-02 lr: 1.52e-05:  70%|▋| 9635/13852 [36:09<15:36,  4.50it/s\u001b[A\n",
      "Training loss: 2.93e-02 lr: 1.52e-05:  70%|▋| 9636/13852 [36:09<15:35,  4.51it/s\u001b[A\n",
      "Training loss: 5.58e-02 lr: 1.52e-05:  70%|▋| 9637/13852 [36:09<15:34,  4.51it/s\u001b[A\n",
      "Training loss: 4.08e-02 lr: 1.52e-05:  70%|▋| 9638/13852 [36:09<15:34,  4.51it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 1.52e-05:  70%|▋| 9639/13852 [36:10<15:38,  4.49it/s\u001b[A\n",
      "Training loss: 2.36e-02 lr: 1.52e-05:  70%|▋| 9640/13852 [36:10<15:36,  4.50it/s\u001b[A\n",
      "Training loss: 3.24e-02 lr: 1.52e-05:  70%|▋| 9641/13852 [36:10<15:36,  4.49it/s\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.52e-05:  70%|▋| 9642/13852 [36:10<15:33,  4.51it/s\u001b[A\n",
      "Training loss: 3.37e-02 lr: 1.52e-05:  70%|▋| 9643/13852 [36:11<15:27,  4.54it/s\u001b[A\n",
      "Training loss: 3.07e-02 lr: 1.52e-05:  70%|▋| 9644/13852 [36:11<15:30,  4.52it/s\u001b[A\n",
      "Training loss: 2.39e-02 lr: 1.52e-05:  70%|▋| 9645/13852 [36:11<15:39,  4.48it/s\u001b[A\n",
      "Training loss: 3.15e-02 lr: 1.52e-05:  70%|▋| 9646/13852 [36:11<15:36,  4.49it/s\u001b[A\n",
      "Training loss: 2.89e-02 lr: 1.52e-05:  70%|▋| 9647/13852 [36:11<15:33,  4.50it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 1.52e-05:  70%|▋| 9648/13852 [36:12<15:35,  4.49it/s\u001b[A\n",
      "Training loss: 8.70e-02 lr: 1.52e-05:  70%|▋| 9649/13852 [36:12<15:36,  4.49it/s\u001b[A\n",
      "Training loss: 6.17e-02 lr: 1.52e-05:  70%|▋| 9650/13852 [36:12<15:36,  4.48it/s\u001b[A\n",
      "Training loss: 7.63e-02 lr: 1.52e-05:  70%|▋| 9651/13852 [36:12<15:36,  4.48it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 1.52e-05:  70%|▋| 9652/13852 [36:13<15:35,  4.49it/s\u001b[A\n",
      "Training loss: 4.97e-02 lr: 1.52e-05:  70%|▋| 9653/13852 [36:13<15:35,  4.49it/s\u001b[A\n",
      "Training loss: 6.07e-02 lr: 1.52e-05:  70%|▋| 9654/13852 [36:13<15:30,  4.51it/s\u001b[A\n",
      "Training loss: 4.70e-02 lr: 1.52e-05:  70%|▋| 9655/13852 [36:13<15:27,  4.52it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 1.51e-05:  70%|▋| 9656/13852 [36:13<15:25,  4.53it/s\u001b[A\n",
      "Training loss: 3.91e-02 lr: 1.51e-05:  70%|▋| 9657/13852 [36:14<15:26,  4.53it/s\u001b[A\n",
      "Training loss: 3.01e-02 lr: 1.51e-05:  70%|▋| 9658/13852 [36:14<15:26,  4.53it/s\u001b[A\n",
      "Training loss: 3.60e-02 lr: 1.51e-05:  70%|▋| 9659/13852 [36:14<15:27,  4.52it/s\u001b[A\n",
      "Training loss: 9.70e-02 lr: 1.51e-05:  70%|▋| 9660/13852 [36:14<15:28,  4.52it/s\u001b[A\n",
      "Training loss: 7.37e-02 lr: 1.51e-05:  70%|▋| 9661/13852 [36:15<15:29,  4.51it/s\u001b[A\n",
      "Training loss: 9.53e-02 lr: 1.51e-05:  70%|▋| 9662/13852 [36:15<15:30,  4.50it/s\u001b[A\n",
      "Training loss: 7.49e-02 lr: 1.51e-05:  70%|▋| 9663/13852 [36:15<15:30,  4.50it/s\u001b[A\n",
      "Training loss: 1.50e-01 lr: 1.51e-05:  70%|▋| 9664/13852 [36:15<15:30,  4.50it/s\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.51e-05:  70%|▋| 9665/13852 [36:15<15:32,  4.49it/s\u001b[A\n",
      "Training loss: 9.43e-02 lr: 1.51e-05:  70%|▋| 9666/13852 [36:16<15:33,  4.49it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.51e-05:  70%|▋| 9667/13852 [36:16<15:26,  4.52it/s\u001b[A\n",
      "Training loss: 8.46e-02 lr: 1.51e-05:  70%|▋| 9668/13852 [36:16<15:22,  4.53it/s\u001b[A\n",
      "Training loss: 6.24e-02 lr: 1.51e-05:  70%|▋| 9669/13852 [36:16<15:28,  4.51it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 1.51e-05:  70%|▋| 9670/13852 [36:17<15:26,  4.51it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 1.51e-05:  70%|▋| 9671/13852 [36:17<15:31,  4.49it/s\u001b[A\n",
      "Training loss: 6.53e-02 lr: 1.51e-05:  70%|▋| 9672/13852 [36:17<15:31,  4.49it/s\u001b[A\n",
      "Training loss: 7.60e-02 lr: 1.51e-05:  70%|▋| 9673/13852 [36:17<15:31,  4.49it/s\u001b[A\n",
      "Training loss: 8.86e-02 lr: 1.51e-05:  70%|▋| 9674/13852 [36:17<15:29,  4.49it/s\u001b[A\n",
      "Training loss: 7.46e-02 lr: 1.51e-05:  70%|▋| 9675/13852 [36:18<15:29,  4.49it/s\u001b[A\n",
      "Training loss: 6.95e-02 lr: 1.51e-05:  70%|▋| 9676/13852 [36:18<15:29,  4.49it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 1.51e-05:  70%|▋| 9677/13852 [36:18<15:33,  4.47it/s\u001b[A\n",
      "Training loss: 6.62e-02 lr: 1.51e-05:  70%|▋| 9678/13852 [36:18<15:28,  4.49it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 1.51e-05:  70%|▋| 9679/13852 [36:19<15:24,  4.51it/s\u001b[A\n",
      "Training loss: 3.73e-02 lr: 1.51e-05:  70%|▋| 9680/13852 [36:19<15:31,  4.48it/s\u001b[A\n",
      "Training loss: 3.91e-02 lr: 1.51e-05:  70%|▋| 9681/13852 [36:19<15:29,  4.49it/s\u001b[A\n",
      "Training loss: 3.27e-02 lr: 1.51e-05:  70%|▋| 9682/13852 [36:19<15:26,  4.50it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 1.50e-05:  70%|▋| 9683/13852 [36:19<15:25,  4.50it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 1.50e-05:  70%|▋| 9684/13852 [36:20<15:24,  4.51it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 1.50e-05:  70%|▋| 9685/13852 [36:20<15:25,  4.50it/s\u001b[A\n",
      "Training loss: 7.84e-02 lr: 1.50e-05:  70%|▋| 9686/13852 [36:20<15:26,  4.50it/s\u001b[A\n",
      "Training loss: 6.19e-02 lr: 1.50e-05:  70%|▋| 9687/13852 [36:20<15:27,  4.49it/s\u001b[A\n",
      "Training loss: 9.12e-02 lr: 1.50e-05:  70%|▋| 9688/13852 [36:21<15:26,  4.49it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 1.50e-05:  70%|▋| 9689/13852 [36:21<15:26,  4.49it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 1.50e-05:  70%|▋| 9690/13852 [36:21<15:24,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.37e-02 lr: 1.50e-05:  70%|▋| 9691/13852 [36:21<15:18,  4.53it/s\u001b[A\n",
      "Training loss: 6.03e-02 lr: 1.50e-05:  70%|▋| 9692/13852 [36:21<15:13,  4.55it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 1.50e-05:  70%|▋| 9693/13852 [36:22<15:17,  4.54it/s\u001b[A\n",
      "Training loss: 3.59e-02 lr: 1.50e-05:  70%|▋| 9694/13852 [36:22<15:19,  4.52it/s\u001b[A\n",
      "Training loss: 3.21e-02 lr: 1.50e-05:  70%|▋| 9695/13852 [36:22<15:22,  4.51it/s\u001b[A\n",
      "Training loss: 2.72e-02 lr: 1.50e-05:  70%|▋| 9696/13852 [36:22<15:22,  4.51it/s\u001b[A\n",
      "Training loss: 9.45e-02 lr: 1.50e-05:  70%|▋| 9697/13852 [36:23<15:27,  4.48it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 1.50e-05:  70%|▋| 9698/13852 [36:23<15:28,  4.48it/s\u001b[A\n",
      "Training loss: 7.53e-02 lr: 1.50e-05:  70%|▋| 9699/13852 [36:23<15:29,  4.47it/s\u001b[A\n",
      "Training loss: 8.32e-02 lr: 1.50e-05:  70%|▋| 9700/13852 [36:23<15:28,  4.47it/s\u001b[A\n",
      "Training loss: 6.38e-02 lr: 1.50e-05:  70%|▋| 9701/13852 [36:23<15:29,  4.46it/s\u001b[A\n",
      "Training loss: 5.89e-02 lr: 1.50e-05:  70%|▋| 9702/13852 [36:24<15:22,  4.50it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 1.50e-05:  70%|▋| 9703/13852 [36:24<15:16,  4.53it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 1.50e-05:  70%|▋| 9704/13852 [36:24<15:22,  4.50it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 1.50e-05:  70%|▋| 9705/13852 [36:24<15:21,  4.50it/s\u001b[A\n",
      "Training loss: 3.82e-02 lr: 1.50e-05:  70%|▋| 9706/13852 [36:25<15:19,  4.51it/s\u001b[A\n",
      "Training loss: 3.05e-02 lr: 1.50e-05:  70%|▋| 9707/13852 [36:25<15:18,  4.51it/s\u001b[A\n",
      "Training loss: 4.44e-02 lr: 1.50e-05:  70%|▋| 9708/13852 [36:25<15:20,  4.50it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 1.50e-05:  70%|▋| 9709/13852 [36:25<15:21,  4.50it/s\u001b[A\n",
      "Training loss: 3.48e-02 lr: 1.50e-05:  70%|▋| 9710/13852 [36:25<15:28,  4.46it/s\u001b[A\n",
      "Training loss: 3.04e-02 lr: 1.49e-05:  70%|▋| 9711/13852 [36:26<15:26,  4.47it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 1.49e-05:  70%|▋| 9712/13852 [36:26<15:25,  4.47it/s\u001b[A\n",
      "Training loss: 3.40e-02 lr: 1.49e-05:  70%|▋| 9713/13852 [36:26<15:21,  4.49it/s\u001b[A\n",
      "Training loss: 7.63e-02 lr: 1.49e-05:  70%|▋| 9714/13852 [36:26<15:15,  4.52it/s\u001b[A\n",
      "Training loss: 5.51e-02 lr: 1.49e-05:  70%|▋| 9715/13852 [36:27<15:18,  4.51it/s\u001b[A\n",
      "Training loss: 5.09e-02 lr: 1.49e-05:  70%|▋| 9716/13852 [36:27<15:26,  4.47it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 1.49e-05:  70%|▋| 9717/13852 [36:27<15:24,  4.47it/s\u001b[A\n",
      "Training loss: 6.11e-02 lr: 1.49e-05:  70%|▋| 9718/13852 [36:27<15:21,  4.49it/s\u001b[A\n",
      "Training loss: 4.89e-02 lr: 1.49e-05:  70%|▋| 9719/13852 [36:27<15:20,  4.49it/s\u001b[A\n",
      "Training loss: 4.67e-02 lr: 1.49e-05:  70%|▋| 9720/13852 [36:28<15:19,  4.49it/s\u001b[A\n",
      "Training loss: 3.45e-02 lr: 1.49e-05:  70%|▋| 9721/13852 [36:28<15:19,  4.49it/s\u001b[A\n",
      "Training loss: 4.36e-02 lr: 1.49e-05:  70%|▋| 9722/13852 [36:28<15:20,  4.48it/s\u001b[A\n",
      "Training loss: 6.58e-02 lr: 1.49e-05:  70%|▋| 9723/13852 [36:28<15:19,  4.49it/s\u001b[A\n",
      "Training loss: 1.27e-01 lr: 1.49e-05:  70%|▋| 9724/13852 [36:29<15:14,  4.51it/s\u001b[A\n",
      "Training loss: 9.36e-02 lr: 1.49e-05:  70%|▋| 9725/13852 [36:29<15:09,  4.54it/s\u001b[A\n",
      "Training loss: 7.43e-02 lr: 1.49e-05:  70%|▋| 9726/13852 [36:29<15:06,  4.55it/s\u001b[A\n",
      "Training loss: 5.99e-02 lr: 1.49e-05:  70%|▋| 9727/13852 [36:29<15:16,  4.50it/s\u001b[A\n",
      "Training loss: 4.33e-02 lr: 1.49e-05:  70%|▋| 9728/13852 [36:29<15:15,  4.50it/s\u001b[A\n",
      "Training loss: 5.22e-02 lr: 1.49e-05:  70%|▋| 9729/13852 [36:30<15:16,  4.50it/s\u001b[A\n",
      "Training loss: 4.43e-02 lr: 1.49e-05:  70%|▋| 9730/13852 [36:30<15:15,  4.50it/s\u001b[A\n",
      "Training loss: 4.04e-02 lr: 1.49e-05:  70%|▋| 9731/13852 [36:30<15:17,  4.49it/s\u001b[A\n",
      "Training loss: 9.94e-02 lr: 1.49e-05:  70%|▋| 9732/13852 [36:30<15:18,  4.49it/s\u001b[A\n",
      "Training loss: 7.56e-02 lr: 1.49e-05:  70%|▋| 9733/13852 [36:31<15:17,  4.49it/s\u001b[A\n",
      "Training loss: 8.17e-02 lr: 1.49e-05:  70%|▋| 9734/13852 [36:31<15:21,  4.47it/s\u001b[A\n",
      "Training loss: 6.41e-02 lr: 1.49e-05:  70%|▋| 9735/13852 [36:31<15:23,  4.46it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.49e-05:  70%|▋| 9736/13852 [36:31<15:16,  4.49it/s\u001b[A\n",
      "Training loss: 7.26e-02 lr: 1.49e-05:  70%|▋| 9737/13852 [36:31<15:08,  4.53it/s\u001b[A\n",
      "Training loss: 7.83e-02 lr: 1.49e-05:  70%|▋| 9738/13852 [36:32<15:06,  4.54it/s\u001b[A\n",
      "Training loss: 5.79e-02 lr: 1.48e-05:  70%|▋| 9739/13852 [36:32<15:08,  4.53it/s\u001b[A\n",
      "Training loss: 4.27e-02 lr: 1.48e-05:  70%|▋| 9740/13852 [36:32<15:10,  4.52it/s\u001b[A\n",
      "Training loss: 3.71e-02 lr: 1.48e-05:  70%|▋| 9741/13852 [36:32<15:11,  4.51it/s\u001b[A\n",
      "Training loss: 3.22e-02 lr: 1.48e-05:  70%|▋| 9742/13852 [36:33<15:13,  4.50it/s\u001b[A\n",
      "Training loss: 3.09e-02 lr: 1.48e-05:  70%|▋| 9743/13852 [36:33<15:13,  4.50it/s\u001b[A\n",
      "Training loss: 3.47e-02 lr: 1.48e-05:  70%|▋| 9744/13852 [36:33<15:18,  4.47it/s\u001b[A\n",
      "Training loss: 4.07e-02 lr: 1.48e-05:  70%|▋| 9745/13852 [36:33<15:17,  4.48it/s\u001b[A\n",
      "Training loss: 4.64e-02 lr: 1.48e-05:  70%|▋| 9746/13852 [36:33<15:17,  4.47it/s\u001b[A\n",
      "Training loss: 6.66e-02 lr: 1.48e-05:  70%|▋| 9747/13852 [36:34<15:15,  4.48it/s\u001b[A\n",
      "Training loss: 4.98e-02 lr: 1.48e-05:  70%|▋| 9748/13852 [36:34<15:10,  4.51it/s\u001b[A\n",
      "Training loss: 4.72e-02 lr: 1.48e-05:  70%|▋| 9749/13852 [36:34<15:05,  4.53it/s\u001b[A\n",
      "Training loss: 6.57e-02 lr: 1.48e-05:  70%|▋| 9750/13852 [36:34<15:03,  4.54it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 1.48e-05:  70%|▋| 9751/13852 [36:35<15:07,  4.52it/s\u001b[A\n",
      "Training loss: 6.34e-02 lr: 1.48e-05:  70%|▋| 9752/13852 [36:35<15:07,  4.52it/s\u001b[A\n",
      "Training loss: 6.97e-02 lr: 1.48e-05:  70%|▋| 9753/13852 [36:35<15:07,  4.52it/s\u001b[A\n",
      "Training loss: 7.38e-02 lr: 1.48e-05:  70%|▋| 9754/13852 [36:35<15:06,  4.52it/s\u001b[A\n",
      "Training loss: 7.19e-02 lr: 1.48e-05:  70%|▋| 9755/13852 [36:35<15:08,  4.51it/s\u001b[A\n",
      "Training loss: 5.47e-02 lr: 1.48e-05:  70%|▋| 9756/13852 [36:36<15:09,  4.50it/s\u001b[A\n",
      "Training loss: 4.87e-02 lr: 1.48e-05:  70%|▋| 9757/13852 [36:36<15:09,  4.50it/s\u001b[A\n",
      "Training loss: 5.07e-02 lr: 1.48e-05:  70%|▋| 9758/13852 [36:36<15:10,  4.50it/s\u001b[A\n",
      "Training loss: 3.72e-02 lr: 1.48e-05:  70%|▋| 9759/13852 [36:36<15:10,  4.50it/s\u001b[A\n",
      "Training loss: 2.90e-02 lr: 1.48e-05:  70%|▋| 9760/13852 [36:37<15:06,  4.51it/s\u001b[A\n",
      "Training loss: 2.98e-02 lr: 1.48e-05:  70%|▋| 9761/13852 [36:37<15:43,  4.33it/s\u001b[A\n",
      "Training loss: 2.21e-02 lr: 1.48e-05:  70%|▋| 9762/13852 [36:37<15:59,  4.26it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 1.48e-05:  70%|▋| 9763/13852 [36:37<16:05,  4.24it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 1.48e-05:  70%|▋| 9764/13852 [36:37<16:14,  4.20it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.48e-05:  70%|▋| 9765/13852 [36:38<16:17,  4.18it/s\u001b[A\n",
      "Training loss: 1.44e-01 lr: 1.47e-05:  71%|▋| 9766/13852 [36:38<16:14,  4.19it/s\u001b[A\n",
      "Training loss: 1.06e-01 lr: 1.47e-05:  71%|▋| 9767/13852 [36:38<15:48,  4.31it/s\u001b[A\n",
      "Training loss: 7.76e-02 lr: 1.47e-05:  71%|▋| 9768/13852 [36:38<15:39,  4.35it/s\u001b[A\n",
      "Training loss: 1.40e-01 lr: 1.47e-05:  71%|▋| 9769/13852 [36:39<15:27,  4.40it/s\u001b[A\n",
      "Training loss: 1.09e-01 lr: 1.47e-05:  71%|▋| 9770/13852 [36:39<15:20,  4.43it/s\u001b[A\n",
      "Training loss: 8.14e-02 lr: 1.47e-05:  71%|▋| 9771/13852 [36:39<15:13,  4.47it/s\u001b[A\n",
      "Training loss: 9.61e-02 lr: 1.47e-05:  71%|▋| 9772/13852 [36:39<15:15,  4.46it/s\u001b[A\n",
      "Training loss: 7.19e-02 lr: 1.47e-05:  71%|▋| 9773/13852 [36:40<15:11,  4.47it/s\u001b[A\n",
      "Training loss: 7.69e-02 lr: 1.47e-05:  71%|▋| 9774/13852 [36:40<15:09,  4.48it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 1.47e-05:  71%|▋| 9775/13852 [36:40<15:07,  4.49it/s\u001b[A\n",
      "Training loss: 4.84e-02 lr: 1.47e-05:  71%|▋| 9776/13852 [36:40<15:07,  4.49it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 1.47e-05:  71%|▋| 9777/13852 [36:40<15:01,  4.52it/s\u001b[A\n",
      "Training loss: 4.49e-02 lr: 1.47e-05:  71%|▋| 9778/13852 [36:41<14:56,  4.54it/s\u001b[A\n",
      "Training loss: 3.22e-02 lr: 1.47e-05:  71%|▋| 9779/13852 [36:41<15:22,  4.42it/s\u001b[A\n",
      "Training loss: 3.81e-02 lr: 1.47e-05:  71%|▋| 9780/13852 [36:41<15:15,  4.45it/s\u001b[A\n",
      "Training loss: 3.63e-02 lr: 1.47e-05:  71%|▋| 9781/13852 [36:41<15:12,  4.46it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 1.47e-05:  71%|▋| 9782/13852 [36:42<15:09,  4.48it/s\u001b[A\n",
      "Training loss: 3.80e-02 lr: 1.47e-05:  71%|▋| 9783/13852 [36:42<15:16,  4.44it/s\u001b[A\n",
      "Training loss: 3.38e-02 lr: 1.47e-05:  71%|▋| 9784/13852 [36:42<15:12,  4.46it/s\u001b[A\n",
      "Training loss: 2.70e-02 lr: 1.47e-05:  71%|▋| 9785/13852 [36:42<15:11,  4.46it/s\u001b[A\n",
      "Training loss: 3.59e-02 lr: 1.47e-05:  71%|▋| 9786/13852 [36:42<15:10,  4.47it/s\u001b[A\n",
      "Training loss: 5.21e-02 lr: 1.47e-05:  71%|▋| 9787/13852 [36:43<15:08,  4.47it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.05e-02 lr: 1.47e-05:  71%|▋| 9788/13852 [36:43<15:02,  4.50it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 1.47e-05:  71%|▋| 9789/13852 [36:43<14:56,  4.53it/s\u001b[A\n",
      "Training loss: 9.22e-02 lr: 1.47e-05:  71%|▋| 9790/13852 [36:43<15:05,  4.49it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.47e-05:  71%|▋| 9791/13852 [36:44<15:02,  4.50it/s\u001b[A\n",
      "Training loss: 7.39e-02 lr: 1.47e-05:  71%|▋| 9792/13852 [36:44<15:00,  4.51it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 1.47e-05:  71%|▋| 9793/13852 [36:44<14:59,  4.51it/s\u001b[A\n",
      "Training loss: 7.74e-02 lr: 1.46e-05:  71%|▋| 9794/13852 [36:44<14:58,  4.52it/s\u001b[A\n",
      "Training loss: 6.26e-02 lr: 1.46e-05:  71%|▋| 9795/13852 [36:44<14:59,  4.51it/s\u001b[A\n",
      "Training loss: 4.80e-02 lr: 1.46e-05:  71%|▋| 9796/13852 [36:45<15:00,  4.50it/s\u001b[A\n",
      "Training loss: 3.49e-02 lr: 1.46e-05:  71%|▋| 9797/13852 [36:45<15:00,  4.50it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 1.46e-05:  71%|▋| 9798/13852 [36:45<15:00,  4.50it/s\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.46e-05:  71%|▋| 9799/13852 [36:45<15:02,  4.49it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 1.46e-05:  71%|▋| 9800/13852 [36:46<15:13,  4.44it/s\u001b[A\n",
      "Training loss: 1.13e-01 lr: 1.46e-05:  71%|▋| 9801/13852 [36:46<15:05,  4.48it/s\u001b[A\n",
      "Training loss: 8.73e-02 lr: 1.46e-05:  71%|▋| 9802/13852 [36:46<15:04,  4.48it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 1.46e-05:  71%|▋| 9803/13852 [36:46<15:00,  4.50it/s\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.46e-05:  71%|▋| 9804/13852 [36:46<15:00,  4.50it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 1.46e-05:  71%|▋| 9805/13852 [36:47<15:03,  4.48it/s\u001b[A\n",
      "Training loss: 5.28e-02 lr: 1.46e-05:  71%|▋| 9806/13852 [36:47<15:06,  4.46it/s\u001b[A\n",
      "Training loss: 6.27e-02 lr: 1.46e-05:  71%|▋| 9807/13852 [36:47<15:04,  4.47it/s\u001b[A\n",
      "Training loss: 6.02e-02 lr: 1.46e-05:  71%|▋| 9808/13852 [36:47<15:03,  4.48it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 1.46e-05:  71%|▋| 9809/13852 [36:48<15:02,  4.48it/s\u001b[A\n",
      "Training loss: 5.63e-02 lr: 1.46e-05:  71%|▋| 9810/13852 [36:48<15:01,  4.48it/s\u001b[A\n",
      "Training loss: 4.10e-02 lr: 1.46e-05:  71%|▋| 9811/13852 [36:48<15:03,  4.47it/s\u001b[A\n",
      "Training loss: 4.14e-02 lr: 1.46e-05:  71%|▋| 9812/13852 [36:48<14:56,  4.51it/s\u001b[A\n",
      "Training loss: 4.36e-02 lr: 1.46e-05:  71%|▋| 9813/13852 [36:48<15:03,  4.47it/s\u001b[A\n",
      "Training loss: 3.65e-02 lr: 1.46e-05:  71%|▋| 9814/13852 [36:49<15:01,  4.48it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 1.46e-05:  71%|▋| 9815/13852 [36:49<14:59,  4.49it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 1.46e-05:  71%|▋| 9816/13852 [36:49<14:56,  4.50it/s\u001b[A\n",
      "Training loss: 4.58e-02 lr: 1.46e-05:  71%|▋| 9817/13852 [36:49<14:56,  4.50it/s\u001b[A\n",
      "Training loss: 4.38e-02 lr: 1.46e-05:  71%|▋| 9818/13852 [36:50<14:56,  4.50it/s\u001b[A\n",
      "Training loss: 3.58e-02 lr: 1.46e-05:  71%|▋| 9819/13852 [36:50<14:55,  4.50it/s\u001b[A\n",
      "Training loss: 2.70e-02 lr: 1.46e-05:  71%|▋| 9820/13852 [36:50<14:55,  4.50it/s\u001b[A\n",
      "Training loss: 2.26e-02 lr: 1.46e-05:  71%|▋| 9821/13852 [36:50<14:55,  4.50it/s\u001b[A\n",
      "Training loss: 1.65e-02 lr: 1.45e-05:  71%|▋| 9822/13852 [36:50<14:51,  4.52it/s\u001b[A\n",
      "Training loss: 2.10e-02 lr: 1.45e-05:  71%|▋| 9823/13852 [36:51<14:46,  4.54it/s\u001b[A\n",
      "Training loss: 2.43e-02 lr: 1.45e-05:  71%|▋| 9824/13852 [36:51<14:49,  4.53it/s\u001b[A\n",
      "Training loss: 3.26e-02 lr: 1.45e-05:  71%|▋| 9825/13852 [36:51<14:57,  4.48it/s\u001b[A\n",
      "Training loss: 2.92e-02 lr: 1.45e-05:  71%|▋| 9826/13852 [36:51<14:56,  4.49it/s\u001b[A\n",
      "Training loss: 2.09e-02 lr: 1.45e-05:  71%|▋| 9827/13852 [36:52<14:54,  4.50it/s\u001b[A\n",
      "Training loss: 3.20e-02 lr: 1.45e-05:  71%|▋| 9828/13852 [36:52<14:59,  4.47it/s\u001b[A\n",
      "Training loss: 2.76e-02 lr: 1.45e-05:  71%|▋| 9829/13852 [36:52<14:57,  4.48it/s\u001b[A\n",
      "Training loss: 5.43e-02 lr: 1.45e-05:  71%|▋| 9830/13852 [36:52<14:55,  4.49it/s\u001b[A\n",
      "Training loss: 6.29e-02 lr: 1.45e-05:  71%|▋| 9831/13852 [36:52<14:58,  4.48it/s\u001b[A\n",
      "Training loss: 6.67e-02 lr: 1.45e-05:  71%|▋| 9832/13852 [36:53<14:55,  4.49it/s\u001b[A\n",
      "Training loss: 5.48e-02 lr: 1.45e-05:  71%|▋| 9833/13852 [36:53<14:51,  4.51it/s\u001b[A\n",
      "Training loss: 8.72e-02 lr: 1.45e-05:  71%|▋| 9834/13852 [36:53<14:47,  4.53it/s\u001b[A\n",
      "Training loss: 7.20e-02 lr: 1.45e-05:  71%|▋| 9835/13852 [36:53<14:44,  4.54it/s\u001b[A\n",
      "Training loss: 6.10e-02 lr: 1.45e-05:  71%|▋| 9836/13852 [36:54<14:41,  4.56it/s\u001b[A\n",
      "Training loss: 4.91e-02 lr: 1.45e-05:  71%|▋| 9837/13852 [36:54<14:39,  4.57it/s\u001b[A\n",
      "Training loss: 9.74e-02 lr: 1.45e-05:  71%|▋| 9838/13852 [36:54<14:41,  4.56it/s\u001b[A\n",
      "Training loss: 1.05e-01 lr: 1.45e-05:  71%|▋| 9839/13852 [36:54<14:42,  4.55it/s\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.45e-05:  71%|▋| 9840/13852 [36:54<14:45,  4.53it/s\u001b[A\n",
      "Training loss: 9.04e-02 lr: 1.45e-05:  71%|▋| 9841/13852 [36:55<14:45,  4.53it/s\u001b[A\n",
      "Training loss: 7.52e-02 lr: 1.45e-05:  71%|▋| 9842/13852 [36:55<14:46,  4.52it/s\u001b[A\n",
      "Training loss: 5.75e-02 lr: 1.45e-05:  71%|▋| 9843/13852 [36:55<14:47,  4.52it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 1.45e-05:  71%|▋| 9844/13852 [36:55<14:47,  4.51it/s\u001b[A\n",
      "Training loss: 4.83e-02 lr: 1.45e-05:  71%|▋| 9845/13852 [36:56<14:48,  4.51it/s\u001b[A\n",
      "Training loss: 3.70e-02 lr: 1.45e-05:  71%|▋| 9846/13852 [36:56<14:50,  4.50it/s\u001b[A\n",
      "Training loss: 3.64e-02 lr: 1.45e-05:  71%|▋| 9847/13852 [36:56<14:46,  4.52it/s\u001b[A\n",
      "Training loss: 2.70e-02 lr: 1.45e-05:  71%|▋| 9848/13852 [36:56<14:40,  4.55it/s\u001b[A\n",
      "Training loss: 3.22e-02 lr: 1.45e-05:  71%|▋| 9849/13852 [36:56<14:37,  4.56it/s\u001b[A\n",
      "Training loss: 6.52e-02 lr: 1.44e-05:  71%|▋| 9850/13852 [36:57<14:46,  4.52it/s\u001b[A\n",
      "Training loss: 7.86e-02 lr: 1.44e-05:  71%|▋| 9851/13852 [36:57<14:51,  4.49it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 1.44e-05:  71%|▋| 9852/13852 [36:57<14:51,  4.49it/s\u001b[A\n",
      "Training loss: 4.92e-02 lr: 1.44e-05:  71%|▋| 9853/13852 [36:57<14:51,  4.49it/s\u001b[A\n",
      "Training loss: 4.12e-02 lr: 1.44e-05:  71%|▋| 9854/13852 [36:58<14:51,  4.48it/s\u001b[A\n",
      "Training loss: 4.46e-02 lr: 1.44e-05:  71%|▋| 9855/13852 [36:58<14:54,  4.47it/s\u001b[A\n",
      "Training loss: 5.36e-02 lr: 1.44e-05:  71%|▋| 9856/13852 [36:58<14:51,  4.48it/s\u001b[A\n",
      "Training loss: 3.97e-02 lr: 1.44e-05:  71%|▋| 9857/13852 [36:58<14:49,  4.49it/s\u001b[A\n",
      "Training loss: 4.41e-02 lr: 1.44e-05:  71%|▋| 9858/13852 [36:58<14:47,  4.50it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.44e-05:  71%|▋| 9859/13852 [36:59<14:41,  4.53it/s\u001b[A\n",
      "Training loss: 6.98e-02 lr: 1.44e-05:  71%|▋| 9860/13852 [36:59<14:37,  4.55it/s\u001b[A\n",
      "Training loss: 5.95e-02 lr: 1.44e-05:  71%|▋| 9861/13852 [36:59<14:35,  4.56it/s\u001b[A\n",
      "Training loss: 7.73e-02 lr: 1.44e-05:  71%|▋| 9862/13852 [36:59<14:36,  4.55it/s\u001b[A\n",
      "Training loss: 6.88e-02 lr: 1.44e-05:  71%|▋| 9863/13852 [37:00<14:36,  4.55it/s\u001b[A\n",
      "Training loss: 5.05e-02 lr: 1.44e-05:  71%|▋| 9864/13852 [37:00<14:38,  4.54it/s\u001b[A\n",
      "Training loss: 9.27e-02 lr: 1.44e-05:  71%|▋| 9865/13852 [37:00<14:39,  4.53it/s\u001b[A\n",
      "Training loss: 7.99e-02 lr: 1.44e-05:  71%|▋| 9866/13852 [37:00<14:41,  4.52it/s\u001b[A\n",
      "Training loss: 7.45e-02 lr: 1.44e-05:  71%|▋| 9867/13852 [37:00<14:44,  4.51it/s\u001b[A\n",
      "Training loss: 5.46e-02 lr: 1.44e-05:  71%|▋| 9868/13852 [37:01<14:45,  4.50it/s\u001b[A\n",
      "Training loss: 9.22e-02 lr: 1.44e-05:  71%|▋| 9869/13852 [37:01<14:54,  4.45it/s\u001b[A\n",
      "Training loss: 7.87e-02 lr: 1.44e-05:  71%|▋| 9870/13852 [37:01<14:53,  4.46it/s\u001b[A\n",
      "Training loss: 5.83e-02 lr: 1.44e-05:  71%|▋| 9871/13852 [37:01<14:47,  4.49it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 1.44e-05:  71%|▋| 9872/13852 [37:02<14:40,  4.52it/s\u001b[A\n",
      "Training loss: 3.48e-02 lr: 1.44e-05:  71%|▋| 9873/13852 [37:02<14:41,  4.52it/s\u001b[A\n",
      "Training loss: 2.82e-02 lr: 1.44e-05:  71%|▋| 9874/13852 [37:02<14:43,  4.50it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 1.44e-05:  71%|▋| 9875/13852 [37:02<14:42,  4.51it/s\u001b[A\n",
      "Training loss: 3.27e-02 lr: 1.44e-05:  71%|▋| 9876/13852 [37:02<14:41,  4.51it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 1.43e-05:  71%|▋| 9877/13852 [37:03<14:41,  4.51it/s\u001b[A\n",
      "Training loss: 4.54e-02 lr: 1.43e-05:  71%|▋| 9878/13852 [37:03<14:42,  4.50it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 1.43e-05:  71%|▋| 9879/13852 [37:03<14:45,  4.49it/s\u001b[A\n",
      "Training loss: 3.84e-02 lr: 1.43e-05:  71%|▋| 9880/13852 [37:03<14:44,  4.49it/s\u001b[A\n",
      "Training loss: 2.87e-02 lr: 1.43e-05:  71%|▋| 9881/13852 [37:04<14:43,  4.50it/s\u001b[A\n",
      "Training loss: 9.20e-02 lr: 1.43e-05:  71%|▋| 9882/13852 [37:04<14:44,  4.49it/s\u001b[A\n",
      "Training loss: 9.12e-02 lr: 1.43e-05:  71%|▋| 9883/13852 [37:04<14:40,  4.51it/s\u001b[A\n",
      "Training loss: 6.63e-02 lr: 1.43e-05:  71%|▋| 9884/13852 [37:04<14:34,  4.54it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.79e-02 lr: 1.43e-05:  71%|▋| 9885/13852 [37:04<14:30,  4.56it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 1.43e-05:  71%|▋| 9886/13852 [37:05<14:37,  4.52it/s\u001b[A\n",
      "Training loss: 4.15e-02 lr: 1.43e-05:  71%|▋| 9887/13852 [37:05<14:38,  4.52it/s\u001b[A\n",
      "Training loss: 3.45e-02 lr: 1.43e-05:  71%|▋| 9888/13852 [37:05<14:36,  4.52it/s\u001b[A\n",
      "Training loss: 4.07e-02 lr: 1.43e-05:  71%|▋| 9889/13852 [37:05<14:38,  4.51it/s\u001b[A\n",
      "Training loss: 5.92e-02 lr: 1.43e-05:  71%|▋| 9890/13852 [37:06<14:39,  4.51it/s\u001b[A\n",
      "Training loss: 5.06e-02 lr: 1.43e-05:  71%|▋| 9891/13852 [37:06<14:43,  4.48it/s\u001b[A\n",
      "Training loss: 3.98e-02 lr: 1.43e-05:  71%|▋| 9892/13852 [37:06<14:42,  4.49it/s\u001b[A\n",
      "Training loss: 5.43e-02 lr: 1.43e-05:  71%|▋| 9893/13852 [37:06<14:41,  4.49it/s\u001b[A\n",
      "Training loss: 4.09e-02 lr: 1.43e-05:  71%|▋| 9894/13852 [37:06<14:42,  4.49it/s\u001b[A\n",
      "Training loss: 5.17e-02 lr: 1.43e-05:  71%|▋| 9895/13852 [37:07<14:43,  4.48it/s\u001b[A\n",
      "Training loss: 6.43e-02 lr: 1.43e-05:  71%|▋| 9896/13852 [37:07<15:06,  4.36it/s\u001b[A\n",
      "Training loss: 4.76e-02 lr: 1.43e-05:  71%|▋| 9897/13852 [37:07<15:26,  4.27it/s\u001b[A\n",
      "Training loss: 3.88e-02 lr: 1.43e-05:  71%|▋| 9898/13852 [37:07<15:37,  4.22it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 1.43e-05:  71%|▋| 9899/13852 [37:08<15:45,  4.18it/s\u001b[A\n",
      "Training loss: 3.48e-02 lr: 1.43e-05:  71%|▋| 9900/13852 [37:08<15:51,  4.15it/s\u001b[A\n",
      "Training loss: 9.57e-02 lr: 1.43e-05:  71%|▋| 9901/13852 [37:08<15:27,  4.26it/s\u001b[A\n",
      "Training loss: 8.44e-02 lr: 1.43e-05:  71%|▋| 9902/13852 [37:08<15:06,  4.36it/s\u001b[A\n",
      "Training loss: 6.56e-02 lr: 1.43e-05:  71%|▋| 9903/13852 [37:09<15:01,  4.38it/s\u001b[A\n",
      "Training loss: 7.28e-02 lr: 1.43e-05:  71%|▋| 9904/13852 [37:09<14:54,  4.41it/s\u001b[A\n",
      "Training loss: 6.60e-02 lr: 1.42e-05:  72%|▋| 9905/13852 [37:09<14:47,  4.45it/s\u001b[A\n",
      "Training loss: 6.70e-02 lr: 1.42e-05:  72%|▋| 9906/13852 [37:09<14:44,  4.46it/s\u001b[A\n",
      "Training loss: 5.07e-02 lr: 1.42e-05:  72%|▋| 9907/13852 [37:09<14:41,  4.47it/s\u001b[A\n",
      "Training loss: 3.79e-02 lr: 1.42e-05:  72%|▋| 9908/13852 [37:10<14:40,  4.48it/s\u001b[A\n",
      "Training loss: 7.40e-02 lr: 1.42e-05:  72%|▋| 9909/13852 [37:10<14:38,  4.49it/s\u001b[A\n",
      "Training loss: 9.22e-02 lr: 1.42e-05:  72%|▋| 9910/13852 [37:10<14:39,  4.48it/s\u001b[A\n",
      "Training loss: 8.09e-02 lr: 1.42e-05:  72%|▋| 9911/13852 [37:10<14:39,  4.48it/s\u001b[A\n",
      "Training loss: 8.86e-02 lr: 1.42e-05:  72%|▋| 9912/13852 [37:11<14:35,  4.50it/s\u001b[A\n",
      "Training loss: 7.50e-02 lr: 1.42e-05:  72%|▋| 9913/13852 [37:11<14:36,  4.50it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 1.42e-05:  72%|▋| 9914/13852 [37:11<14:46,  4.44it/s\u001b[A\n",
      "Training loss: 6.45e-02 lr: 1.42e-05:  72%|▋| 9915/13852 [37:11<14:42,  4.46it/s\u001b[A\n",
      "Training loss: 6.74e-02 lr: 1.42e-05:  72%|▋| 9916/13852 [37:11<14:39,  4.48it/s\u001b[A\n",
      "Training loss: 6.65e-02 lr: 1.42e-05:  72%|▋| 9917/13852 [37:12<14:40,  4.47it/s\u001b[A\n",
      "Training loss: 6.94e-02 lr: 1.42e-05:  72%|▋| 9918/13852 [37:12<14:40,  4.47it/s\u001b[A\n",
      "Training loss: 6.42e-02 lr: 1.42e-05:  72%|▋| 9919/13852 [37:12<14:39,  4.47it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 1.42e-05:  72%|▋| 9920/13852 [37:12<14:37,  4.48it/s\u001b[A\n",
      "Training loss: 4.37e-02 lr: 1.42e-05:  72%|▋| 9921/13852 [37:13<14:35,  4.49it/s\u001b[A\n",
      "Training loss: 3.33e-02 lr: 1.42e-05:  72%|▋| 9922/13852 [37:13<14:35,  4.49it/s\u001b[A\n",
      "Training loss: 3.84e-02 lr: 1.42e-05:  72%|▋| 9923/13852 [37:13<14:34,  4.49it/s\u001b[A\n",
      "Training loss: 6.92e-02 lr: 1.42e-05:  72%|▋| 9924/13852 [37:13<14:30,  4.51it/s\u001b[A\n",
      "Training loss: 7.54e-02 lr: 1.42e-05:  72%|▋| 9925/13852 [37:13<14:26,  4.53it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.42e-05:  72%|▋| 9926/13852 [37:14<14:28,  4.52it/s\u001b[A\n",
      "Training loss: 1.19e-01 lr: 1.42e-05:  72%|▋| 9927/13852 [37:14<14:29,  4.52it/s\u001b[A\n",
      "Training loss: 9.81e-02 lr: 1.42e-05:  72%|▋| 9928/13852 [37:14<14:29,  4.51it/s\u001b[A\n",
      "Training loss: 8.09e-02 lr: 1.42e-05:  72%|▋| 9929/13852 [37:14<14:28,  4.52it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 1.42e-05:  72%|▋| 9930/13852 [37:15<14:29,  4.51it/s\u001b[A\n",
      "Training loss: 1.11e-01 lr: 1.42e-05:  72%|▋| 9931/13852 [37:15<14:29,  4.51it/s\u001b[A\n",
      "Training loss: 8.03e-02 lr: 1.42e-05:  72%|▋| 9932/13852 [37:15<14:30,  4.50it/s\u001b[A\n",
      "Training loss: 6.50e-02 lr: 1.41e-05:  72%|▋| 9933/13852 [37:15<14:29,  4.51it/s\u001b[A\n",
      "Training loss: 5.04e-02 lr: 1.41e-05:  72%|▋| 9934/13852 [37:15<14:30,  4.50it/s\u001b[A\n",
      "Training loss: 5.69e-02 lr: 1.41e-05:  72%|▋| 9935/13852 [37:16<14:30,  4.50it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 1.41e-05:  72%|▋| 9936/13852 [37:16<14:26,  4.52it/s\u001b[A\n",
      "Training loss: 5.18e-02 lr: 1.41e-05:  72%|▋| 9937/13852 [37:16<14:24,  4.53it/s\u001b[A\n",
      "Training loss: 7.36e-02 lr: 1.41e-05:  72%|▋| 9938/13852 [37:16<14:27,  4.51it/s\u001b[A\n",
      "Training loss: 5.67e-02 lr: 1.41e-05:  72%|▋| 9939/13852 [37:17<14:26,  4.52it/s\u001b[A\n",
      "Training loss: 4.19e-02 lr: 1.41e-05:  72%|▋| 9940/13852 [37:17<14:32,  4.48it/s\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.41e-05:  72%|▋| 9941/13852 [37:17<14:29,  4.50it/s\u001b[A\n",
      "Training loss: 9.68e-02 lr: 1.41e-05:  72%|▋| 9942/13852 [37:17<14:31,  4.49it/s\u001b[A\n",
      "Training loss: 7.30e-02 lr: 1.41e-05:  72%|▋| 9943/13852 [37:17<14:29,  4.49it/s\u001b[A\n",
      "Training loss: 8.85e-02 lr: 1.41e-05:  72%|▋| 9944/13852 [37:18<14:29,  4.50it/s\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.41e-05:  72%|▋| 9945/13852 [37:18<14:28,  4.50it/s\u001b[A\n",
      "Training loss: 1.10e-01 lr: 1.41e-05:  72%|▋| 9946/13852 [37:18<14:28,  4.50it/s\u001b[A\n",
      "Training loss: 9.02e-02 lr: 1.41e-05:  72%|▋| 9947/13852 [37:18<14:25,  4.51it/s\u001b[A\n",
      "Training loss: 6.83e-02 lr: 1.41e-05:  72%|▋| 9948/13852 [37:19<14:20,  4.54it/s\u001b[A\n",
      "Training loss: 5.19e-02 lr: 1.41e-05:  72%|▋| 9949/13852 [37:19<14:16,  4.55it/s\u001b[A\n",
      "Training loss: 3.94e-02 lr: 1.41e-05:  72%|▋| 9950/13852 [37:19<14:14,  4.57it/s\u001b[A\n",
      "Training loss: 5.00e-02 lr: 1.41e-05:  72%|▋| 9951/13852 [37:19<14:16,  4.55it/s\u001b[A\n",
      "Training loss: 5.23e-02 lr: 1.41e-05:  72%|▋| 9952/13852 [37:19<14:18,  4.54it/s\u001b[A\n",
      "Training loss: 4.47e-02 lr: 1.41e-05:  72%|▋| 9953/13852 [37:20<14:19,  4.54it/s\u001b[A\n",
      "Training loss: 8.08e-02 lr: 1.41e-05:  72%|▋| 9954/13852 [37:20<14:18,  4.54it/s\u001b[A\n",
      "Training loss: 5.73e-02 lr: 1.41e-05:  72%|▋| 9955/13852 [37:20<14:21,  4.52it/s\u001b[A\n",
      "Training loss: 7.07e-02 lr: 1.41e-05:  72%|▋| 9956/13852 [37:20<14:22,  4.52it/s\u001b[A\n",
      "Training loss: 7.14e-02 lr: 1.41e-05:  72%|▋| 9957/13852 [37:20<14:22,  4.52it/s\u001b[A\n",
      "Training loss: 5.71e-02 lr: 1.41e-05:  72%|▋| 9958/13852 [37:21<14:25,  4.50it/s\u001b[A\n",
      "Training loss: 1.03e-01 lr: 1.41e-05:  72%|▋| 9959/13852 [37:21<14:27,  4.49it/s\u001b[A\n",
      "Training loss: 8.42e-02 lr: 1.40e-05:  72%|▋| 9960/13852 [37:21<14:22,  4.51it/s\u001b[A\n",
      "Training loss: 6.72e-02 lr: 1.40e-05:  72%|▋| 9961/13852 [37:21<14:17,  4.54it/s\u001b[A\n",
      "Training loss: 9.01e-02 lr: 1.40e-05:  72%|▋| 9962/13852 [37:22<14:13,  4.56it/s\u001b[A\n",
      "Training loss: 8.10e-02 lr: 1.40e-05:  72%|▋| 9963/13852 [37:22<14:21,  4.51it/s\u001b[A\n",
      "Training loss: 6.77e-02 lr: 1.40e-05:  72%|▋| 9964/13852 [37:22<14:21,  4.51it/s\u001b[A\n",
      "Training loss: 5.57e-02 lr: 1.40e-05:  72%|▋| 9965/13852 [37:22<14:19,  4.52it/s\u001b[A\n",
      "Training loss: 8.05e-02 lr: 1.40e-05:  72%|▋| 9966/13852 [37:22<14:18,  4.52it/s\u001b[A\n",
      "Training loss: 5.78e-02 lr: 1.40e-05:  72%|▋| 9967/13852 [37:23<14:18,  4.52it/s\u001b[A\n",
      "Training loss: 4.71e-02 lr: 1.40e-05:  72%|▋| 9968/13852 [37:23<14:19,  4.52it/s\u001b[A\n",
      "Training loss: 3.56e-02 lr: 1.40e-05:  72%|▋| 9969/13852 [37:23<14:19,  4.52it/s\u001b[A\n",
      "Training loss: 3.66e-02 lr: 1.40e-05:  72%|▋| 9970/13852 [37:23<14:19,  4.51it/s\u001b[A\n",
      "Training loss: 6.81e-02 lr: 1.40e-05:  72%|▋| 9971/13852 [37:24<14:20,  4.51it/s\u001b[A\n",
      "Training loss: 5.24e-02 lr: 1.40e-05:  72%|▋| 9972/13852 [37:24<14:19,  4.51it/s\u001b[A\n",
      "Training loss: 4.25e-02 lr: 1.40e-05:  72%|▋| 9973/13852 [37:24<14:15,  4.54it/s\u001b[A\n",
      "Training loss: 4.39e-02 lr: 1.40e-05:  72%|▋| 9974/13852 [37:24<14:12,  4.55it/s\u001b[A\n",
      "Training loss: 5.81e-02 lr: 1.40e-05:  72%|▋| 9975/13852 [37:24<14:19,  4.51it/s\u001b[A\n",
      "Training loss: 5.25e-02 lr: 1.40e-05:  72%|▋| 9976/13852 [37:25<14:17,  4.52it/s\u001b[A\n",
      "Training loss: 6.33e-02 lr: 1.40e-05:  72%|▋| 9977/13852 [37:25<14:16,  4.52it/s\u001b[A\n",
      "Training loss: 9.20e-02 lr: 1.40e-05:  72%|▋| 9978/13852 [37:25<14:16,  4.52it/s\u001b[A\n",
      "Training loss: 8.17e-02 lr: 1.40e-05:  72%|▋| 9979/13852 [37:25<14:15,  4.53it/s\u001b[A\n",
      "Training loss: 6.13e-02 lr: 1.40e-05:  72%|▋| 9980/13852 [37:26<14:15,  4.53it/s\u001b[A\n",
      "Training loss: 6.49e-02 lr: 1.40e-05:  72%|▋| 9981/13852 [37:26<14:21,  4.50it/s\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.13e-02 lr: 1.40e-05:  72%|▋| 9982/13852 [37:26<14:19,  4.50it/s\u001b[A\n",
      "Training loss: 4.68e-02 lr: 1.40e-05:  72%|▋| 9983/13852 [37:26<14:18,  4.51it/s\u001b[A\n",
      "Training loss: 3.45e-02 lr: 1.40e-05:  72%|▋| 9984/13852 [37:26<14:17,  4.51it/s\u001b[A\n",
      "Training loss: 5.70e-02 lr: 1.40e-05:  72%|▋| 9985/13852 [37:27<14:19,  4.50it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.40e-05:  72%|▋| 9986/13852 [37:27<14:16,  4.52it/s\u001b[A\n",
      "Training loss: 4.94e-02 lr: 1.40e-05:  72%|▋| 9987/13852 [37:27<14:11,  4.54it/s\u001b[A\n",
      "Training loss: 3.92e-02 lr: 1.39e-05:  72%|▋| 9988/13852 [37:27<14:14,  4.52it/s\u001b[A\n",
      "Training loss: 4.30e-02 lr: 1.39e-05:  72%|▋| 9989/13852 [37:28<14:14,  4.52it/s\u001b[A\n",
      "Training loss: 4.16e-02 lr: 1.39e-05:  72%|▋| 9990/13852 [37:28<14:14,  4.52it/s\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.39e-05:  72%|▋| 9991/13852 [37:28<14:13,  4.52it/s\u001b[A\n",
      "Training loss: 4.24e-02 lr: 1.39e-05:  72%|▋| 9992/13852 [37:28<14:14,  4.52it/s\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.39e-05:  72%|▋| 9993/13852 [37:28<14:16,  4.51it/s\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.39e-05:  72%|▋| 9994/13852 [37:29<14:14,  4.51it/s\u001b[A\n",
      "Training loss: 5.41e-02 lr: 1.39e-05:  72%|▋| 9995/13852 [37:29<14:14,  4.52it/s\u001b[A\n",
      "Training loss: 4.23e-02 lr: 1.39e-05:  72%|▋| 9996/13852 [37:29<14:15,  4.51it/s\u001b[A\n",
      "Training loss: 3.08e-02 lr: 1.39e-05:  72%|▋| 9997/13852 [37:29<14:12,  4.52it/s\u001b[A\n",
      "Training loss: 3.00e-02 lr: 1.39e-05:  72%|▋| 9998/13852 [37:30<14:08,  4.54it/s\u001b[A\n",
      "Training loss: 4.34e-02 lr: 1.39e-05:  72%|▋| 9999/13852 [37:30<14:05,  4.56it/s\u001b[A\n",
      "Training loss: 4.70e-02 lr: 1.39e-05:  72%|▋| 10000/13852 [37:30<14:13,  4.51it/\u001b[A\n",
      "Training loss: 5.48e-02 lr: 1.39e-05:  72%|▋| 10001/13852 [37:30<14:14,  4.51it/\u001b[A\n",
      "Training loss: 6.57e-02 lr: 1.39e-05:  72%|▋| 10002/13852 [37:30<14:14,  4.51it/\u001b[A\n",
      "Training loss: 4.70e-02 lr: 1.39e-05:  72%|▋| 10003/13852 [37:31<14:11,  4.52it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 1.39e-05:  72%|▋| 10004/13852 [37:31<14:17,  4.49it/\u001b[A\n",
      "Training loss: 6.16e-02 lr: 1.39e-05:  72%|▋| 10005/13852 [37:31<14:17,  4.49it/\u001b[A\n",
      "Training loss: 5.93e-02 lr: 1.39e-05:  72%|▋| 10006/13852 [37:31<14:16,  4.49it/\u001b[A\n",
      "Training loss: 4.19e-02 lr: 1.39e-05:  72%|▋| 10007/13852 [37:32<14:15,  4.49it/\u001b[A\n",
      "Training loss: 3.36e-02 lr: 1.39e-05:  72%|▋| 10008/13852 [37:32<14:17,  4.48it/\u001b[A\n",
      "Training loss: 2.72e-02 lr: 1.39e-05:  72%|▋| 10009/13852 [37:32<14:12,  4.51it/\u001b[A\n",
      "Training loss: 3.11e-02 lr: 1.39e-05:  72%|▋| 10010/13852 [37:32<14:08,  4.53it/\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.39e-05:  72%|▋| 10011/13852 [37:32<14:08,  4.52it/\u001b[A\n",
      "Training loss: 8.64e-02 lr: 1.39e-05:  72%|▋| 10012/13852 [37:33<14:09,  4.52it/\u001b[A\n",
      "Training loss: 7.33e-02 lr: 1.39e-05:  72%|▋| 10013/13852 [37:33<14:08,  4.53it/\u001b[A\n",
      "Training loss: 5.94e-02 lr: 1.39e-05:  72%|▋| 10014/13852 [37:33<14:08,  4.52it/\u001b[A\n",
      "Training loss: 4.77e-02 lr: 1.39e-05:  72%|▋| 10015/13852 [37:33<14:07,  4.53it/\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.38e-05:  72%|▋| 10016/13852 [37:34<14:31,  4.40it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 1.38e-05:  72%|▋| 10017/13852 [37:34<14:25,  4.43it/\u001b[A\n",
      "Training loss: 3.81e-02 lr: 1.38e-05:  72%|▋| 10018/13852 [37:34<14:19,  4.46it/\u001b[A\n",
      "Training loss: 2.72e-02 lr: 1.38e-05:  72%|▋| 10019/13852 [37:34<14:16,  4.47it/\u001b[A\n",
      "Training loss: 2.42e-02 lr: 1.38e-05:  72%|▋| 10020/13852 [37:34<14:13,  4.49it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 1.38e-05:  72%|▋| 10021/13852 [37:35<14:07,  4.52it/\u001b[A\n",
      "Training loss: 4.04e-02 lr: 1.38e-05:  72%|▋| 10022/13852 [37:35<14:01,  4.55it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 1.38e-05:  72%|▋| 10023/13852 [37:35<13:58,  4.57it/\u001b[A\n",
      "Training loss: 3.70e-02 lr: 1.38e-05:  72%|▋| 10024/13852 [37:35<14:02,  4.54it/\u001b[A\n",
      "Training loss: 3.00e-02 lr: 1.38e-05:  72%|▋| 10025/13852 [37:36<14:02,  4.54it/\u001b[A\n",
      "Training loss: 2.33e-02 lr: 1.38e-05:  72%|▋| 10026/13852 [37:36<14:03,  4.54it/\u001b[A\n",
      "Training loss: 7.11e-02 lr: 1.38e-05:  72%|▋| 10027/13852 [37:36<14:02,  4.54it/\u001b[A\n",
      "Training loss: 5.33e-02 lr: 1.38e-05:  72%|▋| 10028/13852 [37:36<14:04,  4.53it/\u001b[A\n",
      "Training loss: 8.90e-02 lr: 1.38e-05:  72%|▋| 10029/13852 [37:36<14:05,  4.52it/\u001b[A\n",
      "Training loss: 1.06e-01 lr: 1.38e-05:  72%|▋| 10030/13852 [37:37<14:13,  4.48it/\u001b[A\n",
      "Training loss: 7.98e-02 lr: 1.38e-05:  72%|▋| 10031/13852 [37:37<14:27,  4.41it/\u001b[A\n",
      "Training loss: 5.68e-02 lr: 1.38e-05:  72%|▋| 10032/13852 [37:37<14:43,  4.32it/\u001b[A\n",
      "Training loss: 5.10e-02 lr: 1.38e-05:  72%|▋| 10033/13852 [37:37<14:38,  4.35it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 1.38e-05:  72%|▋| 10034/13852 [37:38<14:27,  4.40it/\u001b[A\n",
      "Training loss: 4.28e-02 lr: 1.38e-05:  72%|▋| 10035/13852 [37:38<14:22,  4.43it/\u001b[A\n",
      "Training loss: 4.09e-02 lr: 1.38e-05:  72%|▋| 10036/13852 [37:38<14:15,  4.46it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 1.38e-05:  72%|▋| 10037/13852 [37:38<14:12,  4.48it/\u001b[A\n",
      "Training loss: 2.73e-02 lr: 1.38e-05:  72%|▋| 10038/13852 [37:38<14:12,  4.48it/\u001b[A\n",
      "Training loss: 4.10e-02 lr: 1.38e-05:  72%|▋| 10039/13852 [37:39<14:09,  4.49it/\u001b[A\n",
      "Training loss: 3.21e-02 lr: 1.38e-05:  72%|▋| 10040/13852 [37:39<14:07,  4.50it/\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.38e-05:  72%|▋| 10041/13852 [37:39<14:06,  4.50it/\u001b[A\n",
      "Training loss: 4.56e-02 lr: 1.38e-05:  72%|▋| 10042/13852 [37:39<14:30,  4.38it/\u001b[A\n",
      "Training loss: 4.81e-02 lr: 1.37e-05:  73%|▋| 10043/13852 [37:40<14:20,  4.43it/\u001b[A\n",
      "Training loss: 3.88e-02 lr: 1.37e-05:  73%|▋| 10044/13852 [37:40<14:13,  4.46it/\u001b[A\n",
      "Training loss: 4.06e-02 lr: 1.37e-05:  73%|▋| 10045/13852 [37:40<14:09,  4.48it/\u001b[A\n",
      "Training loss: 2.99e-02 lr: 1.37e-05:  73%|▋| 10046/13852 [37:40<14:07,  4.49it/\u001b[A\n",
      "Training loss: 2.38e-02 lr: 1.37e-05:  73%|▋| 10047/13852 [37:40<14:05,  4.50it/\u001b[A\n",
      "Training loss: 2.11e-02 lr: 1.37e-05:  73%|▋| 10048/13852 [37:41<14:06,  4.49it/\u001b[A\n",
      "Training loss: 1.71e-02 lr: 1.37e-05:  73%|▋| 10049/13852 [37:41<14:09,  4.47it/\u001b[A\n",
      "Training loss: 2.22e-02 lr: 1.37e-05:  73%|▋| 10050/13852 [37:41<14:09,  4.48it/\u001b[A\n",
      "Training loss: 2.30e-02 lr: 1.37e-05:  73%|▋| 10051/13852 [37:41<14:07,  4.49it/\u001b[A\n",
      "Training loss: 7.16e-02 lr: 1.37e-05:  73%|▋| 10052/13852 [37:42<14:06,  4.49it/\u001b[A\n",
      "Training loss: 7.30e-02 lr: 1.37e-05:  73%|▋| 10053/13852 [37:42<14:07,  4.48it/\u001b[A\n",
      "Training loss: 5.95e-02 lr: 1.37e-05:  73%|▋| 10054/13852 [37:42<14:02,  4.51it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 1.37e-05:  73%|▋| 10055/13852 [37:42<13:57,  4.53it/\u001b[A\n",
      "Training loss: 5.10e-02 lr: 1.37e-05:  73%|▋| 10056/13852 [37:42<13:54,  4.55it/\u001b[A\n",
      "Training loss: 4.53e-02 lr: 1.37e-05:  73%|▋| 10057/13852 [37:43<13:54,  4.55it/\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.37e-05:  73%|▋| 10058/13852 [37:43<13:55,  4.54it/\u001b[A\n",
      "Training loss: 1.05e-01 lr: 1.37e-05:  73%|▋| 10059/13852 [37:43<13:56,  4.53it/\u001b[A\n",
      "Training loss: 9.07e-02 lr: 1.37e-05:  73%|▋| 10060/13852 [37:43<13:58,  4.52it/\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.37e-05:  73%|▋| 10061/13852 [37:44<14:00,  4.51it/\u001b[A\n",
      "Training loss: 8.49e-02 lr: 1.37e-05:  73%|▋| 10062/13852 [37:44<14:01,  4.51it/\u001b[A\n",
      "Training loss: 6.09e-02 lr: 1.37e-05:  73%|▋| 10063/13852 [37:44<14:01,  4.50it/\u001b[A\n",
      "Training loss: 4.83e-02 lr: 1.37e-05:  73%|▋| 10064/13852 [37:44<14:02,  4.50it/\u001b[A\n",
      "Training loss: 3.43e-02 lr: 1.37e-05:  73%|▋| 10065/13852 [37:44<14:03,  4.49it/\u001b[A\n",
      "Training loss: 7.57e-02 lr: 1.37e-05:  73%|▋| 10066/13852 [37:45<14:01,  4.50it/\u001b[A\n",
      "Training loss: 8.75e-02 lr: 1.37e-05:  73%|▋| 10067/13852 [37:45<13:58,  4.52it/\u001b[A\n",
      "Training loss: 6.91e-02 lr: 1.37e-05:  73%|▋| 10068/13852 [37:45<13:54,  4.54it/\u001b[A\n",
      "Training loss: 6.07e-02 lr: 1.37e-05:  73%|▋| 10069/13852 [37:45<13:58,  4.51it/\u001b[A\n",
      "Training loss: 4.36e-02 lr: 1.37e-05:  73%|▋| 10070/13852 [37:46<13:57,  4.52it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 1.36e-05:  73%|▋| 10071/13852 [37:46<13:57,  4.51it/\u001b[A\n",
      "Training loss: 5.45e-02 lr: 1.36e-05:  73%|▋| 10072/13852 [37:46<13:58,  4.51it/\u001b[A\n",
      "Training loss: 4.03e-02 lr: 1.36e-05:  73%|▋| 10073/13852 [37:46<13:59,  4.50it/\u001b[A\n",
      "Training loss: 3.39e-02 lr: 1.36e-05:  73%|▋| 10074/13852 [37:46<13:58,  4.50it/\u001b[A\n",
      "Training loss: 4.36e-02 lr: 1.36e-05:  73%|▋| 10075/13852 [37:47<13:59,  4.50it/\u001b[A\n",
      "Training loss: 4.43e-02 lr: 1.36e-05:  73%|▋| 10076/13852 [37:47<14:00,  4.49it/\u001b[A\n",
      "Training loss: 4.15e-02 lr: 1.36e-05:  73%|▋| 10077/13852 [37:47<14:00,  4.49it/\u001b[A\n",
      "Training loss: 7.13e-02 lr: 1.36e-05:  73%|▋| 10078/13852 [37:47<13:57,  4.51it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.42e-02 lr: 1.36e-05:  73%|▋| 10079/13852 [37:48<13:52,  4.53it/\u001b[A\n",
      "Training loss: 5.06e-02 lr: 1.36e-05:  73%|▋| 10080/13852 [37:48<13:50,  4.54it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 1.36e-05:  73%|▋| 10081/13852 [37:48<14:01,  4.48it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 1.36e-05:  73%|▋| 10082/13852 [37:48<14:00,  4.48it/\u001b[A\n",
      "Training loss: 6.39e-02 lr: 1.36e-05:  73%|▋| 10083/13852 [37:48<14:00,  4.48it/\u001b[A\n",
      "Training loss: 6.02e-02 lr: 1.36e-05:  73%|▋| 10084/13852 [37:49<14:03,  4.47it/\u001b[A\n",
      "Training loss: 4.74e-02 lr: 1.36e-05:  73%|▋| 10085/13852 [37:49<14:26,  4.35it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 1.36e-05:  73%|▋| 10086/13852 [37:49<14:45,  4.25it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 1.36e-05:  73%|▋| 10087/13852 [37:49<14:51,  4.22it/\u001b[A\n",
      "Training loss: 5.64e-02 lr: 1.36e-05:  73%|▋| 10088/13852 [37:50<14:37,  4.29it/\u001b[A\n",
      "Training loss: 1.20e-01 lr: 1.36e-05:  73%|▋| 10089/13852 [37:50<14:24,  4.35it/\u001b[A\n",
      "Training loss: 1.50e-01 lr: 1.36e-05:  73%|▋| 10090/13852 [37:50<14:15,  4.40it/\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.36e-05:  73%|▋| 10091/13852 [37:50<14:07,  4.44it/\u001b[A\n",
      "Training loss: 8.35e-02 lr: 1.36e-05:  73%|▋| 10092/13852 [37:51<14:03,  4.46it/\u001b[A\n",
      "Training loss: 8.79e-02 lr: 1.36e-05:  73%|▋| 10093/13852 [37:51<14:05,  4.45it/\u001b[A\n",
      "Training loss: 6.54e-02 lr: 1.36e-05:  73%|▋| 10094/13852 [37:51<14:06,  4.44it/\u001b[A\n",
      "Training loss: 5.00e-02 lr: 1.36e-05:  73%|▋| 10095/13852 [37:51<14:29,  4.32it/\u001b[A\n",
      "Training loss: 5.45e-02 lr: 1.36e-05:  73%|▋| 10096/13852 [37:52<14:45,  4.24it/\u001b[A\n",
      "Training loss: 5.52e-02 lr: 1.36e-05:  73%|▋| 10097/13852 [37:52<15:01,  4.16it/\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.36e-05:  73%|▋| 10098/13852 [37:52<14:51,  4.21it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 1.35e-05:  73%|▋| 10099/13852 [37:52<14:37,  4.28it/\u001b[A\n",
      "Training loss: 6.20e-02 lr: 1.35e-05:  73%|▋| 10100/13852 [37:52<14:32,  4.30it/\u001b[A\n",
      "Training loss: 7.94e-02 lr: 1.35e-05:  73%|▋| 10101/13852 [37:53<14:26,  4.33it/\u001b[A\n",
      "Training loss: 5.66e-02 lr: 1.35e-05:  73%|▋| 10102/13852 [37:53<14:21,  4.35it/\u001b[A\n",
      "Training loss: 4.68e-02 lr: 1.35e-05:  73%|▋| 10103/13852 [37:53<14:21,  4.35it/\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.35e-05:  73%|▋| 10104/13852 [37:53<14:13,  4.39it/\u001b[A\n",
      "Training loss: 3.93e-02 lr: 1.35e-05:  73%|▋| 10105/13852 [37:54<14:11,  4.40it/\u001b[A\n",
      "Training loss: 4.61e-02 lr: 1.35e-05:  73%|▋| 10106/13852 [37:54<14:32,  4.29it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 1.35e-05:  73%|▋| 10107/13852 [37:54<14:50,  4.20it/\u001b[A\n",
      "Training loss: 6.90e-02 lr: 1.35e-05:  73%|▋| 10108/13852 [37:54<14:33,  4.29it/\u001b[A\n",
      "Training loss: 7.17e-02 lr: 1.35e-05:  73%|▋| 10109/13852 [37:55<14:21,  4.34it/\u001b[A\n",
      "Training loss: 5.20e-02 lr: 1.35e-05:  73%|▋| 10110/13852 [37:55<14:11,  4.39it/\u001b[A\n",
      "Training loss: 4.37e-02 lr: 1.35e-05:  73%|▋| 10111/13852 [37:55<14:01,  4.44it/\u001b[A\n",
      "Training loss: 4.59e-02 lr: 1.35e-05:  73%|▋| 10112/13852 [37:55<13:55,  4.48it/\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.35e-05:  73%|▋| 10113/13852 [37:55<13:49,  4.51it/\u001b[A\n",
      "Training loss: 3.29e-02 lr: 1.35e-05:  73%|▋| 10114/13852 [37:56<13:55,  4.48it/\u001b[A\n",
      "Training loss: 3.42e-02 lr: 1.35e-05:  73%|▋| 10115/13852 [37:56<13:52,  4.49it/\u001b[A\n",
      "Training loss: 2.95e-02 lr: 1.35e-05:  73%|▋| 10116/13852 [37:56<14:04,  4.42it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.35e-05:  73%|▋| 10117/13852 [37:56<13:59,  4.45it/\u001b[A\n",
      "Training loss: 3.90e-02 lr: 1.35e-05:  73%|▋| 10118/13852 [37:57<14:01,  4.44it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 1.35e-05:  73%|▋| 10119/13852 [37:57<14:06,  4.41it/\u001b[A\n",
      "Training loss: 2.89e-02 lr: 1.35e-05:  73%|▋| 10120/13852 [37:57<14:01,  4.44it/\u001b[A\n",
      "Training loss: 4.17e-02 lr: 1.35e-05:  73%|▋| 10121/13852 [37:57<13:56,  4.46it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 1.35e-05:  73%|▋| 10122/13852 [37:57<13:50,  4.49it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 1.35e-05:  73%|▋| 10123/13852 [37:58<13:45,  4.52it/\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.35e-05:  73%|▋| 10124/13852 [37:58<13:40,  4.54it/\u001b[A\n",
      "Training loss: 2.28e-02 lr: 1.35e-05:  73%|▋| 10125/13852 [37:58<13:49,  4.49it/\u001b[A\n",
      "Training loss: 2.20e-02 lr: 1.35e-05:  73%|▋| 10126/13852 [37:58<13:52,  4.47it/\u001b[A\n",
      "Training loss: 2.09e-02 lr: 1.34e-05:  73%|▋| 10127/13852 [37:59<13:50,  4.49it/\u001b[A\n",
      "Training loss: 3.64e-02 lr: 1.34e-05:  73%|▋| 10128/13852 [37:59<13:48,  4.49it/\u001b[A\n",
      "Training loss: 2.61e-02 lr: 1.34e-05:  73%|▋| 10129/13852 [37:59<13:48,  4.50it/\u001b[A\n",
      "Training loss: 2.47e-02 lr: 1.34e-05:  73%|▋| 10130/13852 [37:59<13:50,  4.48it/\u001b[A\n",
      "Training loss: 2.18e-02 lr: 1.34e-05:  73%|▋| 10131/13852 [37:59<13:48,  4.49it/\u001b[A\n",
      "Training loss: 9.23e-02 lr: 1.34e-05:  73%|▋| 10132/13852 [38:00<13:49,  4.49it/\u001b[A\n",
      "Training loss: 8.19e-02 lr: 1.34e-05:  73%|▋| 10133/13852 [38:00<13:48,  4.49it/\u001b[A\n",
      "Training loss: 8.98e-02 lr: 1.34e-05:  73%|▋| 10134/13852 [38:00<13:49,  4.48it/\u001b[A\n",
      "Training loss: 1.03e-01 lr: 1.34e-05:  73%|▋| 10135/13852 [38:00<13:43,  4.51it/\u001b[A\n",
      "Training loss: 7.82e-02 lr: 1.34e-05:  73%|▋| 10136/13852 [38:01<13:38,  4.54it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 1.34e-05:  73%|▋| 10137/13852 [38:01<13:47,  4.49it/\u001b[A\n",
      "Training loss: 4.31e-02 lr: 1.34e-05:  73%|▋| 10138/13852 [38:01<13:48,  4.48it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 1.34e-05:  73%|▋| 10139/13852 [38:01<13:46,  4.49it/\u001b[A\n",
      "Training loss: 3.33e-02 lr: 1.34e-05:  73%|▋| 10140/13852 [38:01<13:46,  4.49it/\u001b[A\n",
      "Training loss: 7.38e-02 lr: 1.34e-05:  73%|▋| 10141/13852 [38:02<13:48,  4.48it/\u001b[A\n",
      "Training loss: 6.07e-02 lr: 1.34e-05:  73%|▋| 10142/13852 [38:02<13:51,  4.46it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 1.34e-05:  73%|▋| 10143/13852 [38:02<13:50,  4.46it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 1.34e-05:  73%|▋| 10144/13852 [38:02<13:49,  4.47it/\u001b[A\n",
      "Training loss: 3.01e-02 lr: 1.34e-05:  73%|▋| 10145/13852 [38:03<13:44,  4.49it/\u001b[A\n",
      "Training loss: 5.48e-02 lr: 1.34e-05:  73%|▋| 10146/13852 [38:03<13:44,  4.49it/\u001b[A\n",
      "Training loss: 4.18e-02 lr: 1.34e-05:  73%|▋| 10147/13852 [38:03<13:43,  4.50it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 1.34e-05:  73%|▋| 10148/13852 [38:03<13:43,  4.50it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 1.34e-05:  73%|▋| 10149/13852 [38:03<13:41,  4.50it/\u001b[A\n",
      "Training loss: 2.99e-02 lr: 1.34e-05:  73%|▋| 10150/13852 [38:04<13:41,  4.51it/\u001b[A\n",
      "Training loss: 3.16e-02 lr: 1.34e-05:  73%|▋| 10151/13852 [38:04<13:40,  4.51it/\u001b[A\n",
      "Training loss: 2.91e-02 lr: 1.34e-05:  73%|▋| 10152/13852 [38:04<13:41,  4.51it/\u001b[A\n",
      "Training loss: 5.23e-02 lr: 1.34e-05:  73%|▋| 10153/13852 [38:04<13:42,  4.50it/\u001b[A\n",
      "Training loss: 4.70e-02 lr: 1.33e-05:  73%|▋| 10154/13852 [38:05<13:41,  4.50it/\u001b[A\n",
      "Training loss: 3.34e-02 lr: 1.33e-05:  73%|▋| 10155/13852 [38:05<13:41,  4.50it/\u001b[A\n",
      "Training loss: 7.00e-02 lr: 1.33e-05:  73%|▋| 10156/13852 [38:05<13:41,  4.50it/\u001b[A\n",
      "Training loss: 5.12e-02 lr: 1.33e-05:  73%|▋| 10157/13852 [38:05<13:37,  4.52it/\u001b[A\n",
      "Training loss: 3.88e-02 lr: 1.33e-05:  73%|▋| 10158/13852 [38:05<13:35,  4.53it/\u001b[A\n",
      "Training loss: 2.87e-02 lr: 1.33e-05:  73%|▋| 10159/13852 [38:06<13:31,  4.55it/\u001b[A\n",
      "Training loss: 3.46e-02 lr: 1.33e-05:  73%|▋| 10160/13852 [38:06<13:39,  4.51it/\u001b[A\n",
      "Training loss: 3.05e-02 lr: 1.33e-05:  73%|▋| 10161/13852 [38:06<13:45,  4.47it/\u001b[A\n",
      "Training loss: 2.28e-02 lr: 1.33e-05:  73%|▋| 10162/13852 [38:06<13:43,  4.48it/\u001b[A\n",
      "Training loss: 4.18e-02 lr: 1.33e-05:  73%|▋| 10163/13852 [38:07<13:43,  4.48it/\u001b[A\n",
      "Training loss: 3.16e-02 lr: 1.33e-05:  73%|▋| 10164/13852 [38:07<13:50,  4.44it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 1.33e-05:  73%|▋| 10165/13852 [38:07<13:56,  4.41it/\u001b[A\n",
      "Training loss: 5.53e-02 lr: 1.33e-05:  73%|▋| 10166/13852 [38:07<13:54,  4.42it/\u001b[A\n",
      "Training loss: 3.98e-02 lr: 1.33e-05:  73%|▋| 10167/13852 [38:07<13:57,  4.40it/\u001b[A\n",
      "Training loss: 6.38e-02 lr: 1.33e-05:  73%|▋| 10168/13852 [38:08<13:48,  4.45it/\u001b[A\n",
      "Training loss: 5.05e-02 lr: 1.33e-05:  73%|▋| 10169/13852 [38:08<13:40,  4.49it/\u001b[A\n",
      "Training loss: 4.89e-02 lr: 1.33e-05:  73%|▋| 10170/13852 [38:08<13:45,  4.46it/\u001b[A\n",
      "Training loss: 3.75e-02 lr: 1.33e-05:  73%|▋| 10171/13852 [38:08<13:43,  4.47it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 1.33e-05:  73%|▋| 10172/13852 [38:09<13:40,  4.48it/\u001b[A\n",
      "Training loss: 3.43e-02 lr: 1.33e-05:  73%|▋| 10173/13852 [38:09<13:40,  4.48it/\u001b[A\n",
      "Training loss: 4.18e-02 lr: 1.33e-05:  73%|▋| 10174/13852 [38:09<13:39,  4.49it/\u001b[A\n",
      "Training loss: 3.53e-02 lr: 1.33e-05:  73%|▋| 10175/13852 [38:09<13:39,  4.49it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.17e-02 lr: 1.33e-05:  73%|▋| 10176/13852 [38:09<13:40,  4.48it/\u001b[A\n",
      "Training loss: 3.58e-02 lr: 1.33e-05:  73%|▋| 10177/13852 [38:10<13:40,  4.48it/\u001b[A\n",
      "Training loss: 5.42e-02 lr: 1.33e-05:  73%|▋| 10178/13852 [38:10<13:39,  4.48it/\u001b[A\n",
      "Training loss: 4.64e-02 lr: 1.33e-05:  73%|▋| 10179/13852 [38:10<13:36,  4.50it/\u001b[A\n",
      "Training loss: 3.49e-02 lr: 1.33e-05:  73%|▋| 10180/13852 [38:10<13:32,  4.52it/\u001b[A\n",
      "Training loss: 2.95e-02 lr: 1.33e-05:  73%|▋| 10181/13852 [38:11<13:28,  4.54it/\u001b[A\n",
      "Training loss: 5.18e-02 lr: 1.32e-05:  74%|▋| 10182/13852 [38:11<13:36,  4.50it/\u001b[A\n",
      "Training loss: 3.88e-02 lr: 1.32e-05:  74%|▋| 10183/13852 [38:11<13:36,  4.50it/\u001b[A\n",
      "Training loss: 2.83e-02 lr: 1.32e-05:  74%|▋| 10184/13852 [38:11<13:34,  4.50it/\u001b[A\n",
      "Training loss: 2.04e-02 lr: 1.32e-05:  74%|▋| 10185/13852 [38:11<13:35,  4.50it/\u001b[A\n",
      "Training loss: 1.83e-02 lr: 1.32e-05:  74%|▋| 10186/13852 [38:12<13:39,  4.48it/\u001b[A\n",
      "Training loss: 1.46e-02 lr: 1.32e-05:  74%|▋| 10187/13852 [38:12<13:41,  4.46it/\u001b[A\n",
      "Training loss: 2.49e-02 lr: 1.32e-05:  74%|▋| 10188/13852 [38:12<13:41,  4.46it/\u001b[A\n",
      "Training loss: 2.55e-02 lr: 1.32e-05:  74%|▋| 10189/13852 [38:12<13:39,  4.47it/\u001b[A\n",
      "Training loss: 2.20e-02 lr: 1.32e-05:  74%|▋| 10190/13852 [38:13<13:39,  4.47it/\u001b[A\n",
      "Training loss: 5.63e-02 lr: 1.32e-05:  74%|▋| 10191/13852 [38:13<13:32,  4.51it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 1.32e-05:  74%|▋| 10192/13852 [38:13<13:27,  4.53it/\u001b[A\n",
      "Training loss: 5.21e-02 lr: 1.32e-05:  74%|▋| 10193/13852 [38:13<13:33,  4.50it/\u001b[A\n",
      "Training loss: 5.35e-02 lr: 1.32e-05:  74%|▋| 10194/13852 [38:13<13:33,  4.50it/\u001b[A\n",
      "Training loss: 6.97e-02 lr: 1.32e-05:  74%|▋| 10195/13852 [38:14<13:31,  4.51it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 1.32e-05:  74%|▋| 10196/13852 [38:14<13:31,  4.50it/\u001b[A\n",
      "Training loss: 6.25e-02 lr: 1.32e-05:  74%|▋| 10197/13852 [38:14<13:31,  4.50it/\u001b[A\n",
      "Training loss: 4.52e-02 lr: 1.32e-05:  74%|▋| 10198/13852 [38:14<13:32,  4.50it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 1.32e-05:  74%|▋| 10199/13852 [38:15<13:32,  4.50it/\u001b[A\n",
      "Training loss: 2.81e-02 lr: 1.32e-05:  74%|▋| 10200/13852 [38:15<13:32,  4.49it/\u001b[A\n",
      "Training loss: 2.56e-02 lr: 1.32e-05:  74%|▋| 10201/13852 [38:15<13:32,  4.49it/\u001b[A\n",
      "Training loss: 4.92e-02 lr: 1.32e-05:  74%|▋| 10202/13852 [38:15<13:29,  4.51it/\u001b[A\n",
      "Training loss: 5.54e-02 lr: 1.32e-05:  74%|▋| 10203/13852 [38:15<13:25,  4.53it/\u001b[A\n",
      "Training loss: 7.57e-02 lr: 1.32e-05:  74%|▋| 10204/13852 [38:16<13:21,  4.55it/\u001b[A\n",
      "Training loss: 5.77e-02 lr: 1.32e-05:  74%|▋| 10205/13852 [38:16<13:29,  4.51it/\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.32e-05:  74%|▋| 10206/13852 [38:16<13:29,  4.50it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 1.32e-05:  74%|▋| 10207/13852 [38:16<13:28,  4.51it/\u001b[A\n",
      "Training loss: 2.70e-02 lr: 1.32e-05:  74%|▋| 10208/13852 [38:17<13:28,  4.51it/\u001b[A\n",
      "Training loss: 2.15e-02 lr: 1.32e-05:  74%|▋| 10209/13852 [38:17<13:35,  4.47it/\u001b[A\n",
      "Training loss: 4.89e-02 lr: 1.31e-05:  74%|▋| 10210/13852 [38:17<13:34,  4.47it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 1.31e-05:  74%|▋| 10211/13852 [38:17<13:32,  4.48it/\u001b[A\n",
      "Training loss: 4.06e-02 lr: 1.31e-05:  74%|▋| 10212/13852 [38:17<13:32,  4.48it/\u001b[A\n",
      "Training loss: 3.06e-02 lr: 1.31e-05:  74%|▋| 10213/13852 [38:18<13:31,  4.49it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 1.31e-05:  74%|▋| 10214/13852 [38:18<13:27,  4.50it/\u001b[A\n",
      "Training loss: 7.95e-02 lr: 1.31e-05:  74%|▋| 10215/13852 [38:18<13:23,  4.53it/\u001b[A\n",
      "Training loss: 1.32e-01 lr: 1.31e-05:  74%|▋| 10216/13852 [38:18<13:19,  4.55it/\u001b[A\n",
      "Training loss: 1.07e-01 lr: 1.31e-05:  74%|▋| 10217/13852 [38:19<13:23,  4.52it/\u001b[A\n",
      "Training loss: 8.52e-02 lr: 1.31e-05:  74%|▋| 10218/13852 [38:19<13:24,  4.52it/\u001b[A\n",
      "Training loss: 8.07e-02 lr: 1.31e-05:  74%|▋| 10219/13852 [38:19<13:28,  4.49it/\u001b[A\n",
      "Training loss: 6.08e-02 lr: 1.31e-05:  74%|▋| 10220/13852 [38:19<13:26,  4.50it/\u001b[A\n",
      "Training loss: 6.72e-02 lr: 1.31e-05:  74%|▋| 10221/13852 [38:19<13:26,  4.50it/\u001b[A\n",
      "Training loss: 5.22e-02 lr: 1.31e-05:  74%|▋| 10222/13852 [38:20<13:25,  4.51it/\u001b[A\n",
      "Training loss: 1.19e-01 lr: 1.31e-05:  74%|▋| 10223/13852 [38:20<13:25,  4.50it/\u001b[A\n",
      "Training loss: 8.99e-02 lr: 1.31e-05:  74%|▋| 10224/13852 [38:20<13:31,  4.47it/\u001b[A\n",
      "Training loss: 6.49e-02 lr: 1.31e-05:  74%|▋| 10225/13852 [38:20<13:29,  4.48it/\u001b[A\n",
      "Training loss: 6.22e-02 lr: 1.31e-05:  74%|▋| 10226/13852 [38:21<13:24,  4.51it/\u001b[A\n",
      "Training loss: 4.92e-02 lr: 1.31e-05:  74%|▋| 10227/13852 [38:21<13:23,  4.51it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 1.31e-05:  74%|▋| 10228/13852 [38:21<13:27,  4.49it/\u001b[A\n",
      "Training loss: 9.94e-02 lr: 1.31e-05:  74%|▋| 10229/13852 [38:21<13:25,  4.50it/\u001b[A\n",
      "Training loss: 7.09e-02 lr: 1.31e-05:  74%|▋| 10230/13852 [38:21<13:24,  4.50it/\u001b[A\n",
      "Training loss: 5.68e-02 lr: 1.31e-05:  74%|▋| 10231/13852 [38:22<13:25,  4.50it/\u001b[A\n",
      "Training loss: 6.22e-02 lr: 1.31e-05:  74%|▋| 10232/13852 [38:22<13:24,  4.50it/\u001b[A\n",
      "Training loss: 5.30e-02 lr: 1.31e-05:  74%|▋| 10233/13852 [38:22<13:25,  4.49it/\u001b[A\n",
      "Training loss: 6.22e-02 lr: 1.31e-05:  74%|▋| 10234/13852 [38:22<13:24,  4.50it/\u001b[A\n",
      "Training loss: 7.49e-02 lr: 1.31e-05:  74%|▋| 10235/13852 [38:23<13:24,  4.49it/\u001b[A\n",
      "Training loss: 6.17e-02 lr: 1.31e-05:  74%|▋| 10236/13852 [38:23<13:24,  4.49it/\u001b[A\n",
      "Training loss: 6.18e-02 lr: 1.30e-05:  74%|▋| 10237/13852 [38:23<13:21,  4.51it/\u001b[A\n",
      "Training loss: 7.52e-02 lr: 1.30e-05:  74%|▋| 10238/13852 [38:23<13:16,  4.54it/\u001b[A\n",
      "Training loss: 5.96e-02 lr: 1.30e-05:  74%|▋| 10239/13852 [38:23<13:13,  4.55it/\u001b[A\n",
      "Training loss: 5.26e-02 lr: 1.30e-05:  74%|▋| 10240/13852 [38:24<13:12,  4.56it/\u001b[A\n",
      "Training loss: 5.01e-02 lr: 1.30e-05:  74%|▋| 10241/13852 [38:24<13:12,  4.55it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 1.30e-05:  74%|▋| 10242/13852 [38:24<13:15,  4.54it/\u001b[A\n",
      "Training loss: 7.46e-02 lr: 1.30e-05:  74%|▋| 10243/13852 [38:24<13:16,  4.53it/\u001b[A\n",
      "Training loss: 5.79e-02 lr: 1.30e-05:  74%|▋| 10244/13852 [38:25<13:17,  4.52it/\u001b[A\n",
      "Training loss: 5.41e-02 lr: 1.30e-05:  74%|▋| 10245/13852 [38:25<13:19,  4.51it/\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.30e-05:  74%|▋| 10246/13852 [38:25<13:21,  4.50it/\u001b[A\n",
      "Training loss: 3.57e-02 lr: 1.30e-05:  74%|▋| 10247/13852 [38:25<13:22,  4.49it/\u001b[A\n",
      "Training loss: 2.80e-02 lr: 1.30e-05:  74%|▋| 10248/13852 [38:25<13:23,  4.48it/\u001b[A\n",
      "Training loss: 2.53e-02 lr: 1.30e-05:  74%|▋| 10249/13852 [38:26<13:23,  4.48it/\u001b[A\n",
      "Training loss: 2.37e-02 lr: 1.30e-05:  74%|▋| 10250/13852 [38:26<13:22,  4.49it/\u001b[A\n",
      "Training loss: 3.71e-02 lr: 1.30e-05:  74%|▋| 10251/13852 [38:26<13:21,  4.49it/\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.30e-05:  74%|▋| 10252/13852 [38:26<13:18,  4.51it/\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.30e-05:  74%|▋| 10253/13852 [38:27<13:21,  4.49it/\u001b[A\n",
      "Training loss: 7.33e-02 lr: 1.30e-05:  74%|▋| 10254/13852 [38:27<13:25,  4.47it/\u001b[A\n",
      "Training loss: 7.70e-02 lr: 1.30e-05:  74%|▋| 10255/13852 [38:27<13:23,  4.48it/\u001b[A\n",
      "Training loss: 6.17e-02 lr: 1.30e-05:  74%|▋| 10256/13852 [38:27<13:21,  4.48it/\u001b[A\n",
      "Training loss: 5.21e-02 lr: 1.30e-05:  74%|▋| 10257/13852 [38:27<13:21,  4.48it/\u001b[A\n",
      "Training loss: 5.73e-02 lr: 1.30e-05:  74%|▋| 10258/13852 [38:28<13:21,  4.49it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 1.30e-05:  74%|▋| 10259/13852 [38:28<13:19,  4.49it/\u001b[A\n",
      "Training loss: 3.85e-02 lr: 1.30e-05:  74%|▋| 10260/13852 [38:28<13:23,  4.47it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 1.30e-05:  74%|▋| 10261/13852 [38:28<13:18,  4.50it/\u001b[A\n",
      "Training loss: 3.33e-02 lr: 1.30e-05:  74%|▋| 10262/13852 [38:29<13:14,  4.52it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 1.30e-05:  74%|▋| 10263/13852 [38:29<13:11,  4.53it/\u001b[A\n",
      "Training loss: 7.03e-02 lr: 1.30e-05:  74%|▋| 10264/13852 [38:29<13:18,  4.49it/\u001b[A\n",
      "Training loss: 7.08e-02 lr: 1.29e-05:  74%|▋| 10265/13852 [38:29<13:19,  4.49it/\u001b[A\n",
      "Training loss: 5.54e-02 lr: 1.29e-05:  74%|▋| 10266/13852 [38:29<13:19,  4.49it/\u001b[A\n",
      "Training loss: 4.22e-02 lr: 1.29e-05:  74%|▋| 10267/13852 [38:30<13:18,  4.49it/\u001b[A\n",
      "Training loss: 5.28e-02 lr: 1.29e-05:  74%|▋| 10268/13852 [38:30<13:18,  4.49it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 1.29e-05:  74%|▋| 10269/13852 [38:30<13:19,  4.48it/\u001b[A\n",
      "Training loss: 7.01e-02 lr: 1.29e-05:  74%|▋| 10270/13852 [38:30<13:20,  4.47it/\u001b[A\n",
      "Training loss: 7.27e-02 lr: 1.29e-05:  74%|▋| 10271/13852 [38:31<13:20,  4.48it/\u001b[A\n",
      "Training loss: 8.66e-02 lr: 1.29e-05:  74%|▋| 10272/13852 [38:31<13:22,  4.46it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.68e-02 lr: 1.29e-05:  74%|▋| 10273/13852 [38:31<13:16,  4.49it/\u001b[A\n",
      "Training loss: 1.11e-01 lr: 1.29e-05:  74%|▋| 10274/13852 [38:31<13:11,  4.52it/\u001b[A\n",
      "Training loss: 7.82e-02 lr: 1.29e-05:  74%|▋| 10275/13852 [38:31<13:08,  4.53it/\u001b[A\n",
      "Training loss: 7.06e-02 lr: 1.29e-05:  74%|▋| 10276/13852 [38:32<13:14,  4.50it/\u001b[A\n",
      "Training loss: 1.23e-01 lr: 1.29e-05:  74%|▋| 10277/13852 [38:32<13:14,  4.50it/\u001b[A\n",
      "Training loss: 1.06e-01 lr: 1.29e-05:  74%|▋| 10278/13852 [38:32<13:13,  4.50it/\u001b[A\n",
      "Training loss: 8.91e-02 lr: 1.29e-05:  74%|▋| 10279/13852 [38:32<13:12,  4.51it/\u001b[A\n",
      "Training loss: 7.33e-02 lr: 1.29e-05:  74%|▋| 10280/13852 [38:33<13:12,  4.51it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 1.29e-05:  74%|▋| 10281/13852 [38:33<13:12,  4.51it/\u001b[A\n",
      "Training loss: 7.95e-02 lr: 1.29e-05:  74%|▋| 10282/13852 [38:33<13:18,  4.47it/\u001b[A\n",
      "Training loss: 5.73e-02 lr: 1.29e-05:  74%|▋| 10283/13852 [38:33<13:16,  4.48it/\u001b[A\n",
      "Training loss: 4.47e-02 lr: 1.29e-05:  74%|▋| 10284/13852 [38:33<13:16,  4.48it/\u001b[A\n",
      "Training loss: 5.06e-02 lr: 1.29e-05:  74%|▋| 10285/13852 [38:34<13:11,  4.50it/\u001b[A\n",
      "Training loss: 4.95e-02 lr: 1.29e-05:  74%|▋| 10286/13852 [38:34<13:08,  4.52it/\u001b[A\n",
      "Training loss: 5.67e-02 lr: 1.29e-05:  74%|▋| 10287/13852 [38:34<13:05,  4.54it/\u001b[A\n",
      "Training loss: 5.57e-02 lr: 1.29e-05:  74%|▋| 10288/13852 [38:34<13:08,  4.52it/\u001b[A\n",
      "Training loss: 5.92e-02 lr: 1.29e-05:  74%|▋| 10289/13852 [38:35<13:08,  4.52it/\u001b[A\n",
      "Training loss: 4.74e-02 lr: 1.29e-05:  74%|▋| 10290/13852 [38:35<13:09,  4.51it/\u001b[A\n",
      "Training loss: 4.06e-02 lr: 1.29e-05:  74%|▋| 10291/13852 [38:35<13:10,  4.50it/\u001b[A\n",
      "Training loss: 3.49e-02 lr: 1.29e-05:  74%|▋| 10292/13852 [38:35<13:11,  4.50it/\u001b[A\n",
      "Training loss: 3.95e-02 lr: 1.28e-05:  74%|▋| 10293/13852 [38:35<13:11,  4.49it/\u001b[A\n",
      "Training loss: 2.83e-02 lr: 1.28e-05:  74%|▋| 10294/13852 [38:36<13:12,  4.49it/\u001b[A\n",
      "Training loss: 3.50e-02 lr: 1.28e-05:  74%|▋| 10295/13852 [38:36<13:11,  4.49it/\u001b[A\n",
      "Training loss: 3.91e-02 lr: 1.28e-05:  74%|▋| 10296/13852 [38:36<13:14,  4.47it/\u001b[A\n",
      "Training loss: 2.80e-02 lr: 1.28e-05:  74%|▋| 10297/13852 [38:36<13:18,  4.45it/\u001b[A\n",
      "Training loss: 3.74e-02 lr: 1.28e-05:  74%|▋| 10298/13852 [38:37<13:11,  4.49it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 1.28e-05:  74%|▋| 10299/13852 [38:37<13:36,  4.35it/\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.28e-05:  74%|▋| 10300/13852 [38:37<13:31,  4.38it/\u001b[A\n",
      "Training loss: 4.13e-02 lr: 1.28e-05:  74%|▋| 10301/13852 [38:37<13:27,  4.40it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 1.28e-05:  74%|▋| 10302/13852 [38:37<13:29,  4.38it/\u001b[A\n",
      "Training loss: 3.04e-02 lr: 1.28e-05:  74%|▋| 10303/13852 [38:38<13:22,  4.42it/\u001b[A\n",
      "Training loss: 2.40e-02 lr: 1.28e-05:  74%|▋| 10304/13852 [38:38<13:18,  4.44it/\u001b[A\n",
      "Training loss: 2.20e-02 lr: 1.28e-05:  74%|▋| 10305/13852 [38:38<13:14,  4.46it/\u001b[A\n",
      "Training loss: 1.63e-02 lr: 1.28e-05:  74%|▋| 10306/13852 [38:38<13:10,  4.48it/\u001b[A\n",
      "Training loss: 2.02e-02 lr: 1.28e-05:  74%|▋| 10307/13852 [38:39<13:05,  4.52it/\u001b[A\n",
      "Training loss: 2.40e-02 lr: 1.28e-05:  74%|▋| 10308/13852 [38:39<13:00,  4.54it/\u001b[A\n",
      "Training loss: 2.44e-02 lr: 1.28e-05:  74%|▋| 10309/13852 [38:39<13:06,  4.50it/\u001b[A\n",
      "Training loss: 3.17e-02 lr: 1.28e-05:  74%|▋| 10310/13852 [38:39<13:05,  4.51it/\u001b[A\n",
      "Training loss: 3.40e-02 lr: 1.28e-05:  74%|▋| 10311/13852 [38:39<13:04,  4.51it/\u001b[A\n",
      "Training loss: 3.55e-02 lr: 1.28e-05:  74%|▋| 10312/13852 [38:40<13:04,  4.51it/\u001b[A\n",
      "Training loss: 4.15e-02 lr: 1.28e-05:  74%|▋| 10313/13852 [38:40<13:04,  4.51it/\u001b[A\n",
      "Training loss: 4.16e-02 lr: 1.28e-05:  74%|▋| 10314/13852 [38:40<13:05,  4.51it/\u001b[A\n",
      "Training loss: 3.16e-02 lr: 1.28e-05:  74%|▋| 10315/13852 [38:40<13:04,  4.51it/\u001b[A\n",
      "Training loss: 3.12e-02 lr: 1.28e-05:  74%|▋| 10316/13852 [38:41<13:04,  4.51it/\u001b[A\n",
      "Training loss: 2.74e-02 lr: 1.28e-05:  74%|▋| 10317/13852 [38:41<13:08,  4.48it/\u001b[A\n",
      "Training loss: 2.94e-02 lr: 1.28e-05:  74%|▋| 10318/13852 [38:41<13:06,  4.50it/\u001b[A\n",
      "Training loss: 2.93e-02 lr: 1.28e-05:  74%|▋| 10319/13852 [38:41<13:01,  4.52it/\u001b[A\n",
      "Training loss: 3.46e-02 lr: 1.27e-05:  75%|▋| 10320/13852 [38:41<12:57,  4.54it/\u001b[A\n",
      "Training loss: 2.66e-02 lr: 1.27e-05:  75%|▋| 10321/13852 [38:42<12:58,  4.54it/\u001b[A\n",
      "Training loss: 4.03e-02 lr: 1.27e-05:  75%|▋| 10322/13852 [38:42<12:57,  4.54it/\u001b[A\n",
      "Training loss: 2.88e-02 lr: 1.27e-05:  75%|▋| 10323/13852 [38:42<12:58,  4.53it/\u001b[A\n",
      "Training loss: 5.35e-02 lr: 1.27e-05:  75%|▋| 10324/13852 [38:42<12:58,  4.53it/\u001b[A\n",
      "Training loss: 4.44e-02 lr: 1.27e-05:  75%|▋| 10325/13852 [38:43<12:59,  4.52it/\u001b[A\n",
      "Training loss: 1.03e-01 lr: 1.27e-05:  75%|▋| 10326/13852 [38:43<13:00,  4.52it/\u001b[A\n",
      "Training loss: 7.42e-02 lr: 1.27e-05:  75%|▋| 10327/13852 [38:43<13:01,  4.51it/\u001b[A\n",
      "Training loss: 6.68e-02 lr: 1.27e-05:  75%|▋| 10328/13852 [38:43<13:03,  4.50it/\u001b[A\n",
      "Training loss: 9.36e-02 lr: 1.27e-05:  75%|▋| 10329/13852 [38:43<13:03,  4.50it/\u001b[A\n",
      "Training loss: 6.82e-02 lr: 1.27e-05:  75%|▋| 10330/13852 [38:44<13:03,  4.49it/\u001b[A\n",
      "Training loss: 5.85e-02 lr: 1.27e-05:  75%|▋| 10331/13852 [38:44<13:00,  4.51it/\u001b[A\n",
      "Training loss: 4.19e-02 lr: 1.27e-05:  75%|▋| 10332/13852 [38:44<12:56,  4.54it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 1.27e-05:  75%|▋| 10333/13852 [38:44<12:52,  4.55it/\u001b[A\n",
      "Training loss: 4.84e-02 lr: 1.27e-05:  75%|▋| 10334/13852 [38:45<12:57,  4.53it/\u001b[A\n",
      "Training loss: 3.83e-02 lr: 1.27e-05:  75%|▋| 10335/13852 [38:45<12:58,  4.52it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 1.27e-05:  75%|▋| 10336/13852 [38:45<12:58,  4.52it/\u001b[A\n",
      "Training loss: 3.36e-02 lr: 1.27e-05:  75%|▋| 10337/13852 [38:45<12:57,  4.52it/\u001b[A\n",
      "Training loss: 2.61e-02 lr: 1.27e-05:  75%|▋| 10338/13852 [38:45<12:58,  4.51it/\u001b[A\n",
      "Training loss: 2.64e-02 lr: 1.27e-05:  75%|▋| 10339/13852 [38:46<12:58,  4.51it/\u001b[A\n",
      "Training loss: 3.32e-02 lr: 1.27e-05:  75%|▋| 10340/13852 [38:46<12:58,  4.51it/\u001b[A\n",
      "Training loss: 4.34e-02 lr: 1.27e-05:  75%|▋| 10341/13852 [38:46<12:58,  4.51it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 1.27e-05:  75%|▋| 10342/13852 [38:46<13:03,  4.48it/\u001b[A\n",
      "Training loss: 2.72e-02 lr: 1.27e-05:  75%|▋| 10343/13852 [38:47<12:59,  4.50it/\u001b[A\n",
      "Training loss: 1.96e-02 lr: 1.27e-05:  75%|▋| 10344/13852 [38:47<13:00,  4.49it/\u001b[A\n",
      "Training loss: 1.55e-02 lr: 1.27e-05:  75%|▋| 10345/13852 [38:47<12:58,  4.51it/\u001b[A\n",
      "Training loss: 1.33e-02 lr: 1.27e-05:  75%|▋| 10346/13852 [38:47<12:57,  4.51it/\u001b[A\n",
      "Training loss: 1.15e-02 lr: 1.27e-05:  75%|▋| 10347/13852 [38:47<12:56,  4.51it/\u001b[A\n",
      "Training loss: 8.82e-03 lr: 1.26e-05:  75%|▋| 10348/13852 [38:48<12:56,  4.51it/\u001b[A\n",
      "Training loss: 1.14e-02 lr: 1.26e-05:  75%|▋| 10349/13852 [38:48<12:57,  4.51it/\u001b[A\n",
      "Training loss: 2.01e-02 lr: 1.26e-05:  75%|▋| 10350/13852 [38:48<12:58,  4.50it/\u001b[A\n",
      "Training loss: 1.46e-02 lr: 1.26e-05:  75%|▋| 10351/13852 [38:48<12:58,  4.50it/\u001b[A\n",
      "Training loss: 1.06e-02 lr: 1.26e-05:  75%|▋| 10352/13852 [38:49<12:57,  4.50it/\u001b[A\n",
      "Training loss: 1.55e-02 lr: 1.26e-05:  75%|▋| 10353/13852 [38:49<12:57,  4.50it/\u001b[A\n",
      "Training loss: 2.39e-02 lr: 1.26e-05:  75%|▋| 10354/13852 [38:49<12:57,  4.50it/\u001b[A\n",
      "Training loss: 3.61e-02 lr: 1.26e-05:  75%|▋| 10355/13852 [38:49<12:55,  4.51it/\u001b[A\n",
      "Training loss: 4.60e-02 lr: 1.26e-05:  75%|▋| 10356/13852 [38:49<12:51,  4.53it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 1.26e-05:  75%|▋| 10357/13852 [38:50<12:53,  4.52it/\u001b[A\n",
      "Training loss: 2.88e-02 lr: 1.26e-05:  75%|▋| 10358/13852 [38:50<12:54,  4.51it/\u001b[A\n",
      "Training loss: 2.05e-02 lr: 1.26e-05:  75%|▋| 10359/13852 [38:50<12:54,  4.51it/\u001b[A\n",
      "Training loss: 1.52e-02 lr: 1.26e-05:  75%|▋| 10360/13852 [38:50<12:53,  4.51it/\u001b[A\n",
      "Training loss: 2.75e-02 lr: 1.26e-05:  75%|▋| 10361/13852 [38:51<12:52,  4.52it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 1.26e-05:  75%|▋| 10362/13852 [38:51<12:54,  4.51it/\u001b[A\n",
      "Training loss: 3.13e-02 lr: 1.26e-05:  75%|▋| 10363/13852 [38:51<12:56,  4.49it/\u001b[A\n",
      "Training loss: 2.61e-02 lr: 1.26e-05:  75%|▋| 10364/13852 [38:51<12:56,  4.49it/\u001b[A\n",
      "Training loss: 5.21e-02 lr: 1.26e-05:  75%|▋| 10365/13852 [38:51<12:57,  4.48it/\u001b[A\n",
      "Training loss: 5.99e-02 lr: 1.26e-05:  75%|▋| 10366/13852 [38:52<13:17,  4.37it/\u001b[A\n",
      "Training loss: 5.06e-02 lr: 1.26e-05:  75%|▋| 10367/13852 [38:52<13:33,  4.28it/\u001b[A\n",
      "Training loss: 5.52e-02 lr: 1.26e-05:  75%|▋| 10368/13852 [38:52<13:22,  4.34it/\u001b[A\n",
      "Training loss: 4.54e-02 lr: 1.26e-05:  75%|▋| 10369/13852 [38:52<13:16,  4.37it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.21e-02 lr: 1.26e-05:  75%|▋| 10370/13852 [38:53<13:08,  4.41it/\u001b[A\n",
      "Training loss: 2.29e-02 lr: 1.26e-05:  75%|▋| 10371/13852 [38:53<13:04,  4.44it/\u001b[A\n",
      "Training loss: 2.22e-02 lr: 1.26e-05:  75%|▋| 10372/13852 [38:53<13:01,  4.45it/\u001b[A\n",
      "Training loss: 2.32e-02 lr: 1.26e-05:  75%|▋| 10373/13852 [38:53<12:58,  4.47it/\u001b[A\n",
      "Training loss: 2.67e-02 lr: 1.26e-05:  75%|▋| 10374/13852 [38:53<12:56,  4.48it/\u001b[A\n",
      "Training loss: 2.24e-02 lr: 1.26e-05:  75%|▋| 10375/13852 [38:54<12:54,  4.49it/\u001b[A\n",
      "Training loss: 4.39e-02 lr: 1.25e-05:  75%|▋| 10376/13852 [38:54<12:51,  4.50it/\u001b[A\n",
      "Training loss: 3.75e-02 lr: 1.25e-05:  75%|▋| 10377/13852 [38:54<12:47,  4.53it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 1.25e-05:  75%|▋| 10378/13852 [38:54<12:44,  4.55it/\u001b[A\n",
      "Training loss: 8.83e-02 lr: 1.25e-05:  75%|▋| 10379/13852 [38:55<12:46,  4.53it/\u001b[A\n",
      "Training loss: 7.20e-02 lr: 1.25e-05:  75%|▋| 10380/13852 [38:55<12:48,  4.52it/\u001b[A\n",
      "Training loss: 7.27e-02 lr: 1.25e-05:  75%|▋| 10381/13852 [38:55<12:48,  4.52it/\u001b[A\n",
      "Training loss: 5.36e-02 lr: 1.25e-05:  75%|▋| 10382/13852 [38:55<12:47,  4.52it/\u001b[A\n",
      "Training loss: 6.62e-02 lr: 1.25e-05:  75%|▋| 10383/13852 [38:55<12:50,  4.50it/\u001b[A\n",
      "Training loss: 4.81e-02 lr: 1.25e-05:  75%|▋| 10384/13852 [38:56<12:49,  4.50it/\u001b[A\n",
      "Training loss: 8.39e-02 lr: 1.25e-05:  75%|▋| 10385/13852 [38:56<12:49,  4.51it/\u001b[A\n",
      "Training loss: 5.91e-02 lr: 1.25e-05:  75%|▋| 10386/13852 [38:56<12:49,  4.50it/\u001b[A\n",
      "Training loss: 4.38e-02 lr: 1.25e-05:  75%|▋| 10387/13852 [38:56<12:52,  4.49it/\u001b[A\n",
      "Training loss: 3.64e-02 lr: 1.25e-05:  75%|▋| 10388/13852 [38:57<12:49,  4.50it/\u001b[A\n",
      "Training loss: 3.82e-02 lr: 1.25e-05:  75%|▊| 10389/13852 [38:57<12:51,  4.49it/\u001b[A\n",
      "Training loss: 7.46e-02 lr: 1.25e-05:  75%|▊| 10390/13852 [38:57<12:46,  4.52it/\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.25e-05:  75%|▊| 10391/13852 [38:57<12:49,  4.50it/\u001b[A\n",
      "Training loss: 1.79e-01 lr: 1.25e-05:  75%|▊| 10392/13852 [38:57<12:47,  4.51it/\u001b[A\n",
      "Training loss: 1.49e-01 lr: 1.25e-05:  75%|▊| 10393/13852 [38:58<12:47,  4.51it/\u001b[A\n",
      "Training loss: 1.13e-01 lr: 1.25e-05:  75%|▊| 10394/13852 [38:58<12:47,  4.51it/\u001b[A\n",
      "Training loss: 1.38e-01 lr: 1.25e-05:  75%|▊| 10395/13852 [38:58<12:46,  4.51it/\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.25e-05:  75%|▊| 10396/13852 [38:58<12:46,  4.51it/\u001b[A\n",
      "Training loss: 7.22e-02 lr: 1.25e-05:  75%|▊| 10397/13852 [38:59<12:45,  4.51it/\u001b[A\n",
      "Training loss: 5.37e-02 lr: 1.25e-05:  75%|▊| 10398/13852 [38:59<12:47,  4.50it/\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.25e-05:  75%|▊| 10399/13852 [38:59<12:47,  4.50it/\u001b[A\n",
      "Training loss: 5.41e-02 lr: 1.25e-05:  75%|▊| 10400/13852 [38:59<12:44,  4.51it/\u001b[A\n",
      "Training loss: 4.05e-02 lr: 1.25e-05:  75%|▊| 10401/13852 [38:59<12:40,  4.53it/\u001b[A\n",
      "Training loss: 7.02e-02 lr: 1.25e-05:  75%|▊| 10402/13852 [39:00<12:38,  4.55it/\u001b[A\n",
      "Training loss: 7.66e-02 lr: 1.25e-05:  75%|▊| 10403/13852 [39:00<12:36,  4.56it/\u001b[A\n",
      "Training loss: 5.89e-02 lr: 1.24e-05:  75%|▊| 10404/13852 [39:00<12:40,  4.53it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 1.24e-05:  75%|▊| 10405/13852 [39:00<12:42,  4.52it/\u001b[A\n",
      "Training loss: 5.84e-02 lr: 1.24e-05:  75%|▊| 10406/13852 [39:01<12:42,  4.52it/\u001b[A\n",
      "Training loss: 4.94e-02 lr: 1.24e-05:  75%|▊| 10407/13852 [39:01<12:44,  4.50it/\u001b[A\n",
      "Training loss: 3.81e-02 lr: 1.24e-05:  75%|▊| 10408/13852 [39:01<12:46,  4.49it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.24e-05:  75%|▊| 10409/13852 [39:01<12:46,  4.49it/\u001b[A\n",
      "Training loss: 5.95e-02 lr: 1.24e-05:  75%|▊| 10410/13852 [39:01<12:45,  4.50it/\u001b[A\n",
      "Training loss: 6.12e-02 lr: 1.24e-05:  75%|▊| 10411/13852 [39:02<12:49,  4.47it/\u001b[A\n",
      "Training loss: 1.58e-01 lr: 1.24e-05:  75%|▊| 10412/13852 [39:02<12:51,  4.46it/\u001b[A\n",
      "Training loss: 1.27e-01 lr: 1.24e-05:  75%|▊| 10413/13852 [39:02<12:46,  4.49it/\u001b[A\n",
      "Training loss: 9.75e-02 lr: 1.24e-05:  75%|▊| 10414/13852 [39:02<12:41,  4.52it/\u001b[A\n",
      "Training loss: 1.09e-01 lr: 1.24e-05:  75%|▊| 10415/13852 [39:03<12:42,  4.51it/\u001b[A\n",
      "Training loss: 1.29e-01 lr: 1.24e-05:  75%|▊| 10416/13852 [39:03<12:42,  4.51it/\u001b[A\n",
      "Training loss: 9.36e-02 lr: 1.24e-05:  75%|▊| 10417/13852 [39:03<12:46,  4.48it/\u001b[A\n",
      "Training loss: 8.48e-02 lr: 1.24e-05:  75%|▊| 10418/13852 [39:03<12:44,  4.49it/\u001b[A\n",
      "Training loss: 9.56e-02 lr: 1.24e-05:  75%|▊| 10419/13852 [39:03<12:43,  4.50it/\u001b[A\n",
      "Training loss: 7.32e-02 lr: 1.24e-05:  75%|▊| 10420/13852 [39:04<12:44,  4.49it/\u001b[A\n",
      "Training loss: 5.86e-02 lr: 1.24e-05:  75%|▊| 10421/13852 [39:04<12:43,  4.50it/\u001b[A\n",
      "Training loss: 5.01e-02 lr: 1.24e-05:  75%|▊| 10422/13852 [39:04<12:43,  4.49it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 1.24e-05:  75%|▊| 10423/13852 [39:04<12:42,  4.50it/\u001b[A\n",
      "Training loss: 3.88e-02 lr: 1.24e-05:  75%|▊| 10424/13852 [39:05<12:38,  4.52it/\u001b[A\n",
      "Training loss: 4.86e-02 lr: 1.24e-05:  75%|▊| 10425/13852 [39:05<12:34,  4.54it/\u001b[A\n",
      "Training loss: 4.55e-02 lr: 1.24e-05:  75%|▊| 10426/13852 [39:05<12:31,  4.56it/\u001b[A\n",
      "Training loss: 4.63e-02 lr: 1.24e-05:  75%|▊| 10427/13852 [39:05<12:38,  4.52it/\u001b[A\n",
      "Training loss: 6.01e-02 lr: 1.24e-05:  75%|▊| 10428/13852 [39:05<12:42,  4.49it/\u001b[A\n",
      "Training loss: 5.09e-02 lr: 1.24e-05:  75%|▊| 10429/13852 [39:06<12:41,  4.50it/\u001b[A\n",
      "Training loss: 3.90e-02 lr: 1.24e-05:  75%|▊| 10430/13852 [39:06<12:41,  4.49it/\u001b[A\n",
      "Training loss: 3.62e-02 lr: 1.23e-05:  75%|▊| 10431/13852 [39:06<12:43,  4.48it/\u001b[A\n",
      "Training loss: 3.69e-02 lr: 1.23e-05:  75%|▊| 10432/13852 [39:06<12:42,  4.49it/\u001b[A\n",
      "Training loss: 4.66e-02 lr: 1.23e-05:  75%|▊| 10433/13852 [39:07<12:47,  4.45it/\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.23e-05:  75%|▊| 10434/13852 [39:07<12:52,  4.42it/\u001b[A\n",
      "Training loss: 3.82e-02 lr: 1.23e-05:  75%|▊| 10435/13852 [39:07<12:51,  4.43it/\u001b[A\n",
      "Training loss: 6.62e-02 lr: 1.23e-05:  75%|▊| 10436/13852 [39:07<12:48,  4.44it/\u001b[A\n",
      "Training loss: 5.56e-02 lr: 1.23e-05:  75%|▊| 10437/13852 [39:08<12:55,  4.40it/\u001b[A\n",
      "Training loss: 4.34e-02 lr: 1.23e-05:  75%|▊| 10438/13852 [39:08<12:51,  4.42it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 1.23e-05:  75%|▊| 10439/13852 [39:08<12:48,  4.44it/\u001b[A\n",
      "Training loss: 4.46e-02 lr: 1.23e-05:  75%|▊| 10440/13852 [39:08<12:46,  4.45it/\u001b[A\n",
      "Training loss: 3.70e-02 lr: 1.23e-05:  75%|▊| 10441/13852 [39:08<12:42,  4.47it/\u001b[A\n",
      "Training loss: 3.14e-02 lr: 1.23e-05:  75%|▊| 10442/13852 [39:09<12:40,  4.48it/\u001b[A\n",
      "Training loss: 9.50e-02 lr: 1.23e-05:  75%|▊| 10443/13852 [39:09<12:39,  4.49it/\u001b[A\n",
      "Training loss: 6.80e-02 lr: 1.23e-05:  75%|▊| 10444/13852 [39:09<12:38,  4.49it/\u001b[A\n",
      "Training loss: 5.52e-02 lr: 1.23e-05:  75%|▊| 10445/13852 [39:09<12:39,  4.49it/\u001b[A\n",
      "Training loss: 4.35e-02 lr: 1.23e-05:  75%|▊| 10446/13852 [39:10<12:36,  4.50it/\u001b[A\n",
      "Training loss: 5.06e-02 lr: 1.23e-05:  75%|▊| 10447/13852 [39:10<12:32,  4.53it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 1.23e-05:  75%|▊| 10448/13852 [39:10<12:29,  4.54it/\u001b[A\n",
      "Training loss: 4.66e-02 lr: 1.23e-05:  75%|▊| 10449/13852 [39:10<12:31,  4.53it/\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.23e-05:  75%|▊| 10450/13852 [39:10<12:32,  4.52it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 1.23e-05:  75%|▊| 10451/13852 [39:11<12:32,  4.52it/\u001b[A\n",
      "Training loss: 2.81e-02 lr: 1.23e-05:  75%|▊| 10452/13852 [39:11<12:33,  4.51it/\u001b[A\n",
      "Training loss: 2.87e-02 lr: 1.23e-05:  75%|▊| 10453/13852 [39:11<12:35,  4.50it/\u001b[A\n",
      "Training loss: 2.32e-02 lr: 1.23e-05:  75%|▊| 10454/13852 [39:11<12:35,  4.50it/\u001b[A\n",
      "Training loss: 2.37e-02 lr: 1.23e-05:  75%|▊| 10455/13852 [39:11<12:35,  4.50it/\u001b[A\n",
      "Training loss: 2.01e-02 lr: 1.23e-05:  75%|▊| 10456/13852 [39:12<12:37,  4.48it/\u001b[A\n",
      "Training loss: 1.71e-02 lr: 1.23e-05:  75%|▊| 10457/13852 [39:12<12:37,  4.48it/\u001b[A\n",
      "Training loss: 9.49e-02 lr: 1.23e-05:  75%|▊| 10458/13852 [39:12<12:32,  4.51it/\u001b[A\n",
      "Training loss: 7.06e-02 lr: 1.22e-05:  76%|▊| 10459/13852 [39:12<12:28,  4.54it/\u001b[A\n",
      "Training loss: 1.32e-01 lr: 1.22e-05:  76%|▊| 10460/13852 [39:13<12:25,  4.55it/\u001b[A\n",
      "Training loss: 9.42e-02 lr: 1.22e-05:  76%|▊| 10461/13852 [39:13<12:31,  4.51it/\u001b[A\n",
      "Training loss: 6.88e-02 lr: 1.22e-05:  76%|▊| 10462/13852 [39:13<12:31,  4.51it/\u001b[A\n",
      "Training loss: 5.66e-02 lr: 1.22e-05:  76%|▊| 10463/13852 [39:13<12:30,  4.51it/\u001b[A\n",
      "Training loss: 4.91e-02 lr: 1.22e-05:  76%|▊| 10464/13852 [39:13<12:30,  4.51it/\u001b[A\n",
      "Training loss: 5.99e-02 lr: 1.22e-05:  76%|▊| 10465/13852 [39:14<12:32,  4.50it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 1.22e-05:  76%|▊| 10466/13852 [39:14<12:34,  4.49it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.75e-02 lr: 1.22e-05:  76%|▊| 10467/13852 [39:14<12:33,  4.49it/\u001b[A\n",
      "Training loss: 3.03e-02 lr: 1.22e-05:  76%|▊| 10468/13852 [39:14<12:33,  4.49it/\u001b[A\n",
      "Training loss: 3.44e-02 lr: 1.22e-05:  76%|▊| 10469/13852 [39:15<12:33,  4.49it/\u001b[A\n",
      "Training loss: 2.68e-02 lr: 1.22e-05:  76%|▊| 10470/13852 [39:15<12:29,  4.51it/\u001b[A\n",
      "Training loss: 2.32e-02 lr: 1.22e-05:  76%|▊| 10471/13852 [39:15<12:25,  4.54it/\u001b[A\n",
      "Training loss: 4.36e-02 lr: 1.22e-05:  76%|▊| 10472/13852 [39:15<12:24,  4.54it/\u001b[A\n",
      "Training loss: 3.53e-02 lr: 1.22e-05:  76%|▊| 10473/13852 [39:15<12:23,  4.54it/\u001b[A\n",
      "Training loss: 3.82e-02 lr: 1.22e-05:  76%|▊| 10474/13852 [39:16<12:24,  4.54it/\u001b[A\n",
      "Training loss: 3.06e-02 lr: 1.22e-05:  76%|▊| 10475/13852 [39:16<12:24,  4.54it/\u001b[A\n",
      "Training loss: 3.59e-02 lr: 1.22e-05:  76%|▊| 10476/13852 [39:16<12:25,  4.53it/\u001b[A\n",
      "Training loss: 4.68e-02 lr: 1.22e-05:  76%|▊| 10477/13852 [39:16<12:26,  4.52it/\u001b[A\n",
      "Training loss: 9.35e-02 lr: 1.22e-05:  76%|▊| 10478/13852 [39:17<12:31,  4.49it/\u001b[A\n",
      "Training loss: 7.56e-02 lr: 1.22e-05:  76%|▊| 10479/13852 [39:17<12:37,  4.45it/\u001b[A\n",
      "Training loss: 7.24e-02 lr: 1.22e-05:  76%|▊| 10480/13852 [39:17<12:36,  4.46it/\u001b[A\n",
      "Training loss: 5.13e-02 lr: 1.22e-05:  76%|▊| 10481/13852 [39:17<12:36,  4.46it/\u001b[A\n",
      "Training loss: 4.08e-02 lr: 1.22e-05:  76%|▊| 10482/13852 [39:17<12:33,  4.47it/\u001b[A\n",
      "Training loss: 4.01e-02 lr: 1.22e-05:  76%|▊| 10483/13852 [39:18<12:27,  4.51it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 1.22e-05:  76%|▊| 10484/13852 [39:18<12:23,  4.53it/\u001b[A\n",
      "Training loss: 6.79e-02 lr: 1.22e-05:  76%|▊| 10485/13852 [39:18<12:26,  4.51it/\u001b[A\n",
      "Training loss: 5.67e-02 lr: 1.22e-05:  76%|▊| 10486/13852 [39:18<12:25,  4.51it/\u001b[A\n",
      "Training loss: 6.16e-02 lr: 1.21e-05:  76%|▊| 10487/13852 [39:19<12:24,  4.52it/\u001b[A\n",
      "Training loss: 4.59e-02 lr: 1.21e-05:  76%|▊| 10488/13852 [39:19<12:24,  4.52it/\u001b[A\n",
      "Training loss: 4.82e-02 lr: 1.21e-05:  76%|▊| 10489/13852 [39:19<12:25,  4.51it/\u001b[A\n",
      "Training loss: 3.95e-02 lr: 1.21e-05:  76%|▊| 10490/13852 [39:19<12:25,  4.51it/\u001b[A\n",
      "Training loss: 2.78e-02 lr: 1.21e-05:  76%|▊| 10491/13852 [39:19<12:25,  4.51it/\u001b[A\n",
      "Training loss: 2.69e-02 lr: 1.21e-05:  76%|▊| 10492/13852 [39:20<12:25,  4.51it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 1.21e-05:  76%|▊| 10493/13852 [39:20<12:25,  4.51it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 1.21e-05:  76%|▊| 10494/13852 [39:20<12:25,  4.50it/\u001b[A\n",
      "Training loss: 3.91e-02 lr: 1.21e-05:  76%|▊| 10495/13852 [39:20<12:21,  4.53it/\u001b[A\n",
      "Training loss: 7.26e-02 lr: 1.21e-05:  76%|▊| 10496/13852 [39:21<12:17,  4.55it/\u001b[A\n",
      "Training loss: 5.93e-02 lr: 1.21e-05:  76%|▊| 10497/13852 [39:21<12:25,  4.50it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 1.21e-05:  76%|▊| 10498/13852 [39:21<12:25,  4.50it/\u001b[A\n",
      "Training loss: 4.06e-02 lr: 1.21e-05:  76%|▊| 10499/13852 [39:21<12:25,  4.50it/\u001b[A\n",
      "Training loss: 4.74e-02 lr: 1.21e-05:  76%|▊| 10500/13852 [39:21<12:25,  4.50it/\u001b[A\n",
      "Training loss: 3.40e-02 lr: 1.21e-05:  76%|▊| 10501/13852 [39:22<12:26,  4.49it/\u001b[A\n",
      "Training loss: 1.25e-01 lr: 1.21e-05:  76%|▊| 10502/13852 [39:22<12:25,  4.49it/\u001b[A\n",
      "Training loss: 8.91e-02 lr: 1.21e-05:  76%|▊| 10503/13852 [39:22<12:26,  4.48it/\u001b[A\n",
      "Training loss: 7.25e-02 lr: 1.21e-05:  76%|▊| 10504/13852 [39:22<12:25,  4.49it/\u001b[A\n",
      "Training loss: 5.24e-02 lr: 1.21e-05:  76%|▊| 10505/13852 [39:23<12:25,  4.49it/\u001b[A\n",
      "Training loss: 1.43e-01 lr: 1.21e-05:  76%|▊| 10506/13852 [39:23<12:21,  4.51it/\u001b[A\n",
      "Training loss: 1.09e-01 lr: 1.21e-05:  76%|▊| 10507/13852 [39:23<12:17,  4.53it/\u001b[A\n",
      "Training loss: 9.15e-02 lr: 1.21e-05:  76%|▊| 10508/13852 [39:23<12:15,  4.55it/\u001b[A\n",
      "Training loss: 1.26e-01 lr: 1.21e-05:  76%|▊| 10509/13852 [39:23<12:12,  4.57it/\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.21e-05:  76%|▊| 10510/13852 [39:24<12:15,  4.55it/\u001b[A\n",
      "Training loss: 7.65e-02 lr: 1.21e-05:  76%|▊| 10511/13852 [39:24<12:15,  4.54it/\u001b[A\n",
      "Training loss: 5.46e-02 lr: 1.21e-05:  76%|▊| 10512/13852 [39:24<12:17,  4.53it/\u001b[A\n",
      "Training loss: 1.30e-01 lr: 1.21e-05:  76%|▊| 10513/13852 [39:24<12:17,  4.53it/\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.20e-05:  76%|▊| 10514/13852 [39:25<12:17,  4.52it/\u001b[A\n",
      "Training loss: 7.60e-02 lr: 1.20e-05:  76%|▊| 10515/13852 [39:25<12:18,  4.52it/\u001b[A\n",
      "Training loss: 1.17e-01 lr: 1.20e-05:  76%|▊| 10516/13852 [39:25<12:18,  4.52it/\u001b[A\n",
      "Training loss: 8.52e-02 lr: 1.20e-05:  76%|▊| 10517/13852 [39:25<12:19,  4.51it/\u001b[A\n",
      "Training loss: 7.31e-02 lr: 1.20e-05:  76%|▊| 10518/13852 [39:25<12:20,  4.50it/\u001b[A\n",
      "Training loss: 8.74e-02 lr: 1.20e-05:  76%|▊| 10519/13852 [39:26<12:17,  4.52it/\u001b[A\n",
      "Training loss: 6.91e-02 lr: 1.20e-05:  76%|▊| 10520/13852 [39:26<12:12,  4.55it/\u001b[A\n",
      "Training loss: 6.26e-02 lr: 1.20e-05:  76%|▊| 10521/13852 [39:26<12:10,  4.56it/\u001b[A\n",
      "Training loss: 7.95e-02 lr: 1.20e-05:  76%|▊| 10522/13852 [39:26<12:16,  4.52it/\u001b[A\n",
      "Training loss: 5.90e-02 lr: 1.20e-05:  76%|▊| 10523/13852 [39:27<12:15,  4.52it/\u001b[A\n",
      "Training loss: 5.61e-02 lr: 1.20e-05:  76%|▊| 10524/13852 [39:27<12:20,  4.49it/\u001b[A\n",
      "Training loss: 4.21e-02 lr: 1.20e-05:  76%|▊| 10525/13852 [39:27<12:19,  4.50it/\u001b[A\n",
      "Training loss: 3.91e-02 lr: 1.20e-05:  76%|▊| 10526/13852 [39:27<12:21,  4.48it/\u001b[A\n",
      "Training loss: 3.70e-02 lr: 1.20e-05:  76%|▊| 10527/13852 [39:27<12:21,  4.48it/\u001b[A\n",
      "Training loss: 3.70e-02 lr: 1.20e-05:  76%|▊| 10528/13852 [39:28<12:20,  4.49it/\u001b[A\n",
      "Training loss: 7.89e-02 lr: 1.20e-05:  76%|▊| 10529/13852 [39:28<12:19,  4.49it/\u001b[A\n",
      "Training loss: 8.90e-02 lr: 1.20e-05:  76%|▊| 10530/13852 [39:28<12:18,  4.50it/\u001b[A\n",
      "Training loss: 7.59e-02 lr: 1.20e-05:  76%|▊| 10531/13852 [39:28<12:17,  4.50it/\u001b[A\n",
      "Training loss: 7.00e-02 lr: 1.20e-05:  76%|▊| 10532/13852 [39:29<12:40,  4.36it/\u001b[A\n",
      "Training loss: 6.21e-02 lr: 1.20e-05:  76%|▊| 10533/13852 [39:29<13:01,  4.25it/\u001b[A\n",
      "Training loss: 5.26e-02 lr: 1.20e-05:  76%|▊| 10534/13852 [39:29<12:50,  4.31it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 1.20e-05:  76%|▊| 10535/13852 [39:29<12:46,  4.33it/\u001b[A\n",
      "Training loss: 3.66e-02 lr: 1.20e-05:  76%|▊| 10536/13852 [39:30<12:39,  4.36it/\u001b[A\n",
      "Training loss: 5.66e-02 lr: 1.20e-05:  76%|▊| 10537/13852 [39:30<12:36,  4.38it/\u001b[A\n",
      "Training loss: 9.37e-02 lr: 1.20e-05:  76%|▊| 10538/13852 [39:30<12:33,  4.40it/\u001b[A\n",
      "Training loss: 1.14e-01 lr: 1.20e-05:  76%|▊| 10539/13852 [39:30<12:28,  4.43it/\u001b[A\n",
      "Training loss: 1.00e-01 lr: 1.20e-05:  76%|▊| 10540/13852 [39:30<12:23,  4.45it/\u001b[A\n",
      "Training loss: 8.48e-02 lr: 1.20e-05:  76%|▊| 10541/13852 [39:31<12:27,  4.43it/\u001b[A\n",
      "Training loss: 7.52e-02 lr: 1.19e-05:  76%|▊| 10542/13852 [39:31<12:45,  4.33it/\u001b[A\n",
      "Training loss: 5.82e-02 lr: 1.19e-05:  76%|▊| 10543/13852 [39:31<12:57,  4.25it/\u001b[A\n",
      "Training loss: 9.36e-02 lr: 1.19e-05:  76%|▊| 10544/13852 [39:31<12:46,  4.32it/\u001b[A\n",
      "Training loss: 7.13e-02 lr: 1.19e-05:  76%|▊| 10545/13852 [39:32<12:39,  4.35it/\u001b[A\n",
      "Training loss: 5.47e-02 lr: 1.19e-05:  76%|▊| 10546/13852 [39:32<12:33,  4.39it/\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.19e-05:  76%|▊| 10547/13852 [39:32<12:27,  4.42it/\u001b[A\n",
      "Training loss: 4.00e-02 lr: 1.19e-05:  76%|▊| 10548/13852 [39:32<12:22,  4.45it/\u001b[A\n",
      "Training loss: 4.12e-02 lr: 1.19e-05:  76%|▊| 10549/13852 [39:32<12:15,  4.49it/\u001b[A\n",
      "Training loss: 6.26e-02 lr: 1.19e-05:  76%|▊| 10550/13852 [39:33<12:17,  4.48it/\u001b[A\n",
      "Training loss: 7.18e-02 lr: 1.19e-05:  76%|▊| 10551/13852 [39:33<12:15,  4.49it/\u001b[A\n",
      "Training loss: 6.19e-02 lr: 1.19e-05:  76%|▊| 10552/13852 [39:33<12:12,  4.50it/\u001b[A\n",
      "Training loss: 4.53e-02 lr: 1.19e-05:  76%|▊| 10553/13852 [39:33<12:12,  4.50it/\u001b[A\n",
      "Training loss: 4.14e-02 lr: 1.19e-05:  76%|▊| 10554/13852 [39:34<12:14,  4.49it/\u001b[A\n",
      "Training loss: 3.49e-02 lr: 1.19e-05:  76%|▊| 10555/13852 [39:34<12:12,  4.50it/\u001b[A\n",
      "Training loss: 4.23e-02 lr: 1.19e-05:  76%|▊| 10556/13852 [39:34<12:16,  4.48it/\u001b[A\n",
      "Training loss: 9.34e-02 lr: 1.19e-05:  76%|▊| 10557/13852 [39:34<12:14,  4.48it/\u001b[A\n",
      "Training loss: 8.13e-02 lr: 1.19e-05:  76%|▊| 10558/13852 [39:34<12:14,  4.48it/\u001b[A\n",
      "Training loss: 6.50e-02 lr: 1.19e-05:  76%|▊| 10559/13852 [39:35<12:10,  4.51it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 1.19e-05:  76%|▊| 10560/13852 [39:35<12:09,  4.51it/\u001b[A\n",
      "Training loss: 4.84e-02 lr: 1.19e-05:  76%|▊| 10561/13852 [39:35<12:08,  4.52it/\u001b[A\n",
      "Training loss: 5.68e-02 lr: 1.19e-05:  76%|▊| 10562/13852 [39:35<12:11,  4.50it/\u001b[A\n",
      "Training loss: 1.29e-01 lr: 1.19e-05:  76%|▊| 10563/13852 [39:36<12:10,  4.50it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.30e-02 lr: 1.19e-05:  76%|▊| 10564/13852 [39:36<12:09,  4.51it/\u001b[A\n",
      "Training loss: 6.94e-02 lr: 1.19e-05:  76%|▊| 10565/13852 [39:36<12:09,  4.51it/\u001b[A\n",
      "Training loss: 5.43e-02 lr: 1.19e-05:  76%|▊| 10566/13852 [39:36<12:09,  4.51it/\u001b[A\n",
      "Training loss: 6.59e-02 lr: 1.19e-05:  76%|▊| 10567/13852 [39:36<12:11,  4.49it/\u001b[A\n",
      "Training loss: 9.72e-02 lr: 1.19e-05:  76%|▊| 10568/13852 [39:37<12:18,  4.44it/\u001b[A\n",
      "Training loss: 7.30e-02 lr: 1.19e-05:  76%|▊| 10569/13852 [39:37<12:35,  4.34it/\u001b[A\n",
      "Training loss: 7.78e-02 lr: 1.18e-05:  76%|▊| 10570/13852 [39:37<12:44,  4.29it/\u001b[A\n",
      "Training loss: 7.39e-02 lr: 1.18e-05:  76%|▊| 10571/13852 [39:37<12:40,  4.32it/\u001b[A\n",
      "Training loss: 6.81e-02 lr: 1.18e-05:  76%|▊| 10572/13852 [39:38<12:33,  4.35it/\u001b[A\n",
      "Training loss: 8.11e-02 lr: 1.18e-05:  76%|▊| 10573/13852 [39:38<12:24,  4.40it/\u001b[A\n",
      "Training loss: 6.22e-02 lr: 1.18e-05:  76%|▊| 10574/13852 [39:38<12:19,  4.43it/\u001b[A\n",
      "Training loss: 6.04e-02 lr: 1.18e-05:  76%|▊| 10575/13852 [39:38<12:15,  4.46it/\u001b[A\n",
      "Training loss: 6.34e-02 lr: 1.18e-05:  76%|▊| 10576/13852 [39:39<12:13,  4.47it/\u001b[A\n",
      "Training loss: 7.27e-02 lr: 1.18e-05:  76%|▊| 10577/13852 [39:39<12:10,  4.48it/\u001b[A\n",
      "Training loss: 5.61e-02 lr: 1.18e-05:  76%|▊| 10578/13852 [39:39<12:09,  4.49it/\u001b[A\n",
      "Training loss: 5.61e-02 lr: 1.18e-05:  76%|▊| 10579/13852 [39:39<12:09,  4.49it/\u001b[A\n",
      "Training loss: 9.10e-02 lr: 1.18e-05:  76%|▊| 10580/13852 [39:39<12:06,  4.51it/\u001b[A\n",
      "Training loss: 7.30e-02 lr: 1.18e-05:  76%|▊| 10581/13852 [39:40<12:01,  4.53it/\u001b[A\n",
      "Training loss: 5.75e-02 lr: 1.18e-05:  76%|▊| 10582/13852 [39:40<11:58,  4.55it/\u001b[A\n",
      "Training loss: 5.61e-02 lr: 1.18e-05:  76%|▊| 10583/13852 [39:40<12:02,  4.52it/\u001b[A\n",
      "Training loss: 4.96e-02 lr: 1.18e-05:  76%|▊| 10584/13852 [39:40<12:03,  4.52it/\u001b[A\n",
      "Training loss: 3.62e-02 lr: 1.18e-05:  76%|▊| 10585/13852 [39:41<12:04,  4.51it/\u001b[A\n",
      "Training loss: 3.98e-02 lr: 1.18e-05:  76%|▊| 10586/13852 [39:41<12:05,  4.50it/\u001b[A\n",
      "Training loss: 1.48e-01 lr: 1.18e-05:  76%|▊| 10587/13852 [39:41<12:06,  4.49it/\u001b[A\n",
      "Training loss: 1.20e-01 lr: 1.18e-05:  76%|▊| 10588/13852 [39:41<12:08,  4.48it/\u001b[A\n",
      "Training loss: 9.33e-02 lr: 1.18e-05:  76%|▊| 10589/13852 [39:41<12:08,  4.48it/\u001b[A\n",
      "Training loss: 7.95e-02 lr: 1.18e-05:  76%|▊| 10590/13852 [39:42<12:07,  4.48it/\u001b[A\n",
      "Training loss: 6.82e-02 lr: 1.18e-05:  76%|▊| 10591/13852 [39:42<12:08,  4.48it/\u001b[A\n",
      "Training loss: 5.25e-02 lr: 1.18e-05:  76%|▊| 10592/13852 [39:42<12:06,  4.49it/\u001b[A\n",
      "Training loss: 4.36e-02 lr: 1.18e-05:  76%|▊| 10593/13852 [39:42<12:02,  4.51it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 1.18e-05:  76%|▊| 10594/13852 [39:43<12:06,  4.49it/\u001b[A\n",
      "Training loss: 4.07e-02 lr: 1.18e-05:  76%|▊| 10595/13852 [39:43<12:04,  4.49it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 1.18e-05:  76%|▊| 10596/13852 [39:43<12:04,  4.49it/\u001b[A\n",
      "Training loss: 4.02e-02 lr: 1.18e-05:  77%|▊| 10597/13852 [39:43<12:03,  4.50it/\u001b[A\n",
      "Training loss: 3.93e-02 lr: 1.17e-05:  77%|▊| 10598/13852 [39:43<12:03,  4.50it/\u001b[A\n",
      "Training loss: 3.05e-02 lr: 1.17e-05:  77%|▊| 10599/13852 [39:44<12:02,  4.50it/\u001b[A\n",
      "Training loss: 2.49e-02 lr: 1.17e-05:  77%|▊| 10600/13852 [39:44<12:02,  4.50it/\u001b[A\n",
      "Training loss: 3.85e-02 lr: 1.17e-05:  77%|▊| 10601/13852 [39:44<12:03,  4.49it/\u001b[A\n",
      "Training loss: 3.15e-02 lr: 1.17e-05:  77%|▊| 10602/13852 [39:44<12:04,  4.49it/\u001b[A\n",
      "Training loss: 2.76e-02 lr: 1.17e-05:  77%|▊| 10603/13852 [39:45<12:01,  4.51it/\u001b[A\n",
      "Training loss: 2.42e-02 lr: 1.17e-05:  77%|▊| 10604/13852 [39:45<11:56,  4.53it/\u001b[A\n",
      "Training loss: 1.88e-02 lr: 1.17e-05:  77%|▊| 10605/13852 [39:45<11:53,  4.55it/\u001b[A\n",
      "Training loss: 1.93e-02 lr: 1.17e-05:  77%|▊| 10606/13852 [39:45<12:01,  4.50it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 1.17e-05:  77%|▊| 10607/13852 [39:45<12:00,  4.50it/\u001b[A\n",
      "Training loss: 2.58e-02 lr: 1.17e-05:  77%|▊| 10608/13852 [39:46<12:00,  4.51it/\u001b[A\n",
      "Training loss: 2.98e-02 lr: 1.17e-05:  77%|▊| 10609/13852 [39:46<12:00,  4.50it/\u001b[A\n",
      "Training loss: 5.39e-02 lr: 1.17e-05:  77%|▊| 10610/13852 [39:46<12:01,  4.49it/\u001b[A\n",
      "Training loss: 4.10e-02 lr: 1.17e-05:  77%|▊| 10611/13852 [39:46<12:02,  4.49it/\u001b[A\n",
      "Training loss: 3.05e-02 lr: 1.17e-05:  77%|▊| 10612/13852 [39:47<12:02,  4.49it/\u001b[A\n",
      "Training loss: 2.24e-02 lr: 1.17e-05:  77%|▊| 10613/13852 [39:47<12:05,  4.46it/\u001b[A\n",
      "Training loss: 1.66e-02 lr: 1.17e-05:  77%|▊| 10614/13852 [39:47<12:04,  4.47it/\u001b[A\n",
      "Training loss: 1.25e-02 lr: 1.17e-05:  77%|▊| 10615/13852 [39:47<12:00,  4.50it/\u001b[A\n",
      "Training loss: 1.22e-02 lr: 1.17e-05:  77%|▊| 10616/13852 [39:47<11:57,  4.51it/\u001b[A\n",
      "Training loss: 3.65e-02 lr: 1.17e-05:  77%|▊| 10617/13852 [39:48<11:54,  4.53it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.17e-05:  77%|▊| 10618/13852 [39:48<11:57,  4.51it/\u001b[A\n",
      "Training loss: 7.10e-02 lr: 1.17e-05:  77%|▊| 10619/13852 [39:48<11:58,  4.50it/\u001b[A\n",
      "Training loss: 6.82e-02 lr: 1.17e-05:  77%|▊| 10620/13852 [39:48<11:58,  4.50it/\u001b[A\n",
      "Training loss: 7.30e-02 lr: 1.17e-05:  77%|▊| 10621/13852 [39:49<11:56,  4.51it/\u001b[A\n",
      "Training loss: 7.51e-02 lr: 1.17e-05:  77%|▊| 10622/13852 [39:49<11:57,  4.50it/\u001b[A\n",
      "Training loss: 5.66e-02 lr: 1.17e-05:  77%|▊| 10623/13852 [39:49<11:58,  4.50it/\u001b[A\n",
      "Training loss: 7.52e-02 lr: 1.17e-05:  77%|▊| 10624/13852 [39:49<11:57,  4.50it/\u001b[A\n",
      "Training loss: 6.07e-02 lr: 1.16e-05:  77%|▊| 10625/13852 [39:49<11:56,  4.50it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 1.16e-05:  77%|▊| 10626/13852 [39:50<11:56,  4.50it/\u001b[A\n",
      "Training loss: 6.07e-02 lr: 1.16e-05:  77%|▊| 10627/13852 [39:50<11:53,  4.52it/\u001b[A\n",
      "Training loss: 6.80e-02 lr: 1.16e-05:  77%|▊| 10628/13852 [39:50<11:49,  4.54it/\u001b[A\n",
      "Training loss: 5.90e-02 lr: 1.16e-05:  77%|▊| 10629/13852 [39:50<11:47,  4.56it/\u001b[A\n",
      "Training loss: 8.72e-02 lr: 1.16e-05:  77%|▊| 10630/13852 [39:51<11:53,  4.52it/\u001b[A\n",
      "Training loss: 1.04e-01 lr: 1.16e-05:  77%|▊| 10631/13852 [39:51<11:54,  4.51it/\u001b[A\n",
      "Training loss: 7.90e-02 lr: 1.16e-05:  77%|▊| 10632/13852 [39:51<11:55,  4.50it/\u001b[A\n",
      "Training loss: 6.01e-02 lr: 1.16e-05:  77%|▊| 10633/13852 [39:51<11:54,  4.51it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 1.16e-05:  77%|▊| 10634/13852 [39:51<11:54,  4.50it/\u001b[A\n",
      "Training loss: 5.43e-02 lr: 1.16e-05:  77%|▊| 10635/13852 [39:52<11:56,  4.49it/\u001b[A\n",
      "Training loss: 4.27e-02 lr: 1.16e-05:  77%|▊| 10636/13852 [39:52<11:58,  4.47it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 1.16e-05:  77%|▊| 10637/13852 [39:52<12:00,  4.46it/\u001b[A\n",
      "Training loss: 8.72e-02 lr: 1.16e-05:  77%|▊| 10638/13852 [39:52<11:59,  4.46it/\u001b[A\n",
      "Training loss: 6.61e-02 lr: 1.16e-05:  77%|▊| 10639/13852 [39:53<11:55,  4.49it/\u001b[A\n",
      "Training loss: 4.97e-02 lr: 1.16e-05:  77%|▊| 10640/13852 [39:53<11:51,  4.51it/\u001b[A\n",
      "Training loss: 3.68e-02 lr: 1.16e-05:  77%|▊| 10641/13852 [39:53<11:56,  4.48it/\u001b[A\n",
      "Training loss: 2.75e-02 lr: 1.16e-05:  77%|▊| 10642/13852 [39:53<11:56,  4.48it/\u001b[A\n",
      "Training loss: 2.27e-02 lr: 1.16e-05:  77%|▊| 10643/13852 [39:53<11:53,  4.49it/\u001b[A\n",
      "Training loss: 4.08e-02 lr: 1.16e-05:  77%|▊| 10644/13852 [39:54<11:52,  4.50it/\u001b[A\n",
      "Training loss: 4.27e-02 lr: 1.16e-05:  77%|▊| 10645/13852 [39:54<11:52,  4.50it/\u001b[A\n",
      "Training loss: 3.04e-02 lr: 1.16e-05:  77%|▊| 10646/13852 [39:54<11:51,  4.50it/\u001b[A\n",
      "Training loss: 6.37e-02 lr: 1.16e-05:  77%|▊| 10647/13852 [39:54<11:51,  4.50it/\u001b[A\n",
      "Training loss: 4.69e-02 lr: 1.16e-05:  77%|▊| 10648/13852 [39:55<11:51,  4.50it/\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.16e-05:  77%|▊| 10649/13852 [39:55<11:51,  4.50it/\u001b[A\n",
      "Training loss: 3.60e-02 lr: 1.16e-05:  77%|▊| 10650/13852 [39:55<11:49,  4.51it/\u001b[A\n",
      "Training loss: 3.68e-02 lr: 1.16e-05:  77%|▊| 10651/13852 [39:55<11:45,  4.54it/\u001b[A\n",
      "Training loss: 2.64e-02 lr: 1.16e-05:  77%|▊| 10652/13852 [39:55<11:42,  4.55it/\u001b[A\n",
      "Training loss: 5.40e-02 lr: 1.15e-05:  77%|▊| 10653/13852 [39:56<11:44,  4.54it/\u001b[A\n",
      "Training loss: 4.37e-02 lr: 1.15e-05:  77%|▊| 10654/13852 [39:56<11:45,  4.53it/\u001b[A\n",
      "Training loss: 7.54e-02 lr: 1.15e-05:  77%|▊| 10655/13852 [39:56<11:47,  4.52it/\u001b[A\n",
      "Training loss: 5.54e-02 lr: 1.15e-05:  77%|▊| 10656/13852 [39:56<11:47,  4.52it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 1.15e-05:  77%|▊| 10657/13852 [39:57<11:45,  4.53it/\u001b[A\n",
      "Training loss: 5.90e-02 lr: 1.15e-05:  77%|▊| 10658/13852 [39:57<11:49,  4.50it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 1.15e-05:  77%|▊| 10659/13852 [39:57<11:52,  4.48it/\u001b[A\n",
      "Training loss: 3.59e-02 lr: 1.15e-05:  77%|▊| 10660/13852 [39:57<11:50,  4.49it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.96e-02 lr: 1.15e-05:  77%|▊| 10661/13852 [39:57<11:49,  4.50it/\u001b[A\n",
      "Training loss: 3.95e-02 lr: 1.15e-05:  77%|▊| 10662/13852 [39:58<11:48,  4.50it/\u001b[A\n",
      "Training loss: 6.29e-02 lr: 1.15e-05:  77%|▊| 10663/13852 [39:58<11:46,  4.51it/\u001b[A\n",
      "Training loss: 5.24e-02 lr: 1.15e-05:  77%|▊| 10664/13852 [39:58<11:43,  4.53it/\u001b[A\n",
      "Training loss: 5.47e-02 lr: 1.15e-05:  77%|▊| 10665/13852 [39:58<11:41,  4.55it/\u001b[A\n",
      "Training loss: 4.31e-02 lr: 1.15e-05:  77%|▊| 10666/13852 [39:58<11:43,  4.53it/\u001b[A\n",
      "Training loss: 4.54e-02 lr: 1.15e-05:  77%|▊| 10667/13852 [39:59<11:43,  4.53it/\u001b[A\n",
      "Training loss: 5.26e-02 lr: 1.15e-05:  77%|▊| 10668/13852 [39:59<11:43,  4.53it/\u001b[A\n",
      "Training loss: 4.83e-02 lr: 1.15e-05:  77%|▊| 10669/13852 [39:59<11:43,  4.52it/\u001b[A\n",
      "Training loss: 5.27e-02 lr: 1.15e-05:  77%|▊| 10670/13852 [39:59<11:44,  4.51it/\u001b[A\n",
      "Training loss: 6.17e-02 lr: 1.15e-05:  77%|▊| 10671/13852 [40:00<11:44,  4.52it/\u001b[A\n",
      "Training loss: 5.13e-02 lr: 1.15e-05:  77%|▊| 10672/13852 [40:00<11:45,  4.50it/\u001b[A\n",
      "Training loss: 5.58e-02 lr: 1.15e-05:  77%|▊| 10673/13852 [40:00<11:45,  4.50it/\u001b[A\n",
      "Training loss: 4.38e-02 lr: 1.15e-05:  77%|▊| 10674/13852 [40:00<11:47,  4.49it/\u001b[A\n",
      "Training loss: 8.23e-02 lr: 1.15e-05:  77%|▊| 10675/13852 [40:00<11:43,  4.51it/\u001b[A\n",
      "Training loss: 8.44e-02 lr: 1.15e-05:  77%|▊| 10676/13852 [40:01<11:41,  4.53it/\u001b[A\n",
      "Training loss: 6.20e-02 lr: 1.15e-05:  77%|▊| 10677/13852 [40:01<11:40,  4.53it/\u001b[A\n",
      "Training loss: 8.49e-02 lr: 1.15e-05:  77%|▊| 10678/13852 [40:01<11:45,  4.50it/\u001b[A\n",
      "Training loss: 8.58e-02 lr: 1.15e-05:  77%|▊| 10679/13852 [40:01<11:44,  4.50it/\u001b[A\n",
      "Training loss: 8.57e-02 lr: 1.15e-05:  77%|▊| 10680/13852 [40:02<11:43,  4.51it/\u001b[A\n",
      "Training loss: 6.66e-02 lr: 1.14e-05:  77%|▊| 10681/13852 [40:02<11:44,  4.50it/\u001b[A\n",
      "Training loss: 4.84e-02 lr: 1.14e-05:  77%|▊| 10682/13852 [40:02<11:44,  4.50it/\u001b[A\n",
      "Training loss: 3.73e-02 lr: 1.14e-05:  77%|▊| 10683/13852 [40:02<11:44,  4.50it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 1.14e-05:  77%|▊| 10684/13852 [40:02<11:43,  4.50it/\u001b[A\n",
      "Training loss: 2.58e-02 lr: 1.14e-05:  77%|▊| 10685/13852 [40:03<11:42,  4.51it/\u001b[A\n",
      "Training loss: 2.00e-02 lr: 1.14e-05:  77%|▊| 10686/13852 [40:03<11:42,  4.50it/\u001b[A\n",
      "Training loss: 2.55e-02 lr: 1.14e-05:  77%|▊| 10687/13852 [40:03<11:39,  4.52it/\u001b[A\n",
      "Training loss: 2.29e-02 lr: 1.14e-05:  77%|▊| 10688/13852 [40:03<11:37,  4.54it/\u001b[A\n",
      "Training loss: 2.41e-02 lr: 1.14e-05:  77%|▊| 10689/13852 [40:04<11:36,  4.54it/\u001b[A\n",
      "Training loss: 7.27e-02 lr: 1.14e-05:  77%|▊| 10690/13852 [40:04<11:33,  4.56it/\u001b[A\n",
      "Training loss: 6.08e-02 lr: 1.14e-05:  77%|▊| 10691/13852 [40:04<11:36,  4.54it/\u001b[A\n",
      "Training loss: 5.46e-02 lr: 1.14e-05:  77%|▊| 10692/13852 [40:04<11:37,  4.53it/\u001b[A\n",
      "Training loss: 6.38e-02 lr: 1.14e-05:  77%|▊| 10693/13852 [40:04<11:38,  4.53it/\u001b[A\n",
      "Training loss: 4.61e-02 lr: 1.14e-05:  77%|▊| 10694/13852 [40:05<11:38,  4.52it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 1.14e-05:  77%|▊| 10695/13852 [40:05<11:39,  4.51it/\u001b[A\n",
      "Training loss: 3.81e-02 lr: 1.14e-05:  77%|▊| 10696/13852 [40:05<11:39,  4.51it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 1.14e-05:  77%|▊| 10697/13852 [40:05<11:40,  4.51it/\u001b[A\n",
      "Training loss: 6.39e-02 lr: 1.14e-05:  77%|▊| 10698/13852 [40:06<11:40,  4.50it/\u001b[A\n",
      "Training loss: 5.72e-02 lr: 1.14e-05:  77%|▊| 10699/13852 [40:06<11:41,  4.50it/\u001b[A\n",
      "Training loss: 4.37e-02 lr: 1.14e-05:  77%|▊| 10700/13852 [40:06<11:38,  4.51it/\u001b[A\n",
      "Training loss: 5.98e-02 lr: 1.14e-05:  77%|▊| 10701/13852 [40:06<11:34,  4.54it/\u001b[A\n",
      "Training loss: 5.46e-02 lr: 1.14e-05:  77%|▊| 10702/13852 [40:06<11:32,  4.55it/\u001b[A\n",
      "Training loss: 4.90e-02 lr: 1.14e-05:  77%|▊| 10703/13852 [40:07<11:39,  4.50it/\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.14e-05:  77%|▊| 10704/13852 [40:07<11:42,  4.48it/\u001b[A\n",
      "Training loss: 7.99e-02 lr: 1.14e-05:  77%|▊| 10705/13852 [40:07<11:44,  4.47it/\u001b[A\n",
      "Training loss: 6.49e-02 lr: 1.14e-05:  77%|▊| 10706/13852 [40:07<11:46,  4.45it/\u001b[A\n",
      "Training loss: 4.76e-02 lr: 1.14e-05:  77%|▊| 10707/13852 [40:08<11:45,  4.46it/\u001b[A\n",
      "Training loss: 3.39e-02 lr: 1.13e-05:  77%|▊| 10708/13852 [40:08<11:45,  4.46it/\u001b[A\n",
      "Training loss: 9.69e-02 lr: 1.13e-05:  77%|▊| 10709/13852 [40:08<11:42,  4.47it/\u001b[A\n",
      "Training loss: 7.09e-02 lr: 1.13e-05:  77%|▊| 10710/13852 [40:08<11:42,  4.47it/\u001b[A\n",
      "Training loss: 1.20e-01 lr: 1.13e-05:  77%|▊| 10711/13852 [40:08<11:38,  4.50it/\u001b[A\n",
      "Training loss: 8.46e-02 lr: 1.13e-05:  77%|▊| 10712/13852 [40:09<11:50,  4.42it/\u001b[A\n",
      "Training loss: 1.12e-01 lr: 1.13e-05:  77%|▊| 10713/13852 [40:09<11:46,  4.44it/\u001b[A\n",
      "Training loss: 7.93e-02 lr: 1.13e-05:  77%|▊| 10714/13852 [40:09<11:42,  4.47it/\u001b[A\n",
      "Training loss: 5.96e-02 lr: 1.13e-05:  77%|▊| 10715/13852 [40:09<11:40,  4.48it/\u001b[A\n",
      "Training loss: 6.15e-02 lr: 1.13e-05:  77%|▊| 10716/13852 [40:10<11:37,  4.50it/\u001b[A\n",
      "Training loss: 5.48e-02 lr: 1.13e-05:  77%|▊| 10717/13852 [40:10<11:36,  4.50it/\u001b[A\n",
      "Training loss: 4.17e-02 lr: 1.13e-05:  77%|▊| 10718/13852 [40:10<11:35,  4.51it/\u001b[A\n",
      "Training loss: 5.73e-02 lr: 1.13e-05:  77%|▊| 10719/13852 [40:10<11:34,  4.51it/\u001b[A\n",
      "Training loss: 4.75e-02 lr: 1.13e-05:  77%|▊| 10720/13852 [40:10<11:34,  4.51it/\u001b[A\n",
      "Training loss: 3.68e-02 lr: 1.13e-05:  77%|▊| 10721/13852 [40:11<11:35,  4.50it/\u001b[A\n",
      "Training loss: 8.88e-02 lr: 1.13e-05:  77%|▊| 10722/13852 [40:11<11:35,  4.50it/\u001b[A\n",
      "Training loss: 7.26e-02 lr: 1.13e-05:  77%|▊| 10723/13852 [40:11<11:31,  4.53it/\u001b[A\n",
      "Training loss: 5.54e-02 lr: 1.13e-05:  77%|▊| 10724/13852 [40:11<11:27,  4.55it/\u001b[A\n",
      "Training loss: 5.82e-02 lr: 1.13e-05:  77%|▊| 10725/13852 [40:12<11:34,  4.51it/\u001b[A\n",
      "Training loss: 7.80e-02 lr: 1.13e-05:  77%|▊| 10726/13852 [40:12<11:35,  4.49it/\u001b[A\n",
      "Training loss: 5.69e-02 lr: 1.13e-05:  77%|▊| 10727/13852 [40:12<11:34,  4.50it/\u001b[A\n",
      "Training loss: 6.72e-02 lr: 1.13e-05:  77%|▊| 10728/13852 [40:12<11:33,  4.50it/\u001b[A\n",
      "Training loss: 5.07e-02 lr: 1.13e-05:  77%|▊| 10729/13852 [40:12<11:32,  4.51it/\u001b[A\n",
      "Training loss: 3.83e-02 lr: 1.13e-05:  77%|▊| 10730/13852 [40:13<11:32,  4.51it/\u001b[A\n",
      "Training loss: 3.30e-02 lr: 1.13e-05:  77%|▊| 10731/13852 [40:13<11:32,  4.51it/\u001b[A\n",
      "Training loss: 7.07e-02 lr: 1.13e-05:  77%|▊| 10732/13852 [40:13<11:32,  4.51it/\u001b[A\n",
      "Training loss: 7.75e-02 lr: 1.13e-05:  77%|▊| 10733/13852 [40:13<11:31,  4.51it/\u001b[A\n",
      "Training loss: 5.96e-02 lr: 1.13e-05:  77%|▊| 10734/13852 [40:14<11:34,  4.49it/\u001b[A\n",
      "Training loss: 6.11e-02 lr: 1.13e-05:  77%|▊| 10735/13852 [40:14<11:31,  4.51it/\u001b[A\n",
      "Training loss: 4.60e-02 lr: 1.12e-05:  78%|▊| 10736/13852 [40:14<11:27,  4.53it/\u001b[A\n",
      "Training loss: 8.29e-02 lr: 1.12e-05:  78%|▊| 10737/13852 [40:14<11:24,  4.55it/\u001b[A\n",
      "Training loss: 6.21e-02 lr: 1.12e-05:  78%|▊| 10738/13852 [40:14<11:25,  4.55it/\u001b[A\n",
      "Training loss: 5.33e-02 lr: 1.12e-05:  78%|▊| 10739/13852 [40:15<11:25,  4.54it/\u001b[A\n",
      "Training loss: 4.93e-02 lr: 1.12e-05:  78%|▊| 10740/13852 [40:15<11:26,  4.53it/\u001b[A\n",
      "Training loss: 6.14e-02 lr: 1.12e-05:  78%|▊| 10741/13852 [40:15<11:26,  4.53it/\u001b[A\n",
      "Training loss: 5.28e-02 lr: 1.12e-05:  78%|▊| 10742/13852 [40:15<11:27,  4.52it/\u001b[A\n",
      "Training loss: 4.06e-02 lr: 1.12e-05:  78%|▊| 10743/13852 [40:16<11:26,  4.53it/\u001b[A\n",
      "Training loss: 3.08e-02 lr: 1.12e-05:  78%|▊| 10744/13852 [40:16<11:27,  4.52it/\u001b[A\n",
      "Training loss: 2.43e-02 lr: 1.12e-05:  78%|▊| 10745/13852 [40:16<11:28,  4.52it/\u001b[A\n",
      "Training loss: 6.49e-02 lr: 1.12e-05:  78%|▊| 10746/13852 [40:16<11:27,  4.52it/\u001b[A\n",
      "Training loss: 4.95e-02 lr: 1.12e-05:  78%|▊| 10747/13852 [40:16<11:26,  4.52it/\u001b[A\n",
      "Training loss: 3.91e-02 lr: 1.12e-05:  78%|▊| 10748/13852 [40:17<11:24,  4.54it/\u001b[A\n",
      "Training loss: 6.06e-02 lr: 1.12e-05:  78%|▊| 10749/13852 [40:17<11:25,  4.53it/\u001b[A\n",
      "Training loss: 5.07e-02 lr: 1.12e-05:  78%|▊| 10750/13852 [40:17<11:29,  4.50it/\u001b[A\n",
      "Training loss: 7.41e-02 lr: 1.12e-05:  78%|▊| 10751/13852 [40:17<11:28,  4.50it/\u001b[A\n",
      "Training loss: 6.91e-02 lr: 1.12e-05:  78%|▊| 10752/13852 [40:18<11:27,  4.51it/\u001b[A\n",
      "Training loss: 4.90e-02 lr: 1.12e-05:  78%|▊| 10753/13852 [40:18<11:27,  4.51it/\u001b[A\n",
      "Training loss: 3.93e-02 lr: 1.12e-05:  78%|▊| 10754/13852 [40:18<11:28,  4.50it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 1.12e-05:  78%|▊| 10755/13852 [40:18<11:28,  4.50it/\u001b[A\n",
      "Training loss: 9.69e-02 lr: 1.12e-05:  78%|▊| 10756/13852 [40:18<11:27,  4.50it/\u001b[A\n",
      "Training loss: 1.55e-01 lr: 1.12e-05:  78%|▊| 10757/13852 [40:19<11:26,  4.51it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.30e-01 lr: 1.12e-05:  78%|▊| 10758/13852 [40:19<11:25,  4.51it/\u001b[A\n",
      "Training loss: 1.66e-01 lr: 1.12e-05:  78%|▊| 10759/13852 [40:19<11:21,  4.54it/\u001b[A\n",
      "Training loss: 1.30e-01 lr: 1.12e-05:  78%|▊| 10760/13852 [40:19<11:18,  4.55it/\u001b[A\n",
      "Training loss: 9.49e-02 lr: 1.12e-05:  78%|▊| 10761/13852 [40:20<11:16,  4.57it/\u001b[A\n",
      "Training loss: 7.72e-02 lr: 1.12e-05:  78%|▊| 10762/13852 [40:20<11:24,  4.52it/\u001b[A\n",
      "Training loss: 8.51e-02 lr: 1.12e-05:  78%|▊| 10763/13852 [40:20<11:22,  4.53it/\u001b[A\n",
      "Training loss: 7.89e-02 lr: 1.11e-05:  78%|▊| 10764/13852 [40:20<11:22,  4.52it/\u001b[A\n",
      "Training loss: 6.08e-02 lr: 1.11e-05:  78%|▊| 10765/13852 [40:20<11:22,  4.52it/\u001b[A\n",
      "Training loss: 7.10e-02 lr: 1.11e-05:  78%|▊| 10766/13852 [40:21<11:21,  4.53it/\u001b[A\n",
      "Training loss: 5.62e-02 lr: 1.11e-05:  78%|▊| 10767/13852 [40:21<11:27,  4.49it/\u001b[A\n",
      "Training loss: 7.48e-02 lr: 1.11e-05:  78%|▊| 10768/13852 [40:21<11:24,  4.50it/\u001b[A\n",
      "Training loss: 5.33e-02 lr: 1.11e-05:  78%|▊| 10769/13852 [40:21<11:23,  4.51it/\u001b[A\n",
      "Training loss: 4.61e-02 lr: 1.11e-05:  78%|▊| 10770/13852 [40:22<11:23,  4.51it/\u001b[A\n",
      "Training loss: 5.27e-02 lr: 1.11e-05:  78%|▊| 10771/13852 [40:22<11:26,  4.49it/\u001b[A\n",
      "Training loss: 4.94e-02 lr: 1.11e-05:  78%|▊| 10772/13852 [40:22<11:22,  4.51it/\u001b[A\n",
      "Training loss: 1.16e-01 lr: 1.11e-05:  78%|▊| 10773/13852 [40:22<11:19,  4.53it/\u001b[A\n",
      "Training loss: 1.74e-01 lr: 1.11e-05:  78%|▊| 10774/13852 [40:22<11:17,  4.54it/\u001b[A\n",
      "Training loss: 1.34e-01 lr: 1.11e-05:  78%|▊| 10775/13852 [40:23<11:19,  4.53it/\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.11e-05:  78%|▊| 10776/13852 [40:23<11:19,  4.52it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.11e-05:  78%|▊| 10777/13852 [40:23<11:18,  4.53it/\u001b[A\n",
      "Training loss: 8.77e-02 lr: 1.11e-05:  78%|▊| 10778/13852 [40:23<11:17,  4.54it/\u001b[A\n",
      "Training loss: 9.43e-02 lr: 1.11e-05:  78%|▊| 10779/13852 [40:24<11:18,  4.53it/\u001b[A\n",
      "Training loss: 6.96e-02 lr: 1.11e-05:  78%|▊| 10780/13852 [40:24<11:18,  4.53it/\u001b[A\n",
      "Training loss: 6.12e-02 lr: 1.11e-05:  78%|▊| 10781/13852 [40:24<11:21,  4.51it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 1.11e-05:  78%|▊| 10782/13852 [40:24<11:20,  4.51it/\u001b[A\n",
      "Training loss: 3.98e-02 lr: 1.11e-05:  78%|▊| 10783/13852 [40:24<11:19,  4.52it/\u001b[A\n",
      "Training loss: 4.21e-02 lr: 1.11e-05:  78%|▊| 10784/13852 [40:25<11:17,  4.53it/\u001b[A\n",
      "Training loss: 4.61e-02 lr: 1.11e-05:  78%|▊| 10785/13852 [40:25<11:16,  4.54it/\u001b[A\n",
      "Training loss: 4.51e-02 lr: 1.11e-05:  78%|▊| 10786/13852 [40:25<11:12,  4.56it/\u001b[A\n",
      "Training loss: 4.51e-02 lr: 1.11e-05:  78%|▊| 10787/13852 [40:25<11:15,  4.54it/\u001b[A\n",
      "Training loss: 4.51e-02 lr: 1.11e-05:  78%|▊| 10788/13852 [40:26<11:15,  4.54it/\u001b[A\n",
      "Training loss: 5.60e-02 lr: 1.11e-05:  78%|▊| 10789/13852 [40:26<11:15,  4.53it/\u001b[A\n",
      "Training loss: 5.01e-02 lr: 1.11e-05:  78%|▊| 10790/13852 [40:26<11:15,  4.54it/\u001b[A\n",
      "Training loss: 3.85e-02 lr: 1.10e-05:  78%|▊| 10791/13852 [40:26<11:14,  4.54it/\u001b[A\n",
      "Training loss: 4.53e-02 lr: 1.10e-05:  78%|▊| 10792/13852 [40:26<11:15,  4.53it/\u001b[A\n",
      "Training loss: 3.87e-02 lr: 1.10e-05:  78%|▊| 10793/13852 [40:27<11:17,  4.52it/\u001b[A\n",
      "Training loss: 3.05e-02 lr: 1.10e-05:  78%|▊| 10794/13852 [40:27<11:22,  4.48it/\u001b[A\n",
      "Training loss: 3.34e-02 lr: 1.10e-05:  78%|▊| 10795/13852 [40:27<11:25,  4.46it/\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.10e-05:  78%|▊| 10796/13852 [40:27<11:20,  4.49it/\u001b[A\n",
      "Training loss: 3.60e-02 lr: 1.10e-05:  78%|▊| 10797/13852 [40:28<11:15,  4.52it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 1.10e-05:  78%|▊| 10798/13852 [40:28<11:12,  4.54it/\u001b[A\n",
      "Training loss: 3.12e-02 lr: 1.10e-05:  78%|▊| 10799/13852 [40:28<11:10,  4.55it/\u001b[A\n",
      "Training loss: 2.78e-02 lr: 1.10e-05:  78%|▊| 10800/13852 [40:28<11:10,  4.55it/\u001b[A\n",
      "Training loss: 9.33e-02 lr: 1.10e-05:  78%|▊| 10801/13852 [40:28<11:11,  4.55it/\u001b[A\n",
      "Training loss: 7.57e-02 lr: 1.10e-05:  78%|▊| 10802/13852 [40:29<11:12,  4.53it/\u001b[A\n",
      "Training loss: 7.83e-02 lr: 1.10e-05:  78%|▊| 10803/13852 [40:29<11:13,  4.53it/\u001b[A\n",
      "Training loss: 5.75e-02 lr: 1.10e-05:  78%|▊| 10804/13852 [40:29<11:14,  4.52it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 1.10e-05:  78%|▊| 10805/13852 [40:29<11:15,  4.51it/\u001b[A\n",
      "Training loss: 4.41e-02 lr: 1.10e-05:  78%|▊| 10806/13852 [40:30<11:15,  4.51it/\u001b[A\n",
      "Training loss: 3.61e-02 lr: 1.10e-05:  78%|▊| 10807/13852 [40:30<11:16,  4.50it/\u001b[A\n",
      "Training loss: 3.36e-02 lr: 1.10e-05:  78%|▊| 10808/13852 [40:30<11:16,  4.50it/\u001b[A\n",
      "Training loss: 2.85e-02 lr: 1.10e-05:  78%|▊| 10809/13852 [40:30<11:15,  4.51it/\u001b[A\n",
      "Training loss: 4.12e-02 lr: 1.10e-05:  78%|▊| 10810/13852 [40:30<11:12,  4.52it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 1.10e-05:  78%|▊| 10811/13852 [40:31<11:09,  4.54it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 1.10e-05:  78%|▊| 10812/13852 [40:31<11:12,  4.52it/\u001b[A\n",
      "Training loss: 3.63e-02 lr: 1.10e-05:  78%|▊| 10813/13852 [40:31<11:13,  4.51it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 1.10e-05:  78%|▊| 10814/13852 [40:31<11:13,  4.51it/\u001b[A\n",
      "Training loss: 2.53e-02 lr: 1.10e-05:  78%|▊| 10815/13852 [40:32<11:12,  4.51it/\u001b[A\n",
      "Training loss: 1.84e-02 lr: 1.10e-05:  78%|▊| 10816/13852 [40:32<11:15,  4.49it/\u001b[A\n",
      "Training loss: 1.96e-02 lr: 1.10e-05:  78%|▊| 10817/13852 [40:32<11:15,  4.49it/\u001b[A\n",
      "Training loss: 1.67e-02 lr: 1.10e-05:  78%|▊| 10818/13852 [40:32<11:14,  4.50it/\u001b[A\n",
      "Training loss: 1.22e-02 lr: 1.09e-05:  78%|▊| 10819/13852 [40:32<11:13,  4.50it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 1.09e-05:  78%|▊| 10820/13852 [40:33<11:12,  4.51it/\u001b[A\n",
      "Training loss: 4.96e-02 lr: 1.09e-05:  78%|▊| 10821/13852 [40:33<11:10,  4.52it/\u001b[A\n",
      "Training loss: 6.47e-02 lr: 1.09e-05:  78%|▊| 10822/13852 [40:33<11:12,  4.51it/\u001b[A\n",
      "Training loss: 9.93e-02 lr: 1.09e-05:  78%|▊| 10823/13852 [40:33<11:07,  4.54it/\u001b[A\n",
      "Training loss: 7.15e-02 lr: 1.09e-05:  78%|▊| 10824/13852 [40:34<11:05,  4.55it/\u001b[A\n",
      "Training loss: 5.20e-02 lr: 1.09e-05:  78%|▊| 10825/13852 [40:34<11:07,  4.53it/\u001b[A\n",
      "Training loss: 3.83e-02 lr: 1.09e-05:  78%|▊| 10826/13852 [40:34<11:08,  4.53it/\u001b[A\n",
      "Training loss: 5.34e-02 lr: 1.09e-05:  78%|▊| 10827/13852 [40:34<11:08,  4.53it/\u001b[A\n",
      "Training loss: 9.45e-02 lr: 1.09e-05:  78%|▊| 10828/13852 [40:34<11:07,  4.53it/\u001b[A\n",
      "Training loss: 7.48e-02 lr: 1.09e-05:  78%|▊| 10829/13852 [40:35<11:08,  4.52it/\u001b[A\n",
      "Training loss: 5.53e-02 lr: 1.09e-05:  78%|▊| 10830/13852 [40:35<11:09,  4.51it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 1.09e-05:  78%|▊| 10831/13852 [40:35<11:11,  4.50it/\u001b[A\n",
      "Training loss: 3.49e-02 lr: 1.09e-05:  78%|▊| 10832/13852 [40:35<11:11,  4.50it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 1.09e-05:  78%|▊| 10833/13852 [40:36<11:11,  4.50it/\u001b[A\n",
      "Training loss: 8.56e-02 lr: 1.09e-05:  78%|▊| 10834/13852 [40:36<11:09,  4.51it/\u001b[A\n",
      "Training loss: 6.57e-02 lr: 1.09e-05:  78%|▊| 10835/13852 [40:36<11:06,  4.53it/\u001b[A\n",
      "Training loss: 6.08e-02 lr: 1.09e-05:  78%|▊| 10836/13852 [40:36<11:03,  4.54it/\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.09e-05:  78%|▊| 10837/13852 [40:36<11:07,  4.52it/\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.09e-05:  78%|▊| 10838/13852 [40:37<11:07,  4.52it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 1.09e-05:  78%|▊| 10839/13852 [40:37<11:13,  4.48it/\u001b[A\n",
      "Training loss: 7.49e-02 lr: 1.09e-05:  78%|▊| 10840/13852 [40:37<11:31,  4.35it/\u001b[A\n",
      "Training loss: 9.32e-02 lr: 1.09e-05:  78%|▊| 10841/13852 [40:37<11:43,  4.28it/\u001b[A\n",
      "Training loss: 7.16e-02 lr: 1.09e-05:  78%|▊| 10842/13852 [40:38<11:53,  4.22it/\u001b[A\n",
      "Training loss: 5.49e-02 lr: 1.09e-05:  78%|▊| 10843/13852 [40:38<11:54,  4.21it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 1.09e-05:  78%|▊| 10844/13852 [40:38<11:38,  4.30it/\u001b[A\n",
      "Training loss: 3.53e-02 lr: 1.09e-05:  78%|▊| 10845/13852 [40:38<11:29,  4.36it/\u001b[A\n",
      "Training loss: 4.34e-02 lr: 1.09e-05:  78%|▊| 10846/13852 [40:38<11:22,  4.40it/\u001b[A\n",
      "Training loss: 8.15e-02 lr: 1.08e-05:  78%|▊| 10847/13852 [40:39<11:16,  4.44it/\u001b[A\n",
      "Training loss: 5.88e-02 lr: 1.08e-05:  78%|▊| 10848/13852 [40:39<11:14,  4.45it/\u001b[A\n",
      "Training loss: 6.48e-02 lr: 1.08e-05:  78%|▊| 10849/13852 [40:39<11:11,  4.47it/\u001b[A\n",
      "Training loss: 5.33e-02 lr: 1.08e-05:  78%|▊| 10850/13852 [40:39<11:10,  4.48it/\u001b[A\n",
      "Training loss: 4.08e-02 lr: 1.08e-05:  78%|▊| 10851/13852 [40:40<11:09,  4.48it/\u001b[A\n",
      "Training loss: 6.98e-02 lr: 1.08e-05:  78%|▊| 10852/13852 [40:40<11:08,  4.49it/\u001b[A\n",
      "Training loss: 8.55e-02 lr: 1.08e-05:  78%|▊| 10853/13852 [40:40<11:04,  4.51it/\u001b[A\n",
      "Training loss: 7.02e-02 lr: 1.08e-05:  78%|▊| 10854/13852 [40:40<11:00,  4.54it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.16e-02 lr: 1.08e-05:  78%|▊| 10855/13852 [40:40<11:00,  4.54it/\u001b[A\n",
      "Training loss: 6.18e-02 lr: 1.08e-05:  78%|▊| 10856/13852 [40:41<11:04,  4.51it/\u001b[A\n",
      "Training loss: 4.84e-02 lr: 1.08e-05:  78%|▊| 10857/13852 [40:41<11:07,  4.48it/\u001b[A\n",
      "Training loss: 7.29e-02 lr: 1.08e-05:  78%|▊| 10858/13852 [40:41<11:06,  4.50it/\u001b[A\n",
      "Training loss: 5.68e-02 lr: 1.08e-05:  78%|▊| 10859/13852 [40:41<11:04,  4.51it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 1.08e-05:  78%|▊| 10860/13852 [40:42<11:04,  4.50it/\u001b[A\n",
      "Training loss: 3.44e-02 lr: 1.08e-05:  78%|▊| 10861/13852 [40:42<11:07,  4.48it/\u001b[A\n",
      "Training loss: 2.59e-02 lr: 1.08e-05:  78%|▊| 10862/13852 [40:42<11:07,  4.48it/\u001b[A\n",
      "Training loss: 2.50e-02 lr: 1.08e-05:  78%|▊| 10863/13852 [40:42<11:06,  4.48it/\u001b[A\n",
      "Training loss: 2.05e-02 lr: 1.08e-05:  78%|▊| 10864/13852 [40:42<11:05,  4.49it/\u001b[A\n",
      "Training loss: 1.57e-02 lr: 1.08e-05:  78%|▊| 10865/13852 [40:43<11:01,  4.51it/\u001b[A\n",
      "Training loss: 1.69e-02 lr: 1.08e-05:  78%|▊| 10866/13852 [40:43<10:58,  4.53it/\u001b[A\n",
      "Training loss: 1.49e-02 lr: 1.08e-05:  78%|▊| 10867/13852 [40:43<10:58,  4.53it/\u001b[A\n",
      "Training loss: 1.46e-02 lr: 1.08e-05:  78%|▊| 10868/13852 [40:43<10:55,  4.55it/\u001b[A\n",
      "Training loss: 2.96e-02 lr: 1.08e-05:  78%|▊| 10869/13852 [40:44<10:55,  4.55it/\u001b[A\n",
      "Training loss: 2.23e-02 lr: 1.08e-05:  78%|▊| 10870/13852 [40:44<10:56,  4.54it/\u001b[A\n",
      "Training loss: 2.44e-02 lr: 1.08e-05:  78%|▊| 10871/13852 [40:44<10:56,  4.54it/\u001b[A\n",
      "Training loss: 3.98e-02 lr: 1.08e-05:  78%|▊| 10872/13852 [40:44<10:57,  4.53it/\u001b[A\n",
      "Training loss: 4.92e-02 lr: 1.08e-05:  78%|▊| 10873/13852 [40:44<10:58,  4.52it/\u001b[A\n",
      "Training loss: 8.91e-02 lr: 1.08e-05:  79%|▊| 10874/13852 [40:45<10:57,  4.53it/\u001b[A\n",
      "Training loss: 7.67e-02 lr: 1.07e-05:  79%|▊| 10875/13852 [40:45<10:57,  4.53it/\u001b[A\n",
      "Training loss: 1.22e-01 lr: 1.07e-05:  79%|▊| 10876/13852 [40:45<11:00,  4.51it/\u001b[A\n",
      "Training loss: 8.73e-02 lr: 1.07e-05:  79%|▊| 10877/13852 [40:45<11:00,  4.51it/\u001b[A\n",
      "Training loss: 8.50e-02 lr: 1.07e-05:  79%|▊| 10878/13852 [40:46<10:57,  4.52it/\u001b[A\n",
      "Training loss: 6.19e-02 lr: 1.07e-05:  79%|▊| 10879/13852 [40:46<10:54,  4.54it/\u001b[A\n",
      "Training loss: 4.38e-02 lr: 1.07e-05:  79%|▊| 10880/13852 [40:46<10:54,  4.54it/\u001b[A\n",
      "Training loss: 3.42e-02 lr: 1.07e-05:  79%|▊| 10881/13852 [40:46<10:58,  4.51it/\u001b[A\n",
      "Training loss: 3.95e-02 lr: 1.07e-05:  79%|▊| 10882/13852 [40:46<10:58,  4.51it/\u001b[A\n",
      "Training loss: 2.84e-02 lr: 1.07e-05:  79%|▊| 10883/13852 [40:47<10:59,  4.50it/\u001b[A\n",
      "Training loss: 2.51e-02 lr: 1.07e-05:  79%|▊| 10884/13852 [40:47<11:01,  4.49it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 1.07e-05:  79%|▊| 10885/13852 [40:47<11:00,  4.49it/\u001b[A\n",
      "Training loss: 4.53e-02 lr: 1.07e-05:  79%|▊| 10886/13852 [40:47<11:02,  4.48it/\u001b[A\n",
      "Training loss: 4.78e-02 lr: 1.07e-05:  79%|▊| 10887/13852 [40:48<11:01,  4.48it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 1.07e-05:  79%|▊| 10888/13852 [40:48<11:01,  4.48it/\u001b[A\n",
      "Training loss: 2.65e-02 lr: 1.07e-05:  79%|▊| 10889/13852 [40:48<11:03,  4.47it/\u001b[A\n",
      "Training loss: 1.94e-02 lr: 1.07e-05:  79%|▊| 10890/13852 [40:48<10:58,  4.50it/\u001b[A\n",
      "Training loss: 4.73e-02 lr: 1.07e-05:  79%|▊| 10891/13852 [40:48<10:54,  4.52it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 1.07e-05:  79%|▊| 10892/13852 [40:49<11:16,  4.37it/\u001b[A\n",
      "Training loss: 2.80e-02 lr: 1.07e-05:  79%|▊| 10893/13852 [40:49<11:22,  4.34it/\u001b[A\n",
      "Training loss: 2.18e-02 lr: 1.07e-05:  79%|▊| 10894/13852 [40:49<11:12,  4.40it/\u001b[A\n",
      "Training loss: 2.96e-02 lr: 1.07e-05:  79%|▊| 10895/13852 [40:49<11:07,  4.43it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 1.07e-05:  79%|▊| 10896/13852 [40:50<11:02,  4.46it/\u001b[A\n",
      "Training loss: 7.34e-02 lr: 1.07e-05:  79%|▊| 10897/13852 [40:50<11:01,  4.47it/\u001b[A\n",
      "Training loss: 5.78e-02 lr: 1.07e-05:  79%|▊| 10898/13852 [40:50<10:59,  4.48it/\u001b[A\n",
      "Training loss: 9.52e-02 lr: 1.07e-05:  79%|▊| 10899/13852 [40:50<10:58,  4.49it/\u001b[A\n",
      "Training loss: 9.06e-02 lr: 1.07e-05:  79%|▊| 10900/13852 [40:50<10:54,  4.51it/\u001b[A\n",
      "Training loss: 7.66e-02 lr: 1.07e-05:  79%|▊| 10901/13852 [40:51<10:49,  4.54it/\u001b[A\n",
      "Training loss: 6.22e-02 lr: 1.06e-05:  79%|▊| 10902/13852 [40:51<10:52,  4.52it/\u001b[A\n",
      "Training loss: 6.48e-02 lr: 1.06e-05:  79%|▊| 10903/13852 [40:51<10:52,  4.52it/\u001b[A\n",
      "Training loss: 5.36e-02 lr: 1.06e-05:  79%|▊| 10904/13852 [40:51<10:51,  4.52it/\u001b[A\n",
      "Training loss: 5.06e-02 lr: 1.06e-05:  79%|▊| 10905/13852 [40:52<10:51,  4.52it/\u001b[A\n",
      "Training loss: 3.90e-02 lr: 1.06e-05:  79%|▊| 10906/13852 [40:52<10:53,  4.51it/\u001b[A\n",
      "Training loss: 8.51e-02 lr: 1.06e-05:  79%|▊| 10907/13852 [40:52<11:12,  4.38it/\u001b[A\n",
      "Training loss: 6.04e-02 lr: 1.06e-05:  79%|▊| 10908/13852 [40:52<11:07,  4.41it/\u001b[A\n",
      "Training loss: 4.75e-02 lr: 1.06e-05:  79%|▊| 10909/13852 [40:52<11:01,  4.45it/\u001b[A\n",
      "Training loss: 7.03e-02 lr: 1.06e-05:  79%|▊| 10910/13852 [40:53<10:57,  4.47it/\u001b[A\n",
      "Training loss: 8.17e-02 lr: 1.06e-05:  79%|▊| 10911/13852 [40:53<10:52,  4.51it/\u001b[A\n",
      "Training loss: 1.27e-01 lr: 1.06e-05:  79%|▊| 10912/13852 [40:53<10:48,  4.54it/\u001b[A\n",
      "Training loss: 9.62e-02 lr: 1.06e-05:  79%|▊| 10913/13852 [40:53<10:48,  4.53it/\u001b[A\n",
      "Training loss: 8.07e-02 lr: 1.06e-05:  79%|▊| 10914/13852 [40:54<10:45,  4.55it/\u001b[A\n",
      "Training loss: 6.39e-02 lr: 1.06e-05:  79%|▊| 10915/13852 [40:54<10:45,  4.55it/\u001b[A\n",
      "Training loss: 5.08e-02 lr: 1.06e-05:  79%|▊| 10916/13852 [40:54<10:46,  4.54it/\u001b[A\n",
      "Training loss: 4.71e-02 lr: 1.06e-05:  79%|▊| 10917/13852 [40:54<10:48,  4.53it/\u001b[A\n",
      "Training loss: 3.88e-02 lr: 1.06e-05:  79%|▊| 10918/13852 [40:54<10:47,  4.53it/\u001b[A\n",
      "Training loss: 6.17e-02 lr: 1.06e-05:  79%|▊| 10919/13852 [40:55<10:47,  4.53it/\u001b[A\n",
      "Training loss: 5.34e-02 lr: 1.06e-05:  79%|▊| 10920/13852 [40:55<10:46,  4.53it/\u001b[A\n",
      "Training loss: 4.39e-02 lr: 1.06e-05:  79%|▊| 10921/13852 [40:55<10:49,  4.51it/\u001b[A\n",
      "Training loss: 6.93e-02 lr: 1.06e-05:  79%|▊| 10922/13852 [40:55<10:48,  4.52it/\u001b[A\n",
      "Training loss: 5.81e-02 lr: 1.06e-05:  79%|▊| 10923/13852 [40:56<10:48,  4.52it/\u001b[A\n",
      "Training loss: 5.14e-02 lr: 1.06e-05:  79%|▊| 10924/13852 [40:56<10:48,  4.52it/\u001b[A\n",
      "Training loss: 4.93e-02 lr: 1.06e-05:  79%|▊| 10925/13852 [40:56<10:44,  4.54it/\u001b[A\n",
      "Training loss: 3.58e-02 lr: 1.06e-05:  79%|▊| 10926/13852 [40:56<10:42,  4.55it/\u001b[A\n",
      "Training loss: 8.60e-02 lr: 1.06e-05:  79%|▊| 10927/13852 [40:56<10:46,  4.52it/\u001b[A\n",
      "Training loss: 6.44e-02 lr: 1.06e-05:  79%|▊| 10928/13852 [40:57<10:50,  4.50it/\u001b[A\n",
      "Training loss: 5.70e-02 lr: 1.06e-05:  79%|▊| 10929/13852 [40:57<10:49,  4.50it/\u001b[A\n",
      "Training loss: 4.49e-02 lr: 1.05e-05:  79%|▊| 10930/13852 [40:57<10:47,  4.51it/\u001b[A\n",
      "Training loss: 1.06e-01 lr: 1.05e-05:  79%|▊| 10931/13852 [40:57<10:53,  4.47it/\u001b[A\n",
      "Training loss: 1.30e-01 lr: 1.05e-05:  79%|▊| 10932/13852 [40:58<10:51,  4.48it/\u001b[A\n",
      "Training loss: 9.34e-02 lr: 1.05e-05:  79%|▊| 10933/13852 [40:58<10:50,  4.49it/\u001b[A\n",
      "Training loss: 6.99e-02 lr: 1.05e-05:  79%|▊| 10934/13852 [40:58<10:49,  4.50it/\u001b[A\n",
      "Training loss: 5.71e-02 lr: 1.05e-05:  79%|▊| 10935/13852 [40:58<10:48,  4.50it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 1.05e-05:  79%|▊| 10936/13852 [40:58<10:44,  4.52it/\u001b[A\n",
      "Training loss: 5.32e-02 lr: 1.05e-05:  79%|▊| 10937/13852 [40:59<10:42,  4.54it/\u001b[A\n",
      "Training loss: 4.93e-02 lr: 1.05e-05:  79%|▊| 10938/13852 [40:59<10:39,  4.56it/\u001b[A\n",
      "Training loss: 4.47e-02 lr: 1.05e-05:  79%|▊| 10939/13852 [40:59<10:44,  4.52it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 1.05e-05:  79%|▊| 10940/13852 [40:59<10:46,  4.50it/\u001b[A\n",
      "Training loss: 5.01e-02 lr: 1.05e-05:  79%|▊| 10941/13852 [41:00<10:45,  4.51it/\u001b[A\n",
      "Training loss: 4.57e-02 lr: 1.05e-05:  79%|▊| 10942/13852 [41:00<10:44,  4.52it/\u001b[A\n",
      "Training loss: 3.71e-02 lr: 1.05e-05:  79%|▊| 10943/13852 [41:00<10:44,  4.52it/\u001b[A\n",
      "Training loss: 2.64e-02 lr: 1.05e-05:  79%|▊| 10944/13852 [41:00<10:44,  4.51it/\u001b[A\n",
      "Training loss: 4.23e-02 lr: 1.05e-05:  79%|▊| 10945/13852 [41:00<10:44,  4.51it/\u001b[A\n",
      "Training loss: 3.88e-02 lr: 1.05e-05:  79%|▊| 10946/13852 [41:01<10:44,  4.51it/\u001b[A\n",
      "Training loss: 3.68e-02 lr: 1.05e-05:  79%|▊| 10947/13852 [41:01<10:47,  4.48it/\u001b[A\n",
      "Training loss: 3.34e-02 lr: 1.05e-05:  79%|▊| 10948/13852 [41:01<10:47,  4.48it/\u001b[A\n",
      "Training loss: 2.55e-02 lr: 1.05e-05:  79%|▊| 10949/13852 [41:01<10:43,  4.51it/\u001b[A\n",
      "Training loss: 1.89e-02 lr: 1.05e-05:  79%|▊| 10950/13852 [41:02<10:38,  4.54it/\u001b[A\n",
      "Training loss: 1.88e-02 lr: 1.05e-05:  79%|▊| 10951/13852 [41:02<10:40,  4.53it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.45e-02 lr: 1.05e-05:  79%|▊| 10952/13852 [41:02<10:40,  4.53it/\u001b[A\n",
      "Training loss: 4.93e-02 lr: 1.05e-05:  79%|▊| 10953/13852 [41:02<10:40,  4.52it/\u001b[A\n",
      "Training loss: 5.55e-02 lr: 1.05e-05:  79%|▊| 10954/13852 [41:02<10:40,  4.53it/\u001b[A\n",
      "Training loss: 5.22e-02 lr: 1.05e-05:  79%|▊| 10955/13852 [41:03<10:41,  4.52it/\u001b[A\n",
      "Training loss: 4.34e-02 lr: 1.05e-05:  79%|▊| 10956/13852 [41:03<10:41,  4.51it/\u001b[A\n",
      "Training loss: 6.09e-02 lr: 1.05e-05:  79%|▊| 10957/13852 [41:03<10:41,  4.51it/\u001b[A\n",
      "Training loss: 5.14e-02 lr: 1.04e-05:  79%|▊| 10958/13852 [41:03<10:41,  4.51it/\u001b[A\n",
      "Training loss: 1.01e-01 lr: 1.04e-05:  79%|▊| 10959/13852 [41:04<10:42,  4.50it/\u001b[A\n",
      "Training loss: 7.19e-02 lr: 1.04e-05:  79%|▊| 10960/13852 [41:04<10:51,  4.44it/\u001b[A\n",
      "Training loss: 7.24e-02 lr: 1.04e-05:  79%|▊| 10961/13852 [41:04<10:47,  4.47it/\u001b[A\n",
      "Training loss: 5.30e-02 lr: 1.04e-05:  79%|▊| 10962/13852 [41:04<10:41,  4.50it/\u001b[A\n",
      "Training loss: 6.79e-02 lr: 1.04e-05:  79%|▊| 10963/13852 [41:04<10:42,  4.50it/\u001b[A\n",
      "Training loss: 8.58e-02 lr: 1.04e-05:  79%|▊| 10964/13852 [41:05<10:41,  4.50it/\u001b[A\n",
      "Training loss: 7.90e-02 lr: 1.04e-05:  79%|▊| 10965/13852 [41:05<10:39,  4.52it/\u001b[A\n",
      "Training loss: 7.06e-02 lr: 1.04e-05:  79%|▊| 10966/13852 [41:05<10:39,  4.51it/\u001b[A\n",
      "Training loss: 5.43e-02 lr: 1.04e-05:  79%|▊| 10967/13852 [41:05<10:42,  4.49it/\u001b[A\n",
      "Training loss: 5.88e-02 lr: 1.04e-05:  79%|▊| 10968/13852 [41:06<10:40,  4.50it/\u001b[A\n",
      "Training loss: 4.74e-02 lr: 1.04e-05:  79%|▊| 10969/13852 [41:06<10:41,  4.50it/\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.04e-05:  79%|▊| 10970/13852 [41:06<10:40,  4.50it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 1.04e-05:  79%|▊| 10971/13852 [41:06<10:39,  4.50it/\u001b[A\n",
      "Training loss: 4.61e-02 lr: 1.04e-05:  79%|▊| 10972/13852 [41:06<10:38,  4.51it/\u001b[A\n",
      "Training loss: 3.39e-02 lr: 1.04e-05:  79%|▊| 10973/13852 [41:07<10:39,  4.50it/\u001b[A\n",
      "Training loss: 3.68e-02 lr: 1.04e-05:  79%|▊| 10974/13852 [41:07<10:38,  4.51it/\u001b[A\n",
      "Training loss: 2.90e-02 lr: 1.04e-05:  79%|▊| 10975/13852 [41:07<10:39,  4.50it/\u001b[A\n",
      "Training loss: 2.38e-02 lr: 1.04e-05:  79%|▊| 10976/13852 [41:07<10:40,  4.49it/\u001b[A\n",
      "Training loss: 1.71e-02 lr: 1.04e-05:  79%|▊| 10977/13852 [41:08<10:42,  4.47it/\u001b[A\n",
      "Training loss: 1.28e-02 lr: 1.04e-05:  79%|▊| 10978/13852 [41:08<10:42,  4.47it/\u001b[A\n",
      "Training loss: 3.08e-02 lr: 1.04e-05:  79%|▊| 10979/13852 [41:08<10:40,  4.48it/\u001b[A\n",
      "Training loss: 9.59e-02 lr: 1.04e-05:  79%|▊| 10980/13852 [41:08<10:39,  4.49it/\u001b[A\n",
      "Training loss: 9.26e-02 lr: 1.04e-05:  79%|▊| 10981/13852 [41:08<10:39,  4.49it/\u001b[A\n",
      "Training loss: 6.74e-02 lr: 1.04e-05:  79%|▊| 10982/13852 [41:09<10:40,  4.48it/\u001b[A\n",
      "Training loss: 4.78e-02 lr: 1.04e-05:  79%|▊| 10983/13852 [41:09<10:39,  4.49it/\u001b[A\n",
      "Training loss: 3.63e-02 lr: 1.04e-05:  79%|▊| 10984/13852 [41:09<10:35,  4.51it/\u001b[A\n",
      "Training loss: 2.92e-02 lr: 1.03e-05:  79%|▊| 10985/13852 [41:09<10:31,  4.54it/\u001b[A\n",
      "Training loss: 5.75e-02 lr: 1.03e-05:  79%|▊| 10986/13852 [41:10<10:36,  4.50it/\u001b[A\n",
      "Training loss: 7.70e-02 lr: 1.03e-05:  79%|▊| 10987/13852 [41:10<10:35,  4.51it/\u001b[A\n",
      "Training loss: 5.95e-02 lr: 1.03e-05:  79%|▊| 10988/13852 [41:10<10:36,  4.50it/\u001b[A\n",
      "Training loss: 1.02e-01 lr: 1.03e-05:  79%|▊| 10989/13852 [41:10<10:34,  4.51it/\u001b[A\n",
      "Training loss: 9.47e-02 lr: 1.03e-05:  79%|▊| 10990/13852 [41:10<10:33,  4.52it/\u001b[A\n",
      "Training loss: 8.16e-02 lr: 1.03e-05:  79%|▊| 10991/13852 [41:11<10:33,  4.52it/\u001b[A\n",
      "Training loss: 6.94e-02 lr: 1.03e-05:  79%|▊| 10992/13852 [41:11<10:36,  4.49it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 1.03e-05:  79%|▊| 10993/13852 [41:11<10:37,  4.49it/\u001b[A\n",
      "Training loss: 3.87e-02 lr: 1.03e-05:  79%|▊| 10994/13852 [41:11<10:36,  4.49it/\u001b[A\n",
      "Training loss: 6.46e-02 lr: 1.03e-05:  79%|▊| 10995/13852 [41:12<10:37,  4.48it/\u001b[A\n",
      "Training loss: 5.89e-02 lr: 1.03e-05:  79%|▊| 10996/13852 [41:12<10:36,  4.49it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 1.03e-05:  79%|▊| 10997/13852 [41:12<10:32,  4.52it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 1.03e-05:  79%|▊| 10998/13852 [41:12<10:30,  4.53it/\u001b[A\n",
      "Training loss: 3.85e-02 lr: 1.03e-05:  79%|▊| 10999/13852 [41:12<10:29,  4.54it/\u001b[A\n",
      "Training loss: 5.94e-02 lr: 1.03e-05:  79%|▊| 11000/13852 [41:13<10:28,  4.54it/\u001b[A\n",
      "Training loss: 4.82e-02 lr: 1.03e-05:  79%|▊| 11001/13852 [41:13<10:29,  4.53it/\u001b[A\n",
      "Training loss: 5.85e-02 lr: 1.03e-05:  79%|▊| 11002/13852 [41:13<10:28,  4.53it/\u001b[A\n",
      "Training loss: 4.71e-02 lr: 1.03e-05:  79%|▊| 11003/13852 [41:13<10:29,  4.53it/\u001b[A\n",
      "Training loss: 1.67e-01 lr: 1.03e-05:  79%|▊| 11004/13852 [41:14<10:29,  4.52it/\u001b[A\n",
      "Training loss: 1.24e-01 lr: 1.03e-05:  79%|▊| 11005/13852 [41:14<10:30,  4.52it/\u001b[A\n",
      "Training loss: 9.05e-02 lr: 1.03e-05:  79%|▊| 11006/13852 [41:14<10:30,  4.52it/\u001b[A\n",
      "Training loss: 9.89e-02 lr: 1.03e-05:  79%|▊| 11007/13852 [41:14<10:30,  4.51it/\u001b[A\n",
      "Training loss: 7.29e-02 lr: 1.03e-05:  79%|▊| 11008/13852 [41:14<10:27,  4.53it/\u001b[A\n",
      "Training loss: 5.21e-02 lr: 1.03e-05:  79%|▊| 11009/13852 [41:15<10:24,  4.56it/\u001b[A\n",
      "Training loss: 4.57e-02 lr: 1.03e-05:  79%|▊| 11010/13852 [41:15<10:22,  4.56it/\u001b[A\n",
      "Training loss: 7.56e-02 lr: 1.03e-05:  79%|▊| 11011/13852 [41:15<10:28,  4.52it/\u001b[A\n",
      "Training loss: 9.60e-02 lr: 1.03e-05:  79%|▊| 11012/13852 [41:15<10:27,  4.52it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.02e-05:  80%|▊| 11013/13852 [41:16<10:26,  4.53it/\u001b[A\n",
      "Training loss: 9.47e-02 lr: 1.02e-05:  80%|▊| 11014/13852 [41:16<10:26,  4.53it/\u001b[A\n",
      "Training loss: 7.11e-02 lr: 1.02e-05:  80%|▊| 11015/13852 [41:16<10:27,  4.52it/\u001b[A\n",
      "Training loss: 7.61e-02 lr: 1.02e-05:  80%|▊| 11016/13852 [41:16<10:28,  4.51it/\u001b[A\n",
      "Training loss: 6.48e-02 lr: 1.02e-05:  80%|▊| 11017/13852 [41:16<10:27,  4.52it/\u001b[A\n",
      "Training loss: 5.62e-02 lr: 1.02e-05:  80%|▊| 11018/13852 [41:17<10:29,  4.51it/\u001b[A\n",
      "Training loss: 4.19e-02 lr: 1.02e-05:  80%|▊| 11019/13852 [41:17<10:32,  4.48it/\u001b[A\n",
      "Training loss: 3.08e-02 lr: 1.02e-05:  80%|▊| 11020/13852 [41:17<10:28,  4.51it/\u001b[A\n",
      "Training loss: 2.71e-02 lr: 1.02e-05:  80%|▊| 11021/13852 [41:17<10:24,  4.53it/\u001b[A\n",
      "Training loss: 4.10e-02 lr: 1.02e-05:  80%|▊| 11022/13852 [41:18<10:25,  4.53it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 1.02e-05:  80%|▊| 11023/13852 [41:18<10:22,  4.54it/\u001b[A\n",
      "Training loss: 3.36e-02 lr: 1.02e-05:  80%|▊| 11024/13852 [41:18<10:27,  4.51it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.02e-05:  80%|▊| 11025/13852 [41:18<10:26,  4.52it/\u001b[A\n",
      "Training loss: 3.26e-02 lr: 1.02e-05:  80%|▊| 11026/13852 [41:18<10:25,  4.52it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 1.02e-05:  80%|▊| 11027/13852 [41:19<10:25,  4.52it/\u001b[A\n",
      "Training loss: 4.55e-02 lr: 1.02e-05:  80%|▊| 11028/13852 [41:19<10:43,  4.39it/\u001b[A\n",
      "Training loss: 4.86e-02 lr: 1.02e-05:  80%|▊| 11029/13852 [41:19<10:37,  4.43it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 1.02e-05:  80%|▊| 11030/13852 [41:19<10:34,  4.45it/\u001b[A\n",
      "Training loss: 3.06e-02 lr: 1.02e-05:  80%|▊| 11031/13852 [41:20<10:31,  4.47it/\u001b[A\n",
      "Training loss: 3.37e-02 lr: 1.02e-05:  80%|▊| 11032/13852 [41:20<10:27,  4.49it/\u001b[A\n",
      "Training loss: 3.90e-02 lr: 1.02e-05:  80%|▊| 11033/13852 [41:20<10:23,  4.52it/\u001b[A\n",
      "Training loss: 3.20e-02 lr: 1.02e-05:  80%|▊| 11034/13852 [41:20<10:19,  4.55it/\u001b[A\n",
      "Training loss: 3.21e-02 lr: 1.02e-05:  80%|▊| 11035/13852 [41:20<10:23,  4.52it/\u001b[A\n",
      "Training loss: 4.48e-02 lr: 1.02e-05:  80%|▊| 11036/13852 [41:21<10:22,  4.52it/\u001b[A\n",
      "Training loss: 4.23e-02 lr: 1.02e-05:  80%|▊| 11037/13852 [41:21<10:32,  4.45it/\u001b[A\n",
      "Training loss: 4.69e-02 lr: 1.02e-05:  80%|▊| 11038/13852 [41:21<10:32,  4.45it/\u001b[A\n",
      "Training loss: 4.44e-02 lr: 1.02e-05:  80%|▊| 11039/13852 [41:21<10:30,  4.46it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 1.02e-05:  80%|▊| 11040/13852 [41:22<10:28,  4.47it/\u001b[A\n",
      "Training loss: 2.96e-02 lr: 1.01e-05:  80%|▊| 11041/13852 [41:22<10:33,  4.44it/\u001b[A\n",
      "Training loss: 2.91e-02 lr: 1.01e-05:  80%|▊| 11042/13852 [41:22<10:30,  4.46it/\u001b[A\n",
      "Training loss: 2.35e-02 lr: 1.01e-05:  80%|▊| 11043/13852 [41:22<10:28,  4.47it/\u001b[A\n",
      "Training loss: 2.74e-02 lr: 1.01e-05:  80%|▊| 11044/13852 [41:22<10:22,  4.51it/\u001b[A\n",
      "Training loss: 2.07e-02 lr: 1.01e-05:  80%|▊| 11045/13852 [41:23<10:19,  4.53it/\u001b[A\n",
      "Training loss: 4.39e-02 lr: 1.01e-05:  80%|▊| 11046/13852 [41:23<10:23,  4.50it/\u001b[A\n",
      "Training loss: 4.27e-02 lr: 1.01e-05:  80%|▊| 11047/13852 [41:23<10:22,  4.51it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 1.01e-05:  80%|▊| 11048/13852 [41:23<10:21,  4.51it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.99e-02 lr: 1.01e-05:  80%|▊| 11049/13852 [41:24<10:20,  4.52it/\u001b[A\n",
      "Training loss: 2.61e-02 lr: 1.01e-05:  80%|▊| 11050/13852 [41:24<10:21,  4.51it/\u001b[A\n",
      "Training loss: 2.40e-02 lr: 1.01e-05:  80%|▊| 11051/13852 [41:24<10:21,  4.51it/\u001b[A\n",
      "Training loss: 3.29e-02 lr: 1.01e-05:  80%|▊| 11052/13852 [41:24<10:22,  4.50it/\u001b[A\n",
      "Training loss: 4.35e-02 lr: 1.01e-05:  80%|▊| 11053/13852 [41:24<10:21,  4.51it/\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.01e-05:  80%|▊| 11054/13852 [41:25<10:21,  4.50it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.01e-05:  80%|▊| 11055/13852 [41:25<10:18,  4.52it/\u001b[A\n",
      "Training loss: 5.00e-02 lr: 1.01e-05:  80%|▊| 11056/13852 [41:25<10:15,  4.54it/\u001b[A\n",
      "Training loss: 6.31e-02 lr: 1.01e-05:  80%|▊| 11057/13852 [41:25<10:12,  4.56it/\u001b[A\n",
      "Training loss: 8.18e-02 lr: 1.01e-05:  80%|▊| 11058/13852 [41:26<10:10,  4.58it/\u001b[A\n",
      "Training loss: 5.79e-02 lr: 1.01e-05:  80%|▊| 11059/13852 [41:26<10:14,  4.55it/\u001b[A\n",
      "Training loss: 4.57e-02 lr: 1.01e-05:  80%|▊| 11060/13852 [41:26<10:14,  4.55it/\u001b[A\n",
      "Training loss: 4.51e-02 lr: 1.01e-05:  80%|▊| 11061/13852 [41:26<10:15,  4.53it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 1.01e-05:  80%|▊| 11062/13852 [41:26<10:16,  4.52it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 1.01e-05:  80%|▊| 11063/13852 [41:27<10:17,  4.52it/\u001b[A\n",
      "Training loss: 8.99e-02 lr: 1.01e-05:  80%|▊| 11064/13852 [41:27<10:21,  4.49it/\u001b[A\n",
      "Training loss: 6.53e-02 lr: 1.01e-05:  80%|▊| 11065/13852 [41:27<10:22,  4.48it/\u001b[A\n",
      "Training loss: 5.00e-02 lr: 1.01e-05:  80%|▊| 11066/13852 [41:27<10:21,  4.48it/\u001b[A\n",
      "Training loss: 3.89e-02 lr: 1.01e-05:  80%|▊| 11067/13852 [41:28<10:24,  4.46it/\u001b[A\n",
      "Training loss: 7.34e-02 lr: 1.00e-05:  80%|▊| 11068/13852 [41:28<10:20,  4.49it/\u001b[A\n",
      "Training loss: 5.96e-02 lr: 1.00e-05:  80%|▊| 11069/13852 [41:28<10:15,  4.52it/\u001b[A\n",
      "Training loss: 6.67e-02 lr: 1.00e-05:  80%|▊| 11070/13852 [41:28<10:11,  4.55it/\u001b[A\n",
      "Training loss: 7.01e-02 lr: 1.00e-05:  80%|▊| 11071/13852 [41:28<10:13,  4.53it/\u001b[A\n",
      "Training loss: 6.59e-02 lr: 1.00e-05:  80%|▊| 11072/13852 [41:29<10:13,  4.53it/\u001b[A\n",
      "Training loss: 7.87e-02 lr: 1.00e-05:  80%|▊| 11073/13852 [41:29<10:13,  4.53it/\u001b[A\n",
      "Training loss: 6.46e-02 lr: 1.00e-05:  80%|▊| 11074/13852 [41:29<10:13,  4.53it/\u001b[A\n",
      "Training loss: 5.02e-02 lr: 1.00e-05:  80%|▊| 11075/13852 [41:29<10:14,  4.52it/\u001b[A\n",
      "Training loss: 4.91e-02 lr: 1.00e-05:  80%|▊| 11076/13852 [41:30<10:14,  4.51it/\u001b[A\n",
      "Training loss: 5.36e-02 lr: 1.00e-05:  80%|▊| 11077/13852 [41:30<10:15,  4.51it/\u001b[A\n",
      "Training loss: 4.26e-02 lr: 1.00e-05:  80%|▊| 11078/13852 [41:30<10:15,  4.51it/\u001b[A\n",
      "Training loss: 3.20e-02 lr: 1.00e-05:  80%|▊| 11079/13852 [41:30<10:15,  4.51it/\u001b[A\n",
      "Training loss: 6.38e-02 lr: 1.00e-05:  80%|▊| 11080/13852 [41:30<10:12,  4.52it/\u001b[A\n",
      "Training loss: 4.84e-02 lr: 1.00e-05:  80%|▊| 11081/13852 [41:31<10:09,  4.55it/\u001b[A\n",
      "Training loss: 6.98e-02 lr: 1.00e-05:  80%|▊| 11082/13852 [41:31<10:11,  4.53it/\u001b[A\n",
      "Training loss: 5.15e-02 lr: 1.00e-05:  80%|▊| 11083/13852 [41:31<10:17,  4.48it/\u001b[A\n",
      "Training loss: 3.68e-02 lr: 9.99e-06:  80%|▊| 11084/13852 [41:31<10:16,  4.49it/\u001b[A\n",
      "Training loss: 9.65e-02 lr: 9.99e-06:  80%|▊| 11085/13852 [41:32<10:15,  4.49it/\u001b[A\n",
      "Training loss: 1.04e-01 lr: 9.98e-06:  80%|▊| 11086/13852 [41:32<10:19,  4.47it/\u001b[A\n",
      "Training loss: 7.39e-02 lr: 9.98e-06:  80%|▊| 11087/13852 [41:32<10:17,  4.48it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 9.98e-06:  80%|▊| 11088/13852 [41:32<10:16,  4.49it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 9.97e-06:  80%|▊| 11089/13852 [41:32<10:17,  4.48it/\u001b[A\n",
      "Training loss: 3.93e-02 lr: 9.97e-06:  80%|▊| 11090/13852 [41:33<10:17,  4.47it/\u001b[A\n",
      "Training loss: 3.18e-02 lr: 9.97e-06:  80%|▊| 11091/13852 [41:33<10:16,  4.48it/\u001b[A\n",
      "Training loss: 2.47e-02 lr: 9.96e-06:  80%|▊| 11092/13852 [41:33<10:14,  4.49it/\u001b[A\n",
      "Training loss: 2.26e-02 lr: 9.96e-06:  80%|▊| 11093/13852 [41:33<10:10,  4.52it/\u001b[A\n",
      "Training loss: 2.98e-02 lr: 9.96e-06:  80%|▊| 11094/13852 [41:34<10:06,  4.55it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 9.95e-06:  80%|▊| 11095/13852 [41:34<10:08,  4.53it/\u001b[A\n",
      "Training loss: 5.36e-02 lr: 9.95e-06:  80%|▊| 11096/13852 [41:34<10:08,  4.53it/\u001b[A\n",
      "Training loss: 8.73e-02 lr: 9.95e-06:  80%|▊| 11097/13852 [41:34<10:08,  4.53it/\u001b[A\n",
      "Training loss: 7.61e-02 lr: 9.94e-06:  80%|▊| 11098/13852 [41:34<10:08,  4.53it/\u001b[A\n",
      "Training loss: 7.11e-02 lr: 9.94e-06:  80%|▊| 11099/13852 [41:35<10:08,  4.52it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 9.93e-06:  80%|▊| 11100/13852 [41:35<10:10,  4.51it/\u001b[A\n",
      "Training loss: 6.32e-02 lr: 9.93e-06:  80%|▊| 11101/13852 [41:35<10:10,  4.51it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 9.93e-06:  80%|▊| 11102/13852 [41:35<10:10,  4.50it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 9.92e-06:  80%|▊| 11103/13852 [41:36<10:11,  4.50it/\u001b[A\n",
      "Training loss: 2.85e-02 lr: 9.92e-06:  80%|▊| 11104/13852 [41:36<10:07,  4.52it/\u001b[A\n",
      "Training loss: 2.74e-02 lr: 9.92e-06:  80%|▊| 11105/13852 [41:36<10:03,  4.55it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 9.91e-06:  80%|▊| 11106/13852 [41:36<10:01,  4.56it/\u001b[A\n",
      "Training loss: 5.28e-02 lr: 9.91e-06:  80%|▊| 11107/13852 [41:36<10:07,  4.52it/\u001b[A\n",
      "Training loss: 5.96e-02 lr: 9.91e-06:  80%|▊| 11108/13852 [41:37<10:07,  4.52it/\u001b[A\n",
      "Training loss: 4.91e-02 lr: 9.90e-06:  80%|▊| 11109/13852 [41:37<10:11,  4.48it/\u001b[A\n",
      "Training loss: 8.77e-02 lr: 9.90e-06:  80%|▊| 11110/13852 [41:37<10:14,  4.46it/\u001b[A\n",
      "Training loss: 7.67e-02 lr: 9.89e-06:  80%|▊| 11111/13852 [41:37<10:17,  4.44it/\u001b[A\n",
      "Training loss: 6.74e-02 lr: 9.89e-06:  80%|▊| 11112/13852 [41:38<10:17,  4.44it/\u001b[A\n",
      "Training loss: 5.55e-02 lr: 9.89e-06:  80%|▊| 11113/13852 [41:38<10:15,  4.45it/\u001b[A\n",
      "Training loss: 4.05e-02 lr: 9.88e-06:  80%|▊| 11114/13852 [41:38<10:14,  4.46it/\u001b[A\n",
      "Training loss: 3.21e-02 lr: 9.88e-06:  80%|▊| 11115/13852 [41:38<10:09,  4.49it/\u001b[A\n",
      "Training loss: 2.47e-02 lr: 9.88e-06:  80%|▊| 11116/13852 [41:38<10:04,  4.53it/\u001b[A\n",
      "Training loss: 2.86e-02 lr: 9.87e-06:  80%|▊| 11117/13852 [41:39<10:00,  4.55it/\u001b[A\n",
      "Training loss: 2.38e-02 lr: 9.87e-06:  80%|▊| 11118/13852 [41:39<10:07,  4.50it/\u001b[A\n",
      "Training loss: 2.40e-02 lr: 9.87e-06:  80%|▊| 11119/13852 [41:39<10:05,  4.51it/\u001b[A\n",
      "Training loss: 2.99e-02 lr: 9.86e-06:  80%|▊| 11120/13852 [41:39<10:04,  4.52it/\u001b[A\n",
      "Training loss: 3.05e-02 lr: 9.86e-06:  80%|▊| 11121/13852 [41:40<10:04,  4.51it/\u001b[A\n",
      "Training loss: 2.39e-02 lr: 9.85e-06:  80%|▊| 11122/13852 [41:40<10:04,  4.52it/\u001b[A\n",
      "Training loss: 4.86e-02 lr: 9.85e-06:  80%|▊| 11123/13852 [41:40<10:04,  4.51it/\u001b[A\n",
      "Training loss: 3.56e-02 lr: 9.85e-06:  80%|▊| 11124/13852 [41:40<10:04,  4.51it/\u001b[A\n",
      "Training loss: 2.81e-02 lr: 9.84e-06:  80%|▊| 11125/13852 [41:40<10:04,  4.51it/\u001b[A\n",
      "Training loss: 3.87e-02 lr: 9.84e-06:  80%|▊| 11126/13852 [41:41<10:04,  4.51it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 9.84e-06:  80%|▊| 11127/13852 [41:41<10:10,  4.47it/\u001b[A\n",
      "Training loss: 4.74e-02 lr: 9.83e-06:  80%|▊| 11128/13852 [41:41<10:06,  4.49it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 9.83e-06:  80%|▊| 11129/13852 [41:41<10:01,  4.52it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 9.83e-06:  80%|▊| 11130/13852 [41:41<09:58,  4.55it/\u001b[A\n",
      "Training loss: 5.51e-02 lr: 9.82e-06:  80%|▊| 11131/13852 [41:42<10:01,  4.52it/\u001b[A\n",
      "Training loss: 5.60e-02 lr: 9.82e-06:  80%|▊| 11132/13852 [41:42<10:01,  4.52it/\u001b[A\n",
      "Training loss: 4.92e-02 lr: 9.82e-06:  80%|▊| 11133/13852 [41:42<10:01,  4.52it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 9.81e-06:  80%|▊| 11134/13852 [41:42<10:00,  4.53it/\u001b[A\n",
      "Training loss: 7.46e-02 lr: 9.81e-06:  80%|▊| 11135/13852 [41:43<10:00,  4.52it/\u001b[A\n",
      "Training loss: 9.61e-02 lr: 9.80e-06:  80%|▊| 11136/13852 [41:43<10:01,  4.52it/\u001b[A\n",
      "Training loss: 7.06e-02 lr: 9.80e-06:  80%|▊| 11137/13852 [41:43<10:02,  4.51it/\u001b[A\n",
      "Training loss: 5.72e-02 lr: 9.80e-06:  80%|▊| 11138/13852 [41:43<10:02,  4.51it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 9.79e-06:  80%|▊| 11139/13852 [41:43<10:01,  4.51it/\u001b[A\n",
      "Training loss: 4.10e-02 lr: 9.79e-06:  80%|▊| 11140/13852 [41:44<10:00,  4.52it/\u001b[A\n",
      "Training loss: 7.49e-02 lr: 9.79e-06:  80%|▊| 11141/13852 [41:44<09:56,  4.54it/\u001b[A\n",
      "Training loss: 1.04e-01 lr: 9.78e-06:  80%|▊| 11142/13852 [41:44<09:54,  4.56it/\u001b[A\n",
      "Training loss: 1.17e-01 lr: 9.78e-06:  80%|▊| 11143/13852 [41:44<09:59,  4.52it/\u001b[A\n",
      "Training loss: 1.22e-01 lr: 9.78e-06:  80%|▊| 11144/13852 [41:45<09:58,  4.52it/\u001b[A\n",
      "Training loss: 1.27e-01 lr: 9.77e-06:  80%|▊| 11145/13852 [41:45<09:57,  4.53it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.26e-01 lr: 9.77e-06:  80%|▊| 11146/13852 [41:45<09:59,  4.52it/\u001b[A\n",
      "Training loss: 1.55e-01 lr: 9.76e-06:  80%|▊| 11147/13852 [41:45<09:58,  4.52it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 9.76e-06:  80%|▊| 11148/13852 [41:45<09:58,  4.52it/\u001b[A\n",
      "Training loss: 8.76e-02 lr: 9.76e-06:  80%|▊| 11149/13852 [41:46<09:58,  4.52it/\u001b[A\n",
      "Training loss: 7.78e-02 lr: 9.75e-06:  80%|▊| 11150/13852 [41:46<09:58,  4.52it/\u001b[A\n",
      "Training loss: 1.09e-01 lr: 9.75e-06:  81%|▊| 11151/13852 [41:46<09:58,  4.51it/\u001b[A\n",
      "Training loss: 8.48e-02 lr: 9.75e-06:  81%|▊| 11152/13852 [41:46<09:59,  4.51it/\u001b[A\n",
      "Training loss: 6.24e-02 lr: 9.74e-06:  81%|▊| 11153/13852 [41:47<09:54,  4.54it/\u001b[A\n",
      "Training loss: 4.78e-02 lr: 9.74e-06:  81%|▊| 11154/13852 [41:47<09:55,  4.53it/\u001b[A\n",
      "Training loss: 1.04e-01 lr: 9.74e-06:  81%|▊| 11155/13852 [41:47<09:52,  4.55it/\u001b[A\n",
      "Training loss: 8.79e-02 lr: 9.73e-06:  81%|▊| 11156/13852 [41:47<09:54,  4.54it/\u001b[A\n",
      "Training loss: 8.63e-02 lr: 9.73e-06:  81%|▊| 11157/13852 [41:47<09:54,  4.53it/\u001b[A\n",
      "Training loss: 6.21e-02 lr: 9.72e-06:  81%|▊| 11158/13852 [41:48<09:58,  4.50it/\u001b[A\n",
      "Training loss: 6.11e-02 lr: 9.72e-06:  81%|▊| 11159/13852 [41:48<09:57,  4.51it/\u001b[A\n",
      "Training loss: 4.52e-02 lr: 9.72e-06:  81%|▊| 11160/13852 [41:48<09:58,  4.50it/\u001b[A\n",
      "Training loss: 3.58e-02 lr: 9.71e-06:  81%|▊| 11161/13852 [41:48<09:57,  4.51it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 9.71e-06:  81%|▊| 11162/13852 [41:49<09:56,  4.51it/\u001b[A\n",
      "Training loss: 6.87e-02 lr: 9.71e-06:  81%|▊| 11163/13852 [41:49<09:56,  4.51it/\u001b[A\n",
      "Training loss: 5.57e-02 lr: 9.70e-06:  81%|▊| 11164/13852 [41:49<09:57,  4.50it/\u001b[A\n",
      "Training loss: 8.00e-02 lr: 9.70e-06:  81%|▊| 11165/13852 [41:49<09:57,  4.50it/\u001b[A\n",
      "Training loss: 8.31e-02 lr: 9.70e-06:  81%|▊| 11166/13852 [41:49<09:53,  4.52it/\u001b[A\n",
      "Training loss: 7.79e-02 lr: 9.69e-06:  81%|▊| 11167/13852 [41:50<09:50,  4.55it/\u001b[A\n",
      "Training loss: 6.78e-02 lr: 9.69e-06:  81%|▊| 11168/13852 [41:50<09:53,  4.52it/\u001b[A\n",
      "Training loss: 6.31e-02 lr: 9.69e-06:  81%|▊| 11169/13852 [41:50<09:53,  4.52it/\u001b[A\n",
      "Training loss: 7.23e-02 lr: 9.68e-06:  81%|▊| 11170/13852 [41:50<09:52,  4.52it/\u001b[A\n",
      "Training loss: 7.48e-02 lr: 9.68e-06:  81%|▊| 11171/13852 [41:51<09:51,  4.53it/\u001b[A\n",
      "Training loss: 5.43e-02 lr: 9.67e-06:  81%|▊| 11172/13852 [41:51<09:55,  4.50it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 9.67e-06:  81%|▊| 11173/13852 [41:51<09:54,  4.50it/\u001b[A\n",
      "Training loss: 4.60e-02 lr: 9.67e-06:  81%|▊| 11174/13852 [41:51<09:55,  4.50it/\u001b[A\n",
      "Training loss: 3.83e-02 lr: 9.66e-06:  81%|▊| 11175/13852 [41:51<09:54,  4.50it/\u001b[A\n",
      "Training loss: 6.03e-02 lr: 9.66e-06:  81%|▊| 11176/13852 [41:52<09:55,  4.49it/\u001b[A\n",
      "Training loss: 7.50e-02 lr: 9.66e-06:  81%|▊| 11177/13852 [41:52<09:53,  4.51it/\u001b[A\n",
      "Training loss: 5.79e-02 lr: 9.65e-06:  81%|▊| 11178/13852 [41:52<09:50,  4.53it/\u001b[A\n",
      "Training loss: 4.16e-02 lr: 9.65e-06:  81%|▊| 11179/13852 [41:52<09:47,  4.55it/\u001b[A\n",
      "Training loss: 3.53e-02 lr: 9.65e-06:  81%|▊| 11180/13852 [41:53<09:52,  4.51it/\u001b[A\n",
      "Training loss: 4.17e-02 lr: 9.64e-06:  81%|▊| 11181/13852 [41:53<09:52,  4.51it/\u001b[A\n",
      "Training loss: 3.23e-02 lr: 9.64e-06:  81%|▊| 11182/13852 [41:53<09:50,  4.52it/\u001b[A\n",
      "Training loss: 3.81e-02 lr: 9.63e-06:  81%|▊| 11183/13852 [41:53<09:50,  4.52it/\u001b[A\n",
      "Training loss: 3.63e-02 lr: 9.63e-06:  81%|▊| 11184/13852 [41:53<09:50,  4.52it/\u001b[A\n",
      "Training loss: 5.40e-02 lr: 9.63e-06:  81%|▊| 11185/13852 [41:54<09:50,  4.52it/\u001b[A\n",
      "Training loss: 6.32e-02 lr: 9.62e-06:  81%|▊| 11186/13852 [41:54<09:50,  4.51it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 9.62e-06:  81%|▊| 11187/13852 [41:54<09:51,  4.51it/\u001b[A\n",
      "Training loss: 5.32e-02 lr: 9.62e-06:  81%|▊| 11188/13852 [41:54<09:50,  4.51it/\u001b[A\n",
      "Training loss: 8.05e-02 lr: 9.61e-06:  81%|▊| 11189/13852 [41:55<09:48,  4.52it/\u001b[A\n",
      "Training loss: 5.84e-02 lr: 9.61e-06:  81%|▊| 11190/13852 [41:55<09:45,  4.55it/\u001b[A\n",
      "Training loss: 7.27e-02 lr: 9.61e-06:  81%|▊| 11191/13852 [41:55<09:42,  4.56it/\u001b[A\n",
      "Training loss: 6.37e-02 lr: 9.60e-06:  81%|▊| 11192/13852 [41:55<09:41,  4.57it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 9.60e-06:  81%|▊| 11193/13852 [41:55<09:39,  4.59it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 9.59e-06:  81%|▊| 11194/13852 [41:56<09:43,  4.55it/\u001b[A\n",
      "Training loss: 4.54e-02 lr: 9.59e-06:  81%|▊| 11195/13852 [41:56<09:44,  4.55it/\u001b[A\n",
      "Training loss: 3.62e-02 lr: 9.59e-06:  81%|▊| 11196/13852 [41:56<09:46,  4.53it/\u001b[A\n",
      "Training loss: 3.11e-02 lr: 9.58e-06:  81%|▊| 11197/13852 [41:56<09:46,  4.52it/\u001b[A\n",
      "Training loss: 2.45e-02 lr: 9.58e-06:  81%|▊| 11198/13852 [41:57<09:47,  4.52it/\u001b[A\n",
      "Training loss: 4.77e-02 lr: 9.58e-06:  81%|▊| 11199/13852 [41:57<09:51,  4.49it/\u001b[A\n",
      "Training loss: 3.71e-02 lr: 9.57e-06:  81%|▊| 11200/13852 [41:57<09:50,  4.49it/\u001b[A\n",
      "Training loss: 6.36e-02 lr: 9.57e-06:  81%|▊| 11201/13852 [41:57<09:50,  4.49it/\u001b[A\n",
      "Training loss: 6.86e-02 lr: 9.57e-06:  81%|▊| 11202/13852 [41:57<09:49,  4.49it/\u001b[A\n",
      "Training loss: 5.05e-02 lr: 9.56e-06:  81%|▊| 11203/13852 [41:58<09:46,  4.52it/\u001b[A\n",
      "Training loss: 4.98e-02 lr: 9.56e-06:  81%|▊| 11204/13852 [41:58<09:43,  4.54it/\u001b[A\n",
      "Training loss: 3.62e-02 lr: 9.56e-06:  81%|▊| 11205/13852 [41:58<09:41,  4.55it/\u001b[A\n",
      "Training loss: 4.82e-02 lr: 9.55e-06:  81%|▊| 11206/13852 [41:58<09:44,  4.53it/\u001b[A\n",
      "Training loss: 3.82e-02 lr: 9.55e-06:  81%|▊| 11207/13852 [41:59<09:43,  4.53it/\u001b[A\n",
      "Training loss: 1.06e-01 lr: 9.54e-06:  81%|▊| 11208/13852 [41:59<09:43,  4.53it/\u001b[A\n",
      "Training loss: 8.30e-02 lr: 9.54e-06:  81%|▊| 11209/13852 [41:59<09:43,  4.53it/\u001b[A\n",
      "Training loss: 7.36e-02 lr: 9.54e-06:  81%|▊| 11210/13852 [41:59<09:44,  4.52it/\u001b[A\n",
      "Training loss: 5.94e-02 lr: 9.53e-06:  81%|▊| 11211/13852 [41:59<09:44,  4.52it/\u001b[A\n",
      "Training loss: 5.73e-02 lr: 9.53e-06:  81%|▊| 11212/13852 [42:00<09:45,  4.51it/\u001b[A\n",
      "Training loss: 5.39e-02 lr: 9.53e-06:  81%|▊| 11213/13852 [42:00<09:44,  4.51it/\u001b[A\n",
      "Training loss: 3.95e-02 lr: 9.52e-06:  81%|▊| 11214/13852 [42:00<09:45,  4.51it/\u001b[A\n",
      "Training loss: 6.48e-02 lr: 9.52e-06:  81%|▊| 11215/13852 [42:00<09:44,  4.51it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 9.52e-06:  81%|▊| 11216/13852 [42:01<09:40,  4.54it/\u001b[A\n",
      "Training loss: 5.85e-02 lr: 9.51e-06:  81%|▊| 11217/13852 [42:01<09:41,  4.53it/\u001b[A\n",
      "Training loss: 4.47e-02 lr: 9.51e-06:  81%|▊| 11218/13852 [42:01<09:47,  4.48it/\u001b[A\n",
      "Training loss: 3.34e-02 lr: 9.50e-06:  81%|▊| 11219/13852 [42:01<09:46,  4.49it/\u001b[A\n",
      "Training loss: 3.00e-02 lr: 9.50e-06:  81%|▊| 11220/13852 [42:01<10:04,  4.35it/\u001b[A\n",
      "Training loss: 4.65e-02 lr: 9.50e-06:  81%|▊| 11221/13852 [42:02<10:18,  4.25it/\u001b[A\n",
      "Training loss: 5.75e-02 lr: 9.49e-06:  81%|▊| 11222/13852 [42:02<10:11,  4.30it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 9.49e-06:  81%|▊| 11223/13852 [42:02<10:08,  4.32it/\u001b[A\n",
      "Training loss: 3.25e-02 lr: 9.49e-06:  81%|▊| 11224/13852 [42:02<10:02,  4.36it/\u001b[A\n",
      "Training loss: 3.41e-02 lr: 9.48e-06:  81%|▊| 11225/13852 [42:03<10:12,  4.29it/\u001b[A\n",
      "Training loss: 4.94e-02 lr: 9.48e-06:  81%|▊| 11226/13852 [42:03<10:20,  4.23it/\u001b[A\n",
      "Training loss: 3.91e-02 lr: 9.48e-06:  81%|▊| 11227/13852 [42:03<10:24,  4.20it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 9.47e-06:  81%|▊| 11228/13852 [42:03<10:13,  4.27it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 9.47e-06:  81%|▊| 11229/13852 [42:04<10:04,  4.34it/\u001b[A\n",
      "Training loss: 1.12e-01 lr: 9.47e-06:  81%|▊| 11230/13852 [42:04<10:00,  4.37it/\u001b[A\n",
      "Training loss: 7.93e-02 lr: 9.46e-06:  81%|▊| 11231/13852 [42:04<09:54,  4.41it/\u001b[A\n",
      "Training loss: 6.13e-02 lr: 9.46e-06:  81%|▊| 11232/13852 [42:04<09:47,  4.46it/\u001b[A\n",
      "Training loss: 1.00e-01 lr: 9.45e-06:  81%|▊| 11233/13852 [42:04<09:42,  4.50it/\u001b[A\n",
      "Training loss: 7.78e-02 lr: 9.45e-06:  81%|▊| 11234/13852 [42:05<09:47,  4.46it/\u001b[A\n",
      "Training loss: 8.20e-02 lr: 9.45e-06:  81%|▊| 11235/13852 [42:05<09:44,  4.48it/\u001b[A\n",
      "Training loss: 1.12e-01 lr: 9.44e-06:  81%|▊| 11236/13852 [42:05<09:42,  4.49it/\u001b[A\n",
      "Training loss: 8.86e-02 lr: 9.44e-06:  81%|▊| 11237/13852 [42:05<09:42,  4.49it/\u001b[A\n",
      "Training loss: 6.68e-02 lr: 9.44e-06:  81%|▊| 11238/13852 [42:06<09:44,  4.48it/\u001b[A\n",
      "Training loss: 6.62e-02 lr: 9.43e-06:  81%|▊| 11239/13852 [42:06<09:43,  4.48it/\u001b[A\n",
      "Training loss: 5.89e-02 lr: 9.43e-06:  81%|▊| 11240/13852 [42:06<09:52,  4.41it/\u001b[A\n",
      "Training loss: 1.50e-01 lr: 9.43e-06:  81%|▊| 11241/13852 [42:06<10:05,  4.31it/\u001b[A\n",
      "Training loss: 1.23e-01 lr: 9.42e-06:  81%|▊| 11242/13852 [42:06<10:14,  4.25it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.29e-02 lr: 9.42e-06:  81%|▊| 11243/13852 [42:07<10:07,  4.29it/\u001b[A\n",
      "Training loss: 7.36e-02 lr: 9.41e-06:  81%|▊| 11244/13852 [42:07<10:05,  4.31it/\u001b[A\n",
      "Training loss: 7.66e-02 lr: 9.41e-06:  81%|▊| 11245/13852 [42:07<10:01,  4.33it/\u001b[A\n",
      "Training loss: 9.77e-02 lr: 9.41e-06:  81%|▊| 11246/13852 [42:07<10:00,  4.34it/\u001b[A\n",
      "Training loss: 7.31e-02 lr: 9.40e-06:  81%|▊| 11247/13852 [42:08<10:12,  4.25it/\u001b[A\n",
      "Training loss: 6.41e-02 lr: 9.40e-06:  81%|▊| 11248/13852 [42:08<10:20,  4.20it/\u001b[A\n",
      "Training loss: 6.02e-02 lr: 9.40e-06:  81%|▊| 11249/13852 [42:08<10:20,  4.20it/\u001b[A\n",
      "Training loss: 1.06e-01 lr: 9.39e-06:  81%|▊| 11250/13852 [42:08<10:11,  4.25it/\u001b[A\n",
      "Training loss: 8.43e-02 lr: 9.39e-06:  81%|▊| 11251/13852 [42:09<10:03,  4.31it/\u001b[A\n",
      "Training loss: 7.47e-02 lr: 9.39e-06:  81%|▊| 11252/13852 [42:09<10:01,  4.32it/\u001b[A\n",
      "Training loss: 1.05e-01 lr: 9.38e-06:  81%|▊| 11253/13852 [42:09<10:01,  4.32it/\u001b[A\n",
      "Training loss: 8.48e-02 lr: 9.38e-06:  81%|▊| 11254/13852 [42:09<10:03,  4.31it/\u001b[A\n",
      "Training loss: 6.07e-02 lr: 9.37e-06:  81%|▊| 11255/13852 [42:10<10:02,  4.31it/\u001b[A\n",
      "Training loss: 5.63e-02 lr: 9.37e-06:  81%|▊| 11256/13852 [42:10<09:54,  4.37it/\u001b[A\n",
      "Training loss: 4.88e-02 lr: 9.37e-06:  81%|▊| 11257/13852 [42:10<09:47,  4.42it/\u001b[A\n",
      "Training loss: 5.02e-02 lr: 9.36e-06:  81%|▊| 11258/13852 [42:10<09:44,  4.44it/\u001b[A\n",
      "Training loss: 3.85e-02 lr: 9.36e-06:  81%|▊| 11259/13852 [42:10<09:42,  4.45it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 9.36e-06:  81%|▊| 11260/13852 [42:11<09:40,  4.46it/\u001b[A\n",
      "Training loss: 2.40e-02 lr: 9.35e-06:  81%|▊| 11261/13852 [42:11<09:43,  4.44it/\u001b[A\n",
      "Training loss: 3.39e-02 lr: 9.35e-06:  81%|▊| 11262/13852 [42:11<09:43,  4.44it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 9.35e-06:  81%|▊| 11263/13852 [42:11<09:42,  4.45it/\u001b[A\n",
      "Training loss: 5.52e-02 lr: 9.34e-06:  81%|▊| 11264/13852 [42:12<09:43,  4.44it/\u001b[A\n",
      "Training loss: 6.97e-02 lr: 9.34e-06:  81%|▊| 11265/13852 [42:12<09:45,  4.42it/\u001b[A\n",
      "Training loss: 5.84e-02 lr: 9.34e-06:  81%|▊| 11266/13852 [42:12<10:00,  4.30it/\u001b[A\n",
      "Training loss: 5.62e-02 lr: 9.33e-06:  81%|▊| 11267/13852 [42:12<10:08,  4.25it/\u001b[A\n",
      "Training loss: 6.31e-02 lr: 9.33e-06:  81%|▊| 11268/13852 [42:12<09:59,  4.31it/\u001b[A\n",
      "Training loss: 7.18e-02 lr: 9.32e-06:  81%|▊| 11269/13852 [42:13<09:50,  4.38it/\u001b[A\n",
      "Training loss: 5.95e-02 lr: 9.32e-06:  81%|▊| 11270/13852 [42:13<09:45,  4.41it/\u001b[A\n",
      "Training loss: 4.46e-02 lr: 9.32e-06:  81%|▊| 11271/13852 [42:13<09:40,  4.44it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 9.31e-06:  81%|▊| 11272/13852 [42:13<09:37,  4.46it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 9.31e-06:  81%|▊| 11273/13852 [42:14<09:37,  4.47it/\u001b[A\n",
      "Training loss: 2.89e-02 lr: 9.31e-06:  81%|▊| 11274/13852 [42:14<09:38,  4.46it/\u001b[A\n",
      "Training loss: 2.28e-02 lr: 9.30e-06:  81%|▊| 11275/13852 [42:14<09:36,  4.47it/\u001b[A\n",
      "Training loss: 2.56e-02 lr: 9.30e-06:  81%|▊| 11276/13852 [42:14<09:31,  4.51it/\u001b[A\n",
      "Training loss: 2.18e-02 lr: 9.30e-06:  81%|▊| 11277/13852 [42:14<09:27,  4.53it/\u001b[A\n",
      "Training loss: 7.06e-02 lr: 9.29e-06:  81%|▊| 11278/13852 [42:15<09:30,  4.51it/\u001b[A\n",
      "Training loss: 5.48e-02 lr: 9.29e-06:  81%|▊| 11279/13852 [42:15<09:29,  4.52it/\u001b[A\n",
      "Training loss: 4.41e-02 lr: 9.28e-06:  81%|▊| 11280/13852 [42:15<09:28,  4.52it/\u001b[A\n",
      "Training loss: 5.37e-02 lr: 9.28e-06:  81%|▊| 11281/13852 [42:15<09:26,  4.54it/\u001b[A\n",
      "Training loss: 1.27e-01 lr: 9.28e-06:  81%|▊| 11282/13852 [42:16<09:31,  4.50it/\u001b[A\n",
      "Training loss: 9.22e-02 lr: 9.27e-06:  81%|▊| 11283/13852 [42:16<09:29,  4.51it/\u001b[A\n",
      "Training loss: 6.80e-02 lr: 9.27e-06:  81%|▊| 11284/13852 [42:16<09:28,  4.51it/\u001b[A\n",
      "Training loss: 8.08e-02 lr: 9.27e-06:  81%|▊| 11285/13852 [42:16<09:29,  4.51it/\u001b[A\n",
      "Training loss: 5.83e-02 lr: 9.26e-06:  81%|▊| 11286/13852 [42:16<09:29,  4.50it/\u001b[A\n",
      "Training loss: 4.93e-02 lr: 9.26e-06:  81%|▊| 11287/13852 [42:17<09:32,  4.48it/\u001b[A\n",
      "Training loss: 4.94e-02 lr: 9.26e-06:  81%|▊| 11288/13852 [42:17<09:31,  4.49it/\u001b[A\n",
      "Training loss: 7.12e-02 lr: 9.25e-06:  81%|▊| 11289/13852 [42:17<09:26,  4.52it/\u001b[A\n",
      "Training loss: 5.12e-02 lr: 9.25e-06:  82%|▊| 11290/13852 [42:17<09:33,  4.47it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 9.24e-06:  82%|▊| 11291/13852 [42:18<09:31,  4.48it/\u001b[A\n",
      "Training loss: 7.58e-02 lr: 9.24e-06:  82%|▊| 11292/13852 [42:18<09:30,  4.49it/\u001b[A\n",
      "Training loss: 5.50e-02 lr: 9.24e-06:  82%|▊| 11293/13852 [42:18<09:31,  4.48it/\u001b[A\n",
      "Training loss: 8.15e-02 lr: 9.23e-06:  82%|▊| 11294/13852 [42:18<09:29,  4.49it/\u001b[A\n",
      "Training loss: 6.96e-02 lr: 9.23e-06:  82%|▊| 11295/13852 [42:18<09:29,  4.49it/\u001b[A\n",
      "Training loss: 5.03e-02 lr: 9.23e-06:  82%|▊| 11296/13852 [42:19<09:28,  4.49it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 9.22e-06:  82%|▊| 11297/13852 [42:19<09:28,  4.50it/\u001b[A\n",
      "Training loss: 3.20e-02 lr: 9.22e-06:  82%|▊| 11298/13852 [42:19<09:29,  4.48it/\u001b[A\n",
      "Training loss: 6.77e-02 lr: 9.22e-06:  82%|▊| 11299/13852 [42:19<09:25,  4.52it/\u001b[A\n",
      "Training loss: 6.37e-02 lr: 9.21e-06:  82%|▊| 11300/13852 [42:20<09:22,  4.54it/\u001b[A\n",
      "Training loss: 5.30e-02 lr: 9.21e-06:  82%|▊| 11301/13852 [42:20<09:25,  4.51it/\u001b[A\n",
      "Training loss: 4.73e-02 lr: 9.21e-06:  82%|▊| 11302/13852 [42:20<09:25,  4.51it/\u001b[A\n",
      "Training loss: 5.70e-02 lr: 9.20e-06:  82%|▊| 11303/13852 [42:20<09:25,  4.51it/\u001b[A\n",
      "Training loss: 4.96e-02 lr: 9.20e-06:  82%|▊| 11304/13852 [42:20<09:24,  4.51it/\u001b[A\n",
      "Training loss: 4.23e-02 lr: 9.19e-06:  82%|▊| 11305/13852 [42:21<09:23,  4.52it/\u001b[A\n",
      "Training loss: 3.74e-02 lr: 9.19e-06:  82%|▊| 11306/13852 [42:21<09:29,  4.47it/\u001b[A\n",
      "Training loss: 2.92e-02 lr: 9.19e-06:  82%|▊| 11307/13852 [42:21<09:30,  4.46it/\u001b[A\n",
      "Training loss: 2.27e-02 lr: 9.18e-06:  82%|▊| 11308/13852 [42:21<09:28,  4.47it/\u001b[A\n",
      "Training loss: 1.89e-02 lr: 9.18e-06:  82%|▊| 11309/13852 [42:22<09:27,  4.48it/\u001b[A\n",
      "Training loss: 1.52e-02 lr: 9.18e-06:  82%|▊| 11310/13852 [42:22<09:29,  4.46it/\u001b[A\n",
      "Training loss: 3.17e-02 lr: 9.17e-06:  82%|▊| 11311/13852 [42:22<09:25,  4.50it/\u001b[A\n",
      "Training loss: 3.32e-02 lr: 9.17e-06:  82%|▊| 11312/13852 [42:22<09:23,  4.51it/\u001b[A\n",
      "Training loss: 2.61e-02 lr: 9.17e-06:  82%|▊| 11313/13852 [42:22<09:25,  4.49it/\u001b[A\n",
      "Training loss: 2.63e-02 lr: 9.16e-06:  82%|▊| 11314/13852 [42:23<09:24,  4.50it/\u001b[A\n",
      "Training loss: 2.01e-02 lr: 9.16e-06:  82%|▊| 11315/13852 [42:23<09:26,  4.48it/\u001b[A\n",
      "Training loss: 2.49e-02 lr: 9.15e-06:  82%|▊| 11316/13852 [42:23<09:23,  4.50it/\u001b[A\n",
      "Training loss: 1.94e-02 lr: 9.15e-06:  82%|▊| 11317/13852 [42:23<09:22,  4.50it/\u001b[A\n",
      "Training loss: 2.84e-02 lr: 9.15e-06:  82%|▊| 11318/13852 [42:24<09:21,  4.51it/\u001b[A\n",
      "Training loss: 6.39e-02 lr: 9.14e-06:  82%|▊| 11319/13852 [42:24<09:22,  4.51it/\u001b[A\n",
      "Training loss: 4.75e-02 lr: 9.14e-06:  82%|▊| 11320/13852 [42:24<09:21,  4.51it/\u001b[A\n",
      "Training loss: 4.55e-02 lr: 9.14e-06:  82%|▊| 11321/13852 [42:24<09:23,  4.49it/\u001b[A\n",
      "Training loss: 4.71e-02 lr: 9.13e-06:  82%|▊| 11322/13852 [42:24<09:20,  4.52it/\u001b[A\n",
      "Training loss: 3.68e-02 lr: 9.13e-06:  82%|▊| 11323/13852 [42:25<09:17,  4.54it/\u001b[A\n",
      "Training loss: 4.13e-02 lr: 9.13e-06:  82%|▊| 11324/13852 [42:25<09:16,  4.55it/\u001b[A\n",
      "Training loss: 3.06e-02 lr: 9.12e-06:  82%|▊| 11325/13852 [42:25<09:21,  4.50it/\u001b[A\n",
      "Training loss: 2.33e-02 lr: 9.12e-06:  82%|▊| 11326/13852 [42:25<09:20,  4.51it/\u001b[A\n",
      "Training loss: 5.15e-02 lr: 9.11e-06:  82%|▊| 11327/13852 [42:26<09:19,  4.51it/\u001b[A\n",
      "Training loss: 6.30e-02 lr: 9.11e-06:  82%|▊| 11328/13852 [42:26<09:19,  4.51it/\u001b[A\n",
      "Training loss: 5.24e-02 lr: 9.11e-06:  82%|▊| 11329/13852 [42:26<09:18,  4.52it/\u001b[A\n",
      "Training loss: 4.01e-02 lr: 9.10e-06:  82%|▊| 11330/13852 [42:26<09:18,  4.51it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 9.10e-06:  82%|▊| 11331/13852 [42:26<09:19,  4.50it/\u001b[A\n",
      "Training loss: 5.36e-02 lr: 9.10e-06:  82%|▊| 11332/13852 [42:27<09:21,  4.49it/\u001b[A\n",
      "Training loss: 1.00e-01 lr: 9.09e-06:  82%|▊| 11333/13852 [42:27<09:21,  4.49it/\u001b[A\n",
      "Training loss: 7.78e-02 lr: 9.09e-06:  82%|▊| 11334/13852 [42:27<09:17,  4.51it/\u001b[A\n",
      "Training loss: 5.85e-02 lr: 9.09e-06:  82%|▊| 11335/13852 [42:27<09:15,  4.53it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 9.08e-06:  82%|▊| 11336/13852 [42:28<09:12,  4.55it/\u001b[A\n",
      "Training loss: 6.81e-02 lr: 9.08e-06:  82%|▊| 11337/13852 [42:28<09:11,  4.56it/\u001b[A\n",
      "Training loss: 5.50e-02 lr: 9.08e-06:  82%|▊| 11338/13852 [42:28<09:16,  4.52it/\u001b[A\n",
      "Training loss: 6.74e-02 lr: 9.07e-06:  82%|▊| 11339/13852 [42:28<09:16,  4.52it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.97e-02 lr: 9.07e-06:  82%|▊| 11340/13852 [42:28<09:15,  4.52it/\u001b[A\n",
      "Training loss: 4.74e-02 lr: 9.06e-06:  82%|▊| 11341/13852 [42:29<09:14,  4.53it/\u001b[A\n",
      "Training loss: 7.38e-02 lr: 9.06e-06:  82%|▊| 11342/13852 [42:29<09:15,  4.52it/\u001b[A\n",
      "Training loss: 5.37e-02 lr: 9.06e-06:  82%|▊| 11343/13852 [42:29<09:15,  4.52it/\u001b[A\n",
      "Training loss: 4.07e-02 lr: 9.05e-06:  82%|▊| 11344/13852 [42:29<09:16,  4.51it/\u001b[A\n",
      "Training loss: 5.29e-02 lr: 9.05e-06:  82%|▊| 11345/13852 [42:30<09:16,  4.51it/\u001b[A\n",
      "Training loss: 3.93e-02 lr: 9.05e-06:  82%|▊| 11346/13852 [42:30<09:16,  4.50it/\u001b[A\n",
      "Training loss: 2.87e-02 lr: 9.04e-06:  82%|▊| 11347/13852 [42:30<09:16,  4.50it/\u001b[A\n",
      "Training loss: 2.13e-02 lr: 9.04e-06:  82%|▊| 11348/13852 [42:30<09:13,  4.52it/\u001b[A\n",
      "Training loss: 2.55e-02 lr: 9.04e-06:  82%|▊| 11349/13852 [42:30<09:11,  4.54it/\u001b[A\n",
      "Training loss: 4.57e-02 lr: 9.03e-06:  82%|▊| 11350/13852 [42:31<09:14,  4.51it/\u001b[A\n",
      "Training loss: 9.36e-02 lr: 9.03e-06:  82%|▊| 11351/13852 [42:31<09:19,  4.47it/\u001b[A\n",
      "Training loss: 6.93e-02 lr: 9.02e-06:  82%|▊| 11352/13852 [42:31<09:17,  4.49it/\u001b[A\n",
      "Training loss: 6.14e-02 lr: 9.02e-06:  82%|▊| 11353/13852 [42:31<09:17,  4.48it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 9.02e-06:  82%|▊| 11354/13852 [42:32<09:16,  4.49it/\u001b[A\n",
      "Training loss: 9.08e-02 lr: 9.01e-06:  82%|▊| 11355/13852 [42:32<09:18,  4.47it/\u001b[A\n",
      "Training loss: 7.55e-02 lr: 9.01e-06:  82%|▊| 11356/13852 [42:32<09:17,  4.47it/\u001b[A\n",
      "Training loss: 1.10e-01 lr: 9.01e-06:  82%|▊| 11357/13852 [42:32<09:17,  4.48it/\u001b[A\n",
      "Training loss: 1.25e-01 lr: 9.00e-06:  82%|▊| 11358/13852 [42:32<09:15,  4.49it/\u001b[A\n",
      "Training loss: 9.76e-02 lr: 9.00e-06:  82%|▊| 11359/13852 [42:33<09:11,  4.52it/\u001b[A\n",
      "Training loss: 7.70e-02 lr: 9.00e-06:  82%|▊| 11360/13852 [42:33<09:09,  4.54it/\u001b[A\n",
      "Training loss: 1.06e-01 lr: 8.99e-06:  82%|▊| 11361/13852 [42:33<09:13,  4.50it/\u001b[A\n",
      "Training loss: 8.14e-02 lr: 8.99e-06:  82%|▊| 11362/13852 [42:33<09:13,  4.50it/\u001b[A\n",
      "Training loss: 6.26e-02 lr: 8.98e-06:  82%|▊| 11363/13852 [42:34<09:12,  4.50it/\u001b[A\n",
      "Training loss: 5.68e-02 lr: 8.98e-06:  82%|▊| 11364/13852 [42:34<09:13,  4.50it/\u001b[A\n",
      "Training loss: 6.18e-02 lr: 8.98e-06:  82%|▊| 11365/13852 [42:34<09:11,  4.51it/\u001b[A\n",
      "Training loss: 8.47e-02 lr: 8.97e-06:  82%|▊| 11366/13852 [42:34<09:11,  4.51it/\u001b[A\n",
      "Training loss: 6.41e-02 lr: 8.97e-06:  82%|▊| 11367/13852 [42:34<09:10,  4.51it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 8.97e-06:  82%|▊| 11368/13852 [42:35<09:12,  4.50it/\u001b[A\n",
      "Training loss: 9.18e-02 lr: 8.96e-06:  82%|▊| 11369/13852 [42:35<09:11,  4.50it/\u001b[A\n",
      "Training loss: 8.51e-02 lr: 8.96e-06:  82%|▊| 11370/13852 [42:35<09:09,  4.52it/\u001b[A\n",
      "Training loss: 6.95e-02 lr: 8.96e-06:  82%|▊| 11371/13852 [42:35<09:06,  4.54it/\u001b[A\n",
      "Training loss: 7.57e-02 lr: 8.95e-06:  82%|▊| 11372/13852 [42:36<09:04,  4.55it/\u001b[A\n",
      "Training loss: 5.66e-02 lr: 8.95e-06:  82%|▊| 11373/13852 [42:36<09:04,  4.55it/\u001b[A\n",
      "Training loss: 4.12e-02 lr: 8.95e-06:  82%|▊| 11374/13852 [42:36<09:06,  4.54it/\u001b[A\n",
      "Training loss: 3.65e-02 lr: 8.94e-06:  82%|▊| 11375/13852 [42:36<09:06,  4.53it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 8.94e-06:  82%|▊| 11376/13852 [42:36<09:06,  4.53it/\u001b[A\n",
      "Training loss: 3.20e-02 lr: 8.93e-06:  82%|▊| 11377/13852 [42:37<09:09,  4.51it/\u001b[A\n",
      "Training loss: 3.26e-02 lr: 8.93e-06:  82%|▊| 11378/13852 [42:37<09:15,  4.45it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 8.93e-06:  82%|▊| 11379/13852 [42:37<09:17,  4.44it/\u001b[A\n",
      "Training loss: 9.35e-02 lr: 8.92e-06:  82%|▊| 11380/13852 [42:37<09:18,  4.43it/\u001b[A\n",
      "Training loss: 6.80e-02 lr: 8.92e-06:  82%|▊| 11381/13852 [42:38<09:49,  4.19it/\u001b[A\n",
      "Training loss: 7.17e-02 lr: 8.92e-06:  82%|▊| 11382/13852 [42:38<09:58,  4.13it/\u001b[A\n",
      "Training loss: 5.16e-02 lr: 8.91e-06:  82%|▊| 11383/13852 [42:38<09:59,  4.12it/\u001b[A\n",
      "Training loss: 7.87e-02 lr: 8.91e-06:  82%|▊| 11384/13852 [42:38<09:56,  4.13it/\u001b[A\n",
      "Training loss: 7.62e-02 lr: 8.91e-06:  82%|▊| 11385/13852 [42:39<09:54,  4.15it/\u001b[A\n",
      "Training loss: 5.81e-02 lr: 8.90e-06:  82%|▊| 11386/13852 [42:39<09:51,  4.17it/\u001b[A\n",
      "Training loss: 4.80e-02 lr: 8.90e-06:  82%|▊| 11387/13852 [42:39<09:47,  4.20it/\u001b[A\n",
      "Training loss: 3.56e-02 lr: 8.89e-06:  82%|▊| 11388/13852 [42:39<09:50,  4.17it/\u001b[A\n",
      "Training loss: 5.85e-02 lr: 8.89e-06:  82%|▊| 11389/13852 [42:40<09:49,  4.18it/\u001b[A\n",
      "Training loss: 4.88e-02 lr: 8.89e-06:  82%|▊| 11390/13852 [42:40<09:49,  4.18it/\u001b[A\n",
      "Training loss: 4.12e-02 lr: 8.88e-06:  82%|▊| 11391/13852 [42:40<09:49,  4.18it/\u001b[A\n",
      "Training loss: 8.12e-02 lr: 8.88e-06:  82%|▊| 11392/13852 [42:40<09:50,  4.17it/\u001b[A\n",
      "Training loss: 6.01e-02 lr: 8.88e-06:  82%|▊| 11393/13852 [42:40<09:47,  4.18it/\u001b[A\n",
      "Training loss: 8.71e-02 lr: 8.87e-06:  82%|▊| 11394/13852 [42:41<09:50,  4.16it/\u001b[A\n",
      "Training loss: 9.19e-02 lr: 8.87e-06:  82%|▊| 11395/13852 [42:41<09:51,  4.15it/\u001b[A\n",
      "Training loss: 7.01e-02 lr: 8.87e-06:  82%|▊| 11396/13852 [42:41<09:50,  4.16it/\u001b[A\n",
      "Training loss: 5.97e-02 lr: 8.86e-06:  82%|▊| 11397/13852 [42:41<09:49,  4.17it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 8.86e-06:  82%|▊| 11398/13852 [42:42<09:53,  4.13it/\u001b[A\n",
      "Training loss: 4.22e-02 lr: 8.85e-06:  82%|▊| 11399/13852 [42:42<09:51,  4.15it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 8.85e-06:  82%|▊| 11400/13852 [42:42<09:49,  4.16it/\u001b[A\n",
      "Training loss: 2.67e-02 lr: 8.85e-06:  82%|▊| 11401/13852 [42:42<09:50,  4.15it/\u001b[A\n",
      "Training loss: 4.43e-02 lr: 8.84e-06:  82%|▊| 11402/13852 [42:43<09:49,  4.16it/\u001b[A\n",
      "Training loss: 6.95e-02 lr: 8.84e-06:  82%|▊| 11403/13852 [42:43<09:48,  4.16it/\u001b[A\n",
      "Training loss: 5.95e-02 lr: 8.84e-06:  82%|▊| 11404/13852 [42:43<09:45,  4.18it/\u001b[A\n",
      "Training loss: 9.01e-02 lr: 8.83e-06:  82%|▊| 11405/13852 [42:43<09:46,  4.17it/\u001b[A\n",
      "Training loss: 1.20e-01 lr: 8.83e-06:  82%|▊| 11406/13852 [42:44<09:46,  4.17it/\u001b[A\n",
      "Training loss: 9.15e-02 lr: 8.83e-06:  82%|▊| 11407/13852 [42:44<09:46,  4.17it/\u001b[A\n",
      "Training loss: 9.69e-02 lr: 8.82e-06:  82%|▊| 11408/13852 [42:44<09:33,  4.26it/\u001b[A\n",
      "Training loss: 8.30e-02 lr: 8.82e-06:  82%|▊| 11409/13852 [42:44<09:24,  4.33it/\u001b[A\n",
      "Training loss: 6.26e-02 lr: 8.82e-06:  82%|▊| 11410/13852 [42:45<09:17,  4.38it/\u001b[A\n",
      "Training loss: 5.71e-02 lr: 8.81e-06:  82%|▊| 11411/13852 [42:45<09:10,  4.44it/\u001b[A\n",
      "Training loss: 4.19e-02 lr: 8.81e-06:  82%|▊| 11412/13852 [42:45<09:03,  4.49it/\u001b[A\n",
      "Training loss: 4.95e-02 lr: 8.80e-06:  82%|▊| 11413/13852 [42:45<08:59,  4.52it/\u001b[A\n",
      "Training loss: 3.64e-02 lr: 8.80e-06:  82%|▊| 11414/13852 [42:45<09:03,  4.49it/\u001b[A\n",
      "Training loss: 6.71e-02 lr: 8.80e-06:  82%|▊| 11415/13852 [42:46<09:02,  4.49it/\u001b[A\n",
      "Training loss: 5.43e-02 lr: 8.79e-06:  82%|▊| 11416/13852 [42:46<09:00,  4.50it/\u001b[A\n",
      "Training loss: 4.23e-02 lr: 8.79e-06:  82%|▊| 11417/13852 [42:46<08:59,  4.51it/\u001b[A\n",
      "Training loss: 7.48e-02 lr: 8.79e-06:  82%|▊| 11418/13852 [42:46<09:00,  4.51it/\u001b[A\n",
      "Training loss: 6.95e-02 lr: 8.78e-06:  82%|▊| 11419/13852 [42:47<08:59,  4.51it/\u001b[A\n",
      "Training loss: 6.00e-02 lr: 8.78e-06:  82%|▊| 11420/13852 [42:47<09:00,  4.50it/\u001b[A\n",
      "Training loss: 7.12e-02 lr: 8.78e-06:  82%|▊| 11421/13852 [42:47<09:00,  4.50it/\u001b[A\n",
      "Training loss: 6.39e-02 lr: 8.77e-06:  82%|▊| 11422/13852 [42:47<09:01,  4.48it/\u001b[A\n",
      "Training loss: 4.96e-02 lr: 8.77e-06:  82%|▊| 11423/13852 [42:47<09:01,  4.49it/\u001b[A\n",
      "Training loss: 3.65e-02 lr: 8.76e-06:  82%|▊| 11424/13852 [42:48<08:58,  4.51it/\u001b[A\n",
      "Training loss: 3.69e-02 lr: 8.76e-06:  82%|▊| 11425/13852 [42:48<08:55,  4.53it/\u001b[A\n",
      "Training loss: 4.86e-02 lr: 8.76e-06:  82%|▊| 11426/13852 [42:48<08:58,  4.51it/\u001b[A\n",
      "Training loss: 3.50e-02 lr: 8.75e-06:  82%|▊| 11427/13852 [42:48<08:58,  4.51it/\u001b[A\n",
      "Training loss: 1.16e-01 lr: 8.75e-06:  83%|▊| 11428/13852 [42:49<08:57,  4.51it/\u001b[A\n",
      "Training loss: 1.09e-01 lr: 8.75e-06:  83%|▊| 11429/13852 [42:49<08:56,  4.51it/\u001b[A\n",
      "Training loss: 8.75e-02 lr: 8.74e-06:  83%|▊| 11430/13852 [42:49<09:00,  4.48it/\u001b[A\n",
      "Training loss: 7.88e-02 lr: 8.74e-06:  83%|▊| 11431/13852 [42:49<08:59,  4.49it/\u001b[A\n",
      "Training loss: 7.77e-02 lr: 8.74e-06:  83%|▊| 11432/13852 [42:49<08:58,  4.50it/\u001b[A\n",
      "Training loss: 6.56e-02 lr: 8.73e-06:  83%|▊| 11433/13852 [42:50<08:57,  4.50it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 8.73e-06:  83%|▊| 11434/13852 [42:50<08:56,  4.50it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 8.73e-06:  83%|▊| 11435/13852 [42:50<08:56,  4.51it/\u001b[A\n",
      "Training loss: 6.78e-02 lr: 8.72e-06:  83%|▊| 11436/13852 [42:50<08:54,  4.52it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.80e-02 lr: 8.72e-06:  83%|▊| 11437/13852 [42:51<08:51,  4.55it/\u001b[A\n",
      "Training loss: 4.36e-02 lr: 8.71e-06:  83%|▊| 11438/13852 [42:51<08:56,  4.50it/\u001b[A\n",
      "Training loss: 4.10e-02 lr: 8.71e-06:  83%|▊| 11439/13852 [42:51<08:57,  4.49it/\u001b[A\n",
      "Training loss: 4.04e-02 lr: 8.71e-06:  83%|▊| 11440/13852 [42:51<08:57,  4.49it/\u001b[A\n",
      "Training loss: 3.53e-02 lr: 8.70e-06:  83%|▊| 11441/13852 [42:51<08:55,  4.50it/\u001b[A\n",
      "Training loss: 5.21e-02 lr: 8.70e-06:  83%|▊| 11442/13852 [42:52<08:55,  4.50it/\u001b[A\n",
      "Training loss: 4.48e-02 lr: 8.70e-06:  83%|▊| 11443/13852 [42:52<08:56,  4.49it/\u001b[A\n",
      "Training loss: 5.95e-02 lr: 8.69e-06:  83%|▊| 11444/13852 [42:52<08:55,  4.49it/\u001b[A\n",
      "Training loss: 5.86e-02 lr: 8.69e-06:  83%|▊| 11445/13852 [42:52<08:55,  4.49it/\u001b[A\n",
      "Training loss: 4.83e-02 lr: 8.69e-06:  83%|▊| 11446/13852 [42:53<08:56,  4.49it/\u001b[A\n",
      "Training loss: 4.00e-02 lr: 8.68e-06:  83%|▊| 11447/13852 [42:53<08:53,  4.51it/\u001b[A\n",
      "Training loss: 3.87e-02 lr: 8.68e-06:  83%|▊| 11448/13852 [42:53<08:51,  4.52it/\u001b[A\n",
      "Training loss: 3.23e-02 lr: 8.67e-06:  83%|▊| 11449/13852 [42:53<08:54,  4.49it/\u001b[A\n",
      "Training loss: 2.96e-02 lr: 8.67e-06:  83%|▊| 11450/13852 [42:53<08:52,  4.51it/\u001b[A\n",
      "Training loss: 2.18e-02 lr: 8.67e-06:  83%|▊| 11451/13852 [42:54<08:52,  4.51it/\u001b[A\n",
      "Training loss: 2.27e-02 lr: 8.66e-06:  83%|▊| 11452/13852 [42:54<08:51,  4.51it/\u001b[A\n",
      "Training loss: 1.70e-02 lr: 8.66e-06:  83%|▊| 11453/13852 [42:54<08:50,  4.52it/\u001b[A\n",
      "Training loss: 3.07e-02 lr: 8.66e-06:  83%|▊| 11454/13852 [42:54<08:53,  4.50it/\u001b[A\n",
      "Training loss: 4.38e-02 lr: 8.65e-06:  83%|▊| 11455/13852 [42:55<08:51,  4.51it/\u001b[A\n",
      "Training loss: 3.73e-02 lr: 8.65e-06:  83%|▊| 11456/13852 [42:55<08:51,  4.51it/\u001b[A\n",
      "Training loss: 8.92e-02 lr: 8.65e-06:  83%|▊| 11457/13852 [42:55<08:50,  4.51it/\u001b[A\n",
      "Training loss: 9.00e-02 lr: 8.64e-06:  83%|▊| 11458/13852 [42:55<08:50,  4.51it/\u001b[A\n",
      "Training loss: 7.28e-02 lr: 8.64e-06:  83%|▊| 11459/13852 [42:55<08:50,  4.51it/\u001b[A\n",
      "Training loss: 5.97e-02 lr: 8.63e-06:  83%|▊| 11460/13852 [42:56<08:48,  4.52it/\u001b[A\n",
      "Training loss: 5.68e-02 lr: 8.63e-06:  83%|▊| 11461/13852 [42:56<08:46,  4.54it/\u001b[A\n",
      "Training loss: 4.08e-02 lr: 8.63e-06:  83%|▊| 11462/13852 [42:56<08:48,  4.53it/\u001b[A\n",
      "Training loss: 5.84e-02 lr: 8.62e-06:  83%|▊| 11463/13852 [42:56<08:47,  4.52it/\u001b[A\n",
      "Training loss: 4.87e-02 lr: 8.62e-06:  83%|▊| 11464/13852 [42:56<08:47,  4.52it/\u001b[A\n",
      "Training loss: 3.61e-02 lr: 8.62e-06:  83%|▊| 11465/13852 [42:57<08:49,  4.51it/\u001b[A\n",
      "Training loss: 5.46e-02 lr: 8.61e-06:  83%|▊| 11466/13852 [42:57<08:49,  4.51it/\u001b[A\n",
      "Training loss: 4.28e-02 lr: 8.61e-06:  83%|▊| 11467/13852 [42:57<08:47,  4.52it/\u001b[A\n",
      "Training loss: 6.43e-02 lr: 8.61e-06:  83%|▊| 11468/13852 [42:57<08:47,  4.52it/\u001b[A\n",
      "Training loss: 6.03e-02 lr: 8.60e-06:  83%|▊| 11469/13852 [42:58<08:47,  4.52it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 8.60e-06:  83%|▊| 11470/13852 [42:58<08:48,  4.51it/\u001b[A\n",
      "Training loss: 3.34e-02 lr: 8.60e-06:  83%|▊| 11471/13852 [42:58<08:47,  4.51it/\u001b[A\n",
      "Training loss: 6.75e-02 lr: 8.59e-06:  83%|▊| 11472/13852 [42:58<08:45,  4.53it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 8.59e-06:  83%|▊| 11473/13852 [42:58<08:43,  4.54it/\u001b[A\n",
      "Training loss: 4.75e-02 lr: 8.58e-06:  83%|▊| 11474/13852 [42:59<08:47,  4.51it/\u001b[A\n",
      "Training loss: 3.41e-02 lr: 8.58e-06:  83%|▊| 11475/13852 [42:59<08:46,  4.52it/\u001b[A\n",
      "Training loss: 2.83e-02 lr: 8.58e-06:  83%|▊| 11476/13852 [42:59<08:46,  4.52it/\u001b[A\n",
      "Training loss: 2.42e-02 lr: 8.57e-06:  83%|▊| 11477/13852 [42:59<08:46,  4.51it/\u001b[A\n",
      "Training loss: 1.73e-02 lr: 8.57e-06:  83%|▊| 11478/13852 [43:00<08:44,  4.53it/\u001b[A\n",
      "Training loss: 4.18e-02 lr: 8.57e-06:  83%|▊| 11479/13852 [43:00<08:44,  4.52it/\u001b[A\n",
      "Training loss: 5.51e-02 lr: 8.56e-06:  83%|▊| 11480/13852 [43:00<08:44,  4.52it/\u001b[A\n",
      "Training loss: 5.75e-02 lr: 8.56e-06:  83%|▊| 11481/13852 [43:00<08:44,  4.52it/\u001b[A\n",
      "Training loss: 5.55e-02 lr: 8.56e-06:  83%|▊| 11482/13852 [43:00<08:43,  4.52it/\u001b[A\n",
      "Training loss: 4.04e-02 lr: 8.55e-06:  83%|▊| 11483/13852 [43:01<08:44,  4.52it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 8.55e-06:  83%|▊| 11484/13852 [43:01<08:47,  4.49it/\u001b[A\n",
      "Training loss: 3.64e-02 lr: 8.54e-06:  83%|▊| 11485/13852 [43:01<08:45,  4.51it/\u001b[A\n",
      "Training loss: 7.06e-02 lr: 8.54e-06:  83%|▊| 11486/13852 [43:01<08:44,  4.51it/\u001b[A\n",
      "Training loss: 5.35e-02 lr: 8.54e-06:  83%|▊| 11487/13852 [43:02<08:43,  4.52it/\u001b[A\n",
      "Training loss: 4.22e-02 lr: 8.53e-06:  83%|▊| 11488/13852 [43:02<08:44,  4.51it/\u001b[A\n",
      "Training loss: 5.60e-02 lr: 8.53e-06:  83%|▊| 11489/13852 [43:02<08:42,  4.52it/\u001b[A\n",
      "Training loss: 4.00e-02 lr: 8.53e-06:  83%|▊| 11490/13852 [43:02<08:41,  4.53it/\u001b[A\n",
      "Training loss: 4.68e-02 lr: 8.52e-06:  83%|▊| 11491/13852 [43:02<08:41,  4.52it/\u001b[A\n",
      "Training loss: 5.73e-02 lr: 8.52e-06:  83%|▊| 11492/13852 [43:03<08:41,  4.53it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 8.52e-06:  83%|▊| 11493/13852 [43:03<08:41,  4.53it/\u001b[A\n",
      "Training loss: 4.13e-02 lr: 8.51e-06:  83%|▊| 11494/13852 [43:03<08:41,  4.52it/\u001b[A\n",
      "Training loss: 7.25e-02 lr: 8.51e-06:  83%|▊| 11495/13852 [43:03<08:41,  4.52it/\u001b[A\n",
      "Training loss: 5.95e-02 lr: 8.50e-06:  83%|▊| 11496/13852 [43:04<08:40,  4.52it/\u001b[A\n",
      "Training loss: 5.19e-02 lr: 8.50e-06:  83%|▊| 11497/13852 [43:04<08:40,  4.52it/\u001b[A\n",
      "Training loss: 4.50e-02 lr: 8.50e-06:  83%|▊| 11498/13852 [43:04<08:38,  4.54it/\u001b[A\n",
      "Training loss: 6.41e-02 lr: 8.49e-06:  83%|▊| 11499/13852 [43:04<08:42,  4.51it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 8.49e-06:  83%|▊| 11500/13852 [43:04<08:41,  4.51it/\u001b[A\n",
      "Training loss: 4.96e-02 lr: 8.49e-06:  83%|▊| 11501/13852 [43:05<08:40,  4.52it/\u001b[A\n",
      "Training loss: 3.63e-02 lr: 8.48e-06:  83%|▊| 11502/13852 [43:05<08:40,  4.52it/\u001b[A\n",
      "Training loss: 7.89e-02 lr: 8.48e-06:  83%|▊| 11503/13852 [43:05<08:38,  4.53it/\u001b[A\n",
      "Training loss: 8.53e-02 lr: 8.48e-06:  83%|▊| 11504/13852 [43:05<08:39,  4.52it/\u001b[A\n",
      "Training loss: 1.71e-01 lr: 8.47e-06:  83%|▊| 11505/13852 [43:06<08:39,  4.52it/\u001b[A\n",
      "Training loss: 1.31e-01 lr: 8.47e-06:  83%|▊| 11506/13852 [43:06<08:39,  4.52it/\u001b[A\n",
      "Training loss: 1.17e-01 lr: 8.47e-06:  83%|▊| 11507/13852 [43:06<08:39,  4.51it/\u001b[A\n",
      "Training loss: 1.68e-01 lr: 8.46e-06:  83%|▊| 11508/13852 [43:06<08:39,  4.51it/\u001b[A\n",
      "Training loss: 1.26e-01 lr: 8.46e-06:  83%|▊| 11509/13852 [43:06<08:37,  4.53it/\u001b[A\n",
      "Training loss: 9.10e-02 lr: 8.45e-06:  83%|▊| 11510/13852 [43:07<08:37,  4.52it/\u001b[A\n",
      "Training loss: 6.57e-02 lr: 8.45e-06:  83%|▊| 11511/13852 [43:07<08:38,  4.51it/\u001b[A\n",
      "Training loss: 5.73e-02 lr: 8.45e-06:  83%|▊| 11512/13852 [43:07<08:39,  4.50it/\u001b[A\n",
      "Training loss: 4.36e-02 lr: 8.44e-06:  83%|▊| 11513/13852 [43:07<08:43,  4.46it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 8.44e-06:  83%|▊| 11514/13852 [43:08<08:42,  4.47it/\u001b[A\n",
      "Training loss: 7.42e-02 lr: 8.44e-06:  83%|▊| 11515/13852 [43:08<08:40,  4.49it/\u001b[A\n",
      "Training loss: 5.85e-02 lr: 8.43e-06:  83%|▊| 11516/13852 [43:08<08:42,  4.47it/\u001b[A\n",
      "Training loss: 4.15e-02 lr: 8.43e-06:  83%|▊| 11517/13852 [43:08<08:45,  4.44it/\u001b[A\n",
      "Training loss: 3.37e-02 lr: 8.43e-06:  83%|▊| 11518/13852 [43:08<08:42,  4.47it/\u001b[A\n",
      "Training loss: 2.80e-02 lr: 8.42e-06:  83%|▊| 11519/13852 [43:09<08:40,  4.49it/\u001b[A\n",
      "Training loss: 2.11e-02 lr: 8.42e-06:  83%|▊| 11520/13852 [43:09<08:36,  4.51it/\u001b[A\n",
      "Training loss: 1.98e-02 lr: 8.41e-06:  83%|▊| 11521/13852 [43:09<08:33,  4.54it/\u001b[A\n",
      "Training loss: 1.87e-02 lr: 8.41e-06:  83%|▊| 11522/13852 [43:09<08:31,  4.56it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 8.41e-06:  83%|▊| 11523/13852 [43:10<08:29,  4.57it/\u001b[A\n",
      "Training loss: 5.30e-02 lr: 8.40e-06:  83%|▊| 11524/13852 [43:10<08:31,  4.56it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 8.40e-06:  83%|▊| 11525/13852 [43:10<08:31,  4.55it/\u001b[A\n",
      "Training loss: 4.06e-02 lr: 8.40e-06:  83%|▊| 11526/13852 [43:10<08:31,  4.54it/\u001b[A\n",
      "Training loss: 3.14e-02 lr: 8.39e-06:  83%|▊| 11527/13852 [43:10<08:31,  4.55it/\u001b[A\n",
      "Training loss: 2.39e-02 lr: 8.39e-06:  83%|▊| 11528/13852 [43:11<08:32,  4.54it/\u001b[A\n",
      "Training loss: 7.03e-02 lr: 8.39e-06:  83%|▊| 11529/13852 [43:11<08:36,  4.50it/\u001b[A\n",
      "Training loss: 5.12e-02 lr: 8.38e-06:  83%|▊| 11530/13852 [43:11<08:35,  4.51it/\u001b[A\n",
      "Training loss: 4.46e-02 lr: 8.38e-06:  83%|▊| 11531/13852 [43:11<08:35,  4.50it/\u001b[A\n",
      "Training loss: 6.26e-02 lr: 8.37e-06:  83%|▊| 11532/13852 [43:12<08:36,  4.49it/\u001b[A\n",
      "Training loss: 5.89e-02 lr: 8.37e-06:  83%|▊| 11533/13852 [43:12<08:35,  4.50it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.39e-02 lr: 8.37e-06:  83%|▊| 11534/13852 [43:12<08:32,  4.52it/\u001b[A\n",
      "Training loss: 3.37e-02 lr: 8.36e-06:  83%|▊| 11535/13852 [43:12<08:29,  4.55it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 8.36e-06:  83%|▊| 11536/13852 [43:12<08:32,  4.52it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 8.36e-06:  83%|▊| 11537/13852 [43:13<08:32,  4.52it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 8.35e-06:  83%|▊| 11538/13852 [43:13<08:31,  4.52it/\u001b[A\n",
      "Training loss: 3.89e-02 lr: 8.35e-06:  83%|▊| 11539/13852 [43:13<08:30,  4.53it/\u001b[A\n",
      "Training loss: 3.84e-02 lr: 8.35e-06:  83%|▊| 11540/13852 [43:13<08:30,  4.53it/\u001b[A\n",
      "Training loss: 4.34e-02 lr: 8.34e-06:  83%|▊| 11541/13852 [43:14<08:30,  4.53it/\u001b[A\n",
      "Training loss: 3.74e-02 lr: 8.34e-06:  83%|▊| 11542/13852 [43:14<08:31,  4.51it/\u001b[A\n",
      "Training loss: 3.73e-02 lr: 8.34e-06:  83%|▊| 11543/13852 [43:14<08:31,  4.51it/\u001b[A\n",
      "Training loss: 2.76e-02 lr: 8.33e-06:  83%|▊| 11544/13852 [43:14<08:31,  4.52it/\u001b[A\n",
      "Training loss: 4.02e-02 lr: 8.33e-06:  83%|▊| 11545/13852 [43:14<08:29,  4.52it/\u001b[A\n",
      "Training loss: 6.13e-02 lr: 8.32e-06:  83%|▊| 11546/13852 [43:15<08:28,  4.54it/\u001b[A\n",
      "Training loss: 7.31e-02 lr: 8.32e-06:  83%|▊| 11547/13852 [43:15<08:26,  4.55it/\u001b[A\n",
      "Training loss: 6.28e-02 lr: 8.32e-06:  83%|▊| 11548/13852 [43:15<08:29,  4.52it/\u001b[A\n",
      "Training loss: 4.81e-02 lr: 8.31e-06:  83%|▊| 11549/13852 [43:15<08:29,  4.52it/\u001b[A\n",
      "Training loss: 5.30e-02 lr: 8.31e-06:  83%|▊| 11550/13852 [43:16<08:29,  4.52it/\u001b[A\n",
      "Training loss: 3.82e-02 lr: 8.31e-06:  83%|▊| 11551/13852 [43:16<08:28,  4.52it/\u001b[A\n",
      "Training loss: 3.40e-02 lr: 8.30e-06:  83%|▊| 11552/13852 [43:16<08:28,  4.53it/\u001b[A\n",
      "Training loss: 6.06e-02 lr: 8.30e-06:  83%|▊| 11553/13852 [43:16<08:28,  4.52it/\u001b[A\n",
      "Training loss: 4.39e-02 lr: 8.30e-06:  83%|▊| 11554/13852 [43:16<08:28,  4.52it/\u001b[A\n",
      "Training loss: 4.76e-02 lr: 8.29e-06:  83%|▊| 11555/13852 [43:17<08:31,  4.49it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 8.29e-06:  83%|▊| 11556/13852 [43:17<08:33,  4.47it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 8.28e-06:  83%|▊| 11557/13852 [43:17<08:31,  4.48it/\u001b[A\n",
      "Training loss: 3.60e-02 lr: 8.28e-06:  83%|▊| 11558/13852 [43:17<08:28,  4.51it/\u001b[A\n",
      "Training loss: 2.92e-02 lr: 8.28e-06:  83%|▊| 11559/13852 [43:18<08:25,  4.54it/\u001b[A\n",
      "Training loss: 2.20e-02 lr: 8.27e-06:  83%|▊| 11560/13852 [43:18<08:23,  4.55it/\u001b[A\n",
      "Training loss: 2.42e-02 lr: 8.27e-06:  83%|▊| 11561/13852 [43:18<08:27,  4.52it/\u001b[A\n",
      "Training loss: 2.91e-02 lr: 8.27e-06:  83%|▊| 11562/13852 [43:18<08:27,  4.52it/\u001b[A\n",
      "Training loss: 9.19e-02 lr: 8.26e-06:  83%|▊| 11563/13852 [43:18<08:26,  4.52it/\u001b[A\n",
      "Training loss: 6.54e-02 lr: 8.26e-06:  83%|▊| 11564/13852 [43:19<08:25,  4.53it/\u001b[A\n",
      "Training loss: 6.21e-02 lr: 8.26e-06:  83%|▊| 11565/13852 [43:19<08:25,  4.53it/\u001b[A\n",
      "Training loss: 4.78e-02 lr: 8.25e-06:  83%|▊| 11566/13852 [43:19<08:24,  4.53it/\u001b[A\n",
      "Training loss: 3.84e-02 lr: 8.25e-06:  84%|▊| 11567/13852 [43:19<08:25,  4.52it/\u001b[A\n",
      "Training loss: 8.18e-02 lr: 8.24e-06:  84%|▊| 11568/13852 [43:20<08:25,  4.52it/\u001b[A\n",
      "Training loss: 7.60e-02 lr: 8.24e-06:  84%|▊| 11569/13852 [43:20<08:25,  4.51it/\u001b[A\n",
      "Training loss: 5.42e-02 lr: 8.24e-06:  84%|▊| 11570/13852 [43:20<08:25,  4.51it/\u001b[A\n",
      "Training loss: 4.15e-02 lr: 8.23e-06:  84%|▊| 11571/13852 [43:20<08:23,  4.53it/\u001b[A\n",
      "Training loss: 7.43e-02 lr: 8.23e-06:  84%|▊| 11572/13852 [43:20<08:22,  4.54it/\u001b[A\n",
      "Training loss: 5.71e-02 lr: 8.23e-06:  84%|▊| 11573/13852 [43:21<08:21,  4.54it/\u001b[A\n",
      "Training loss: 7.39e-02 lr: 8.22e-06:  84%|▊| 11574/13852 [43:21<08:25,  4.51it/\u001b[A\n",
      "Training loss: 6.57e-02 lr: 8.22e-06:  84%|▊| 11575/13852 [43:21<08:24,  4.51it/\u001b[A\n",
      "Training loss: 8.70e-02 lr: 8.22e-06:  84%|▊| 11576/13852 [43:21<08:23,  4.52it/\u001b[A\n",
      "Training loss: 6.24e-02 lr: 8.21e-06:  84%|▊| 11577/13852 [43:22<08:23,  4.52it/\u001b[A\n",
      "Training loss: 4.51e-02 lr: 8.21e-06:  84%|▊| 11578/13852 [43:22<08:26,  4.49it/\u001b[A\n",
      "Training loss: 3.32e-02 lr: 8.21e-06:  84%|▊| 11579/13852 [43:22<08:25,  4.50it/\u001b[A\n",
      "Training loss: 5.02e-02 lr: 8.20e-06:  84%|▊| 11580/13852 [43:22<08:28,  4.47it/\u001b[A\n",
      "Training loss: 3.82e-02 lr: 8.20e-06:  84%|▊| 11581/13852 [43:22<08:26,  4.48it/\u001b[A\n",
      "Training loss: 2.83e-02 lr: 8.19e-06:  84%|▊| 11582/13852 [43:23<08:23,  4.51it/\u001b[A\n",
      "Training loss: 2.75e-02 lr: 8.19e-06:  84%|▊| 11583/13852 [43:23<08:21,  4.53it/\u001b[A\n",
      "Training loss: 2.17e-02 lr: 8.19e-06:  84%|▊| 11584/13852 [43:23<08:19,  4.54it/\u001b[A\n",
      "Training loss: 1.89e-02 lr: 8.18e-06:  84%|▊| 11585/13852 [43:23<08:23,  4.50it/\u001b[A\n",
      "Training loss: 4.20e-02 lr: 8.18e-06:  84%|▊| 11586/13852 [43:24<08:22,  4.51it/\u001b[A\n",
      "Training loss: 3.73e-02 lr: 8.18e-06:  84%|▊| 11587/13852 [43:24<08:21,  4.52it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 8.17e-06:  84%|▊| 11588/13852 [43:24<08:20,  4.52it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 8.17e-06:  84%|▊| 11589/13852 [43:24<08:18,  4.54it/\u001b[A\n",
      "Training loss: 8.60e-02 lr: 8.17e-06:  84%|▊| 11590/13852 [43:24<08:19,  4.53it/\u001b[A\n",
      "Training loss: 6.86e-02 lr: 8.16e-06:  84%|▊| 11591/13852 [43:25<08:19,  4.53it/\u001b[A\n",
      "Training loss: 6.36e-02 lr: 8.16e-06:  84%|▊| 11592/13852 [43:25<08:19,  4.52it/\u001b[A\n",
      "Training loss: 6.31e-02 lr: 8.15e-06:  84%|▊| 11593/13852 [43:25<08:19,  4.52it/\u001b[A\n",
      "Training loss: 5.19e-02 lr: 8.15e-06:  84%|▊| 11594/13852 [43:25<08:19,  4.52it/\u001b[A\n",
      "Training loss: 4.52e-02 lr: 8.15e-06:  84%|▊| 11595/13852 [43:25<08:20,  4.51it/\u001b[A\n",
      "Training loss: 3.89e-02 lr: 8.14e-06:  84%|▊| 11596/13852 [43:26<08:18,  4.53it/\u001b[A\n",
      "Training loss: 4.39e-02 lr: 8.14e-06:  84%|▊| 11597/13852 [43:26<08:15,  4.55it/\u001b[A\n",
      "Training loss: 4.44e-02 lr: 8.14e-06:  84%|▊| 11598/13852 [43:26<08:17,  4.53it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 8.13e-06:  84%|▊| 11599/13852 [43:26<08:17,  4.53it/\u001b[A\n",
      "Training loss: 4.26e-02 lr: 8.13e-06:  84%|▊| 11600/13852 [43:27<08:17,  4.53it/\u001b[A\n",
      "Training loss: 5.05e-02 lr: 8.13e-06:  84%|▊| 11601/13852 [43:27<08:20,  4.50it/\u001b[A\n",
      "Training loss: 4.20e-02 lr: 8.12e-06:  84%|▊| 11602/13852 [43:27<08:19,  4.50it/\u001b[A\n",
      "Training loss: 3.55e-02 lr: 8.12e-06:  84%|▊| 11603/13852 [43:27<08:18,  4.51it/\u001b[A\n",
      "Training loss: 7.32e-02 lr: 8.11e-06:  84%|▊| 11604/13852 [43:27<08:18,  4.51it/\u001b[A\n",
      "Training loss: 6.44e-02 lr: 8.11e-06:  84%|▊| 11605/13852 [43:28<08:18,  4.51it/\u001b[A\n",
      "Training loss: 5.17e-02 lr: 8.11e-06:  84%|▊| 11606/13852 [43:28<08:17,  4.51it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 8.10e-06:  84%|▊| 11607/13852 [43:28<08:17,  4.52it/\u001b[A\n",
      "Training loss: 2.78e-02 lr: 8.10e-06:  84%|▊| 11608/13852 [43:28<08:18,  4.50it/\u001b[A\n",
      "Training loss: 9.59e-02 lr: 8.10e-06:  84%|▊| 11609/13852 [43:29<08:15,  4.53it/\u001b[A\n",
      "Training loss: 7.29e-02 lr: 8.09e-06:  84%|▊| 11610/13852 [43:29<08:19,  4.49it/\u001b[A\n",
      "Training loss: 6.39e-02 lr: 8.09e-06:  84%|▊| 11611/13852 [43:29<08:18,  4.50it/\u001b[A\n",
      "Training loss: 5.51e-02 lr: 8.09e-06:  84%|▊| 11612/13852 [43:29<08:17,  4.50it/\u001b[A\n",
      "Training loss: 5.16e-02 lr: 8.08e-06:  84%|▊| 11613/13852 [43:29<08:15,  4.51it/\u001b[A\n",
      "Training loss: 5.46e-02 lr: 8.08e-06:  84%|▊| 11614/13852 [43:30<08:16,  4.51it/\u001b[A\n",
      "Training loss: 3.92e-02 lr: 8.08e-06:  84%|▊| 11615/13852 [43:30<08:15,  4.51it/\u001b[A\n",
      "Training loss: 4.14e-02 lr: 8.07e-06:  84%|▊| 11616/13852 [43:30<08:15,  4.51it/\u001b[A\n",
      "Training loss: 4.76e-02 lr: 8.07e-06:  84%|▊| 11617/13852 [43:30<08:15,  4.51it/\u001b[A\n",
      "Training loss: 6.69e-02 lr: 8.06e-06:  84%|▊| 11618/13852 [43:31<08:15,  4.51it/\u001b[A\n",
      "Training loss: 1.44e-01 lr: 8.06e-06:  84%|▊| 11619/13852 [43:31<08:16,  4.50it/\u001b[A\n",
      "Training loss: 1.27e-01 lr: 8.06e-06:  84%|▊| 11620/13852 [43:31<08:14,  4.51it/\u001b[A\n",
      "Training loss: 9.86e-02 lr: 8.05e-06:  84%|▊| 11621/13852 [43:31<08:12,  4.53it/\u001b[A\n",
      "Training loss: 8.69e-02 lr: 8.05e-06:  84%|▊| 11622/13852 [43:31<08:09,  4.56it/\u001b[A\n",
      "Training loss: 6.50e-02 lr: 8.05e-06:  84%|▊| 11623/13852 [43:32<08:13,  4.52it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 8.04e-06:  84%|▊| 11624/13852 [43:32<08:14,  4.51it/\u001b[A\n",
      "Training loss: 7.88e-02 lr: 8.04e-06:  84%|▊| 11625/13852 [43:32<08:13,  4.51it/\u001b[A\n",
      "Training loss: 6.12e-02 lr: 8.04e-06:  84%|▊| 11626/13852 [43:32<08:12,  4.52it/\u001b[A\n",
      "Training loss: 5.00e-02 lr: 8.03e-06:  84%|▊| 11627/13852 [43:33<08:12,  4.51it/\u001b[A\n",
      "Training loss: 4.75e-02 lr: 8.03e-06:  84%|▊| 11628/13852 [43:33<08:12,  4.52it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 8.02e-06:  84%|▊| 11629/13852 [43:33<08:12,  4.51it/\u001b[A\n",
      "Training loss: 4.54e-02 lr: 8.02e-06:  84%|▊| 11630/13852 [43:33<08:12,  4.51it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.90e-02 lr: 8.02e-06:  84%|▊| 11631/13852 [43:33<08:11,  4.52it/\u001b[A\n",
      "Training loss: 4.47e-02 lr: 8.01e-06:  84%|▊| 11632/13852 [43:34<08:09,  4.53it/\u001b[A\n",
      "Training loss: 3.51e-02 lr: 8.01e-06:  84%|▊| 11633/13852 [43:34<08:07,  4.55it/\u001b[A\n",
      "Training loss: 2.61e-02 lr: 8.01e-06:  84%|▊| 11634/13852 [43:34<08:06,  4.56it/\u001b[A\n",
      "Training loss: 2.97e-02 lr: 8.00e-06:  84%|▊| 11635/13852 [43:34<08:09,  4.53it/\u001b[A\n",
      "Training loss: 3.20e-02 lr: 8.00e-06:  84%|▊| 11636/13852 [43:35<08:09,  4.53it/\u001b[A\n",
      "Training loss: 2.49e-02 lr: 8.00e-06:  84%|▊| 11637/13852 [43:35<08:09,  4.53it/\u001b[A\n",
      "Training loss: 4.01e-02 lr: 7.99e-06:  84%|▊| 11638/13852 [43:35<08:09,  4.52it/\u001b[A\n",
      "Training loss: 3.49e-02 lr: 7.99e-06:  84%|▊| 11639/13852 [43:35<08:09,  4.52it/\u001b[A\n",
      "Training loss: 9.85e-02 lr: 7.98e-06:  84%|▊| 11640/13852 [43:35<08:09,  4.52it/\u001b[A\n",
      "Training loss: 7.21e-02 lr: 7.98e-06:  84%|▊| 11641/13852 [43:36<08:08,  4.52it/\u001b[A\n",
      "Training loss: 6.45e-02 lr: 7.98e-06:  84%|▊| 11642/13852 [43:36<08:08,  4.53it/\u001b[A\n",
      "Training loss: 5.36e-02 lr: 7.97e-06:  84%|▊| 11643/13852 [43:36<08:09,  4.52it/\u001b[A\n",
      "Training loss: 3.84e-02 lr: 7.97e-06:  84%|▊| 11644/13852 [43:36<08:08,  4.52it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 7.97e-06:  84%|▊| 11645/13852 [43:37<08:05,  4.55it/\u001b[A\n",
      "Training loss: 2.60e-02 lr: 7.96e-06:  84%|▊| 11646/13852 [43:37<08:14,  4.46it/\u001b[A\n",
      "Training loss: 2.03e-02 lr: 7.96e-06:  84%|▊| 11647/13852 [43:37<08:24,  4.37it/\u001b[A\n",
      "Training loss: 3.32e-02 lr: 7.96e-06:  84%|▊| 11648/13852 [43:37<08:28,  4.33it/\u001b[A\n",
      "Training loss: 2.68e-02 lr: 7.95e-06:  84%|▊| 11649/13852 [43:37<08:23,  4.37it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 7.95e-06:  84%|▊| 11650/13852 [43:38<08:18,  4.41it/\u001b[A\n",
      "Training loss: 3.92e-02 lr: 7.95e-06:  84%|▊| 11651/13852 [43:38<08:14,  4.45it/\u001b[A\n",
      "Training loss: 2.98e-02 lr: 7.94e-06:  84%|▊| 11652/13852 [43:38<08:12,  4.46it/\u001b[A\n",
      "Training loss: 2.86e-02 lr: 7.94e-06:  84%|▊| 11653/13852 [43:38<08:10,  4.48it/\u001b[A\n",
      "Training loss: 2.48e-02 lr: 7.93e-06:  84%|▊| 11654/13852 [43:39<08:09,  4.49it/\u001b[A\n",
      "Training loss: 6.35e-02 lr: 7.93e-06:  84%|▊| 11655/13852 [43:39<08:08,  4.50it/\u001b[A\n",
      "Training loss: 8.00e-02 lr: 7.93e-06:  84%|▊| 11656/13852 [43:39<08:04,  4.53it/\u001b[A\n",
      "Training loss: 1.07e-01 lr: 7.92e-06:  84%|▊| 11657/13852 [43:39<08:02,  4.55it/\u001b[A\n",
      "Training loss: 7.84e-02 lr: 7.92e-06:  84%|▊| 11658/13852 [43:39<08:03,  4.54it/\u001b[A\n",
      "Training loss: 7.10e-02 lr: 7.92e-06:  84%|▊| 11659/13852 [43:40<08:03,  4.53it/\u001b[A\n",
      "Training loss: 5.32e-02 lr: 7.91e-06:  84%|▊| 11660/13852 [43:40<08:03,  4.54it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 7.91e-06:  84%|▊| 11661/13852 [43:40<08:02,  4.54it/\u001b[A\n",
      "Training loss: 3.03e-02 lr: 7.91e-06:  84%|▊| 11662/13852 [43:40<08:03,  4.53it/\u001b[A\n",
      "Training loss: 2.36e-02 lr: 7.90e-06:  84%|▊| 11663/13852 [43:41<08:02,  4.53it/\u001b[A\n",
      "Training loss: 2.36e-02 lr: 7.90e-06:  84%|▊| 11664/13852 [43:41<08:04,  4.52it/\u001b[A\n",
      "Training loss: 1.97e-02 lr: 7.89e-06:  84%|▊| 11665/13852 [43:41<08:04,  4.52it/\u001b[A\n",
      "Training loss: 2.19e-02 lr: 7.89e-06:  84%|▊| 11666/13852 [43:41<08:03,  4.52it/\u001b[A\n",
      "Training loss: 1.67e-02 lr: 7.89e-06:  84%|▊| 11667/13852 [43:41<08:02,  4.52it/\u001b[A\n",
      "Training loss: 1.05e-01 lr: 7.88e-06:  84%|▊| 11668/13852 [43:42<08:02,  4.52it/\u001b[A\n",
      "Training loss: 8.25e-02 lr: 7.88e-06:  84%|▊| 11669/13852 [43:42<08:00,  4.54it/\u001b[A\n",
      "Training loss: 6.21e-02 lr: 7.88e-06:  84%|▊| 11670/13852 [43:42<08:04,  4.50it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 7.87e-06:  84%|▊| 11671/13852 [43:42<08:03,  4.51it/\u001b[A\n",
      "Training loss: 4.00e-02 lr: 7.87e-06:  84%|▊| 11672/13852 [43:43<08:03,  4.51it/\u001b[A\n",
      "Training loss: 3.16e-02 lr: 7.87e-06:  84%|▊| 11673/13852 [43:43<08:01,  4.52it/\u001b[A\n",
      "Training loss: 3.32e-02 lr: 7.86e-06:  84%|▊| 11674/13852 [43:43<08:00,  4.54it/\u001b[A\n",
      "Training loss: 2.95e-02 lr: 7.86e-06:  84%|▊| 11675/13852 [43:43<07:59,  4.54it/\u001b[A\n",
      "Training loss: 2.72e-02 lr: 7.86e-06:  84%|▊| 11676/13852 [43:43<08:00,  4.53it/\u001b[A\n",
      "Training loss: 2.00e-02 lr: 7.85e-06:  84%|▊| 11677/13852 [43:44<08:00,  4.53it/\u001b[A\n",
      "Training loss: 1.62e-02 lr: 7.85e-06:  84%|▊| 11678/13852 [43:44<08:00,  4.52it/\u001b[A\n",
      "Training loss: 1.32e-02 lr: 7.84e-06:  84%|▊| 11679/13852 [43:44<08:01,  4.51it/\u001b[A\n",
      "Training loss: 1.87e-02 lr: 7.84e-06:  84%|▊| 11680/13852 [43:44<08:01,  4.51it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 7.84e-06:  84%|▊| 11681/13852 [43:45<07:59,  4.53it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 7.83e-06:  84%|▊| 11682/13852 [43:45<07:57,  4.55it/\u001b[A\n",
      "Training loss: 2.90e-02 lr: 7.83e-06:  84%|▊| 11683/13852 [43:45<07:57,  4.54it/\u001b[A\n",
      "Training loss: 2.34e-02 lr: 7.83e-06:  84%|▊| 11684/13852 [43:45<07:57,  4.54it/\u001b[A\n",
      "Training loss: 2.62e-02 lr: 7.82e-06:  84%|▊| 11685/13852 [43:45<07:58,  4.53it/\u001b[A\n",
      "Training loss: 3.56e-02 lr: 7.82e-06:  84%|▊| 11686/13852 [43:46<07:58,  4.53it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 7.82e-06:  84%|▊| 11687/13852 [43:46<07:58,  4.52it/\u001b[A\n",
      "Training loss: 4.84e-02 lr: 7.81e-06:  84%|▊| 11688/13852 [43:46<08:01,  4.50it/\u001b[A\n",
      "Training loss: 4.81e-02 lr: 7.81e-06:  84%|▊| 11689/13852 [43:46<08:00,  4.50it/\u001b[A\n",
      "Training loss: 3.42e-02 lr: 7.80e-06:  84%|▊| 11690/13852 [43:47<08:00,  4.50it/\u001b[A\n",
      "Training loss: 3.08e-02 lr: 7.80e-06:  84%|▊| 11691/13852 [43:47<08:02,  4.48it/\u001b[A\n",
      "Training loss: 3.52e-02 lr: 7.80e-06:  84%|▊| 11692/13852 [43:47<08:00,  4.49it/\u001b[A\n",
      "Training loss: 5.49e-02 lr: 7.79e-06:  84%|▊| 11693/13852 [43:47<07:57,  4.52it/\u001b[A\n",
      "Training loss: 1.36e-01 lr: 7.79e-06:  84%|▊| 11694/13852 [43:47<07:54,  4.54it/\u001b[A\n",
      "Training loss: 1.32e-01 lr: 7.79e-06:  84%|▊| 11695/13852 [43:48<07:57,  4.51it/\u001b[A\n",
      "Training loss: 9.52e-02 lr: 7.78e-06:  84%|▊| 11696/13852 [43:48<07:57,  4.52it/\u001b[A\n",
      "Training loss: 6.95e-02 lr: 7.78e-06:  84%|▊| 11697/13852 [43:48<07:57,  4.51it/\u001b[A\n",
      "Training loss: 5.87e-02 lr: 7.78e-06:  84%|▊| 11698/13852 [43:48<07:57,  4.51it/\u001b[A\n",
      "Training loss: 5.58e-02 lr: 7.77e-06:  84%|▊| 11699/13852 [43:49<07:57,  4.51it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 7.77e-06:  84%|▊| 11700/13852 [43:49<07:57,  4.51it/\u001b[A\n",
      "Training loss: 3.66e-02 lr: 7.76e-06:  84%|▊| 11701/13852 [43:49<08:08,  4.41it/\u001b[A\n",
      "Training loss: 4.26e-02 lr: 7.76e-06:  84%|▊| 11702/13852 [43:49<08:04,  4.44it/\u001b[A\n",
      "Training loss: 3.98e-02 lr: 7.76e-06:  84%|▊| 11703/13852 [43:49<08:01,  4.46it/\u001b[A\n",
      "Training loss: 3.27e-02 lr: 7.75e-06:  84%|▊| 11704/13852 [43:50<08:10,  4.38it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 7.75e-06:  85%|▊| 11705/13852 [43:50<08:16,  4.32it/\u001b[A\n",
      "Training loss: 3.52e-02 lr: 7.75e-06:  85%|▊| 11706/13852 [43:50<08:09,  4.38it/\u001b[A\n",
      "Training loss: 9.54e-02 lr: 7.74e-06:  85%|▊| 11707/13852 [43:50<08:05,  4.42it/\u001b[A\n",
      "Training loss: 8.45e-02 lr: 7.74e-06:  85%|▊| 11708/13852 [43:51<08:01,  4.45it/\u001b[A\n",
      "Training loss: 7.26e-02 lr: 7.74e-06:  85%|▊| 11709/13852 [43:51<07:59,  4.47it/\u001b[A\n",
      "Training loss: 5.29e-02 lr: 7.73e-06:  85%|▊| 11710/13852 [43:51<07:58,  4.48it/\u001b[A\n",
      "Training loss: 4.04e-02 lr: 7.73e-06:  85%|▊| 11711/13852 [43:51<07:56,  4.49it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 7.73e-06:  85%|▊| 11712/13852 [43:51<07:55,  4.50it/\u001b[A\n",
      "Training loss: 7.14e-02 lr: 7.72e-06:  85%|▊| 11713/13852 [43:52<07:56,  4.49it/\u001b[A\n",
      "Training loss: 5.99e-02 lr: 7.72e-06:  85%|▊| 11714/13852 [43:52<07:53,  4.52it/\u001b[A\n",
      "Training loss: 4.27e-02 lr: 7.71e-06:  85%|▊| 11715/13852 [43:52<07:50,  4.54it/\u001b[A\n",
      "Training loss: 3.14e-02 lr: 7.71e-06:  85%|▊| 11716/13852 [43:52<07:49,  4.55it/\u001b[A\n",
      "Training loss: 4.70e-02 lr: 7.71e-06:  85%|▊| 11717/13852 [43:53<07:56,  4.48it/\u001b[A\n",
      "Training loss: 1.02e-01 lr: 7.70e-06:  85%|▊| 11718/13852 [43:53<07:56,  4.48it/\u001b[A\n",
      "Training loss: 7.35e-02 lr: 7.70e-06:  85%|▊| 11719/13852 [43:53<07:54,  4.49it/\u001b[A\n",
      "Training loss: 6.98e-02 lr: 7.70e-06:  85%|▊| 11720/13852 [43:53<07:53,  4.51it/\u001b[A\n",
      "Training loss: 1.02e-01 lr: 7.69e-06:  85%|▊| 11721/13852 [43:53<07:52,  4.51it/\u001b[A\n",
      "Training loss: 7.30e-02 lr: 7.69e-06:  85%|▊| 11722/13852 [43:54<07:51,  4.52it/\u001b[A\n",
      "Training loss: 1.10e-01 lr: 7.69e-06:  85%|▊| 11723/13852 [43:54<08:04,  4.39it/\u001b[A\n",
      "Training loss: 9.69e-02 lr: 7.68e-06:  85%|▊| 11724/13852 [43:54<08:00,  4.43it/\u001b[A\n",
      "Training loss: 8.15e-02 lr: 7.68e-06:  85%|▊| 11725/13852 [43:54<07:57,  4.45it/\u001b[A\n",
      "Training loss: 8.26e-02 lr: 7.67e-06:  85%|▊| 11726/13852 [43:55<07:53,  4.49it/\u001b[A\n",
      "Training loss: 9.37e-02 lr: 7.67e-06:  85%|▊| 11727/13852 [43:55<07:50,  4.52it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.43e-02 lr: 7.67e-06:  85%|▊| 11728/13852 [43:55<07:50,  4.51it/\u001b[A\n",
      "Training loss: 5.40e-02 lr: 7.66e-06:  85%|▊| 11729/13852 [43:55<07:50,  4.51it/\u001b[A\n",
      "Training loss: 7.41e-02 lr: 7.66e-06:  85%|▊| 11730/13852 [43:55<07:49,  4.52it/\u001b[A\n",
      "Training loss: 5.41e-02 lr: 7.66e-06:  85%|▊| 11731/13852 [43:56<07:48,  4.53it/\u001b[A\n",
      "Training loss: 4.08e-02 lr: 7.65e-06:  85%|▊| 11732/13852 [43:56<07:48,  4.52it/\u001b[A\n",
      "Training loss: 3.11e-02 lr: 7.65e-06:  85%|▊| 11733/13852 [43:56<07:48,  4.52it/\u001b[A\n",
      "Training loss: 2.80e-02 lr: 7.65e-06:  85%|▊| 11734/13852 [43:56<07:48,  4.52it/\u001b[A\n",
      "Training loss: 2.74e-02 lr: 7.64e-06:  85%|▊| 11735/13852 [43:57<07:48,  4.51it/\u001b[A\n",
      "Training loss: 2.32e-02 lr: 7.64e-06:  85%|▊| 11736/13852 [43:57<07:52,  4.48it/\u001b[A\n",
      "Training loss: 2.45e-02 lr: 7.63e-06:  85%|▊| 11737/13852 [43:57<07:50,  4.49it/\u001b[A\n",
      "Training loss: 2.49e-02 lr: 7.63e-06:  85%|▊| 11738/13852 [43:57<07:47,  4.52it/\u001b[A\n",
      "Training loss: 2.22e-02 lr: 7.63e-06:  85%|▊| 11739/13852 [43:57<07:45,  4.54it/\u001b[A\n",
      "Training loss: 1.97e-02 lr: 7.62e-06:  85%|▊| 11740/13852 [43:58<07:48,  4.51it/\u001b[A\n",
      "Training loss: 4.77e-02 lr: 7.62e-06:  85%|▊| 11741/13852 [43:58<07:47,  4.51it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 7.62e-06:  85%|▊| 11742/13852 [43:58<07:47,  4.52it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 7.61e-06:  85%|▊| 11743/13852 [43:58<07:46,  4.52it/\u001b[A\n",
      "Training loss: 5.52e-02 lr: 7.61e-06:  85%|▊| 11744/13852 [43:59<07:49,  4.49it/\u001b[A\n",
      "Training loss: 7.89e-02 lr: 7.61e-06:  85%|▊| 11745/13852 [43:59<07:50,  4.48it/\u001b[A\n",
      "Training loss: 5.97e-02 lr: 7.60e-06:  85%|▊| 11746/13852 [43:59<07:49,  4.49it/\u001b[A\n",
      "Training loss: 4.39e-02 lr: 7.60e-06:  85%|▊| 11747/13852 [43:59<07:48,  4.49it/\u001b[A\n",
      "Training loss: 3.52e-02 lr: 7.60e-06:  85%|▊| 11748/13852 [43:59<07:48,  4.49it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 7.59e-06:  85%|▊| 11749/13852 [44:00<07:45,  4.51it/\u001b[A\n",
      "Training loss: 5.39e-02 lr: 7.59e-06:  85%|▊| 11750/13852 [44:00<07:43,  4.54it/\u001b[A\n",
      "Training loss: 3.92e-02 lr: 7.58e-06:  85%|▊| 11751/13852 [44:00<07:41,  4.56it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 7.58e-06:  85%|▊| 11752/13852 [44:00<07:46,  4.51it/\u001b[A\n",
      "Training loss: 3.73e-02 lr: 7.58e-06:  85%|▊| 11753/13852 [44:01<07:45,  4.50it/\u001b[A\n",
      "Training loss: 5.07e-02 lr: 7.57e-06:  85%|▊| 11754/13852 [44:01<07:46,  4.50it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 7.57e-06:  85%|▊| 11755/13852 [44:01<07:46,  4.50it/\u001b[A\n",
      "Training loss: 5.13e-02 lr: 7.57e-06:  85%|▊| 11756/13852 [44:01<07:46,  4.49it/\u001b[A\n",
      "Training loss: 6.04e-02 lr: 7.56e-06:  85%|▊| 11757/13852 [44:01<07:46,  4.49it/\u001b[A\n",
      "Training loss: 5.10e-02 lr: 7.56e-06:  85%|▊| 11758/13852 [44:02<07:46,  4.49it/\u001b[A\n",
      "Training loss: 4.85e-02 lr: 7.56e-06:  85%|▊| 11759/13852 [44:02<07:45,  4.49it/\u001b[A\n",
      "Training loss: 8.45e-02 lr: 7.55e-06:  85%|▊| 11760/13852 [44:02<07:45,  4.49it/\u001b[A\n",
      "Training loss: 1.56e-01 lr: 7.55e-06:  85%|▊| 11761/13852 [44:02<07:44,  4.50it/\u001b[A\n",
      "Training loss: 1.17e-01 lr: 7.54e-06:  85%|▊| 11762/13852 [44:03<07:41,  4.53it/\u001b[A\n",
      "Training loss: 8.27e-02 lr: 7.54e-06:  85%|▊| 11763/13852 [44:03<07:39,  4.54it/\u001b[A\n",
      "Training loss: 5.87e-02 lr: 7.54e-06:  85%|▊| 11764/13852 [44:03<07:42,  4.52it/\u001b[A\n",
      "Training loss: 6.05e-02 lr: 7.53e-06:  85%|▊| 11765/13852 [44:03<07:42,  4.52it/\u001b[A\n",
      "Training loss: 5.17e-02 lr: 7.53e-06:  85%|▊| 11766/13852 [44:03<07:41,  4.52it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 7.53e-06:  85%|▊| 11767/13852 [44:04<07:42,  4.51it/\u001b[A\n",
      "Training loss: 7.25e-02 lr: 7.52e-06:  85%|▊| 11768/13852 [44:04<07:56,  4.37it/\u001b[A\n",
      "Training loss: 7.16e-02 lr: 7.52e-06:  85%|▊| 11769/13852 [44:04<08:06,  4.28it/\u001b[A\n",
      "Training loss: 5.76e-02 lr: 7.52e-06:  85%|▊| 11770/13852 [44:04<08:00,  4.33it/\u001b[A\n",
      "Training loss: 5.79e-02 lr: 7.51e-06:  85%|▊| 11771/13852 [44:05<07:56,  4.37it/\u001b[A\n",
      "Training loss: 4.44e-02 lr: 7.51e-06:  85%|▊| 11772/13852 [44:05<07:54,  4.38it/\u001b[A\n",
      "Training loss: 3.70e-02 lr: 7.50e-06:  85%|▊| 11773/13852 [44:05<07:53,  4.39it/\u001b[A\n",
      "Training loss: 5.46e-02 lr: 7.50e-06:  85%|▊| 11774/13852 [44:05<07:52,  4.39it/\u001b[A\n",
      "Training loss: 5.93e-02 lr: 7.50e-06:  85%|▊| 11775/13852 [44:06<07:50,  4.42it/\u001b[A\n",
      "Training loss: 4.78e-02 lr: 7.49e-06:  85%|▊| 11776/13852 [44:06<07:48,  4.43it/\u001b[A\n",
      "Training loss: 7.21e-02 lr: 7.49e-06:  85%|▊| 11777/13852 [44:06<07:47,  4.44it/\u001b[A\n",
      "Training loss: 5.38e-02 lr: 7.49e-06:  85%|▊| 11778/13852 [44:06<08:00,  4.32it/\u001b[A\n",
      "Training loss: 4.69e-02 lr: 7.48e-06:  85%|▊| 11779/13852 [44:06<08:04,  4.28it/\u001b[A\n",
      "Training loss: 9.11e-02 lr: 7.48e-06:  85%|▊| 11780/13852 [44:07<07:58,  4.33it/\u001b[A\n",
      "Training loss: 8.14e-02 lr: 7.48e-06:  85%|▊| 11781/13852 [44:07<07:55,  4.35it/\u001b[A\n",
      "Training loss: 6.50e-02 lr: 7.47e-06:  85%|▊| 11782/13852 [44:07<07:54,  4.37it/\u001b[A\n",
      "Training loss: 5.12e-02 lr: 7.47e-06:  85%|▊| 11783/13852 [44:07<07:53,  4.37it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 7.47e-06:  85%|▊| 11784/13852 [44:08<08:18,  4.15it/\u001b[A\n",
      "Training loss: 2.79e-02 lr: 7.46e-06:  85%|▊| 11785/13852 [44:08<08:31,  4.04it/\u001b[A\n",
      "Training loss: 3.07e-02 lr: 7.46e-06:  85%|▊| 11786/13852 [44:08<08:27,  4.07it/\u001b[A\n",
      "Training loss: 2.29e-02 lr: 7.45e-06:  85%|▊| 11787/13852 [44:08<08:24,  4.09it/\u001b[A\n",
      "Training loss: 2.08e-02 lr: 7.45e-06:  85%|▊| 11788/13852 [44:09<08:24,  4.09it/\u001b[A\n",
      "Training loss: 2.04e-02 lr: 7.45e-06:  85%|▊| 11789/13852 [44:09<08:23,  4.10it/\u001b[A\n",
      "Training loss: 5.39e-02 lr: 7.44e-06:  85%|▊| 11790/13852 [44:09<08:20,  4.12it/\u001b[A\n",
      "Training loss: 4.78e-02 lr: 7.44e-06:  85%|▊| 11791/13852 [44:09<08:17,  4.14it/\u001b[A\n",
      "Training loss: 9.13e-02 lr: 7.44e-06:  85%|▊| 11792/13852 [44:10<08:17,  4.14it/\u001b[A\n",
      "Training loss: 1.18e-01 lr: 7.43e-06:  85%|▊| 11793/13852 [44:10<08:16,  4.15it/\u001b[A\n",
      "Training loss: 8.35e-02 lr: 7.43e-06:  85%|▊| 11794/13852 [44:10<08:17,  4.14it/\u001b[A\n",
      "Training loss: 6.06e-02 lr: 7.43e-06:  85%|▊| 11795/13852 [44:10<08:16,  4.14it/\u001b[A\n",
      "Training loss: 6.88e-02 lr: 7.42e-06:  85%|▊| 11796/13852 [44:11<08:15,  4.15it/\u001b[A\n",
      "Training loss: 6.12e-02 lr: 7.42e-06:  85%|▊| 11797/13852 [44:11<08:14,  4.15it/\u001b[A\n",
      "Training loss: 5.71e-02 lr: 7.41e-06:  85%|▊| 11798/13852 [44:11<08:14,  4.16it/\u001b[A\n",
      "Training loss: 4.07e-02 lr: 7.41e-06:  85%|▊| 11799/13852 [44:11<08:13,  4.16it/\u001b[A\n",
      "Training loss: 3.75e-02 lr: 7.41e-06:  85%|▊| 11800/13852 [44:12<08:14,  4.15it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 7.40e-06:  85%|▊| 11801/13852 [44:12<08:18,  4.11it/\u001b[A\n",
      "Training loss: 3.42e-02 lr: 7.40e-06:  85%|▊| 11802/13852 [44:12<08:16,  4.13it/\u001b[A\n",
      "Training loss: 8.95e-02 lr: 7.40e-06:  85%|▊| 11803/13852 [44:12<08:16,  4.12it/\u001b[A\n",
      "Training loss: 8.39e-02 lr: 7.39e-06:  85%|▊| 11804/13852 [44:12<08:15,  4.13it/\u001b[A\n",
      "Training loss: 6.08e-02 lr: 7.39e-06:  85%|▊| 11805/13852 [44:13<08:13,  4.15it/\u001b[A\n",
      "Training loss: 4.84e-02 lr: 7.39e-06:  85%|▊| 11806/13852 [44:13<08:12,  4.16it/\u001b[A\n",
      "Training loss: 6.92e-02 lr: 7.38e-06:  85%|▊| 11807/13852 [44:13<08:11,  4.16it/\u001b[A\n",
      "Training loss: 6.73e-02 lr: 7.38e-06:  85%|▊| 11808/13852 [44:13<08:09,  4.18it/\u001b[A\n",
      "Training loss: 5.25e-02 lr: 7.37e-06:  85%|▊| 11809/13852 [44:14<08:11,  4.15it/\u001b[A\n",
      "Training loss: 5.62e-02 lr: 7.37e-06:  85%|▊| 11810/13852 [44:14<08:10,  4.17it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 7.37e-06:  85%|▊| 11811/13852 [44:14<08:08,  4.18it/\u001b[A\n",
      "Training loss: 4.13e-02 lr: 7.36e-06:  85%|▊| 11812/13852 [44:14<08:07,  4.18it/\u001b[A\n",
      "Training loss: 3.29e-02 lr: 7.36e-06:  85%|▊| 11813/13852 [44:15<08:07,  4.18it/\u001b[A\n",
      "Training loss: 2.56e-02 lr: 7.36e-06:  85%|▊| 11814/13852 [44:15<08:07,  4.18it/\u001b[A\n",
      "Training loss: 2.55e-02 lr: 7.35e-06:  85%|▊| 11815/13852 [44:15<08:07,  4.18it/\u001b[A\n",
      "Training loss: 3.70e-02 lr: 7.35e-06:  85%|▊| 11816/13852 [44:15<08:08,  4.17it/\u001b[A\n",
      "Training loss: 3.73e-02 lr: 7.35e-06:  85%|▊| 11817/13852 [44:16<08:07,  4.18it/\u001b[A\n",
      "Training loss: 8.41e-02 lr: 7.34e-06:  85%|▊| 11818/13852 [44:16<08:07,  4.17it/\u001b[A\n",
      "Training loss: 6.01e-02 lr: 7.34e-06:  85%|▊| 11819/13852 [44:16<08:07,  4.17it/\u001b[A\n",
      "Training loss: 4.41e-02 lr: 7.34e-06:  85%|▊| 11820/13852 [44:16<08:05,  4.18it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 7.33e-06:  85%|▊| 11821/13852 [44:17<08:06,  4.17it/\u001b[A\n",
      "Training loss: 2.37e-02 lr: 7.33e-06:  85%|▊| 11822/13852 [44:17<08:09,  4.14it/\u001b[A\n",
      "Training loss: 6.78e-02 lr: 7.32e-06:  85%|▊| 11823/13852 [44:17<08:10,  4.14it/\u001b[A\n",
      "Training loss: 1.13e-01 lr: 7.32e-06:  85%|▊| 11824/13852 [44:17<08:08,  4.15it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.34e-02 lr: 7.32e-06:  85%|▊| 11825/13852 [44:18<08:07,  4.16it/\u001b[A\n",
      "Training loss: 7.49e-02 lr: 7.31e-06:  85%|▊| 11826/13852 [44:18<08:04,  4.18it/\u001b[A\n",
      "Training loss: 6.03e-02 lr: 7.31e-06:  85%|▊| 11827/13852 [44:18<08:07,  4.15it/\u001b[A\n",
      "Training loss: 1.09e-01 lr: 7.31e-06:  85%|▊| 11828/13852 [44:18<08:06,  4.16it/\u001b[A\n",
      "Training loss: 9.02e-02 lr: 7.30e-06:  85%|▊| 11829/13852 [44:18<08:05,  4.17it/\u001b[A\n",
      "Training loss: 8.13e-02 lr: 7.30e-06:  85%|▊| 11830/13852 [44:19<08:07,  4.15it/\u001b[A\n",
      "Training loss: 7.12e-02 lr: 7.30e-06:  85%|▊| 11831/13852 [44:19<08:04,  4.17it/\u001b[A\n",
      "Training loss: 5.47e-02 lr: 7.29e-06:  85%|▊| 11832/13852 [44:19<08:02,  4.19it/\u001b[A\n",
      "Training loss: 5.06e-02 lr: 7.29e-06:  85%|▊| 11833/13852 [44:19<08:02,  4.18it/\u001b[A\n",
      "Training loss: 4.50e-02 lr: 7.28e-06:  85%|▊| 11834/13852 [44:20<08:03,  4.18it/\u001b[A\n",
      "Training loss: 8.76e-02 lr: 7.28e-06:  85%|▊| 11835/13852 [44:20<08:02,  4.18it/\u001b[A\n",
      "Training loss: 6.69e-02 lr: 7.28e-06:  85%|▊| 11836/13852 [44:20<08:02,  4.18it/\u001b[A\n",
      "Training loss: 5.63e-02 lr: 7.27e-06:  85%|▊| 11837/13852 [44:20<08:03,  4.17it/\u001b[A\n",
      "Training loss: 4.96e-02 lr: 7.27e-06:  85%|▊| 11838/13852 [44:21<08:01,  4.19it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 7.27e-06:  85%|▊| 11839/13852 [44:21<08:06,  4.14it/\u001b[A\n",
      "Training loss: 6.15e-02 lr: 7.26e-06:  85%|▊| 11840/13852 [44:21<08:05,  4.15it/\u001b[A\n",
      "Training loss: 4.95e-02 lr: 7.26e-06:  85%|▊| 11841/13852 [44:21<08:03,  4.16it/\u001b[A\n",
      "Training loss: 4.09e-02 lr: 7.26e-06:  85%|▊| 11842/13852 [44:22<08:02,  4.17it/\u001b[A\n",
      "Training loss: 6.10e-02 lr: 7.25e-06:  85%|▊| 11843/13852 [44:22<08:02,  4.17it/\u001b[A\n",
      "Training loss: 4.89e-02 lr: 7.25e-06:  86%|▊| 11844/13852 [44:22<08:04,  4.15it/\u001b[A\n",
      "Training loss: 6.32e-02 lr: 7.24e-06:  86%|▊| 11845/13852 [44:22<08:03,  4.15it/\u001b[A\n",
      "Training loss: 5.65e-02 lr: 7.24e-06:  86%|▊| 11846/13852 [44:23<08:02,  4.16it/\u001b[A\n",
      "Training loss: 4.86e-02 lr: 7.24e-06:  86%|▊| 11847/13852 [44:23<08:01,  4.16it/\u001b[A\n",
      "Training loss: 5.29e-02 lr: 7.23e-06:  86%|▊| 11848/13852 [44:23<08:02,  4.16it/\u001b[A\n",
      "Training loss: 4.61e-02 lr: 7.23e-06:  86%|▊| 11849/13852 [44:23<08:00,  4.17it/\u001b[A\n",
      "Training loss: 3.59e-02 lr: 7.23e-06:  86%|▊| 11850/13852 [44:24<07:59,  4.17it/\u001b[A\n",
      "Training loss: 3.68e-02 lr: 7.22e-06:  86%|▊| 11851/13852 [44:24<07:58,  4.18it/\u001b[A\n",
      "Training loss: 3.56e-02 lr: 7.22e-06:  86%|▊| 11852/13852 [44:24<07:58,  4.18it/\u001b[A\n",
      "Training loss: 3.13e-02 lr: 7.22e-06:  86%|▊| 11853/13852 [44:24<07:57,  4.18it/\u001b[A\n",
      "Training loss: 2.45e-02 lr: 7.21e-06:  86%|▊| 11854/13852 [44:24<07:57,  4.18it/\u001b[A\n",
      "Training loss: 1.99e-02 lr: 7.21e-06:  86%|▊| 11855/13852 [44:25<07:55,  4.20it/\u001b[A\n",
      "Training loss: 1.46e-02 lr: 7.21e-06:  86%|▊| 11856/13852 [44:25<07:56,  4.19it/\u001b[A\n",
      "Training loss: 1.42e-02 lr: 7.20e-06:  86%|▊| 11857/13852 [44:25<07:56,  4.19it/\u001b[A\n",
      "Training loss: 2.48e-02 lr: 7.20e-06:  86%|▊| 11858/13852 [44:25<07:57,  4.17it/\u001b[A\n",
      "Training loss: 5.30e-02 lr: 7.19e-06:  86%|▊| 11859/13852 [44:26<07:57,  4.17it/\u001b[A\n",
      "Training loss: 5.00e-02 lr: 7.19e-06:  86%|▊| 11860/13852 [44:26<07:57,  4.17it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 7.19e-06:  86%|▊| 11861/13852 [44:26<07:55,  4.19it/\u001b[A\n",
      "Training loss: 4.38e-02 lr: 7.18e-06:  86%|▊| 11862/13852 [44:26<07:55,  4.18it/\u001b[A\n",
      "Training loss: 6.17e-02 lr: 7.18e-06:  86%|▊| 11863/13852 [44:27<07:56,  4.17it/\u001b[A\n",
      "Training loss: 5.70e-02 lr: 7.18e-06:  86%|▊| 11864/13852 [44:27<07:57,  4.16it/\u001b[A\n",
      "Training loss: 7.03e-02 lr: 7.17e-06:  86%|▊| 11865/13852 [44:27<07:57,  4.16it/\u001b[A\n",
      "Training loss: 5.14e-02 lr: 7.17e-06:  86%|▊| 11866/13852 [44:27<07:56,  4.17it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 7.17e-06:  86%|▊| 11867/13852 [44:28<07:54,  4.18it/\u001b[A\n",
      "Training loss: 4.17e-02 lr: 7.16e-06:  86%|▊| 11868/13852 [44:28<07:55,  4.17it/\u001b[A\n",
      "Training loss: 4.18e-02 lr: 7.16e-06:  86%|▊| 11869/13852 [44:28<07:55,  4.17it/\u001b[A\n",
      "Training loss: 3.01e-02 lr: 7.15e-06:  86%|▊| 11870/13852 [44:28<07:55,  4.17it/\u001b[A\n",
      "Training loss: 6.48e-02 lr: 7.15e-06:  86%|▊| 11871/13852 [44:29<07:54,  4.17it/\u001b[A\n",
      "Training loss: 4.82e-02 lr: 7.15e-06:  86%|▊| 11872/13852 [44:29<07:59,  4.13it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 7.14e-06:  86%|▊| 11873/13852 [44:29<07:56,  4.15it/\u001b[A\n",
      "Training loss: 3.41e-02 lr: 7.14e-06:  86%|▊| 11874/13852 [44:29<07:55,  4.16it/\u001b[A\n",
      "Training loss: 6.84e-02 lr: 7.14e-06:  86%|▊| 11875/13852 [44:30<07:53,  4.18it/\u001b[A\n",
      "Training loss: 5.98e-02 lr: 7.13e-06:  86%|▊| 11876/13852 [44:30<07:52,  4.18it/\u001b[A\n",
      "Training loss: 5.06e-02 lr: 7.13e-06:  86%|▊| 11877/13852 [44:30<07:52,  4.18it/\u001b[A\n",
      "Training loss: 7.99e-02 lr: 7.13e-06:  86%|▊| 11878/13852 [44:30<07:50,  4.19it/\u001b[A\n",
      "Training loss: 6.13e-02 lr: 7.12e-06:  86%|▊| 11879/13852 [44:30<07:53,  4.16it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 7.12e-06:  86%|▊| 11880/13852 [44:31<07:54,  4.16it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 7.12e-06:  86%|▊| 11881/13852 [44:31<07:55,  4.14it/\u001b[A\n",
      "Training loss: 2.42e-02 lr: 7.11e-06:  86%|▊| 11882/13852 [44:31<07:53,  4.16it/\u001b[A\n",
      "Training loss: 6.88e-02 lr: 7.11e-06:  86%|▊| 11883/13852 [44:31<07:52,  4.17it/\u001b[A\n",
      "Training loss: 5.20e-02 lr: 7.10e-06:  86%|▊| 11884/13852 [44:32<07:51,  4.17it/\u001b[A\n",
      "Training loss: 5.35e-02 lr: 7.10e-06:  86%|▊| 11885/13852 [44:32<07:51,  4.17it/\u001b[A\n",
      "Training loss: 7.03e-02 lr: 7.10e-06:  86%|▊| 11886/13852 [44:32<07:51,  4.17it/\u001b[A\n",
      "Training loss: 6.20e-02 lr: 7.09e-06:  86%|▊| 11887/13852 [44:32<07:49,  4.18it/\u001b[A\n",
      "Training loss: 5.16e-02 lr: 7.09e-06:  86%|▊| 11888/13852 [44:33<07:49,  4.18it/\u001b[A\n",
      "Training loss: 6.68e-02 lr: 7.09e-06:  86%|▊| 11889/13852 [44:33<07:49,  4.18it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 7.08e-06:  86%|▊| 11890/13852 [44:33<07:50,  4.17it/\u001b[A\n",
      "Training loss: 3.53e-02 lr: 7.08e-06:  86%|▊| 11891/13852 [44:33<07:49,  4.17it/\u001b[A\n",
      "Training loss: 3.01e-02 lr: 7.08e-06:  86%|▊| 11892/13852 [44:34<07:49,  4.17it/\u001b[A\n",
      "Training loss: 4.64e-02 lr: 7.07e-06:  86%|▊| 11893/13852 [44:34<07:48,  4.18it/\u001b[A\n",
      "Training loss: 3.70e-02 lr: 7.07e-06:  86%|▊| 11894/13852 [44:34<07:49,  4.17it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 7.06e-06:  86%|▊| 11895/13852 [44:34<07:50,  4.16it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 7.06e-06:  86%|▊| 11896/13852 [44:35<07:48,  4.17it/\u001b[A\n",
      "Training loss: 7.07e-02 lr: 7.06e-06:  86%|▊| 11897/13852 [44:35<07:47,  4.18it/\u001b[A\n",
      "Training loss: 5.50e-02 lr: 7.05e-06:  86%|▊| 11898/13852 [44:35<07:47,  4.18it/\u001b[A\n",
      "Training loss: 5.25e-02 lr: 7.05e-06:  86%|▊| 11899/13852 [44:35<07:46,  4.19it/\u001b[A\n",
      "Training loss: 6.06e-02 lr: 7.05e-06:  86%|▊| 11900/13852 [44:36<07:46,  4.19it/\u001b[A\n",
      "Training loss: 5.07e-02 lr: 7.04e-06:  86%|▊| 11901/13852 [44:36<07:46,  4.19it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 7.04e-06:  86%|▊| 11902/13852 [44:36<07:44,  4.20it/\u001b[A\n",
      "Training loss: 5.29e-02 lr: 7.04e-06:  86%|▊| 11903/13852 [44:36<07:44,  4.20it/\u001b[A\n",
      "Training loss: 4.44e-02 lr: 7.03e-06:  86%|▊| 11904/13852 [44:36<07:44,  4.20it/\u001b[A\n",
      "Training loss: 4.23e-02 lr: 7.03e-06:  86%|▊| 11905/13852 [44:37<07:46,  4.17it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 7.02e-06:  86%|▊| 11906/13852 [44:37<07:52,  4.12it/\u001b[A\n",
      "Training loss: 2.55e-02 lr: 7.02e-06:  86%|▊| 11907/13852 [44:37<07:52,  4.11it/\u001b[A\n",
      "Training loss: 7.45e-02 lr: 7.02e-06:  86%|▊| 11908/13852 [44:37<07:51,  4.12it/\u001b[A\n",
      "Training loss: 1.10e-01 lr: 7.01e-06:  86%|▊| 11909/13852 [44:38<07:50,  4.13it/\u001b[A\n",
      "Training loss: 1.04e-01 lr: 7.01e-06:  86%|▊| 11910/13852 [44:38<07:47,  4.15it/\u001b[A\n",
      "Training loss: 7.80e-02 lr: 7.01e-06:  86%|▊| 11911/13852 [44:38<07:46,  4.16it/\u001b[A\n",
      "Training loss: 5.75e-02 lr: 7.00e-06:  86%|▊| 11912/13852 [44:38<07:44,  4.18it/\u001b[A\n",
      "Training loss: 5.16e-02 lr: 7.00e-06:  86%|▊| 11913/13852 [44:39<07:43,  4.18it/\u001b[A\n",
      "Training loss: 7.73e-02 lr: 7.00e-06:  86%|▊| 11914/13852 [44:39<07:48,  4.14it/\u001b[A\n",
      "Training loss: 6.02e-02 lr: 6.99e-06:  86%|▊| 11915/13852 [44:39<07:46,  4.15it/\u001b[A\n",
      "Training loss: 7.56e-02 lr: 6.99e-06:  86%|▊| 11916/13852 [44:39<07:45,  4.16it/\u001b[A\n",
      "Training loss: 7.37e-02 lr: 6.99e-06:  86%|▊| 11917/13852 [44:40<07:44,  4.17it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 6.98e-06:  86%|▊| 11918/13852 [44:40<07:45,  4.15it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 6.98e-06:  86%|▊| 11919/13852 [44:40<07:43,  4.17it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 6.97e-06:  86%|▊| 11920/13852 [44:40<07:43,  4.17it/\u001b[A\n",
      "Training loss: 6.09e-02 lr: 6.97e-06:  86%|▊| 11921/13852 [44:41<07:42,  4.18it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.18e-02 lr: 6.97e-06:  86%|▊| 11922/13852 [44:41<07:42,  4.17it/\u001b[A\n",
      "Training loss: 4.07e-02 lr: 6.96e-06:  86%|▊| 11923/13852 [44:41<07:41,  4.18it/\u001b[A\n",
      "Training loss: 3.60e-02 lr: 6.96e-06:  86%|▊| 11924/13852 [44:41<07:43,  4.16it/\u001b[A\n",
      "Training loss: 3.19e-02 lr: 6.96e-06:  86%|▊| 11925/13852 [44:42<07:40,  4.18it/\u001b[A\n",
      "Training loss: 2.97e-02 lr: 6.95e-06:  86%|▊| 11926/13852 [44:42<07:44,  4.14it/\u001b[A\n",
      "Training loss: 2.24e-02 lr: 6.95e-06:  86%|▊| 11927/13852 [44:42<07:45,  4.14it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 6.95e-06:  86%|▊| 11928/13852 [44:42<07:43,  4.15it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 6.94e-06:  86%|▊| 11929/13852 [44:42<07:42,  4.16it/\u001b[A\n",
      "Training loss: 2.19e-02 lr: 6.94e-06:  86%|▊| 11930/13852 [44:43<07:40,  4.17it/\u001b[A\n",
      "Training loss: 1.76e-02 lr: 6.93e-06:  86%|▊| 11931/13852 [44:43<07:38,  4.19it/\u001b[A\n",
      "Training loss: 2.49e-02 lr: 6.93e-06:  86%|▊| 11932/13852 [44:43<07:38,  4.19it/\u001b[A\n",
      "Training loss: 4.21e-02 lr: 6.93e-06:  86%|▊| 11933/13852 [44:43<07:38,  4.19it/\u001b[A\n",
      "Training loss: 6.51e-02 lr: 6.92e-06:  86%|▊| 11934/13852 [44:44<07:37,  4.19it/\u001b[A\n",
      "Training loss: 8.26e-02 lr: 6.92e-06:  86%|▊| 11935/13852 [44:44<07:39,  4.17it/\u001b[A\n",
      "Training loss: 7.09e-02 lr: 6.92e-06:  86%|▊| 11936/13852 [44:44<07:38,  4.18it/\u001b[A\n",
      "Training loss: 5.42e-02 lr: 6.91e-06:  86%|▊| 11937/13852 [44:44<07:36,  4.20it/\u001b[A\n",
      "Training loss: 6.47e-02 lr: 6.91e-06:  86%|▊| 11938/13852 [44:45<07:37,  4.19it/\u001b[A\n",
      "Training loss: 5.12e-02 lr: 6.91e-06:  86%|▊| 11939/13852 [44:45<07:37,  4.18it/\u001b[A\n",
      "Training loss: 3.71e-02 lr: 6.90e-06:  86%|▊| 11940/13852 [44:45<07:37,  4.18it/\u001b[A\n",
      "Training loss: 4.49e-02 lr: 6.90e-06:  86%|▊| 11941/13852 [44:45<07:37,  4.18it/\u001b[A\n",
      "Training loss: 3.32e-02 lr: 6.89e-06:  86%|▊| 11942/13852 [44:46<07:37,  4.18it/\u001b[A\n",
      "Training loss: 7.25e-02 lr: 6.89e-06:  86%|▊| 11943/13852 [44:46<07:36,  4.18it/\u001b[A\n",
      "Training loss: 7.78e-02 lr: 6.89e-06:  86%|▊| 11944/13852 [44:46<07:36,  4.18it/\u001b[A\n",
      "Training loss: 5.75e-02 lr: 6.88e-06:  86%|▊| 11945/13852 [44:46<07:37,  4.17it/\u001b[A\n",
      "Training loss: 7.74e-02 lr: 6.88e-06:  86%|▊| 11946/13852 [44:47<07:36,  4.18it/\u001b[A\n",
      "Training loss: 8.12e-02 lr: 6.88e-06:  86%|▊| 11947/13852 [44:47<07:40,  4.14it/\u001b[A\n",
      "Training loss: 1.02e-01 lr: 6.87e-06:  86%|▊| 11948/13852 [44:47<07:38,  4.15it/\u001b[A\n",
      "Training loss: 7.73e-02 lr: 6.87e-06:  86%|▊| 11949/13852 [44:47<07:37,  4.16it/\u001b[A\n",
      "Training loss: 5.69e-02 lr: 6.87e-06:  86%|▊| 11950/13852 [44:48<07:36,  4.17it/\u001b[A\n",
      "Training loss: 1.00e-01 lr: 6.86e-06:  86%|▊| 11951/13852 [44:48<07:35,  4.17it/\u001b[A\n",
      "Training loss: 7.27e-02 lr: 6.86e-06:  86%|▊| 11952/13852 [44:48<07:37,  4.16it/\u001b[A\n",
      "Training loss: 5.93e-02 lr: 6.86e-06:  86%|▊| 11953/13852 [44:48<07:35,  4.17it/\u001b[A\n",
      "Training loss: 4.92e-02 lr: 6.85e-06:  86%|▊| 11954/13852 [44:48<07:33,  4.18it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 6.85e-06:  86%|▊| 11955/13852 [44:49<07:35,  4.17it/\u001b[A\n",
      "Training loss: 3.69e-02 lr: 6.84e-06:  86%|▊| 11956/13852 [44:49<07:37,  4.15it/\u001b[A\n",
      "Training loss: 2.69e-02 lr: 6.84e-06:  86%|▊| 11957/13852 [44:49<07:35,  4.16it/\u001b[A\n",
      "Training loss: 2.66e-02 lr: 6.84e-06:  86%|▊| 11958/13852 [44:49<07:34,  4.17it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 6.83e-06:  86%|▊| 11959/13852 [44:50<07:33,  4.17it/\u001b[A\n",
      "Training loss: 2.85e-02 lr: 6.83e-06:  86%|▊| 11960/13852 [44:50<07:32,  4.19it/\u001b[A\n",
      "Training loss: 8.83e-02 lr: 6.83e-06:  86%|▊| 11961/13852 [44:50<07:31,  4.19it/\u001b[A\n",
      "Training loss: 7.83e-02 lr: 6.82e-06:  86%|▊| 11962/13852 [44:50<07:32,  4.17it/\u001b[A\n",
      "Training loss: 5.62e-02 lr: 6.82e-06:  86%|▊| 11963/13852 [44:51<07:32,  4.17it/\u001b[A\n",
      "Training loss: 4.84e-02 lr: 6.82e-06:  86%|▊| 11964/13852 [44:51<07:36,  4.14it/\u001b[A\n",
      "Training loss: 3.95e-02 lr: 6.81e-06:  86%|▊| 11965/13852 [44:51<07:34,  4.15it/\u001b[A\n",
      "Training loss: 3.46e-02 lr: 6.81e-06:  86%|▊| 11966/13852 [44:51<07:32,  4.17it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 6.80e-06:  86%|▊| 11967/13852 [44:52<07:31,  4.17it/\u001b[A\n",
      "Training loss: 3.11e-02 lr: 6.80e-06:  86%|▊| 11968/13852 [44:52<07:33,  4.16it/\u001b[A\n",
      "Training loss: 8.26e-02 lr: 6.80e-06:  86%|▊| 11969/13852 [44:52<07:32,  4.17it/\u001b[A\n",
      "Training loss: 6.11e-02 lr: 6.79e-06:  86%|▊| 11970/13852 [44:52<07:31,  4.17it/\u001b[A\n",
      "Training loss: 6.99e-02 lr: 6.79e-06:  86%|▊| 11971/13852 [44:53<07:31,  4.17it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 6.79e-06:  86%|▊| 11972/13852 [44:53<07:30,  4.18it/\u001b[A\n",
      "Training loss: 8.20e-02 lr: 6.78e-06:  86%|▊| 11973/13852 [44:53<07:30,  4.17it/\u001b[A\n",
      "Training loss: 6.36e-02 lr: 6.78e-06:  86%|▊| 11974/13852 [44:53<07:31,  4.16it/\u001b[A\n",
      "Training loss: 5.83e-02 lr: 6.78e-06:  86%|▊| 11975/13852 [44:54<07:30,  4.17it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 6.77e-06:  86%|▊| 11976/13852 [44:54<07:28,  4.18it/\u001b[A\n",
      "Training loss: 3.52e-02 lr: 6.77e-06:  86%|▊| 11977/13852 [44:54<07:28,  4.18it/\u001b[A\n",
      "Training loss: 3.02e-02 lr: 6.76e-06:  86%|▊| 11978/13852 [44:54<07:27,  4.19it/\u001b[A\n",
      "Training loss: 2.40e-02 lr: 6.76e-06:  86%|▊| 11979/13852 [44:54<07:28,  4.18it/\u001b[A\n",
      "Training loss: 4.86e-02 lr: 6.76e-06:  86%|▊| 11980/13852 [44:55<07:28,  4.18it/\u001b[A\n",
      "Training loss: 3.60e-02 lr: 6.75e-06:  86%|▊| 11981/13852 [44:55<07:27,  4.18it/\u001b[A\n",
      "Training loss: 2.76e-02 lr: 6.75e-06:  87%|▊| 11982/13852 [44:55<07:27,  4.18it/\u001b[A\n",
      "Training loss: 5.28e-02 lr: 6.75e-06:  87%|▊| 11983/13852 [44:55<07:27,  4.18it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 6.74e-06:  87%|▊| 11984/13852 [44:56<07:26,  4.18it/\u001b[A\n",
      "Training loss: 2.84e-02 lr: 6.74e-06:  87%|▊| 11985/13852 [44:56<07:26,  4.18it/\u001b[A\n",
      "Training loss: 2.45e-02 lr: 6.74e-06:  87%|▊| 11986/13852 [44:56<07:27,  4.17it/\u001b[A\n",
      "Training loss: 3.32e-02 lr: 6.73e-06:  87%|▊| 11987/13852 [44:56<07:26,  4.18it/\u001b[A\n",
      "Training loss: 7.39e-02 lr: 6.73e-06:  87%|▊| 11988/13852 [44:57<07:26,  4.18it/\u001b[A\n",
      "Training loss: 7.77e-02 lr: 6.73e-06:  87%|▊| 11989/13852 [44:57<07:28,  4.15it/\u001b[A\n",
      "Training loss: 7.61e-02 lr: 6.72e-06:  87%|▊| 11990/13852 [44:57<07:26,  4.17it/\u001b[A\n",
      "Training loss: 5.60e-02 lr: 6.72e-06:  87%|▊| 11991/13852 [44:57<07:26,  4.17it/\u001b[A\n",
      "Training loss: 4.55e-02 lr: 6.71e-06:  87%|▊| 11992/13852 [44:58<07:26,  4.17it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 6.71e-06:  87%|▊| 11993/13852 [44:58<07:26,  4.16it/\u001b[A\n",
      "Training loss: 2.48e-02 lr: 6.71e-06:  87%|▊| 11994/13852 [44:58<07:26,  4.16it/\u001b[A\n",
      "Training loss: 1.96e-02 lr: 6.70e-06:  87%|▊| 11995/13852 [44:58<07:26,  4.16it/\u001b[A\n",
      "Training loss: 1.23e-01 lr: 6.70e-06:  87%|▊| 11996/13852 [44:59<07:25,  4.17it/\u001b[A\n",
      "Training loss: 9.34e-02 lr: 6.70e-06:  87%|▊| 11997/13852 [44:59<07:24,  4.17it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 6.69e-06:  87%|▊| 11998/13852 [44:59<07:16,  4.25it/\u001b[A\n",
      "Training loss: 8.51e-02 lr: 6.69e-06:  87%|▊| 11999/13852 [44:59<07:07,  4.33it/\u001b[A\n",
      "Training loss: 7.19e-02 lr: 6.69e-06:  87%|▊| 12000/13852 [44:59<07:01,  4.40it/\u001b[A\n",
      "Training loss: 5.14e-02 lr: 6.68e-06:  87%|▊| 12001/13852 [45:00<06:57,  4.43it/\u001b[A\n",
      "Training loss: 4.16e-02 lr: 6.68e-06:  87%|▊| 12002/13852 [45:00<06:55,  4.45it/\u001b[A\n",
      "Training loss: 4.41e-02 lr: 6.67e-06:  87%|▊| 12003/13852 [45:00<06:53,  4.47it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 6.67e-06:  87%|▊| 12004/13852 [45:00<06:50,  4.50it/\u001b[A\n",
      "Training loss: 5.38e-02 lr: 6.67e-06:  87%|▊| 12005/13852 [45:01<06:48,  4.52it/\u001b[A\n",
      "Training loss: 6.96e-02 lr: 6.66e-06:  87%|▊| 12006/13852 [45:01<06:50,  4.50it/\u001b[A\n",
      "Training loss: 5.54e-02 lr: 6.66e-06:  87%|▊| 12007/13852 [45:01<06:50,  4.50it/\u001b[A\n",
      "Training loss: 4.35e-02 lr: 6.66e-06:  87%|▊| 12008/13852 [45:01<06:49,  4.50it/\u001b[A\n",
      "Training loss: 6.16e-02 lr: 6.65e-06:  87%|▊| 12009/13852 [45:01<06:49,  4.51it/\u001b[A\n",
      "Training loss: 5.57e-02 lr: 6.65e-06:  87%|▊| 12010/13852 [45:02<06:49,  4.50it/\u001b[A\n",
      "Training loss: 4.12e-02 lr: 6.65e-06:  87%|▊| 12011/13852 [45:02<06:48,  4.51it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 6.64e-06:  87%|▊| 12012/13852 [45:02<06:48,  4.51it/\u001b[A\n",
      "Training loss: 2.86e-02 lr: 6.64e-06:  87%|▊| 12013/13852 [45:02<06:47,  4.51it/\u001b[A\n",
      "Training loss: 2.15e-02 lr: 6.63e-06:  87%|▊| 12014/13852 [45:03<06:46,  4.52it/\u001b[A\n",
      "Training loss: 2.79e-02 lr: 6.63e-06:  87%|▊| 12015/13852 [45:03<06:46,  4.52it/\u001b[A\n",
      "Training loss: 3.93e-02 lr: 6.63e-06:  87%|▊| 12016/13852 [45:03<06:47,  4.50it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 6.62e-06:  87%|▊| 12017/13852 [45:03<06:45,  4.53it/\u001b[A\n",
      "Training loss: 3.87e-02 lr: 6.62e-06:  87%|▊| 12018/13852 [45:03<06:42,  4.55it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.68e-02 lr: 6.62e-06:  87%|▊| 12019/13852 [45:04<06:43,  4.54it/\u001b[A\n",
      "Training loss: 3.60e-02 lr: 6.61e-06:  87%|▊| 12020/13852 [45:04<06:44,  4.53it/\u001b[A\n",
      "Training loss: 5.17e-02 lr: 6.61e-06:  87%|▊| 12021/13852 [45:04<06:45,  4.52it/\u001b[A\n",
      "Training loss: 4.00e-02 lr: 6.61e-06:  87%|▊| 12022/13852 [45:04<06:44,  4.52it/\u001b[A\n",
      "Training loss: 3.49e-02 lr: 6.60e-06:  87%|▊| 12023/13852 [45:05<06:43,  4.53it/\u001b[A\n",
      "Training loss: 4.47e-02 lr: 6.60e-06:  87%|▊| 12024/13852 [45:05<06:43,  4.53it/\u001b[A\n",
      "Training loss: 3.87e-02 lr: 6.60e-06:  87%|▊| 12025/13852 [45:05<06:43,  4.53it/\u001b[A\n",
      "Training loss: 4.53e-02 lr: 6.59e-06:  87%|▊| 12026/13852 [45:05<06:43,  4.52it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 6.59e-06:  87%|▊| 12027/13852 [45:05<06:43,  4.53it/\u001b[A\n",
      "Training loss: 3.36e-02 lr: 6.58e-06:  87%|▊| 12028/13852 [45:06<06:43,  4.52it/\u001b[A\n",
      "Training loss: 2.53e-02 lr: 6.58e-06:  87%|▊| 12029/13852 [45:06<06:42,  4.53it/\u001b[A\n",
      "Training loss: 1.97e-02 lr: 6.58e-06:  87%|▊| 12030/13852 [45:06<06:41,  4.54it/\u001b[A\n",
      "Training loss: 3.69e-02 lr: 6.57e-06:  87%|▊| 12031/13852 [45:06<06:42,  4.52it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 6.57e-06:  87%|▊| 12032/13852 [45:07<06:42,  4.52it/\u001b[A\n",
      "Training loss: 2.39e-02 lr: 6.57e-06:  87%|▊| 12033/13852 [45:07<06:46,  4.47it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 6.56e-06:  87%|▊| 12034/13852 [45:07<06:55,  4.37it/\u001b[A\n",
      "Training loss: 5.20e-02 lr: 6.56e-06:  87%|▊| 12035/13852 [45:07<07:01,  4.31it/\u001b[A\n",
      "Training loss: 4.37e-02 lr: 6.56e-06:  87%|▊| 12036/13852 [45:07<07:05,  4.27it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 6.55e-06:  87%|▊| 12037/13852 [45:08<06:56,  4.35it/\u001b[A\n",
      "Training loss: 3.92e-02 lr: 6.55e-06:  87%|▊| 12038/13852 [45:08<06:50,  4.42it/\u001b[A\n",
      "Training loss: 2.92e-02 lr: 6.54e-06:  87%|▊| 12039/13852 [45:08<06:45,  4.47it/\u001b[A\n",
      "Training loss: 3.06e-02 lr: 6.54e-06:  87%|▊| 12040/13852 [45:08<06:44,  4.47it/\u001b[A\n",
      "Training loss: 2.27e-02 lr: 6.54e-06:  87%|▊| 12041/13852 [45:09<06:45,  4.46it/\u001b[A\n",
      "Training loss: 3.88e-02 lr: 6.53e-06:  87%|▊| 12042/13852 [45:09<06:44,  4.47it/\u001b[A\n",
      "Training loss: 2.83e-02 lr: 6.53e-06:  87%|▊| 12043/13852 [45:09<06:45,  4.46it/\u001b[A\n",
      "Training loss: 2.81e-02 lr: 6.53e-06:  87%|▊| 12044/13852 [45:09<06:43,  4.48it/\u001b[A\n",
      "Training loss: 2.34e-02 lr: 6.52e-06:  87%|▊| 12045/13852 [45:09<06:41,  4.50it/\u001b[A\n",
      "Training loss: 1.01e-01 lr: 6.52e-06:  87%|▊| 12046/13852 [45:10<06:41,  4.50it/\u001b[A\n",
      "Training loss: 8.08e-02 lr: 6.52e-06:  87%|▊| 12047/13852 [45:10<06:39,  4.52it/\u001b[A\n",
      "Training loss: 6.77e-02 lr: 6.51e-06:  87%|▊| 12048/13852 [45:10<06:38,  4.53it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 6.51e-06:  87%|▊| 12049/13852 [45:10<06:37,  4.54it/\u001b[A\n",
      "Training loss: 4.65e-02 lr: 6.50e-06:  87%|▊| 12050/13852 [45:11<06:36,  4.55it/\u001b[A\n",
      "Training loss: 3.82e-02 lr: 6.50e-06:  87%|▊| 12051/13852 [45:11<06:35,  4.55it/\u001b[A\n",
      "Training loss: 4.02e-02 lr: 6.50e-06:  87%|▊| 12052/13852 [45:11<06:35,  4.55it/\u001b[A\n",
      "Training loss: 3.69e-02 lr: 6.49e-06:  87%|▊| 12053/13852 [45:11<06:35,  4.55it/\u001b[A\n",
      "Training loss: 2.76e-02 lr: 6.49e-06:  87%|▊| 12054/13852 [45:11<06:35,  4.55it/\u001b[A\n",
      "Training loss: 4.32e-02 lr: 6.49e-06:  87%|▊| 12055/13852 [45:12<06:37,  4.52it/\u001b[A\n",
      "Training loss: 5.08e-02 lr: 6.48e-06:  87%|▊| 12056/13852 [45:12<06:37,  4.52it/\u001b[A\n",
      "Training loss: 4.01e-02 lr: 6.48e-06:  87%|▊| 12057/13852 [45:12<06:37,  4.52it/\u001b[A\n",
      "Training loss: 5.70e-02 lr: 6.48e-06:  87%|▊| 12058/13852 [45:12<06:36,  4.52it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 6.47e-06:  87%|▊| 12059/13852 [45:13<06:36,  4.53it/\u001b[A\n",
      "Training loss: 3.59e-02 lr: 6.47e-06:  87%|▊| 12060/13852 [45:13<06:35,  4.53it/\u001b[A\n",
      "Training loss: 4.74e-02 lr: 6.47e-06:  87%|▊| 12061/13852 [45:13<06:34,  4.54it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 6.46e-06:  87%|▊| 12062/13852 [45:13<06:34,  4.54it/\u001b[A\n",
      "Training loss: 4.32e-02 lr: 6.46e-06:  87%|▊| 12063/13852 [45:13<06:32,  4.56it/\u001b[A\n",
      "Training loss: 1.07e-01 lr: 6.45e-06:  87%|▊| 12064/13852 [45:14<06:30,  4.58it/\u001b[A\n",
      "Training loss: 7.59e-02 lr: 6.45e-06:  87%|▊| 12065/13852 [45:14<06:30,  4.57it/\u001b[A\n",
      "Training loss: 5.47e-02 lr: 6.45e-06:  87%|▊| 12066/13852 [45:14<06:33,  4.54it/\u001b[A\n",
      "Training loss: 5.70e-02 lr: 6.44e-06:  87%|▊| 12067/13852 [45:14<06:33,  4.53it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 6.44e-06:  87%|▊| 12068/13852 [45:15<06:33,  4.53it/\u001b[A\n",
      "Training loss: 3.45e-02 lr: 6.44e-06:  87%|▊| 12069/13852 [45:15<06:33,  4.53it/\u001b[A\n",
      "Training loss: 2.64e-02 lr: 6.43e-06:  87%|▊| 12070/13852 [45:15<06:32,  4.54it/\u001b[A\n",
      "Training loss: 2.01e-02 lr: 6.43e-06:  87%|▊| 12071/13852 [45:15<06:32,  4.54it/\u001b[A\n",
      "Training loss: 4.26e-02 lr: 6.43e-06:  87%|▊| 12072/13852 [45:15<06:32,  4.53it/\u001b[A\n",
      "Training loss: 3.44e-02 lr: 6.42e-06:  87%|▊| 12073/13852 [45:16<06:32,  4.53it/\u001b[A\n",
      "Training loss: 2.58e-02 lr: 6.42e-06:  87%|▊| 12074/13852 [45:16<06:33,  4.52it/\u001b[A\n",
      "Training loss: 1.95e-02 lr: 6.41e-06:  87%|▊| 12075/13852 [45:16<06:33,  4.52it/\u001b[A\n",
      "Training loss: 1.57e-02 lr: 6.41e-06:  87%|▊| 12076/13852 [45:16<06:31,  4.53it/\u001b[A\n",
      "Training loss: 1.74e-02 lr: 6.41e-06:  87%|▊| 12077/13852 [45:17<06:30,  4.54it/\u001b[A\n",
      "Training loss: 5.02e-02 lr: 6.40e-06:  87%|▊| 12078/13852 [45:17<06:30,  4.54it/\u001b[A\n",
      "Training loss: 5.96e-02 lr: 6.40e-06:  87%|▊| 12079/13852 [45:17<06:31,  4.53it/\u001b[A\n",
      "Training loss: 5.13e-02 lr: 6.40e-06:  87%|▊| 12080/13852 [45:17<06:32,  4.52it/\u001b[A\n",
      "Training loss: 8.35e-02 lr: 6.39e-06:  87%|▊| 12081/13852 [45:17<06:31,  4.52it/\u001b[A\n",
      "Training loss: 9.54e-02 lr: 6.39e-06:  87%|▊| 12082/13852 [45:18<06:30,  4.53it/\u001b[A\n",
      "Training loss: 7.40e-02 lr: 6.39e-06:  87%|▊| 12083/13852 [45:18<06:31,  4.52it/\u001b[A\n",
      "Training loss: 5.45e-02 lr: 6.38e-06:  87%|▊| 12084/13852 [45:18<06:32,  4.51it/\u001b[A\n",
      "Training loss: 4.73e-02 lr: 6.38e-06:  87%|▊| 12085/13852 [45:18<06:31,  4.51it/\u001b[A\n",
      "Training loss: 3.55e-02 lr: 6.37e-06:  87%|▊| 12086/13852 [45:19<06:30,  4.52it/\u001b[A\n",
      "Training loss: 3.39e-02 lr: 6.37e-06:  87%|▊| 12087/13852 [45:19<06:29,  4.53it/\u001b[A\n",
      "Training loss: 3.43e-02 lr: 6.37e-06:  87%|▊| 12088/13852 [45:19<06:29,  4.52it/\u001b[A\n",
      "Training loss: 2.79e-02 lr: 6.36e-06:  87%|▊| 12089/13852 [45:19<06:30,  4.52it/\u001b[A\n",
      "Training loss: 3.58e-02 lr: 6.36e-06:  87%|▊| 12090/13852 [45:19<06:28,  4.54it/\u001b[A\n",
      "Training loss: 3.75e-02 lr: 6.36e-06:  87%|▊| 12091/13852 [45:20<06:26,  4.56it/\u001b[A\n",
      "Training loss: 2.70e-02 lr: 6.35e-06:  87%|▊| 12092/13852 [45:20<06:27,  4.55it/\u001b[A\n",
      "Training loss: 5.42e-02 lr: 6.35e-06:  87%|▊| 12093/13852 [45:20<06:27,  4.54it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 6.35e-06:  87%|▊| 12094/13852 [45:20<06:27,  4.54it/\u001b[A\n",
      "Training loss: 4.27e-02 lr: 6.34e-06:  87%|▊| 12095/13852 [45:20<06:26,  4.54it/\u001b[A\n",
      "Training loss: 4.11e-02 lr: 6.34e-06:  87%|▊| 12096/13852 [45:21<06:27,  4.53it/\u001b[A\n",
      "Training loss: 5.52e-02 lr: 6.34e-06:  87%|▊| 12097/13852 [45:21<06:28,  4.51it/\u001b[A\n",
      "Training loss: 4.04e-02 lr: 6.33e-06:  87%|▊| 12098/13852 [45:21<06:28,  4.52it/\u001b[A\n",
      "Training loss: 2.95e-02 lr: 6.33e-06:  87%|▊| 12099/13852 [45:21<06:28,  4.52it/\u001b[A\n",
      "Training loss: 2.18e-02 lr: 6.32e-06:  87%|▊| 12100/13852 [45:22<06:27,  4.52it/\u001b[A\n",
      "Training loss: 2.38e-02 lr: 6.32e-06:  87%|▊| 12101/13852 [45:22<06:27,  4.52it/\u001b[A\n",
      "Training loss: 5.25e-02 lr: 6.32e-06:  87%|▊| 12102/13852 [45:22<06:25,  4.54it/\u001b[A\n",
      "Training loss: 5.89e-02 lr: 6.31e-06:  87%|▊| 12103/13852 [45:22<06:24,  4.55it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 6.31e-06:  87%|▊| 12104/13852 [45:22<06:27,  4.52it/\u001b[A\n",
      "Training loss: 3.50e-02 lr: 6.31e-06:  87%|▊| 12105/13852 [45:23<06:26,  4.52it/\u001b[A\n",
      "Training loss: 4.51e-02 lr: 6.30e-06:  87%|▊| 12106/13852 [45:23<06:26,  4.51it/\u001b[A\n",
      "Training loss: 5.38e-02 lr: 6.30e-06:  87%|▊| 12107/13852 [45:23<06:25,  4.52it/\u001b[A\n",
      "Training loss: 4.63e-02 lr: 6.30e-06:  87%|▊| 12108/13852 [45:23<06:24,  4.53it/\u001b[A\n",
      "Training loss: 3.74e-02 lr: 6.29e-06:  87%|▊| 12109/13852 [45:24<06:26,  4.51it/\u001b[A\n",
      "Training loss: 5.19e-02 lr: 6.29e-06:  87%|▊| 12110/13852 [45:24<06:25,  4.52it/\u001b[A\n",
      "Training loss: 4.57e-02 lr: 6.28e-06:  87%|▊| 12111/13852 [45:24<06:25,  4.52it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 6.28e-06:  87%|▊| 12112/13852 [45:24<06:25,  4.52it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 6.28e-06:  87%|▊| 12113/13852 [45:24<06:24,  4.52it/\u001b[A\n",
      "Training loss: 3.82e-02 lr: 6.27e-06:  87%|▊| 12114/13852 [45:25<06:24,  4.52it/\u001b[A\n",
      "Training loss: 4.23e-02 lr: 6.27e-06:  87%|▊| 12115/13852 [45:25<06:22,  4.54it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.01e-02 lr: 6.27e-06:  87%|▊| 12116/13852 [45:25<06:21,  4.55it/\u001b[A\n",
      "Training loss: 3.58e-02 lr: 6.26e-06:  87%|▊| 12117/13852 [45:25<06:22,  4.53it/\u001b[A\n",
      "Training loss: 3.06e-02 lr: 6.26e-06:  87%|▊| 12118/13852 [45:26<06:22,  4.53it/\u001b[A\n",
      "Training loss: 2.40e-02 lr: 6.26e-06:  87%|▊| 12119/13852 [45:26<06:22,  4.53it/\u001b[A\n",
      "Training loss: 2.09e-02 lr: 6.25e-06:  87%|▊| 12120/13852 [45:26<06:22,  4.53it/\u001b[A\n",
      "Training loss: 2.12e-02 lr: 6.25e-06:  88%|▉| 12121/13852 [45:26<06:22,  4.53it/\u001b[A\n",
      "Training loss: 5.69e-02 lr: 6.25e-06:  88%|▉| 12122/13852 [45:26<06:22,  4.53it/\u001b[A\n",
      "Training loss: 4.98e-02 lr: 6.24e-06:  88%|▉| 12123/13852 [45:27<06:22,  4.52it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 6.24e-06:  88%|▉| 12124/13852 [45:27<06:23,  4.51it/\u001b[A\n",
      "Training loss: 4.56e-02 lr: 6.23e-06:  88%|▉| 12125/13852 [45:27<06:22,  4.51it/\u001b[A\n",
      "Training loss: 4.12e-02 lr: 6.23e-06:  88%|▉| 12126/13852 [45:27<06:22,  4.51it/\u001b[A\n",
      "Training loss: 4.46e-02 lr: 6.23e-06:  88%|▉| 12127/13852 [45:28<06:20,  4.54it/\u001b[A\n",
      "Training loss: 4.98e-02 lr: 6.22e-06:  88%|▉| 12128/13852 [45:28<06:18,  4.56it/\u001b[A\n",
      "Training loss: 4.44e-02 lr: 6.22e-06:  88%|▉| 12129/13852 [45:28<06:16,  4.57it/\u001b[A\n",
      "Training loss: 4.92e-02 lr: 6.22e-06:  88%|▉| 12130/13852 [45:28<06:18,  4.55it/\u001b[A\n",
      "Training loss: 8.58e-02 lr: 6.21e-06:  88%|▉| 12131/13852 [45:28<06:18,  4.54it/\u001b[A\n",
      "Training loss: 6.08e-02 lr: 6.21e-06:  88%|▉| 12132/13852 [45:29<06:18,  4.54it/\u001b[A\n",
      "Training loss: 1.00e-01 lr: 6.21e-06:  88%|▉| 12133/13852 [45:29<06:19,  4.53it/\u001b[A\n",
      "Training loss: 7.13e-02 lr: 6.20e-06:  88%|▉| 12134/13852 [45:29<06:18,  4.54it/\u001b[A\n",
      "Training loss: 9.73e-02 lr: 6.20e-06:  88%|▉| 12135/13852 [45:29<06:19,  4.53it/\u001b[A\n",
      "Training loss: 8.34e-02 lr: 6.19e-06:  88%|▉| 12136/13852 [45:30<06:18,  4.53it/\u001b[A\n",
      "Training loss: 7.68e-02 lr: 6.19e-06:  88%|▉| 12137/13852 [45:30<06:18,  4.53it/\u001b[A\n",
      "Training loss: 6.45e-02 lr: 6.19e-06:  88%|▉| 12138/13852 [45:30<06:18,  4.53it/\u001b[A\n",
      "Training loss: 9.39e-02 lr: 6.18e-06:  88%|▉| 12139/13852 [45:30<06:17,  4.53it/\u001b[A\n",
      "Training loss: 7.61e-02 lr: 6.18e-06:  88%|▉| 12140/13852 [45:30<06:16,  4.55it/\u001b[A\n",
      "Training loss: 8.25e-02 lr: 6.18e-06:  88%|▉| 12141/13852 [45:31<06:14,  4.56it/\u001b[A\n",
      "Training loss: 6.01e-02 lr: 6.17e-06:  88%|▉| 12142/13852 [45:31<06:16,  4.54it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 6.17e-06:  88%|▉| 12143/13852 [45:31<06:15,  4.56it/\u001b[A\n",
      "Training loss: 3.23e-02 lr: 6.17e-06:  88%|▉| 12144/13852 [45:31<06:15,  4.55it/\u001b[A\n",
      "Training loss: 2.41e-02 lr: 6.16e-06:  88%|▉| 12145/13852 [45:32<06:16,  4.54it/\u001b[A\n",
      "Training loss: 2.51e-02 lr: 6.16e-06:  88%|▉| 12146/13852 [45:32<06:18,  4.51it/\u001b[A\n",
      "Training loss: 5.15e-02 lr: 6.15e-06:  88%|▉| 12147/13852 [45:32<06:17,  4.52it/\u001b[A\n",
      "Training loss: 3.92e-02 lr: 6.15e-06:  88%|▉| 12148/13852 [45:32<06:16,  4.52it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 6.15e-06:  88%|▉| 12149/13852 [45:32<06:16,  4.53it/\u001b[A\n",
      "Training loss: 9.22e-02 lr: 6.14e-06:  88%|▉| 12150/13852 [45:33<06:15,  4.53it/\u001b[A\n",
      "Training loss: 6.69e-02 lr: 6.14e-06:  88%|▉| 12151/13852 [45:33<06:15,  4.53it/\u001b[A\n",
      "Training loss: 5.86e-02 lr: 6.14e-06:  88%|▉| 12152/13852 [45:33<06:16,  4.51it/\u001b[A\n",
      "Training loss: 4.22e-02 lr: 6.13e-06:  88%|▉| 12153/13852 [45:33<06:16,  4.51it/\u001b[A\n",
      "Training loss: 3.55e-02 lr: 6.13e-06:  88%|▉| 12154/13852 [45:34<06:14,  4.54it/\u001b[A\n",
      "Training loss: 4.73e-02 lr: 6.13e-06:  88%|▉| 12155/13852 [45:34<06:12,  4.55it/\u001b[A\n",
      "Training loss: 4.91e-02 lr: 6.12e-06:  88%|▉| 12156/13852 [45:34<06:15,  4.52it/\u001b[A\n",
      "Training loss: 5.39e-02 lr: 6.12e-06:  88%|▉| 12157/13852 [45:34<06:15,  4.51it/\u001b[A\n",
      "Training loss: 7.08e-02 lr: 6.12e-06:  88%|▉| 12158/13852 [45:34<06:14,  4.52it/\u001b[A\n",
      "Training loss: 5.64e-02 lr: 6.11e-06:  88%|▉| 12159/13852 [45:35<06:13,  4.54it/\u001b[A\n",
      "Training loss: 4.23e-02 lr: 6.11e-06:  88%|▉| 12160/13852 [45:35<06:13,  4.53it/\u001b[A\n",
      "Training loss: 4.11e-02 lr: 6.10e-06:  88%|▉| 12161/13852 [45:35<06:13,  4.53it/\u001b[A\n",
      "Training loss: 5.21e-02 lr: 6.10e-06:  88%|▉| 12162/13852 [45:35<06:13,  4.52it/\u001b[A\n",
      "Training loss: 4.12e-02 lr: 6.10e-06:  88%|▉| 12163/13852 [45:35<06:13,  4.52it/\u001b[A\n",
      "Training loss: 3.37e-02 lr: 6.09e-06:  88%|▉| 12164/13852 [45:36<06:13,  4.53it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 6.09e-06:  88%|▉| 12165/13852 [45:36<06:13,  4.52it/\u001b[A\n",
      "Training loss: 7.35e-02 lr: 6.09e-06:  88%|▉| 12166/13852 [45:36<06:11,  4.53it/\u001b[A\n",
      "Training loss: 5.84e-02 lr: 6.08e-06:  88%|▉| 12167/13852 [45:36<06:10,  4.55it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 6.08e-06:  88%|▉| 12168/13852 [45:37<06:08,  4.57it/\u001b[A\n",
      "Training loss: 8.12e-02 lr: 6.08e-06:  88%|▉| 12169/13852 [45:37<06:21,  4.41it/\u001b[A\n",
      "Training loss: 6.21e-02 lr: 6.07e-06:  88%|▉| 12170/13852 [45:37<06:29,  4.32it/\u001b[A\n",
      "Training loss: 5.63e-02 lr: 6.07e-06:  88%|▉| 12171/13852 [45:37<06:33,  4.27it/\u001b[A\n",
      "Training loss: 6.18e-02 lr: 6.06e-06:  88%|▉| 12172/13852 [45:38<06:38,  4.21it/\u001b[A\n",
      "Training loss: 5.00e-02 lr: 6.06e-06:  88%|▉| 12173/13852 [45:38<06:39,  4.20it/\u001b[A\n",
      "Training loss: 4.03e-02 lr: 6.06e-06:  88%|▉| 12174/13852 [45:38<06:29,  4.30it/\u001b[A\n",
      "Training loss: 4.87e-02 lr: 6.05e-06:  88%|▉| 12175/13852 [45:38<06:24,  4.36it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 6.05e-06:  88%|▉| 12176/13852 [45:38<06:20,  4.40it/\u001b[A\n",
      "Training loss: 4.71e-02 lr: 6.05e-06:  88%|▉| 12177/13852 [45:39<06:17,  4.44it/\u001b[A\n",
      "Training loss: 6.99e-02 lr: 6.04e-06:  88%|▉| 12178/13852 [45:39<06:14,  4.48it/\u001b[A\n",
      "Training loss: 5.03e-02 lr: 6.04e-06:  88%|▉| 12179/13852 [45:39<06:13,  4.48it/\u001b[A\n",
      "Training loss: 4.09e-02 lr: 6.04e-06:  88%|▉| 12180/13852 [45:39<06:12,  4.49it/\u001b[A\n",
      "Training loss: 3.64e-02 lr: 6.03e-06:  88%|▉| 12181/13852 [45:40<06:11,  4.50it/\u001b[A\n",
      "Training loss: 3.27e-02 lr: 6.03e-06:  88%|▉| 12182/13852 [45:40<06:10,  4.51it/\u001b[A\n",
      "Training loss: 2.65e-02 lr: 6.02e-06:  88%|▉| 12183/13852 [45:40<06:09,  4.52it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 6.02e-06:  88%|▉| 12184/13852 [45:40<06:09,  4.51it/\u001b[A\n",
      "Training loss: 2.89e-02 lr: 6.02e-06:  88%|▉| 12185/13852 [45:40<06:08,  4.53it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 6.01e-06:  88%|▉| 12186/13852 [45:41<06:06,  4.54it/\u001b[A\n",
      "Training loss: 2.47e-02 lr: 6.01e-06:  88%|▉| 12187/13852 [45:41<06:09,  4.51it/\u001b[A\n",
      "Training loss: 1.83e-02 lr: 6.01e-06:  88%|▉| 12188/13852 [45:41<06:08,  4.51it/\u001b[A\n",
      "Training loss: 1.48e-02 lr: 6.00e-06:  88%|▉| 12189/13852 [45:41<06:08,  4.51it/\u001b[A\n",
      "Training loss: 1.13e-02 lr: 6.00e-06:  88%|▉| 12190/13852 [45:42<06:08,  4.51it/\u001b[A\n",
      "Training loss: 2.50e-02 lr: 6.00e-06:  88%|▉| 12191/13852 [45:42<06:09,  4.50it/\u001b[A\n",
      "Training loss: 1.81e-02 lr: 5.99e-06:  88%|▉| 12192/13852 [45:42<06:08,  4.51it/\u001b[A\n",
      "Training loss: 3.69e-02 lr: 5.99e-06:  88%|▉| 12193/13852 [45:42<06:07,  4.51it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 5.99e-06:  88%|▉| 12194/13852 [45:42<06:07,  4.52it/\u001b[A\n",
      "Training loss: 3.75e-02 lr: 5.98e-06:  88%|▉| 12195/13852 [45:43<06:06,  4.52it/\u001b[A\n",
      "Training loss: 5.84e-02 lr: 5.98e-06:  88%|▉| 12196/13852 [45:43<06:06,  4.51it/\u001b[A\n",
      "Training loss: 7.15e-02 lr: 5.97e-06:  88%|▉| 12197/13852 [45:43<06:06,  4.52it/\u001b[A\n",
      "Training loss: 7.05e-02 lr: 5.97e-06:  88%|▉| 12198/13852 [45:43<06:05,  4.53it/\u001b[A\n",
      "Training loss: 1.18e-01 lr: 5.97e-06:  88%|▉| 12199/13852 [45:44<06:03,  4.54it/\u001b[A\n",
      "Training loss: 1.28e-01 lr: 5.96e-06:  88%|▉| 12200/13852 [45:44<06:04,  4.53it/\u001b[A\n",
      "Training loss: 9.03e-02 lr: 5.96e-06:  88%|▉| 12201/13852 [45:44<06:04,  4.53it/\u001b[A\n",
      "Training loss: 8.00e-02 lr: 5.96e-06:  88%|▉| 12202/13852 [45:44<06:05,  4.52it/\u001b[A\n",
      "Training loss: 7.61e-02 lr: 5.95e-06:  88%|▉| 12203/13852 [45:44<06:04,  4.52it/\u001b[A\n",
      "Training loss: 7.68e-02 lr: 5.95e-06:  88%|▉| 12204/13852 [45:45<06:05,  4.51it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 5.95e-06:  88%|▉| 12205/13852 [45:45<06:04,  4.52it/\u001b[A\n",
      "Training loss: 4.77e-02 lr: 5.94e-06:  88%|▉| 12206/13852 [45:45<06:04,  4.51it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 5.94e-06:  88%|▉| 12207/13852 [45:45<06:04,  4.51it/\u001b[A\n",
      "Training loss: 3.32e-02 lr: 5.93e-06:  88%|▉| 12208/13852 [45:46<06:04,  4.51it/\u001b[A\n",
      "Training loss: 3.53e-02 lr: 5.93e-06:  88%|▉| 12209/13852 [45:46<06:04,  4.51it/\u001b[A\n",
      "Training loss: 3.56e-02 lr: 5.93e-06:  88%|▉| 12210/13852 [45:46<06:02,  4.53it/\u001b[A\n",
      "Training loss: 2.96e-02 lr: 5.92e-06:  88%|▉| 12211/13852 [45:46<06:01,  4.54it/\u001b[A\n",
      "Training loss: 2.24e-02 lr: 5.92e-06:  88%|▉| 12212/13852 [45:46<06:02,  4.52it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.94e-02 lr: 5.92e-06:  88%|▉| 12213/13852 [45:47<06:03,  4.51it/\u001b[A\n",
      "Training loss: 2.79e-02 lr: 5.91e-06:  88%|▉| 12214/13852 [45:47<06:04,  4.50it/\u001b[A\n",
      "Training loss: 3.65e-02 lr: 5.91e-06:  88%|▉| 12215/13852 [45:47<06:03,  4.50it/\u001b[A\n",
      "Training loss: 3.20e-02 lr: 5.91e-06:  88%|▉| 12216/13852 [45:47<06:02,  4.52it/\u001b[A\n",
      "Training loss: 2.27e-02 lr: 5.90e-06:  88%|▉| 12217/13852 [45:48<06:01,  4.52it/\u001b[A\n",
      "Training loss: 2.95e-02 lr: 5.90e-06:  88%|▉| 12218/13852 [45:48<06:02,  4.51it/\u001b[A\n",
      "Training loss: 2.23e-02 lr: 5.89e-06:  88%|▉| 12219/13852 [45:48<06:03,  4.49it/\u001b[A\n",
      "Training loss: 1.66e-02 lr: 5.89e-06:  88%|▉| 12220/13852 [45:48<06:02,  4.50it/\u001b[A\n",
      "Training loss: 2.34e-02 lr: 5.89e-06:  88%|▉| 12221/13852 [45:48<06:02,  4.51it/\u001b[A\n",
      "Training loss: 3.39e-02 lr: 5.88e-06:  88%|▉| 12222/13852 [45:49<05:59,  4.53it/\u001b[A\n",
      "Training loss: 2.82e-02 lr: 5.88e-06:  88%|▉| 12223/13852 [45:49<05:58,  4.55it/\u001b[A\n",
      "Training loss: 7.50e-02 lr: 5.88e-06:  88%|▉| 12224/13852 [45:49<05:57,  4.56it/\u001b[A\n",
      "Training loss: 1.32e-01 lr: 5.87e-06:  88%|▉| 12225/13852 [45:49<06:00,  4.52it/\u001b[A\n",
      "Training loss: 9.82e-02 lr: 5.87e-06:  88%|▉| 12226/13852 [45:50<06:00,  4.51it/\u001b[A\n",
      "Training loss: 7.64e-02 lr: 5.87e-06:  88%|▉| 12227/13852 [45:50<06:00,  4.51it/\u001b[A\n",
      "Training loss: 1.37e-01 lr: 5.86e-06:  88%|▉| 12228/13852 [45:50<05:59,  4.52it/\u001b[A\n",
      "Training loss: 1.29e-01 lr: 5.86e-06:  88%|▉| 12229/13852 [45:50<05:59,  4.51it/\u001b[A\n",
      "Training loss: 9.08e-02 lr: 5.86e-06:  88%|▉| 12230/13852 [45:50<05:59,  4.51it/\u001b[A\n",
      "Training loss: 9.38e-02 lr: 5.85e-06:  88%|▉| 12231/13852 [45:51<05:59,  4.51it/\u001b[A\n",
      "Training loss: 1.19e-01 lr: 5.85e-06:  88%|▉| 12232/13852 [45:51<06:01,  4.48it/\u001b[A\n",
      "Training loss: 9.01e-02 lr: 5.84e-06:  88%|▉| 12233/13852 [45:51<06:00,  4.49it/\u001b[A\n",
      "Training loss: 9.65e-02 lr: 5.84e-06:  88%|▉| 12234/13852 [45:51<05:59,  4.50it/\u001b[A\n",
      "Training loss: 6.88e-02 lr: 5.84e-06:  88%|▉| 12235/13852 [45:52<05:57,  4.52it/\u001b[A\n",
      "Training loss: 5.64e-02 lr: 5.83e-06:  88%|▉| 12236/13852 [45:52<05:57,  4.52it/\u001b[A\n",
      "Training loss: 7.05e-02 lr: 5.83e-06:  88%|▉| 12237/13852 [45:52<05:57,  4.52it/\u001b[A\n",
      "Training loss: 5.47e-02 lr: 5.83e-06:  88%|▉| 12238/13852 [45:52<05:57,  4.52it/\u001b[A\n",
      "Training loss: 4.20e-02 lr: 5.82e-06:  88%|▉| 12239/13852 [45:52<05:56,  4.52it/\u001b[A\n",
      "Training loss: 5.63e-02 lr: 5.82e-06:  88%|▉| 12240/13852 [45:53<05:55,  4.53it/\u001b[A\n",
      "Training loss: 4.53e-02 lr: 5.82e-06:  88%|▉| 12241/13852 [45:53<05:55,  4.53it/\u001b[A\n",
      "Training loss: 3.88e-02 lr: 5.81e-06:  88%|▉| 12242/13852 [45:53<05:55,  4.53it/\u001b[A\n",
      "Training loss: 3.19e-02 lr: 5.81e-06:  88%|▉| 12243/13852 [45:53<05:55,  4.53it/\u001b[A\n",
      "Training loss: 2.70e-02 lr: 5.80e-06:  88%|▉| 12244/13852 [45:54<05:55,  4.52it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 5.80e-06:  88%|▉| 12245/13852 [45:54<05:55,  4.52it/\u001b[A\n",
      "Training loss: 2.94e-02 lr: 5.80e-06:  88%|▉| 12246/13852 [45:54<05:56,  4.50it/\u001b[A\n",
      "Training loss: 2.99e-02 lr: 5.79e-06:  88%|▉| 12247/13852 [45:54<05:54,  4.53it/\u001b[A\n",
      "Training loss: 2.36e-02 lr: 5.79e-06:  88%|▉| 12248/13852 [45:54<05:52,  4.55it/\u001b[A\n",
      "Training loss: 2.59e-02 lr: 5.79e-06:  88%|▉| 12249/13852 [45:55<05:55,  4.51it/\u001b[A\n",
      "Training loss: 5.73e-02 lr: 5.78e-06:  88%|▉| 12250/13852 [45:55<05:54,  4.51it/\u001b[A\n",
      "Training loss: 4.52e-02 lr: 5.78e-06:  88%|▉| 12251/13852 [45:55<05:54,  4.52it/\u001b[A\n",
      "Training loss: 3.64e-02 lr: 5.78e-06:  88%|▉| 12252/13852 [45:55<05:54,  4.52it/\u001b[A\n",
      "Training loss: 3.10e-02 lr: 5.77e-06:  88%|▉| 12253/13852 [45:56<05:53,  4.52it/\u001b[A\n",
      "Training loss: 2.58e-02 lr: 5.77e-06:  88%|▉| 12254/13852 [45:56<05:53,  4.52it/\u001b[A\n",
      "Training loss: 3.49e-02 lr: 5.76e-06:  88%|▉| 12255/13852 [45:56<05:53,  4.52it/\u001b[A\n",
      "Training loss: 4.96e-02 lr: 5.76e-06:  88%|▉| 12256/13852 [45:56<05:53,  4.52it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 5.76e-06:  88%|▉| 12257/13852 [45:56<05:53,  4.52it/\u001b[A\n",
      "Training loss: 3.18e-02 lr: 5.75e-06:  88%|▉| 12258/13852 [45:57<05:52,  4.52it/\u001b[A\n",
      "Training loss: 5.74e-02 lr: 5.75e-06:  88%|▉| 12259/13852 [45:57<05:53,  4.50it/\u001b[A\n",
      "Training loss: 4.77e-02 lr: 5.75e-06:  89%|▉| 12260/13852 [45:57<05:52,  4.52it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 5.74e-06:  89%|▉| 12261/13852 [45:57<05:50,  4.54it/\u001b[A\n",
      "Training loss: 6.51e-02 lr: 5.74e-06:  89%|▉| 12262/13852 [45:58<05:50,  4.53it/\u001b[A\n",
      "Training loss: 5.50e-02 lr: 5.74e-06:  89%|▉| 12263/13852 [45:58<05:50,  4.53it/\u001b[A\n",
      "Training loss: 4.08e-02 lr: 5.73e-06:  89%|▉| 12264/13852 [45:58<05:51,  4.52it/\u001b[A\n",
      "Training loss: 6.76e-02 lr: 5.73e-06:  89%|▉| 12265/13852 [45:58<05:50,  4.53it/\u001b[A\n",
      "Training loss: 5.23e-02 lr: 5.73e-06:  89%|▉| 12266/13852 [45:58<05:50,  4.53it/\u001b[A\n",
      "Training loss: 6.14e-02 lr: 5.72e-06:  89%|▉| 12267/13852 [45:59<05:50,  4.52it/\u001b[A\n",
      "Training loss: 4.68e-02 lr: 5.72e-06:  89%|▉| 12268/13852 [45:59<05:50,  4.52it/\u001b[A\n",
      "Training loss: 4.39e-02 lr: 5.71e-06:  89%|▉| 12269/13852 [45:59<06:07,  4.31it/\u001b[A\n",
      "Training loss: 4.01e-02 lr: 5.71e-06:  89%|▉| 12270/13852 [45:59<06:10,  4.27it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 5.71e-06:  89%|▉| 12271/13852 [46:00<06:13,  4.24it/\u001b[A\n",
      "Training loss: 3.08e-02 lr: 5.70e-06:  89%|▉| 12272/13852 [46:00<06:15,  4.20it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 5.70e-06:  89%|▉| 12273/13852 [46:00<06:16,  4.20it/\u001b[A\n",
      "Training loss: 3.99e-02 lr: 5.70e-06:  89%|▉| 12274/13852 [46:00<06:16,  4.19it/\u001b[A\n",
      "Training loss: 3.22e-02 lr: 5.69e-06:  89%|▉| 12275/13852 [46:01<06:16,  4.19it/\u001b[A\n",
      "Training loss: 8.75e-02 lr: 5.69e-06:  89%|▉| 12276/13852 [46:01<06:17,  4.17it/\u001b[A\n",
      "Training loss: 7.93e-02 lr: 5.69e-06:  89%|▉| 12277/13852 [46:01<06:17,  4.17it/\u001b[A\n",
      "Training loss: 5.67e-02 lr: 5.68e-06:  89%|▉| 12278/13852 [46:01<06:17,  4.16it/\u001b[A\n",
      "Training loss: 6.08e-02 lr: 5.68e-06:  89%|▉| 12279/13852 [46:01<06:16,  4.18it/\u001b[A\n",
      "Training loss: 5.21e-02 lr: 5.67e-06:  89%|▉| 12280/13852 [46:02<06:22,  4.11it/\u001b[A\n",
      "Training loss: 4.64e-02 lr: 5.67e-06:  89%|▉| 12281/13852 [46:02<06:21,  4.12it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 5.67e-06:  89%|▉| 12282/13852 [46:02<06:19,  4.14it/\u001b[A\n",
      "Training loss: 3.25e-02 lr: 5.66e-06:  89%|▉| 12283/13852 [46:02<06:09,  4.25it/\u001b[A\n",
      "Training loss: 3.65e-02 lr: 5.66e-06:  89%|▉| 12284/13852 [46:03<06:02,  4.32it/\u001b[A\n",
      "Training loss: 4.92e-02 lr: 5.66e-06:  89%|▉| 12285/13852 [46:03<05:57,  4.38it/\u001b[A\n",
      "Training loss: 4.49e-02 lr: 5.65e-06:  89%|▉| 12286/13852 [46:03<05:54,  4.42it/\u001b[A\n",
      "Training loss: 5.03e-02 lr: 5.65e-06:  89%|▉| 12287/13852 [46:03<05:51,  4.45it/\u001b[A\n",
      "Training loss: 3.71e-02 lr: 5.65e-06:  89%|▉| 12288/13852 [46:04<05:49,  4.47it/\u001b[A\n",
      "Training loss: 5.14e-02 lr: 5.64e-06:  89%|▉| 12289/13852 [46:04<05:48,  4.48it/\u001b[A\n",
      "Training loss: 3.75e-02 lr: 5.64e-06:  89%|▉| 12290/13852 [46:04<05:48,  4.48it/\u001b[A\n",
      "Training loss: 2.88e-02 lr: 5.63e-06:  89%|▉| 12291/13852 [46:04<05:46,  4.51it/\u001b[A\n",
      "Training loss: 2.84e-02 lr: 5.63e-06:  89%|▉| 12292/13852 [46:04<05:44,  4.53it/\u001b[A\n",
      "Training loss: 2.71e-02 lr: 5.63e-06:  89%|▉| 12293/13852 [46:05<05:44,  4.53it/\u001b[A\n",
      "Training loss: 2.76e-02 lr: 5.62e-06:  89%|▉| 12294/13852 [46:05<05:43,  4.54it/\u001b[A\n",
      "Training loss: 3.46e-02 lr: 5.62e-06:  89%|▉| 12295/13852 [46:05<05:43,  4.54it/\u001b[A\n",
      "Training loss: 1.00e-01 lr: 5.62e-06:  89%|▉| 12296/13852 [46:05<05:43,  4.53it/\u001b[A\n",
      "Training loss: 8.63e-02 lr: 5.61e-06:  89%|▉| 12297/13852 [46:06<05:43,  4.53it/\u001b[A\n",
      "Training loss: 1.07e-01 lr: 5.61e-06:  89%|▉| 12298/13852 [46:06<05:43,  4.52it/\u001b[A\n",
      "Training loss: 1.08e-01 lr: 5.61e-06:  89%|▉| 12299/13852 [46:06<05:44,  4.51it/\u001b[A\n",
      "Training loss: 9.12e-02 lr: 5.60e-06:  89%|▉| 12300/13852 [46:06<05:43,  4.51it/\u001b[A\n",
      "Training loss: 6.81e-02 lr: 5.60e-06:  89%|▉| 12301/13852 [46:06<05:43,  4.51it/\u001b[A\n",
      "Training loss: 5.09e-02 lr: 5.60e-06:  89%|▉| 12302/13852 [46:07<05:44,  4.50it/\u001b[A\n",
      "Training loss: 3.82e-02 lr: 5.59e-06:  89%|▉| 12303/13852 [46:07<05:46,  4.47it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 5.59e-06:  89%|▉| 12304/13852 [46:07<05:45,  4.48it/\u001b[A\n",
      "Training loss: 2.86e-02 lr: 5.58e-06:  89%|▉| 12305/13852 [46:07<05:43,  4.50it/\u001b[A\n",
      "Training loss: 2.05e-02 lr: 5.58e-06:  89%|▉| 12306/13852 [46:08<05:52,  4.38it/\u001b[A\n",
      "Training loss: 5.89e-02 lr: 5.58e-06:  89%|▉| 12307/13852 [46:08<05:59,  4.30it/\u001b[A\n",
      "Training loss: 7.60e-02 lr: 5.57e-06:  89%|▉| 12308/13852 [46:08<05:53,  4.37it/\u001b[A\n",
      "Training loss: 6.37e-02 lr: 5.57e-06:  89%|▉| 12309/13852 [46:08<05:50,  4.41it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.88e-02 lr: 5.57e-06:  89%|▉| 12310/13852 [46:08<05:47,  4.44it/\u001b[A\n",
      "Training loss: 1.12e-01 lr: 5.56e-06:  89%|▉| 12311/13852 [46:09<05:45,  4.46it/\u001b[A\n",
      "Training loss: 9.04e-02 lr: 5.56e-06:  89%|▉| 12312/13852 [46:09<05:44,  4.47it/\u001b[A\n",
      "Training loss: 6.39e-02 lr: 5.56e-06:  89%|▉| 12313/13852 [46:09<05:43,  4.48it/\u001b[A\n",
      "Training loss: 6.46e-02 lr: 5.55e-06:  89%|▉| 12314/13852 [46:09<05:41,  4.51it/\u001b[A\n",
      "Training loss: 8.50e-02 lr: 5.55e-06:  89%|▉| 12315/13852 [46:10<05:39,  4.53it/\u001b[A\n",
      "Training loss: 6.40e-02 lr: 5.54e-06:  89%|▉| 12316/13852 [46:10<05:40,  4.51it/\u001b[A\n",
      "Training loss: 4.97e-02 lr: 5.54e-06:  89%|▉| 12317/13852 [46:10<05:40,  4.51it/\u001b[A\n",
      "Training loss: 7.09e-02 lr: 5.54e-06:  89%|▉| 12318/13852 [46:10<05:40,  4.51it/\u001b[A\n",
      "Training loss: 6.99e-02 lr: 5.53e-06:  89%|▉| 12319/13852 [46:10<05:38,  4.53it/\u001b[A\n",
      "Training loss: 5.19e-02 lr: 5.53e-06:  89%|▉| 12320/13852 [46:11<05:38,  4.53it/\u001b[A\n",
      "Training loss: 4.59e-02 lr: 5.53e-06:  89%|▉| 12321/13852 [46:11<05:39,  4.51it/\u001b[A\n",
      "Training loss: 6.29e-02 lr: 5.52e-06:  89%|▉| 12322/13852 [46:11<05:39,  4.51it/\u001b[A\n",
      "Training loss: 4.94e-02 lr: 5.52e-06:  89%|▉| 12323/13852 [46:11<05:39,  4.50it/\u001b[A\n",
      "Training loss: 4.01e-02 lr: 5.52e-06:  89%|▉| 12324/13852 [46:12<05:39,  4.50it/\u001b[A\n",
      "Training loss: 3.21e-02 lr: 5.51e-06:  89%|▉| 12325/13852 [46:12<05:40,  4.49it/\u001b[A\n",
      "Training loss: 2.63e-02 lr: 5.51e-06:  89%|▉| 12326/13852 [46:12<05:38,  4.51it/\u001b[A\n",
      "Training loss: 3.10e-02 lr: 5.51e-06:  89%|▉| 12327/13852 [46:12<05:36,  4.54it/\u001b[A\n",
      "Training loss: 2.57e-02 lr: 5.50e-06:  89%|▉| 12328/13852 [46:12<05:37,  4.52it/\u001b[A\n",
      "Training loss: 2.54e-02 lr: 5.50e-06:  89%|▉| 12329/13852 [46:13<05:37,  4.52it/\u001b[A\n",
      "Training loss: 3.18e-02 lr: 5.49e-06:  89%|▉| 12330/13852 [46:13<05:36,  4.52it/\u001b[A\n",
      "Training loss: 2.36e-02 lr: 5.49e-06:  89%|▉| 12331/13852 [46:13<05:36,  4.53it/\u001b[A\n",
      "Training loss: 2.37e-02 lr: 5.49e-06:  89%|▉| 12332/13852 [46:13<05:35,  4.53it/\u001b[A\n",
      "Training loss: 2.24e-02 lr: 5.48e-06:  89%|▉| 12333/13852 [46:14<05:35,  4.53it/\u001b[A\n",
      "Training loss: 2.55e-02 lr: 5.48e-06:  89%|▉| 12334/13852 [46:14<05:35,  4.53it/\u001b[A\n",
      "Training loss: 3.61e-02 lr: 5.48e-06:  89%|▉| 12335/13852 [46:14<05:48,  4.35it/\u001b[A\n",
      "Training loss: 5.84e-02 lr: 5.47e-06:  89%|▉| 12336/13852 [46:14<05:44,  4.40it/\u001b[A\n",
      "Training loss: 1.34e-01 lr: 5.47e-06:  89%|▉| 12337/13852 [46:14<05:39,  4.46it/\u001b[A\n",
      "Training loss: 9.74e-02 lr: 5.47e-06:  89%|▉| 12338/13852 [46:15<05:36,  4.50it/\u001b[A\n",
      "Training loss: 9.61e-02 lr: 5.46e-06:  89%|▉| 12339/13852 [46:15<05:39,  4.46it/\u001b[A\n",
      "Training loss: 9.22e-02 lr: 5.46e-06:  89%|▉| 12340/13852 [46:15<05:38,  4.47it/\u001b[A\n",
      "Training loss: 6.95e-02 lr: 5.45e-06:  89%|▉| 12341/13852 [46:15<05:37,  4.47it/\u001b[A\n",
      "Training loss: 8.10e-02 lr: 5.45e-06:  89%|▉| 12342/13852 [46:16<05:36,  4.49it/\u001b[A\n",
      "Training loss: 5.71e-02 lr: 5.45e-06:  89%|▉| 12343/13852 [46:16<05:35,  4.50it/\u001b[A\n",
      "Training loss: 4.36e-02 lr: 5.44e-06:  89%|▉| 12344/13852 [46:16<05:35,  4.50it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 5.44e-06:  89%|▉| 12345/13852 [46:16<05:34,  4.50it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 5.44e-06:  89%|▉| 12346/13852 [46:16<05:34,  4.51it/\u001b[A\n",
      "Training loss: 1.08e-01 lr: 5.43e-06:  89%|▉| 12347/13852 [46:17<05:34,  4.50it/\u001b[A\n",
      "Training loss: 7.78e-02 lr: 5.43e-06:  89%|▉| 12348/13852 [46:17<05:34,  4.49it/\u001b[A\n",
      "Training loss: 6.24e-02 lr: 5.43e-06:  89%|▉| 12349/13852 [46:17<05:32,  4.52it/\u001b[A\n",
      "Training loss: 7.25e-02 lr: 5.42e-06:  89%|▉| 12350/13852 [46:17<05:31,  4.54it/\u001b[A\n",
      "Training loss: 5.88e-02 lr: 5.42e-06:  89%|▉| 12351/13852 [46:18<05:29,  4.55it/\u001b[A\n",
      "Training loss: 5.01e-02 lr: 5.41e-06:  89%|▉| 12352/13852 [46:18<05:30,  4.54it/\u001b[A\n",
      "Training loss: 3.73e-02 lr: 5.41e-06:  89%|▉| 12353/13852 [46:18<05:33,  4.50it/\u001b[A\n",
      "Training loss: 2.99e-02 lr: 5.41e-06:  89%|▉| 12354/13852 [46:18<05:32,  4.51it/\u001b[A\n",
      "Training loss: 2.99e-02 lr: 5.40e-06:  89%|▉| 12355/13852 [46:18<05:32,  4.50it/\u001b[A\n",
      "Training loss: 4.55e-02 lr: 5.40e-06:  89%|▉| 12356/13852 [46:19<05:31,  4.51it/\u001b[A\n",
      "Training loss: 3.29e-02 lr: 5.40e-06:  89%|▉| 12357/13852 [46:19<05:32,  4.50it/\u001b[A\n",
      "Training loss: 4.28e-02 lr: 5.39e-06:  89%|▉| 12358/13852 [46:19<05:31,  4.51it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 5.39e-06:  89%|▉| 12359/13852 [46:19<05:31,  4.51it/\u001b[A\n",
      "Training loss: 2.80e-02 lr: 5.39e-06:  89%|▉| 12360/13852 [46:20<05:32,  4.49it/\u001b[A\n",
      "Training loss: 2.08e-02 lr: 5.38e-06:  89%|▉| 12361/13852 [46:20<05:31,  4.49it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 5.38e-06:  89%|▉| 12362/13852 [46:20<05:29,  4.52it/\u001b[A\n",
      "Training loss: 6.04e-02 lr: 5.38e-06:  89%|▉| 12363/13852 [46:20<05:30,  4.50it/\u001b[A\n",
      "Training loss: 4.55e-02 lr: 5.37e-06:  89%|▉| 12364/13852 [46:20<05:30,  4.51it/\u001b[A\n",
      "Training loss: 4.91e-02 lr: 5.37e-06:  89%|▉| 12365/13852 [46:21<05:29,  4.51it/\u001b[A\n",
      "Training loss: 9.33e-02 lr: 5.36e-06:  89%|▉| 12366/13852 [46:21<05:30,  4.49it/\u001b[A\n",
      "Training loss: 8.50e-02 lr: 5.36e-06:  89%|▉| 12367/13852 [46:21<05:30,  4.50it/\u001b[A\n",
      "Training loss: 7.46e-02 lr: 5.36e-06:  89%|▉| 12368/13852 [46:21<05:30,  4.49it/\u001b[A\n",
      "Training loss: 6.37e-02 lr: 5.35e-06:  89%|▉| 12369/13852 [46:22<05:29,  4.50it/\u001b[A\n",
      "Training loss: 6.22e-02 lr: 5.35e-06:  89%|▉| 12370/13852 [46:22<05:30,  4.48it/\u001b[A\n",
      "Training loss: 8.98e-02 lr: 5.35e-06:  89%|▉| 12371/13852 [46:22<05:30,  4.48it/\u001b[A\n",
      "Training loss: 7.32e-02 lr: 5.34e-06:  89%|▉| 12372/13852 [46:22<05:29,  4.49it/\u001b[A\n",
      "Training loss: 7.01e-02 lr: 5.34e-06:  89%|▉| 12373/13852 [46:22<05:27,  4.52it/\u001b[A\n",
      "Training loss: 9.41e-02 lr: 5.34e-06:  89%|▉| 12374/13852 [46:23<05:26,  4.53it/\u001b[A\n",
      "Training loss: 8.22e-02 lr: 5.33e-06:  89%|▉| 12375/13852 [46:23<05:27,  4.51it/\u001b[A\n",
      "Training loss: 6.53e-02 lr: 5.33e-06:  89%|▉| 12376/13852 [46:23<05:27,  4.50it/\u001b[A\n",
      "Training loss: 4.80e-02 lr: 5.32e-06:  89%|▉| 12377/13852 [46:23<05:27,  4.51it/\u001b[A\n",
      "Training loss: 3.73e-02 lr: 5.32e-06:  89%|▉| 12378/13852 [46:24<05:26,  4.51it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 5.32e-06:  89%|▉| 12379/13852 [46:24<05:26,  4.51it/\u001b[A\n",
      "Training loss: 5.24e-02 lr: 5.31e-06:  89%|▉| 12380/13852 [46:24<05:29,  4.47it/\u001b[A\n",
      "Training loss: 4.26e-02 lr: 5.31e-06:  89%|▉| 12381/13852 [46:24<05:28,  4.48it/\u001b[A\n",
      "Training loss: 3.55e-02 lr: 5.31e-06:  89%|▉| 12382/13852 [46:24<05:28,  4.48it/\u001b[A\n",
      "Training loss: 5.25e-02 lr: 5.30e-06:  89%|▉| 12383/13852 [46:25<05:26,  4.50it/\u001b[A\n",
      "Training loss: 4.03e-02 lr: 5.30e-06:  89%|▉| 12384/13852 [46:25<05:24,  4.53it/\u001b[A\n",
      "Training loss: 4.15e-02 lr: 5.30e-06:  89%|▉| 12385/13852 [46:25<05:22,  4.55it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 5.29e-06:  89%|▉| 12386/13852 [46:25<05:21,  4.56it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 5.29e-06:  89%|▉| 12387/13852 [46:26<05:21,  4.55it/\u001b[A\n",
      "Training loss: 2.96e-02 lr: 5.28e-06:  89%|▉| 12388/13852 [46:26<05:24,  4.51it/\u001b[A\n",
      "Training loss: 2.36e-02 lr: 5.28e-06:  89%|▉| 12389/13852 [46:26<05:24,  4.51it/\u001b[A\n",
      "Training loss: 2.05e-02 lr: 5.28e-06:  89%|▉| 12390/13852 [46:26<05:24,  4.51it/\u001b[A\n",
      "Training loss: 4.11e-02 lr: 5.27e-06:  89%|▉| 12391/13852 [46:26<05:24,  4.50it/\u001b[A\n",
      "Training loss: 3.12e-02 lr: 5.27e-06:  89%|▉| 12392/13852 [46:27<05:25,  4.49it/\u001b[A\n",
      "Training loss: 2.58e-02 lr: 5.27e-06:  89%|▉| 12393/13852 [46:27<05:25,  4.48it/\u001b[A\n",
      "Training loss: 2.99e-02 lr: 5.26e-06:  89%|▉| 12394/13852 [46:27<05:25,  4.48it/\u001b[A\n",
      "Training loss: 6.10e-02 lr: 5.26e-06:  89%|▉| 12395/13852 [46:27<05:24,  4.49it/\u001b[A\n",
      "Training loss: 4.38e-02 lr: 5.26e-06:  89%|▉| 12396/13852 [46:28<05:23,  4.50it/\u001b[A\n",
      "Training loss: 3.16e-02 lr: 5.25e-06:  89%|▉| 12397/13852 [46:28<05:21,  4.53it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 5.25e-06:  90%|▉| 12398/13852 [46:28<05:19,  4.55it/\u001b[A\n",
      "Training loss: 4.21e-02 lr: 5.25e-06:  90%|▉| 12399/13852 [46:28<05:20,  4.53it/\u001b[A\n",
      "Training loss: 3.49e-02 lr: 5.24e-06:  90%|▉| 12400/13852 [46:28<05:20,  4.52it/\u001b[A\n",
      "Training loss: 4.41e-02 lr: 5.24e-06:  90%|▉| 12401/13852 [46:29<05:20,  4.53it/\u001b[A\n",
      "Training loss: 3.26e-02 lr: 5.23e-06:  90%|▉| 12402/13852 [46:29<05:20,  4.53it/\u001b[A\n",
      "Training loss: 2.46e-02 lr: 5.23e-06:  90%|▉| 12403/13852 [46:29<05:20,  4.52it/\u001b[A\n",
      "Training loss: 3.63e-02 lr: 5.23e-06:  90%|▉| 12404/13852 [46:29<05:20,  4.52it/\u001b[A\n",
      "Training loss: 2.86e-02 lr: 5.22e-06:  90%|▉| 12405/13852 [46:30<05:21,  4.51it/\u001b[A\n",
      "Training loss: 2.46e-02 lr: 5.22e-06:  90%|▉| 12406/13852 [46:30<05:21,  4.50it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.84e-02 lr: 5.22e-06:  90%|▉| 12407/13852 [46:30<05:20,  4.50it/\u001b[A\n",
      "Training loss: 1.86e-02 lr: 5.21e-06:  90%|▉| 12408/13852 [46:30<05:19,  4.53it/\u001b[A\n",
      "Training loss: 3.50e-02 lr: 5.21e-06:  90%|▉| 12409/13852 [46:30<05:17,  4.55it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 5.21e-06:  90%|▉| 12410/13852 [46:31<05:16,  4.56it/\u001b[A\n",
      "Training loss: 3.84e-02 lr: 5.20e-06:  90%|▉| 12411/13852 [46:31<05:22,  4.47it/\u001b[A\n",
      "Training loss: 9.64e-02 lr: 5.20e-06:  90%|▉| 12412/13852 [46:31<05:20,  4.49it/\u001b[A\n",
      "Training loss: 7.06e-02 lr: 5.19e-06:  90%|▉| 12413/13852 [46:31<05:19,  4.50it/\u001b[A\n",
      "Training loss: 5.22e-02 lr: 5.19e-06:  90%|▉| 12414/13852 [46:32<05:19,  4.50it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 5.19e-06:  90%|▉| 12415/13852 [46:32<05:21,  4.47it/\u001b[A\n",
      "Training loss: 2.79e-02 lr: 5.18e-06:  90%|▉| 12416/13852 [46:32<05:20,  4.48it/\u001b[A\n",
      "Training loss: 2.24e-02 lr: 5.18e-06:  90%|▉| 12417/13852 [46:32<05:20,  4.48it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 5.18e-06:  90%|▉| 12418/13852 [46:32<05:19,  4.49it/\u001b[A\n",
      "Training loss: 5.60e-02 lr: 5.17e-06:  90%|▉| 12419/13852 [46:33<05:19,  4.49it/\u001b[A\n",
      "Training loss: 4.61e-02 lr: 5.17e-06:  90%|▉| 12420/13852 [46:33<05:19,  4.49it/\u001b[A\n",
      "Training loss: 5.12e-02 lr: 5.17e-06:  90%|▉| 12421/13852 [46:33<05:17,  4.51it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 5.16e-06:  90%|▉| 12422/13852 [46:33<05:15,  4.53it/\u001b[A\n",
      "Training loss: 3.36e-02 lr: 5.16e-06:  90%|▉| 12423/13852 [46:34<05:16,  4.52it/\u001b[A\n",
      "Training loss: 1.08e-01 lr: 5.15e-06:  90%|▉| 12424/13852 [46:34<05:16,  4.52it/\u001b[A\n",
      "Training loss: 8.50e-02 lr: 5.15e-06:  90%|▉| 12425/13852 [46:34<05:16,  4.51it/\u001b[A\n",
      "Training loss: 1.04e-01 lr: 5.15e-06:  90%|▉| 12426/13852 [46:34<05:15,  4.52it/\u001b[A\n",
      "Training loss: 1.02e-01 lr: 5.14e-06:  90%|▉| 12427/13852 [46:34<05:15,  4.51it/\u001b[A\n",
      "Training loss: 8.84e-02 lr: 5.14e-06:  90%|▉| 12428/13852 [46:35<05:15,  4.51it/\u001b[A\n",
      "Training loss: 7.38e-02 lr: 5.14e-06:  90%|▉| 12429/13852 [46:35<05:15,  4.51it/\u001b[A\n",
      "Training loss: 5.40e-02 lr: 5.13e-06:  90%|▉| 12430/13852 [46:35<05:15,  4.50it/\u001b[A\n",
      "Training loss: 8.83e-02 lr: 5.13e-06:  90%|▉| 12431/13852 [46:35<05:15,  4.50it/\u001b[A\n",
      "Training loss: 6.34e-02 lr: 5.13e-06:  90%|▉| 12432/13852 [46:36<05:15,  4.50it/\u001b[A\n",
      "Training loss: 5.35e-02 lr: 5.12e-06:  90%|▉| 12433/13852 [46:36<05:13,  4.53it/\u001b[A\n",
      "Training loss: 6.54e-02 lr: 5.12e-06:  90%|▉| 12434/13852 [46:36<05:12,  4.54it/\u001b[A\n",
      "Training loss: 8.72e-02 lr: 5.12e-06:  90%|▉| 12435/13852 [46:36<05:14,  4.51it/\u001b[A\n",
      "Training loss: 6.39e-02 lr: 5.11e-06:  90%|▉| 12436/13852 [46:36<05:13,  4.51it/\u001b[A\n",
      "Training loss: 5.90e-02 lr: 5.11e-06:  90%|▉| 12437/13852 [46:37<05:14,  4.49it/\u001b[A\n",
      "Training loss: 5.32e-02 lr: 5.10e-06:  90%|▉| 12438/13852 [46:37<05:16,  4.47it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 5.10e-06:  90%|▉| 12439/13852 [46:37<05:17,  4.45it/\u001b[A\n",
      "Training loss: 1.44e-01 lr: 5.10e-06:  90%|▉| 12440/13852 [46:37<05:24,  4.34it/\u001b[A\n",
      "Training loss: 1.03e-01 lr: 5.09e-06:  90%|▉| 12441/13852 [46:38<05:29,  4.28it/\u001b[A\n",
      "Training loss: 9.50e-02 lr: 5.09e-06:  90%|▉| 12442/13852 [46:38<05:30,  4.27it/\u001b[A\n",
      "Training loss: 8.06e-02 lr: 5.09e-06:  90%|▉| 12443/13852 [46:38<05:24,  4.34it/\u001b[A\n",
      "Training loss: 6.56e-02 lr: 5.08e-06:  90%|▉| 12444/13852 [46:38<05:20,  4.39it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 5.08e-06:  90%|▉| 12445/13852 [46:38<05:17,  4.43it/\u001b[A\n",
      "Training loss: 3.33e-02 lr: 5.08e-06:  90%|▉| 12446/13852 [46:39<05:14,  4.46it/\u001b[A\n",
      "Training loss: 7.31e-02 lr: 5.07e-06:  90%|▉| 12447/13852 [46:39<05:13,  4.49it/\u001b[A\n",
      "Training loss: 6.08e-02 lr: 5.07e-06:  90%|▉| 12448/13852 [46:39<05:12,  4.49it/\u001b[A\n",
      "Training loss: 4.76e-02 lr: 5.06e-06:  90%|▉| 12449/13852 [46:39<05:11,  4.50it/\u001b[A\n",
      "Training loss: 7.40e-02 lr: 5.06e-06:  90%|▉| 12450/13852 [46:40<05:11,  4.50it/\u001b[A\n",
      "Training loss: 9.60e-02 lr: 5.06e-06:  90%|▉| 12451/13852 [46:40<05:10,  4.51it/\u001b[A\n",
      "Training loss: 8.22e-02 lr: 5.05e-06:  90%|▉| 12452/13852 [46:40<05:10,  4.51it/\u001b[A\n",
      "Training loss: 8.25e-02 lr: 5.05e-06:  90%|▉| 12453/13852 [46:40<05:08,  4.53it/\u001b[A\n",
      "Training loss: 9.39e-02 lr: 5.05e-06:  90%|▉| 12454/13852 [46:40<05:07,  4.55it/\u001b[A\n",
      "Training loss: 7.73e-02 lr: 5.04e-06:  90%|▉| 12455/13852 [46:41<05:05,  4.57it/\u001b[A\n",
      "Training loss: 5.57e-02 lr: 5.04e-06:  90%|▉| 12456/13852 [46:41<05:10,  4.50it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 5.04e-06:  90%|▉| 12457/13852 [46:41<05:10,  4.50it/\u001b[A\n",
      "Training loss: 5.47e-02 lr: 5.03e-06:  90%|▉| 12458/13852 [46:41<05:09,  4.50it/\u001b[A\n",
      "Training loss: 3.91e-02 lr: 5.03e-06:  90%|▉| 12459/13852 [46:42<05:09,  4.51it/\u001b[A\n",
      "Training loss: 4.27e-02 lr: 5.02e-06:  90%|▉| 12460/13852 [46:42<05:09,  4.50it/\u001b[A\n",
      "Training loss: 4.77e-02 lr: 5.02e-06:  90%|▉| 12461/13852 [46:42<05:09,  4.50it/\u001b[A\n",
      "Training loss: 4.21e-02 lr: 5.02e-06:  90%|▉| 12462/13852 [46:42<05:09,  4.49it/\u001b[A\n",
      "Training loss: 3.14e-02 lr: 5.01e-06:  90%|▉| 12463/13852 [46:42<05:08,  4.50it/\u001b[A\n",
      "Training loss: 3.92e-02 lr: 5.01e-06:  90%|▉| 12464/13852 [46:43<05:08,  4.50it/\u001b[A\n",
      "Training loss: 3.10e-02 lr: 5.01e-06:  90%|▉| 12465/13852 [46:43<05:07,  4.51it/\u001b[A\n",
      "Training loss: 4.53e-02 lr: 5.00e-06:  90%|▉| 12466/13852 [46:43<05:06,  4.53it/\u001b[A\n",
      "Training loss: 3.51e-02 lr: 5.00e-06:  90%|▉| 12467/13852 [46:43<05:04,  4.55it/\u001b[A\n",
      "Training loss: 3.92e-02 lr: 5.00e-06:  90%|▉| 12468/13852 [46:44<05:04,  4.54it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 4.99e-06:  90%|▉| 12469/13852 [46:44<05:04,  4.55it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 4.99e-06:  90%|▉| 12470/13852 [46:44<05:04,  4.53it/\u001b[A\n",
      "Training loss: 2.90e-02 lr: 4.99e-06:  90%|▉| 12471/13852 [46:44<05:04,  4.53it/\u001b[A\n",
      "Training loss: 2.32e-02 lr: 4.98e-06:  90%|▉| 12472/13852 [46:44<05:04,  4.53it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 4.98e-06:  90%|▉| 12473/13852 [46:45<05:06,  4.50it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 4.97e-06:  90%|▉| 12474/13852 [46:45<05:05,  4.50it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 4.97e-06:  90%|▉| 12475/13852 [46:45<05:05,  4.51it/\u001b[A\n",
      "Training loss: 4.31e-02 lr: 4.97e-06:  90%|▉| 12476/13852 [46:45<05:04,  4.51it/\u001b[A\n",
      "Training loss: 4.18e-02 lr: 4.96e-06:  90%|▉| 12477/13852 [46:46<05:04,  4.51it/\u001b[A\n",
      "Training loss: 3.16e-02 lr: 4.96e-06:  90%|▉| 12478/13852 [46:46<05:03,  4.53it/\u001b[A\n",
      "Training loss: 6.45e-02 lr: 4.96e-06:  90%|▉| 12479/13852 [46:46<05:01,  4.56it/\u001b[A\n",
      "Training loss: 5.03e-02 lr: 4.95e-06:  90%|▉| 12480/13852 [46:46<04:59,  4.57it/\u001b[A\n",
      "Training loss: 9.88e-02 lr: 4.95e-06:  90%|▉| 12481/13852 [46:46<05:01,  4.55it/\u001b[A\n",
      "Training loss: 7.10e-02 lr: 4.95e-06:  90%|▉| 12482/13852 [46:47<05:02,  4.53it/\u001b[A\n",
      "Training loss: 5.80e-02 lr: 4.94e-06:  90%|▉| 12483/13852 [46:47<05:03,  4.51it/\u001b[A\n",
      "Training loss: 4.39e-02 lr: 4.94e-06:  90%|▉| 12484/13852 [46:47<05:03,  4.51it/\u001b[A\n",
      "Training loss: 3.90e-02 lr: 4.93e-06:  90%|▉| 12485/13852 [46:47<05:03,  4.51it/\u001b[A\n",
      "Training loss: 2.84e-02 lr: 4.93e-06:  90%|▉| 12486/13852 [46:48<05:02,  4.51it/\u001b[A\n",
      "Training loss: 2.58e-02 lr: 4.93e-06:  90%|▉| 12487/13852 [46:48<05:02,  4.51it/\u001b[A\n",
      "Training loss: 2.82e-02 lr: 4.92e-06:  90%|▉| 12488/13852 [46:48<05:03,  4.49it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 4.92e-06:  90%|▉| 12489/13852 [46:48<05:03,  4.49it/\u001b[A\n",
      "Training loss: 1.98e-02 lr: 4.92e-06:  90%|▉| 12490/13852 [46:48<05:01,  4.52it/\u001b[A\n",
      "Training loss: 1.89e-02 lr: 4.91e-06:  90%|▉| 12491/13852 [46:49<04:59,  4.54it/\u001b[A\n",
      "Training loss: 5.21e-02 lr: 4.91e-06:  90%|▉| 12492/13852 [46:49<04:57,  4.57it/\u001b[A\n",
      "Training loss: 9.43e-02 lr: 4.91e-06:  90%|▉| 12493/13852 [46:49<04:57,  4.58it/\u001b[A\n",
      "Training loss: 6.86e-02 lr: 4.90e-06:  90%|▉| 12494/13852 [46:49<04:58,  4.56it/\u001b[A\n",
      "Training loss: 7.13e-02 lr: 4.90e-06:  90%|▉| 12495/13852 [46:50<04:58,  4.54it/\u001b[A\n",
      "Training loss: 5.15e-02 lr: 4.89e-06:  90%|▉| 12496/13852 [46:50<05:00,  4.51it/\u001b[A\n",
      "Training loss: 5.52e-02 lr: 4.89e-06:  90%|▉| 12497/13852 [46:50<04:59,  4.52it/\u001b[A\n",
      "Training loss: 4.85e-02 lr: 4.89e-06:  90%|▉| 12498/13852 [46:50<05:01,  4.50it/\u001b[A\n",
      "Training loss: 9.21e-02 lr: 4.88e-06:  90%|▉| 12499/13852 [46:50<05:01,  4.49it/\u001b[A\n",
      "Training loss: 6.69e-02 lr: 4.88e-06:  90%|▉| 12500/13852 [46:51<05:01,  4.48it/\u001b[A\n",
      "Training loss: 6.31e-02 lr: 4.88e-06:  90%|▉| 12501/13852 [46:51<05:03,  4.45it/\u001b[A\n",
      "Training loss: 5.49e-02 lr: 4.87e-06:  90%|▉| 12502/13852 [46:51<05:02,  4.46it/\u001b[A\n",
      "Training loss: 4.52e-02 lr: 4.87e-06:  90%|▉| 12503/13852 [46:51<04:59,  4.50it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.98e-02 lr: 4.87e-06:  90%|▉| 12504/13852 [46:52<04:57,  4.52it/\u001b[A\n",
      "Training loss: 3.17e-02 lr: 4.86e-06:  90%|▉| 12505/13852 [46:52<04:59,  4.49it/\u001b[A\n",
      "Training loss: 2.62e-02 lr: 4.86e-06:  90%|▉| 12506/13852 [46:52<04:59,  4.50it/\u001b[A\n",
      "Training loss: 2.76e-02 lr: 4.86e-06:  90%|▉| 12507/13852 [46:52<04:58,  4.51it/\u001b[A\n",
      "Training loss: 8.11e-02 lr: 4.85e-06:  90%|▉| 12508/13852 [46:52<04:57,  4.51it/\u001b[A\n",
      "Training loss: 5.85e-02 lr: 4.85e-06:  90%|▉| 12509/13852 [46:53<04:57,  4.51it/\u001b[A\n",
      "Training loss: 4.88e-02 lr: 4.84e-06:  90%|▉| 12510/13852 [46:53<04:57,  4.51it/\u001b[A\n",
      "Training loss: 4.66e-02 lr: 4.84e-06:  90%|▉| 12511/13852 [46:53<04:57,  4.51it/\u001b[A\n",
      "Training loss: 5.16e-02 lr: 4.84e-06:  90%|▉| 12512/13852 [46:53<04:56,  4.51it/\u001b[A\n",
      "Training loss: 5.00e-02 lr: 4.83e-06:  90%|▉| 12513/13852 [46:54<04:56,  4.51it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 4.83e-06:  90%|▉| 12514/13852 [46:54<04:57,  4.50it/\u001b[A\n",
      "Training loss: 3.40e-02 lr: 4.83e-06:  90%|▉| 12515/13852 [46:54<04:55,  4.52it/\u001b[A\n",
      "Training loss: 3.10e-02 lr: 4.82e-06:  90%|▉| 12516/13852 [46:54<04:54,  4.54it/\u001b[A\n",
      "Training loss: 3.02e-02 lr: 4.82e-06:  90%|▉| 12517/13852 [46:54<04:56,  4.50it/\u001b[A\n",
      "Training loss: 2.15e-02 lr: 4.82e-06:  90%|▉| 12518/13852 [46:55<04:55,  4.51it/\u001b[A\n",
      "Training loss: 1.57e-02 lr: 4.81e-06:  90%|▉| 12519/13852 [46:55<04:55,  4.51it/\u001b[A\n",
      "Training loss: 4.76e-02 lr: 4.81e-06:  90%|▉| 12520/13852 [46:55<04:55,  4.51it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 4.80e-06:  90%|▉| 12521/13852 [46:55<04:54,  4.51it/\u001b[A\n",
      "Training loss: 3.39e-02 lr: 4.80e-06:  90%|▉| 12522/13852 [46:56<04:54,  4.52it/\u001b[A\n",
      "Training loss: 2.44e-02 lr: 4.80e-06:  90%|▉| 12523/13852 [46:56<04:54,  4.51it/\u001b[A\n",
      "Training loss: 4.46e-02 lr: 4.79e-06:  90%|▉| 12524/13852 [46:56<04:54,  4.51it/\u001b[A\n",
      "Training loss: 4.56e-02 lr: 4.79e-06:  90%|▉| 12525/13852 [46:56<04:54,  4.50it/\u001b[A\n",
      "Training loss: 3.44e-02 lr: 4.79e-06:  90%|▉| 12526/13852 [46:56<04:53,  4.52it/\u001b[A\n",
      "Training loss: 2.72e-02 lr: 4.78e-06:  90%|▉| 12527/13852 [46:57<04:52,  4.54it/\u001b[A\n",
      "Training loss: 2.79e-02 lr: 4.78e-06:  90%|▉| 12528/13852 [46:57<04:52,  4.53it/\u001b[A\n",
      "Training loss: 2.24e-02 lr: 4.78e-06:  90%|▉| 12529/13852 [46:57<04:51,  4.54it/\u001b[A\n",
      "Training loss: 5.44e-02 lr: 4.77e-06:  90%|▉| 12530/13852 [46:57<04:51,  4.53it/\u001b[A\n",
      "Training loss: 4.19e-02 lr: 4.77e-06:  90%|▉| 12531/13852 [46:58<04:51,  4.53it/\u001b[A\n",
      "Training loss: 3.20e-02 lr: 4.76e-06:  90%|▉| 12532/13852 [46:58<04:51,  4.53it/\u001b[A\n",
      "Training loss: 2.37e-02 lr: 4.76e-06:  90%|▉| 12533/13852 [46:58<04:51,  4.52it/\u001b[A\n",
      "Training loss: 3.25e-02 lr: 4.76e-06:  90%|▉| 12534/13852 [46:58<04:52,  4.51it/\u001b[A\n",
      "Training loss: 2.83e-02 lr: 4.75e-06:  90%|▉| 12535/13852 [46:58<04:51,  4.51it/\u001b[A\n",
      "Training loss: 2.93e-02 lr: 4.75e-06:  90%|▉| 12536/13852 [46:59<04:51,  4.51it/\u001b[A\n",
      "Training loss: 2.57e-02 lr: 4.75e-06:  91%|▉| 12537/13852 [46:59<04:51,  4.51it/\u001b[A\n",
      "Training loss: 5.60e-02 lr: 4.74e-06:  91%|▉| 12538/13852 [46:59<04:52,  4.50it/\u001b[A\n",
      "Training loss: 4.59e-02 lr: 4.74e-06:  91%|▉| 12539/13852 [46:59<04:51,  4.50it/\u001b[A\n",
      "Training loss: 3.29e-02 lr: 4.74e-06:  91%|▉| 12540/13852 [47:00<04:49,  4.53it/\u001b[A\n",
      "Training loss: 2.60e-02 lr: 4.73e-06:  91%|▉| 12541/13852 [47:00<04:48,  4.54it/\u001b[A\n",
      "Training loss: 2.10e-02 lr: 4.73e-06:  91%|▉| 12542/13852 [47:00<04:50,  4.50it/\u001b[A\n",
      "Training loss: 4.47e-02 lr: 4.73e-06:  91%|▉| 12543/13852 [47:00<04:50,  4.50it/\u001b[A\n",
      "Training loss: 3.99e-02 lr: 4.72e-06:  91%|▉| 12544/13852 [47:00<04:49,  4.51it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 4.72e-06:  91%|▉| 12545/13852 [47:01<04:49,  4.52it/\u001b[A\n",
      "Training loss: 3.87e-02 lr: 4.71e-06:  91%|▉| 12546/13852 [47:01<04:51,  4.47it/\u001b[A\n",
      "Training loss: 3.04e-02 lr: 4.71e-06:  91%|▉| 12547/13852 [47:01<04:51,  4.48it/\u001b[A\n",
      "Training loss: 2.17e-02 lr: 4.71e-06:  91%|▉| 12548/13852 [47:01<04:50,  4.48it/\u001b[A\n",
      "Training loss: 2.96e-02 lr: 4.70e-06:  91%|▉| 12549/13852 [47:02<04:50,  4.49it/\u001b[A\n",
      "Training loss: 4.88e-02 lr: 4.70e-06:  91%|▉| 12550/13852 [47:02<04:51,  4.46it/\u001b[A\n",
      "Training loss: 5.61e-02 lr: 4.70e-06:  91%|▉| 12551/13852 [47:02<04:49,  4.49it/\u001b[A\n",
      "Training loss: 4.05e-02 lr: 4.69e-06:  91%|▉| 12552/13852 [47:02<04:48,  4.51it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 4.69e-06:  91%|▉| 12553/13852 [47:02<04:49,  4.49it/\u001b[A\n",
      "Training loss: 2.83e-02 lr: 4.69e-06:  91%|▉| 12554/13852 [47:03<04:48,  4.49it/\u001b[A\n",
      "Training loss: 2.28e-02 lr: 4.68e-06:  91%|▉| 12555/13852 [47:03<04:47,  4.51it/\u001b[A\n",
      "Training loss: 2.85e-02 lr: 4.68e-06:  91%|▉| 12556/13852 [47:03<04:48,  4.49it/\u001b[A\n",
      "Training loss: 4.94e-02 lr: 4.67e-06:  91%|▉| 12557/13852 [47:03<04:48,  4.49it/\u001b[A\n",
      "Training loss: 3.75e-02 lr: 4.67e-06:  91%|▉| 12558/13852 [47:04<04:47,  4.50it/\u001b[A\n",
      "Training loss: 2.72e-02 lr: 4.67e-06:  91%|▉| 12559/13852 [47:04<04:47,  4.50it/\u001b[A\n",
      "Training loss: 3.56e-02 lr: 4.66e-06:  91%|▉| 12560/13852 [47:04<04:47,  4.50it/\u001b[A\n",
      "Training loss: 4.65e-02 lr: 4.66e-06:  91%|▉| 12561/13852 [47:04<04:47,  4.50it/\u001b[A\n",
      "Training loss: 5.29e-02 lr: 4.66e-06:  91%|▉| 12562/13852 [47:04<04:45,  4.52it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 4.65e-06:  91%|▉| 12563/13852 [47:05<04:43,  4.54it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 4.65e-06:  91%|▉| 12564/13852 [47:05<04:42,  4.56it/\u001b[A\n",
      "Training loss: 3.55e-02 lr: 4.65e-06:  91%|▉| 12565/13852 [47:05<04:41,  4.56it/\u001b[A\n",
      "Training loss: 2.65e-02 lr: 4.64e-06:  91%|▉| 12566/13852 [47:05<04:42,  4.56it/\u001b[A\n",
      "Training loss: 1.96e-02 lr: 4.64e-06:  91%|▉| 12567/13852 [47:06<04:42,  4.55it/\u001b[A\n",
      "Training loss: 4.10e-02 lr: 4.64e-06:  91%|▉| 12568/13852 [47:06<04:42,  4.54it/\u001b[A\n",
      "Training loss: 8.99e-02 lr: 4.63e-06:  91%|▉| 12569/13852 [47:06<04:43,  4.53it/\u001b[A\n",
      "Training loss: 6.50e-02 lr: 4.63e-06:  91%|▉| 12570/13852 [47:06<04:43,  4.52it/\u001b[A\n",
      "Training loss: 6.36e-02 lr: 4.62e-06:  91%|▉| 12571/13852 [47:06<04:44,  4.50it/\u001b[A\n",
      "Training loss: 5.55e-02 lr: 4.62e-06:  91%|▉| 12572/13852 [47:07<04:44,  4.50it/\u001b[A\n",
      "Training loss: 8.56e-02 lr: 4.62e-06:  91%|▉| 12573/13852 [47:07<04:49,  4.42it/\u001b[A\n",
      "Training loss: 6.57e-02 lr: 4.61e-06:  91%|▉| 12574/13852 [47:07<04:48,  4.43it/\u001b[A\n",
      "Training loss: 4.84e-02 lr: 4.61e-06:  91%|▉| 12575/13852 [47:07<04:47,  4.44it/\u001b[A\n",
      "Training loss: 3.45e-02 lr: 4.61e-06:  91%|▉| 12576/13852 [47:08<05:02,  4.22it/\u001b[A\n",
      "Training loss: 2.63e-02 lr: 4.60e-06:  91%|▉| 12577/13852 [47:08<05:14,  4.06it/\u001b[A\n",
      "Training loss: 3.52e-02 lr: 4.60e-06:  91%|▉| 12578/13852 [47:08<05:12,  4.07it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 4.60e-06:  91%|▉| 12579/13852 [47:08<05:11,  4.09it/\u001b[A\n",
      "Training loss: 4.10e-02 lr: 4.59e-06:  91%|▉| 12580/13852 [47:09<05:08,  4.12it/\u001b[A\n",
      "Training loss: 3.25e-02 lr: 4.59e-06:  91%|▉| 12581/13852 [47:09<05:07,  4.13it/\u001b[A\n",
      "Training loss: 2.94e-02 lr: 4.58e-06:  91%|▉| 12582/13852 [47:09<05:08,  4.11it/\u001b[A\n",
      "Training loss: 3.17e-02 lr: 4.58e-06:  91%|▉| 12583/13852 [47:09<05:10,  4.09it/\u001b[A\n",
      "Training loss: 2.49e-02 lr: 4.58e-06:  91%|▉| 12584/13852 [47:10<05:10,  4.09it/\u001b[A\n",
      "Training loss: 2.15e-02 lr: 4.57e-06:  91%|▉| 12585/13852 [47:10<05:00,  4.21it/\u001b[A\n",
      "Training loss: 2.53e-02 lr: 4.57e-06:  91%|▉| 12586/13852 [47:10<04:54,  4.30it/\u001b[A\n",
      "Training loss: 1.86e-02 lr: 4.57e-06:  91%|▉| 12587/13852 [47:10<04:51,  4.35it/\u001b[A\n",
      "Training loss: 1.53e-02 lr: 4.56e-06:  91%|▉| 12588/13852 [47:10<04:47,  4.39it/\u001b[A\n",
      "Training loss: 4.89e-02 lr: 4.56e-06:  91%|▉| 12589/13852 [47:11<04:45,  4.43it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 4.56e-06:  91%|▉| 12590/13852 [47:11<04:47,  4.39it/\u001b[A\n",
      "Training loss: 7.03e-02 lr: 4.55e-06:  91%|▉| 12591/13852 [47:11<04:45,  4.42it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 4.55e-06:  91%|▉| 12592/13852 [47:11<04:43,  4.45it/\u001b[A\n",
      "Training loss: 4.73e-02 lr: 4.54e-06:  91%|▉| 12593/13852 [47:12<04:42,  4.46it/\u001b[A\n",
      "Training loss: 4.26e-02 lr: 4.54e-06:  91%|▉| 12594/13852 [47:12<04:42,  4.45it/\u001b[A\n",
      "Training loss: 3.22e-02 lr: 4.54e-06:  91%|▉| 12595/13852 [47:12<04:41,  4.47it/\u001b[A\n",
      "Training loss: 2.48e-02 lr: 4.53e-06:  91%|▉| 12596/13852 [47:12<04:38,  4.51it/\u001b[A\n",
      "Training loss: 1.93e-02 lr: 4.53e-06:  91%|▉| 12597/13852 [47:12<04:37,  4.53it/\u001b[A\n",
      "Training loss: 4.04e-02 lr: 4.53e-06:  91%|▉| 12598/13852 [47:13<04:39,  4.49it/\u001b[A\n",
      "Training loss: 3.82e-02 lr: 4.52e-06:  91%|▉| 12599/13852 [47:13<04:39,  4.49it/\u001b[A\n",
      "Training loss: 2.95e-02 lr: 4.52e-06:  91%|▉| 12600/13852 [47:13<04:38,  4.49it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.85e-02 lr: 4.52e-06:  91%|▉| 12601/13852 [47:13<04:38,  4.50it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.51e-06:  91%|▉| 12602/13852 [47:14<04:38,  4.48it/\u001b[A\n",
      "Training loss: 8.15e-02 lr: 4.51e-06:  91%|▉| 12603/13852 [47:14<04:38,  4.49it/\u001b[A\n",
      "Training loss: 1.08e-01 lr: 4.51e-06:  91%|▉| 12604/13852 [47:14<04:37,  4.49it/\u001b[A\n",
      "Training loss: 8.75e-02 lr: 4.50e-06:  91%|▉| 12605/13852 [47:14<04:37,  4.50it/\u001b[A\n",
      "Training loss: 7.10e-02 lr: 4.50e-06:  91%|▉| 12606/13852 [47:14<04:37,  4.49it/\u001b[A\n",
      "Training loss: 1.07e-01 lr: 4.49e-06:  91%|▉| 12607/13852 [47:15<04:37,  4.49it/\u001b[A\n",
      "Training loss: 8.27e-02 lr: 4.49e-06:  91%|▉| 12608/13852 [47:15<04:35,  4.51it/\u001b[A\n",
      "Training loss: 6.71e-02 lr: 4.49e-06:  91%|▉| 12609/13852 [47:15<04:34,  4.52it/\u001b[A\n",
      "Training loss: 5.25e-02 lr: 4.48e-06:  91%|▉| 12610/13852 [47:15<04:35,  4.51it/\u001b[A\n",
      "Training loss: 7.64e-02 lr: 4.48e-06:  91%|▉| 12611/13852 [47:16<04:35,  4.51it/\u001b[A\n",
      "Training loss: 8.16e-02 lr: 4.48e-06:  91%|▉| 12612/13852 [47:16<04:35,  4.51it/\u001b[A\n",
      "Training loss: 5.96e-02 lr: 4.47e-06:  91%|▉| 12613/13852 [47:16<04:34,  4.52it/\u001b[A\n",
      "Training loss: 5.53e-02 lr: 4.47e-06:  91%|▉| 12614/13852 [47:16<04:34,  4.51it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 4.47e-06:  91%|▉| 12615/13852 [47:16<04:34,  4.51it/\u001b[A\n",
      "Training loss: 9.19e-02 lr: 4.46e-06:  91%|▉| 12616/13852 [47:17<04:35,  4.49it/\u001b[A\n",
      "Training loss: 6.80e-02 lr: 4.46e-06:  91%|▉| 12617/13852 [47:17<04:37,  4.45it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 4.45e-06:  91%|▉| 12618/13852 [47:17<04:36,  4.47it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 4.45e-06:  91%|▉| 12619/13852 [47:17<04:34,  4.50it/\u001b[A\n",
      "Training loss: 4.32e-02 lr: 4.45e-06:  91%|▉| 12620/13852 [47:18<04:32,  4.53it/\u001b[A\n",
      "Training loss: 3.38e-02 lr: 4.44e-06:  91%|▉| 12621/13852 [47:18<04:30,  4.55it/\u001b[A\n",
      "Training loss: 3.40e-02 lr: 4.44e-06:  91%|▉| 12622/13852 [47:18<04:33,  4.50it/\u001b[A\n",
      "Training loss: 3.57e-02 lr: 4.44e-06:  91%|▉| 12623/13852 [47:18<04:32,  4.50it/\u001b[A\n",
      "Training loss: 2.99e-02 lr: 4.43e-06:  91%|▉| 12624/13852 [47:18<04:32,  4.51it/\u001b[A\n",
      "Training loss: 2.67e-02 lr: 4.43e-06:  91%|▉| 12625/13852 [47:19<04:32,  4.50it/\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.43e-06:  91%|▉| 12626/13852 [47:19<04:32,  4.50it/\u001b[A\n",
      "Training loss: 1.05e-01 lr: 4.42e-06:  91%|▉| 12627/13852 [47:19<04:32,  4.50it/\u001b[A\n",
      "Training loss: 9.42e-02 lr: 4.42e-06:  91%|▉| 12628/13852 [47:19<04:31,  4.50it/\u001b[A\n",
      "Training loss: 7.77e-02 lr: 4.41e-06:  91%|▉| 12629/13852 [47:20<04:31,  4.50it/\u001b[A\n",
      "Training loss: 5.71e-02 lr: 4.41e-06:  91%|▉| 12630/13852 [47:20<04:31,  4.50it/\u001b[A\n",
      "Training loss: 6.05e-02 lr: 4.41e-06:  91%|▉| 12631/13852 [47:20<04:31,  4.49it/\u001b[A\n",
      "Training loss: 7.75e-02 lr: 4.40e-06:  91%|▉| 12632/13852 [47:20<04:30,  4.52it/\u001b[A\n",
      "Training loss: 6.04e-02 lr: 4.40e-06:  91%|▉| 12633/13852 [47:20<04:32,  4.47it/\u001b[A\n",
      "Training loss: 7.83e-02 lr: 4.40e-06:  91%|▉| 12634/13852 [47:21<04:31,  4.49it/\u001b[A\n",
      "Training loss: 7.68e-02 lr: 4.39e-06:  91%|▉| 12635/13852 [47:21<04:32,  4.47it/\u001b[A\n",
      "Training loss: 6.79e-02 lr: 4.39e-06:  91%|▉| 12636/13852 [47:21<04:31,  4.48it/\u001b[A\n",
      "Training loss: 4.91e-02 lr: 4.39e-06:  91%|▉| 12637/13852 [47:21<04:30,  4.48it/\u001b[A\n",
      "Training loss: 4.91e-02 lr: 4.38e-06:  91%|▉| 12638/13852 [47:22<04:30,  4.49it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 4.38e-06:  91%|▉| 12639/13852 [47:22<04:31,  4.47it/\u001b[A\n",
      "Training loss: 2.86e-02 lr: 4.38e-06:  91%|▉| 12640/13852 [47:22<04:30,  4.48it/\u001b[A\n",
      "Training loss: 2.53e-02 lr: 4.37e-06:  91%|▉| 12641/13852 [47:22<04:31,  4.46it/\u001b[A\n",
      "Training loss: 8.93e-02 lr: 4.37e-06:  91%|▉| 12642/13852 [47:22<04:29,  4.49it/\u001b[A\n",
      "Training loss: 6.34e-02 lr: 4.36e-06:  91%|▉| 12643/13852 [47:23<04:28,  4.51it/\u001b[A\n",
      "Training loss: 8.73e-02 lr: 4.36e-06:  91%|▉| 12644/13852 [47:23<04:26,  4.53it/\u001b[A\n",
      "Training loss: 6.41e-02 lr: 4.36e-06:  91%|▉| 12645/13852 [47:23<04:26,  4.53it/\u001b[A\n",
      "Training loss: 4.88e-02 lr: 4.35e-06:  91%|▉| 12646/13852 [47:23<04:26,  4.53it/\u001b[A\n",
      "Training loss: 3.95e-02 lr: 4.35e-06:  91%|▉| 12647/13852 [47:24<04:26,  4.53it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 4.35e-06:  91%|▉| 12648/13852 [47:24<04:26,  4.52it/\u001b[A\n",
      "Training loss: 5.89e-02 lr: 4.34e-06:  91%|▉| 12649/13852 [47:24<04:26,  4.51it/\u001b[A\n",
      "Training loss: 5.66e-02 lr: 4.34e-06:  91%|▉| 12650/13852 [47:24<04:26,  4.51it/\u001b[A\n",
      "Training loss: 4.26e-02 lr: 4.34e-06:  91%|▉| 12651/13852 [47:24<04:26,  4.51it/\u001b[A\n",
      "Training loss: 6.27e-02 lr: 4.33e-06:  91%|▉| 12652/13852 [47:25<04:26,  4.51it/\u001b[A\n",
      "Training loss: 4.89e-02 lr: 4.33e-06:  91%|▉| 12653/13852 [47:25<04:26,  4.50it/\u001b[A\n",
      "Training loss: 4.81e-02 lr: 4.32e-06:  91%|▉| 12654/13852 [47:25<04:26,  4.50it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 4.32e-06:  91%|▉| 12655/13852 [47:25<04:24,  4.52it/\u001b[A\n",
      "Training loss: 4.69e-02 lr: 4.32e-06:  91%|▉| 12656/13852 [47:26<04:23,  4.54it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 4.31e-06:  91%|▉| 12657/13852 [47:26<04:22,  4.56it/\u001b[A\n",
      "Training loss: 3.89e-02 lr: 4.31e-06:  91%|▉| 12658/13852 [47:26<04:22,  4.54it/\u001b[A\n",
      "Training loss: 2.80e-02 lr: 4.31e-06:  91%|▉| 12659/13852 [47:26<04:22,  4.54it/\u001b[A\n",
      "Training loss: 2.14e-02 lr: 4.30e-06:  91%|▉| 12660/13852 [47:26<04:22,  4.54it/\u001b[A\n",
      "Training loss: 2.87e-02 lr: 4.30e-06:  91%|▉| 12661/13852 [47:27<04:22,  4.53it/\u001b[A\n",
      "Training loss: 3.49e-02 lr: 4.30e-06:  91%|▉| 12662/13852 [47:27<04:24,  4.50it/\u001b[A\n",
      "Training loss: 5.09e-02 lr: 4.29e-06:  91%|▉| 12663/13852 [47:27<04:24,  4.49it/\u001b[A\n",
      "Training loss: 4.61e-02 lr: 4.29e-06:  91%|▉| 12664/13852 [47:27<04:24,  4.49it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 4.28e-06:  91%|▉| 12665/13852 [47:28<04:24,  4.49it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 4.28e-06:  91%|▉| 12666/13852 [47:28<04:24,  4.49it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 4.28e-06:  91%|▉| 12667/13852 [47:28<04:22,  4.51it/\u001b[A\n",
      "Training loss: 2.42e-02 lr: 4.27e-06:  91%|▉| 12668/13852 [47:28<04:21,  4.52it/\u001b[A\n",
      "Training loss: 2.45e-02 lr: 4.27e-06:  91%|▉| 12669/13852 [47:28<04:23,  4.50it/\u001b[A\n",
      "Training loss: 4.56e-02 lr: 4.27e-06:  91%|▉| 12670/13852 [47:29<04:22,  4.51it/\u001b[A\n",
      "Training loss: 3.63e-02 lr: 4.26e-06:  91%|▉| 12671/13852 [47:29<04:21,  4.51it/\u001b[A\n",
      "Training loss: 2.89e-02 lr: 4.26e-06:  91%|▉| 12672/13852 [47:29<04:21,  4.51it/\u001b[A\n",
      "Training loss: 2.08e-02 lr: 4.26e-06:  91%|▉| 12673/13852 [47:29<04:21,  4.52it/\u001b[A\n",
      "Training loss: 3.01e-02 lr: 4.25e-06:  91%|▉| 12674/13852 [47:30<04:21,  4.51it/\u001b[A\n",
      "Training loss: 4.78e-02 lr: 4.25e-06:  92%|▉| 12675/13852 [47:30<04:20,  4.51it/\u001b[A\n",
      "Training loss: 3.69e-02 lr: 4.25e-06:  92%|▉| 12676/13852 [47:30<04:21,  4.49it/\u001b[A\n",
      "Training loss: 4.05e-02 lr: 4.24e-06:  92%|▉| 12677/13852 [47:30<04:21,  4.49it/\u001b[A\n",
      "Training loss: 3.06e-02 lr: 4.24e-06:  92%|▉| 12678/13852 [47:30<04:20,  4.51it/\u001b[A\n",
      "Training loss: 3.25e-02 lr: 4.23e-06:  92%|▉| 12679/13852 [47:31<04:18,  4.53it/\u001b[A\n",
      "Training loss: 2.86e-02 lr: 4.23e-06:  92%|▉| 12680/13852 [47:31<04:20,  4.50it/\u001b[A\n",
      "Training loss: 2.46e-02 lr: 4.23e-06:  92%|▉| 12681/13852 [47:31<04:18,  4.53it/\u001b[A\n",
      "Training loss: 2.26e-02 lr: 4.22e-06:  92%|▉| 12682/13852 [47:31<04:18,  4.53it/\u001b[A\n",
      "Training loss: 4.12e-02 lr: 4.22e-06:  92%|▉| 12683/13852 [47:32<04:18,  4.52it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 4.22e-06:  92%|▉| 12684/13852 [47:32<04:20,  4.48it/\u001b[A\n",
      "Training loss: 2.97e-02 lr: 4.21e-06:  92%|▉| 12685/13852 [47:32<04:19,  4.50it/\u001b[A\n",
      "Training loss: 2.75e-02 lr: 4.21e-06:  92%|▉| 12686/13852 [47:32<04:19,  4.50it/\u001b[A\n",
      "Training loss: 3.69e-02 lr: 4.21e-06:  92%|▉| 12687/13852 [47:32<04:18,  4.50it/\u001b[A\n",
      "Training loss: 2.84e-02 lr: 4.20e-06:  92%|▉| 12688/13852 [47:33<04:18,  4.51it/\u001b[A\n",
      "Training loss: 2.09e-02 lr: 4.20e-06:  92%|▉| 12689/13852 [47:33<04:17,  4.51it/\u001b[A\n",
      "Training loss: 4.96e-02 lr: 4.19e-06:  92%|▉| 12690/13852 [47:33<04:18,  4.50it/\u001b[A\n",
      "Training loss: 3.57e-02 lr: 4.19e-06:  92%|▉| 12691/13852 [47:33<04:16,  4.52it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 4.19e-06:  92%|▉| 12692/13852 [47:34<04:15,  4.55it/\u001b[A\n",
      "Training loss: 9.99e-02 lr: 4.18e-06:  92%|▉| 12693/13852 [47:34<04:14,  4.56it/\u001b[A\n",
      "Training loss: 7.17e-02 lr: 4.18e-06:  92%|▉| 12694/13852 [47:34<04:15,  4.53it/\u001b[A\n",
      "Training loss: 6.98e-02 lr: 4.18e-06:  92%|▉| 12695/13852 [47:34<04:15,  4.53it/\u001b[A\n",
      "Training loss: 1.09e-01 lr: 4.17e-06:  92%|▉| 12696/13852 [47:34<04:15,  4.52it/\u001b[A\n",
      "Training loss: 9.00e-02 lr: 4.17e-06:  92%|▉| 12697/13852 [47:35<04:15,  4.53it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.72e-02 lr: 4.17e-06:  92%|▉| 12698/13852 [47:35<04:14,  4.53it/\u001b[A\n",
      "Training loss: 6.78e-02 lr: 4.16e-06:  92%|▉| 12699/13852 [47:35<04:15,  4.52it/\u001b[A\n",
      "Training loss: 4.92e-02 lr: 4.16e-06:  92%|▉| 12700/13852 [47:35<04:15,  4.50it/\u001b[A\n",
      "Training loss: 3.88e-02 lr: 4.15e-06:  92%|▉| 12701/13852 [47:36<04:15,  4.50it/\u001b[A\n",
      "Training loss: 2.82e-02 lr: 4.15e-06:  92%|▉| 12702/13852 [47:36<04:15,  4.50it/\u001b[A\n",
      "Training loss: 2.33e-02 lr: 4.15e-06:  92%|▉| 12703/13852 [47:36<04:15,  4.50it/\u001b[A\n",
      "Training loss: 3.03e-02 lr: 4.14e-06:  92%|▉| 12704/13852 [47:36<04:13,  4.52it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 4.14e-06:  92%|▉| 12705/13852 [47:36<04:12,  4.54it/\u001b[A\n",
      "Training loss: 2.75e-02 lr: 4.14e-06:  92%|▉| 12706/13852 [47:37<04:14,  4.50it/\u001b[A\n",
      "Training loss: 2.05e-02 lr: 4.13e-06:  92%|▉| 12707/13852 [47:37<04:16,  4.46it/\u001b[A\n",
      "Training loss: 3.45e-02 lr: 4.13e-06:  92%|▉| 12708/13852 [47:37<04:22,  4.37it/\u001b[A\n",
      "Training loss: 2.85e-02 lr: 4.13e-06:  92%|▉| 12709/13852 [47:37<04:25,  4.30it/\u001b[A\n",
      "Training loss: 3.29e-02 lr: 4.12e-06:  92%|▉| 12710/13852 [47:38<04:22,  4.35it/\u001b[A\n",
      "Training loss: 2.92e-02 lr: 4.12e-06:  92%|▉| 12711/13852 [47:38<04:19,  4.39it/\u001b[A\n",
      "Training loss: 2.89e-02 lr: 4.12e-06:  92%|▉| 12712/13852 [47:38<04:17,  4.43it/\u001b[A\n",
      "Training loss: 6.06e-02 lr: 4.11e-06:  92%|▉| 12713/13852 [47:38<04:16,  4.45it/\u001b[A\n",
      "Training loss: 5.10e-02 lr: 4.11e-06:  92%|▉| 12714/13852 [47:38<04:13,  4.49it/\u001b[A\n",
      "Training loss: 1.02e-01 lr: 4.10e-06:  92%|▉| 12715/13852 [47:39<04:14,  4.47it/\u001b[A\n",
      "Training loss: 7.57e-02 lr: 4.10e-06:  92%|▉| 12716/13852 [47:39<04:13,  4.49it/\u001b[A\n",
      "Training loss: 6.40e-02 lr: 4.10e-06:  92%|▉| 12717/13852 [47:39<04:11,  4.50it/\u001b[A\n",
      "Training loss: 5.51e-02 lr: 4.09e-06:  92%|▉| 12718/13852 [47:39<04:11,  4.51it/\u001b[A\n",
      "Training loss: 4.39e-02 lr: 4.09e-06:  92%|▉| 12719/13852 [47:40<04:11,  4.50it/\u001b[A\n",
      "Training loss: 3.62e-02 lr: 4.09e-06:  92%|▉| 12720/13852 [47:40<04:10,  4.51it/\u001b[A\n",
      "Training loss: 5.37e-02 lr: 4.08e-06:  92%|▉| 12721/13852 [47:40<04:11,  4.49it/\u001b[A\n",
      "Training loss: 6.04e-02 lr: 4.08e-06:  92%|▉| 12722/13852 [47:40<04:11,  4.49it/\u001b[A\n",
      "Training loss: 5.92e-02 lr: 4.08e-06:  92%|▉| 12723/13852 [47:40<04:10,  4.50it/\u001b[A\n",
      "Training loss: 6.32e-02 lr: 4.07e-06:  92%|▉| 12724/13852 [47:41<04:10,  4.50it/\u001b[A\n",
      "Training loss: 4.95e-02 lr: 4.07e-06:  92%|▉| 12725/13852 [47:41<04:11,  4.48it/\u001b[A\n",
      "Training loss: 7.84e-02 lr: 4.06e-06:  92%|▉| 12726/13852 [47:41<04:09,  4.52it/\u001b[A\n",
      "Training loss: 1.17e-01 lr: 4.06e-06:  92%|▉| 12727/13852 [47:41<04:07,  4.54it/\u001b[A\n",
      "Training loss: 9.72e-02 lr: 4.06e-06:  92%|▉| 12728/13852 [47:42<04:09,  4.50it/\u001b[A\n",
      "Training loss: 1.24e-01 lr: 4.05e-06:  92%|▉| 12729/13852 [47:42<04:10,  4.48it/\u001b[A\n",
      "Training loss: 9.34e-02 lr: 4.05e-06:  92%|▉| 12730/13852 [47:42<04:10,  4.48it/\u001b[A\n",
      "Training loss: 8.45e-02 lr: 4.05e-06:  92%|▉| 12731/13852 [47:42<04:09,  4.49it/\u001b[A\n",
      "Training loss: 6.63e-02 lr: 4.04e-06:  92%|▉| 12732/13852 [47:42<04:09,  4.50it/\u001b[A\n",
      "Training loss: 4.81e-02 lr: 4.04e-06:  92%|▉| 12733/13852 [47:43<04:08,  4.50it/\u001b[A\n",
      "Training loss: 3.46e-02 lr: 4.04e-06:  92%|▉| 12734/13852 [47:43<04:08,  4.51it/\u001b[A\n",
      "Training loss: 2.64e-02 lr: 4.03e-06:  92%|▉| 12735/13852 [47:43<04:07,  4.51it/\u001b[A\n",
      "Training loss: 2.74e-02 lr: 4.03e-06:  92%|▉| 12736/13852 [47:43<04:07,  4.52it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 4.02e-06:  92%|▉| 12737/13852 [47:44<04:05,  4.53it/\u001b[A\n",
      "Training loss: 6.26e-02 lr: 4.02e-06:  92%|▉| 12738/13852 [47:44<04:04,  4.56it/\u001b[A\n",
      "Training loss: 4.53e-02 lr: 4.02e-06:  92%|▉| 12739/13852 [47:44<04:03,  4.57it/\u001b[A\n",
      "Training loss: 4.50e-02 lr: 4.01e-06:  92%|▉| 12740/13852 [47:44<04:04,  4.54it/\u001b[A\n",
      "Training loss: 3.23e-02 lr: 4.01e-06:  92%|▉| 12741/13852 [47:44<04:04,  4.54it/\u001b[A\n",
      "Training loss: 7.30e-02 lr: 4.01e-06:  92%|▉| 12742/13852 [47:45<04:04,  4.54it/\u001b[A\n",
      "Training loss: 5.70e-02 lr: 4.00e-06:  92%|▉| 12743/13852 [47:45<04:04,  4.54it/\u001b[A\n",
      "Training loss: 4.16e-02 lr: 4.00e-06:  92%|▉| 12744/13852 [47:45<04:04,  4.53it/\u001b[A\n",
      "Training loss: 2.96e-02 lr: 4.00e-06:  92%|▉| 12745/13852 [47:45<04:04,  4.53it/\u001b[A\n",
      "Training loss: 2.43e-02 lr: 3.99e-06:  92%|▉| 12746/13852 [47:46<04:04,  4.53it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 3.99e-06:  92%|▉| 12747/13852 [47:46<04:04,  4.52it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 3.99e-06:  92%|▉| 12748/13852 [47:46<04:05,  4.50it/\u001b[A\n",
      "Training loss: 3.19e-02 lr: 3.98e-06:  92%|▉| 12749/13852 [47:46<04:04,  4.50it/\u001b[A\n",
      "Training loss: 6.97e-02 lr: 3.98e-06:  92%|▉| 12750/13852 [47:46<04:03,  4.53it/\u001b[A\n",
      "Training loss: 5.14e-02 lr: 3.97e-06:  92%|▉| 12751/13852 [47:47<04:03,  4.52it/\u001b[A\n",
      "Training loss: 4.97e-02 lr: 3.97e-06:  92%|▉| 12752/13852 [47:47<04:06,  4.46it/\u001b[A\n",
      "Training loss: 4.66e-02 lr: 3.97e-06:  92%|▉| 12753/13852 [47:47<04:05,  4.48it/\u001b[A\n",
      "Training loss: 9.05e-02 lr: 3.96e-06:  92%|▉| 12754/13852 [47:47<04:04,  4.50it/\u001b[A\n",
      "Training loss: 9.07e-02 lr: 3.96e-06:  92%|▉| 12755/13852 [47:48<04:03,  4.51it/\u001b[A\n",
      "Training loss: 7.99e-02 lr: 3.96e-06:  92%|▉| 12756/13852 [47:48<04:10,  4.38it/\u001b[A\n",
      "Training loss: 5.84e-02 lr: 3.95e-06:  92%|▉| 12757/13852 [47:48<04:09,  4.39it/\u001b[A\n",
      "Training loss: 4.26e-02 lr: 3.95e-06:  92%|▉| 12758/13852 [47:48<04:06,  4.43it/\u001b[A\n",
      "Training loss: 3.52e-02 lr: 3.95e-06:  92%|▉| 12759/13852 [47:48<04:05,  4.45it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 3.94e-06:  92%|▉| 12760/13852 [47:49<04:03,  4.49it/\u001b[A\n",
      "Training loss: 2.93e-02 lr: 3.94e-06:  92%|▉| 12761/13852 [47:49<04:01,  4.52it/\u001b[A\n",
      "Training loss: 3.38e-02 lr: 3.93e-06:  92%|▉| 12762/13852 [47:49<03:59,  4.54it/\u001b[A\n",
      "Training loss: 4.03e-02 lr: 3.93e-06:  92%|▉| 12763/13852 [47:49<03:58,  4.57it/\u001b[A\n",
      "Training loss: 3.13e-02 lr: 3.93e-06:  92%|▉| 12764/13852 [47:50<03:59,  4.55it/\u001b[A\n",
      "Training loss: 3.59e-02 lr: 3.92e-06:  92%|▉| 12765/13852 [47:50<03:59,  4.54it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 3.92e-06:  92%|▉| 12766/13852 [47:50<03:59,  4.54it/\u001b[A\n",
      "Training loss: 2.49e-02 lr: 3.92e-06:  92%|▉| 12767/13852 [47:50<04:00,  4.52it/\u001b[A\n",
      "Training loss: 6.93e-02 lr: 3.91e-06:  92%|▉| 12768/13852 [47:50<03:59,  4.53it/\u001b[A\n",
      "Training loss: 8.75e-02 lr: 3.91e-06:  92%|▉| 12769/13852 [47:51<03:59,  4.53it/\u001b[A\n",
      "Training loss: 6.29e-02 lr: 3.91e-06:  92%|▉| 12770/13852 [47:51<04:01,  4.49it/\u001b[A\n",
      "Training loss: 4.60e-02 lr: 3.90e-06:  92%|▉| 12771/13852 [47:51<04:00,  4.49it/\u001b[A\n",
      "Training loss: 5.22e-02 lr: 3.90e-06:  92%|▉| 12772/13852 [47:51<03:59,  4.50it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 3.90e-06:  92%|▉| 12773/13852 [47:52<03:58,  4.53it/\u001b[A\n",
      "Training loss: 4.97e-02 lr: 3.89e-06:  92%|▉| 12774/13852 [47:52<03:58,  4.52it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 3.89e-06:  92%|▉| 12775/13852 [47:52<04:04,  4.41it/\u001b[A\n",
      "Training loss: 3.01e-02 lr: 3.88e-06:  92%|▉| 12776/13852 [47:52<04:02,  4.44it/\u001b[A\n",
      "Training loss: 7.29e-02 lr: 3.88e-06:  92%|▉| 12777/13852 [47:52<04:00,  4.47it/\u001b[A\n",
      "Training loss: 6.23e-02 lr: 3.88e-06:  92%|▉| 12778/13852 [47:53<03:58,  4.49it/\u001b[A\n",
      "Training loss: 6.65e-02 lr: 3.87e-06:  92%|▉| 12779/13852 [47:53<03:58,  4.50it/\u001b[A\n",
      "Training loss: 4.76e-02 lr: 3.87e-06:  92%|▉| 12780/13852 [47:53<03:58,  4.50it/\u001b[A\n",
      "Training loss: 5.01e-02 lr: 3.87e-06:  92%|▉| 12781/13852 [47:53<03:57,  4.50it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 3.86e-06:  92%|▉| 12782/13852 [47:54<03:57,  4.51it/\u001b[A\n",
      "Training loss: 3.68e-02 lr: 3.86e-06:  92%|▉| 12783/13852 [47:54<03:57,  4.50it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 3.86e-06:  92%|▉| 12784/13852 [47:54<03:56,  4.51it/\u001b[A\n",
      "Training loss: 3.71e-02 lr: 3.85e-06:  92%|▉| 12785/13852 [47:54<03:55,  4.54it/\u001b[A\n",
      "Training loss: 5.08e-02 lr: 3.85e-06:  92%|▉| 12786/13852 [47:54<03:53,  4.56it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 3.84e-06:  92%|▉| 12787/13852 [47:55<03:55,  4.52it/\u001b[A\n",
      "Training loss: 2.72e-02 lr: 3.84e-06:  92%|▉| 12788/13852 [47:55<03:55,  4.52it/\u001b[A\n",
      "Training loss: 1.01e-01 lr: 3.84e-06:  92%|▉| 12789/13852 [47:55<03:55,  4.52it/\u001b[A\n",
      "Training loss: 7.40e-02 lr: 3.83e-06:  92%|▉| 12790/13852 [47:55<03:54,  4.53it/\u001b[A\n",
      "Training loss: 5.38e-02 lr: 3.83e-06:  92%|▉| 12791/13852 [47:56<03:54,  4.53it/\u001b[A\n",
      "Training loss: 5.57e-02 lr: 3.83e-06:  92%|▉| 12792/13852 [47:56<03:54,  4.52it/\u001b[A\n",
      "Training loss: 5.00e-02 lr: 3.82e-06:  92%|▉| 12793/13852 [47:56<03:54,  4.51it/\u001b[A\n",
      "Training loss: 7.61e-02 lr: 3.82e-06:  92%|▉| 12794/13852 [47:56<03:57,  4.45it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 6.56e-02 lr: 3.82e-06:  92%|▉| 12795/13852 [47:56<03:56,  4.46it/\u001b[A\n",
      "Training loss: 4.68e-02 lr: 3.81e-06:  92%|▉| 12796/13852 [47:57<03:56,  4.46it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 3.81e-06:  92%|▉| 12797/13852 [47:57<03:56,  4.46it/\u001b[A\n",
      "Training loss: 5.88e-02 lr: 3.80e-06:  92%|▉| 12798/13852 [47:57<03:54,  4.49it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 3.80e-06:  92%|▉| 12799/13852 [47:57<03:54,  4.49it/\u001b[A\n",
      "Training loss: 4.43e-02 lr: 3.80e-06:  92%|▉| 12800/13852 [47:58<03:53,  4.50it/\u001b[A\n",
      "Training loss: 3.50e-02 lr: 3.79e-06:  92%|▉| 12801/13852 [47:58<03:54,  4.49it/\u001b[A\n",
      "Training loss: 3.40e-02 lr: 3.79e-06:  92%|▉| 12802/13852 [47:58<03:52,  4.51it/\u001b[A\n",
      "Training loss: 4.89e-02 lr: 3.79e-06:  92%|▉| 12803/13852 [47:58<03:52,  4.51it/\u001b[A\n",
      "Training loss: 8.29e-02 lr: 3.78e-06:  92%|▉| 12804/13852 [47:58<03:52,  4.51it/\u001b[A\n",
      "Training loss: 8.64e-02 lr: 3.78e-06:  92%|▉| 12805/13852 [47:59<03:51,  4.52it/\u001b[A\n",
      "Training loss: 6.69e-02 lr: 3.78e-06:  92%|▉| 12806/13852 [47:59<03:52,  4.50it/\u001b[A\n",
      "Training loss: 4.91e-02 lr: 3.77e-06:  92%|▉| 12807/13852 [47:59<03:52,  4.49it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 3.77e-06:  92%|▉| 12808/13852 [47:59<03:51,  4.51it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 3.77e-06:  92%|▉| 12809/13852 [48:00<03:49,  4.54it/\u001b[A\n",
      "Training loss: 2.82e-02 lr: 3.76e-06:  92%|▉| 12810/13852 [48:00<03:49,  4.54it/\u001b[A\n",
      "Training loss: 6.57e-02 lr: 3.76e-06:  92%|▉| 12811/13852 [48:00<03:51,  4.50it/\u001b[A\n",
      "Training loss: 4.65e-02 lr: 3.75e-06:  92%|▉| 12812/13852 [48:00<03:51,  4.49it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 3.75e-06:  92%|▉| 12813/13852 [48:00<03:50,  4.50it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 3.75e-06:  93%|▉| 12814/13852 [48:01<03:50,  4.50it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 3.74e-06:  93%|▉| 12815/13852 [48:01<03:56,  4.38it/\u001b[A\n",
      "Training loss: 4.64e-02 lr: 3.74e-06:  93%|▉| 12816/13852 [48:01<03:55,  4.41it/\u001b[A\n",
      "Training loss: 7.45e-02 lr: 3.74e-06:  93%|▉| 12817/13852 [48:01<03:53,  4.44it/\u001b[A\n",
      "Training loss: 6.60e-02 lr: 3.73e-06:  93%|▉| 12818/13852 [48:02<03:52,  4.45it/\u001b[A\n",
      "Training loss: 6.64e-02 lr: 3.73e-06:  93%|▉| 12819/13852 [48:02<03:52,  4.45it/\u001b[A\n",
      "Training loss: 5.26e-02 lr: 3.73e-06:  93%|▉| 12820/13852 [48:02<03:50,  4.49it/\u001b[A\n",
      "Training loss: 4.32e-02 lr: 3.72e-06:  93%|▉| 12821/13852 [48:02<03:50,  4.47it/\u001b[A\n",
      "Training loss: 5.09e-02 lr: 3.72e-06:  93%|▉| 12822/13852 [48:02<03:50,  4.47it/\u001b[A\n",
      "Training loss: 3.92e-02 lr: 3.71e-06:  93%|▉| 12823/13852 [48:03<03:49,  4.49it/\u001b[A\n",
      "Training loss: 4.52e-02 lr: 3.71e-06:  93%|▉| 12824/13852 [48:03<03:48,  4.50it/\u001b[A\n",
      "Training loss: 4.02e-02 lr: 3.71e-06:  93%|▉| 12825/13852 [48:03<03:48,  4.50it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 3.70e-06:  93%|▉| 12826/13852 [48:03<03:47,  4.50it/\u001b[A\n",
      "Training loss: 4.89e-02 lr: 3.70e-06:  93%|▉| 12827/13852 [48:04<03:47,  4.51it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 3.70e-06:  93%|▉| 12828/13852 [48:04<03:47,  4.51it/\u001b[A\n",
      "Training loss: 2.81e-02 lr: 3.69e-06:  93%|▉| 12829/13852 [48:04<03:46,  4.51it/\u001b[A\n",
      "Training loss: 2.66e-02 lr: 3.69e-06:  93%|▉| 12830/13852 [48:04<03:46,  4.52it/\u001b[A\n",
      "Training loss: 2.28e-02 lr: 3.69e-06:  93%|▉| 12831/13852 [48:04<03:44,  4.55it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 3.68e-06:  93%|▉| 12832/13852 [48:05<03:43,  4.56it/\u001b[A\n",
      "Training loss: 3.98e-02 lr: 3.68e-06:  93%|▉| 12833/13852 [48:05<03:42,  4.57it/\u001b[A\n",
      "Training loss: 2.98e-02 lr: 3.67e-06:  93%|▉| 12834/13852 [48:05<03:42,  4.58it/\u001b[A\n",
      "Training loss: 2.45e-02 lr: 3.67e-06:  93%|▉| 12835/13852 [48:05<03:43,  4.56it/\u001b[A\n",
      "Training loss: 4.47e-02 lr: 3.67e-06:  93%|▉| 12836/13852 [48:06<03:43,  4.55it/\u001b[A\n",
      "Training loss: 8.20e-02 lr: 3.66e-06:  93%|▉| 12837/13852 [48:06<03:43,  4.53it/\u001b[A\n",
      "Training loss: 5.90e-02 lr: 3.66e-06:  93%|▉| 12838/13852 [48:06<03:43,  4.54it/\u001b[A\n",
      "Training loss: 4.22e-02 lr: 3.66e-06:  93%|▉| 12839/13852 [48:06<03:43,  4.52it/\u001b[A\n",
      "Training loss: 4.01e-02 lr: 3.65e-06:  93%|▉| 12840/13852 [48:06<03:43,  4.52it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 3.65e-06:  93%|▉| 12841/13852 [48:07<03:44,  4.51it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 3.65e-06:  93%|▉| 12842/13852 [48:07<03:51,  4.36it/\u001b[A\n",
      "Training loss: 2.94e-02 lr: 3.64e-06:  93%|▉| 12843/13852 [48:07<03:55,  4.28it/\u001b[A\n",
      "Training loss: 2.25e-02 lr: 3.64e-06:  93%|▉| 12844/13852 [48:07<03:57,  4.24it/\u001b[A\n",
      "Training loss: 3.84e-02 lr: 3.64e-06:  93%|▉| 12845/13852 [48:08<03:59,  4.20it/\u001b[A\n",
      "Training loss: 7.17e-02 lr: 3.63e-06:  93%|▉| 12846/13852 [48:08<04:01,  4.17it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 3.63e-06:  93%|▉| 12847/13852 [48:08<03:55,  4.26it/\u001b[A\n",
      "Training loss: 4.11e-02 lr: 3.62e-06:  93%|▉| 12848/13852 [48:08<03:52,  4.32it/\u001b[A\n",
      "Training loss: 3.44e-02 lr: 3.62e-06:  93%|▉| 12849/13852 [48:09<03:48,  4.39it/\u001b[A\n",
      "Training loss: 3.00e-02 lr: 3.62e-06:  93%|▉| 12850/13852 [48:09<03:45,  4.45it/\u001b[A\n",
      "Training loss: 6.46e-02 lr: 3.61e-06:  93%|▉| 12851/13852 [48:09<03:42,  4.50it/\u001b[A\n",
      "Training loss: 4.89e-02 lr: 3.61e-06:  93%|▉| 12852/13852 [48:09<03:40,  4.53it/\u001b[A\n",
      "Training loss: 6.02e-02 lr: 3.61e-06:  93%|▉| 12853/13852 [48:09<03:43,  4.48it/\u001b[A\n",
      "Training loss: 1.10e-01 lr: 3.60e-06:  93%|▉| 12854/13852 [48:10<03:43,  4.47it/\u001b[A\n",
      "Training loss: 8.91e-02 lr: 3.60e-06:  93%|▉| 12855/13852 [48:10<03:42,  4.48it/\u001b[A\n",
      "Training loss: 6.48e-02 lr: 3.60e-06:  93%|▉| 12856/13852 [48:10<03:41,  4.49it/\u001b[A\n",
      "Training loss: 6.52e-02 lr: 3.59e-06:  93%|▉| 12857/13852 [48:10<03:43,  4.46it/\u001b[A\n",
      "Training loss: 5.52e-02 lr: 3.59e-06:  93%|▉| 12858/13852 [48:11<03:42,  4.46it/\u001b[A\n",
      "Training loss: 4.82e-02 lr: 3.58e-06:  93%|▉| 12859/13852 [48:11<03:42,  4.46it/\u001b[A\n",
      "Training loss: 4.88e-02 lr: 3.58e-06:  93%|▉| 12860/13852 [48:11<03:42,  4.45it/\u001b[A\n",
      "Training loss: 9.08e-02 lr: 3.58e-06:  93%|▉| 12861/13852 [48:11<03:40,  4.49it/\u001b[A\n",
      "Training loss: 6.71e-02 lr: 3.57e-06:  93%|▉| 12862/13852 [48:11<03:38,  4.52it/\u001b[A\n",
      "Training loss: 6.16e-02 lr: 3.57e-06:  93%|▉| 12863/13852 [48:12<03:38,  4.54it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 3.57e-06:  93%|▉| 12864/13852 [48:12<03:42,  4.44it/\u001b[A\n",
      "Training loss: 7.45e-02 lr: 3.56e-06:  93%|▉| 12865/13852 [48:12<03:41,  4.45it/\u001b[A\n",
      "Training loss: 5.40e-02 lr: 3.56e-06:  93%|▉| 12866/13852 [48:12<03:40,  4.47it/\u001b[A\n",
      "Training loss: 4.54e-02 lr: 3.56e-06:  93%|▉| 12867/13852 [48:13<03:39,  4.48it/\u001b[A\n",
      "Training loss: 4.71e-02 lr: 3.55e-06:  93%|▉| 12868/13852 [48:13<03:39,  4.48it/\u001b[A\n",
      "Training loss: 7.44e-02 lr: 3.55e-06:  93%|▉| 12869/13852 [48:13<03:39,  4.49it/\u001b[A\n",
      "Training loss: 7.47e-02 lr: 3.54e-06:  93%|▉| 12870/13852 [48:13<03:38,  4.49it/\u001b[A\n",
      "Training loss: 9.94e-02 lr: 3.54e-06:  93%|▉| 12871/13852 [48:13<03:38,  4.49it/\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.54e-06:  93%|▉| 12872/13852 [48:14<03:38,  4.50it/\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.53e-06:  93%|▉| 12873/13852 [48:14<03:36,  4.52it/\u001b[A\n",
      "Training loss: 9.79e-02 lr: 3.53e-06:  93%|▉| 12874/13852 [48:14<03:36,  4.52it/\u001b[A\n",
      "Training loss: 7.35e-02 lr: 3.53e-06:  93%|▉| 12875/13852 [48:14<03:37,  4.49it/\u001b[A\n",
      "Training loss: 8.47e-02 lr: 3.52e-06:  93%|▉| 12876/13852 [48:15<03:37,  4.50it/\u001b[A\n",
      "Training loss: 7.89e-02 lr: 3.52e-06:  93%|▉| 12877/13852 [48:15<03:36,  4.50it/\u001b[A\n",
      "Training loss: 8.22e-02 lr: 3.52e-06:  93%|▉| 12878/13852 [48:15<03:36,  4.50it/\u001b[A\n",
      "Training loss: 6.63e-02 lr: 3.51e-06:  93%|▉| 12879/13852 [48:15<03:36,  4.50it/\u001b[A\n",
      "Training loss: 1.18e-01 lr: 3.51e-06:  93%|▉| 12880/13852 [48:15<03:36,  4.50it/\u001b[A\n",
      "Training loss: 9.61e-02 lr: 3.51e-06:  93%|▉| 12881/13852 [48:16<03:35,  4.50it/\u001b[A\n",
      "Training loss: 7.35e-02 lr: 3.50e-06:  93%|▉| 12882/13852 [48:16<03:35,  4.49it/\u001b[A\n",
      "Training loss: 6.01e-02 lr: 3.50e-06:  93%|▉| 12883/13852 [48:16<03:35,  4.49it/\u001b[A\n",
      "Training loss: 4.99e-02 lr: 3.49e-06:  93%|▉| 12884/13852 [48:16<03:34,  4.51it/\u001b[A\n",
      "Training loss: 4.90e-02 lr: 3.49e-06:  93%|▉| 12885/13852 [48:17<03:33,  4.53it/\u001b[A\n",
      "Training loss: 3.92e-02 lr: 3.49e-06:  93%|▉| 12886/13852 [48:17<03:33,  4.53it/\u001b[A\n",
      "Training loss: 3.14e-02 lr: 3.48e-06:  93%|▉| 12887/13852 [48:17<03:32,  4.53it/\u001b[A\n",
      "Training loss: 2.36e-02 lr: 3.48e-06:  93%|▉| 12888/13852 [48:17<03:32,  4.53it/\u001b[A\n",
      "Training loss: 2.70e-02 lr: 3.48e-06:  93%|▉| 12889/13852 [48:17<03:32,  4.53it/\u001b[A\n",
      "Training loss: 3.07e-02 lr: 3.47e-06:  93%|▉| 12890/13852 [48:18<03:32,  4.52it/\u001b[A\n",
      "Training loss: 2.95e-02 lr: 3.47e-06:  93%|▉| 12891/13852 [48:18<03:33,  4.51it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.21e-02 lr: 3.47e-06:  93%|▉| 12892/13852 [48:18<03:33,  4.49it/\u001b[A\n",
      "Training loss: 5.98e-02 lr: 3.46e-06:  93%|▉| 12893/13852 [48:18<03:33,  4.49it/\u001b[A\n",
      "Training loss: 8.18e-02 lr: 3.46e-06:  93%|▉| 12894/13852 [48:19<03:33,  4.48it/\u001b[A\n",
      "Training loss: 7.30e-02 lr: 3.45e-06:  93%|▉| 12895/13852 [48:19<03:33,  4.48it/\u001b[A\n",
      "Training loss: 5.45e-02 lr: 3.45e-06:  93%|▉| 12896/13852 [48:19<03:33,  4.49it/\u001b[A\n",
      "Training loss: 5.36e-02 lr: 3.45e-06:  93%|▉| 12897/13852 [48:19<03:31,  4.52it/\u001b[A\n",
      "Training loss: 5.55e-02 lr: 3.44e-06:  93%|▉| 12898/13852 [48:19<03:30,  4.54it/\u001b[A\n",
      "Training loss: 4.09e-02 lr: 3.44e-06:  93%|▉| 12899/13852 [48:20<03:31,  4.51it/\u001b[A\n",
      "Training loss: 3.13e-02 lr: 3.44e-06:  93%|▉| 12900/13852 [48:20<03:30,  4.51it/\u001b[A\n",
      "Training loss: 2.25e-02 lr: 3.43e-06:  93%|▉| 12901/13852 [48:20<03:30,  4.51it/\u001b[A\n",
      "Training loss: 1.80e-02 lr: 3.43e-06:  93%|▉| 12902/13852 [48:20<03:30,  4.51it/\u001b[A\n",
      "Training loss: 1.75e-02 lr: 3.43e-06:  93%|▉| 12903/13852 [48:21<03:31,  4.49it/\u001b[A\n",
      "Training loss: 1.81e-02 lr: 3.42e-06:  93%|▉| 12904/13852 [48:21<03:32,  4.46it/\u001b[A\n",
      "Training loss: 3.74e-02 lr: 3.42e-06:  93%|▉| 12905/13852 [48:21<03:32,  4.46it/\u001b[A\n",
      "Training loss: 4.27e-02 lr: 3.41e-06:  93%|▉| 12906/13852 [48:21<03:32,  4.46it/\u001b[A\n",
      "Training loss: 3.94e-02 lr: 3.41e-06:  93%|▉| 12907/13852 [48:21<03:31,  4.47it/\u001b[A\n",
      "Training loss: 3.62e-02 lr: 3.41e-06:  93%|▉| 12908/13852 [48:22<03:30,  4.49it/\u001b[A\n",
      "Training loss: 4.27e-02 lr: 3.40e-06:  93%|▉| 12909/13852 [48:22<03:29,  4.51it/\u001b[A\n",
      "Training loss: 5.25e-02 lr: 3.40e-06:  93%|▉| 12910/13852 [48:22<03:31,  4.45it/\u001b[A\n",
      "Training loss: 4.91e-02 lr: 3.40e-06:  93%|▉| 12911/13852 [48:22<03:30,  4.48it/\u001b[A\n",
      "Training loss: 4.35e-02 lr: 3.39e-06:  93%|▉| 12912/13852 [48:23<03:29,  4.49it/\u001b[A\n",
      "Training loss: 5.91e-02 lr: 3.39e-06:  93%|▉| 12913/13852 [48:23<03:29,  4.49it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 3.39e-06:  93%|▉| 12914/13852 [48:23<03:29,  4.49it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 3.38e-06:  93%|▉| 12915/13852 [48:23<03:28,  4.49it/\u001b[A\n",
      "Training loss: 5.80e-02 lr: 3.38e-06:  93%|▉| 12916/13852 [48:23<03:28,  4.50it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 3.38e-06:  93%|▉| 12917/13852 [48:24<03:27,  4.50it/\u001b[A\n",
      "Training loss: 3.55e-02 lr: 3.37e-06:  93%|▉| 12918/13852 [48:24<03:27,  4.49it/\u001b[A\n",
      "Training loss: 2.62e-02 lr: 3.37e-06:  93%|▉| 12919/13852 [48:24<03:27,  4.50it/\u001b[A\n",
      "Training loss: 2.24e-02 lr: 3.36e-06:  93%|▉| 12920/13852 [48:24<03:25,  4.53it/\u001b[A\n",
      "Training loss: 2.14e-02 lr: 3.36e-06:  93%|▉| 12921/13852 [48:25<03:25,  4.53it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 3.36e-06:  93%|▉| 12922/13852 [48:25<03:24,  4.55it/\u001b[A\n",
      "Training loss: 4.32e-02 lr: 3.35e-06:  93%|▉| 12923/13852 [48:25<03:24,  4.55it/\u001b[A\n",
      "Training loss: 4.36e-02 lr: 3.35e-06:  93%|▉| 12924/13852 [48:25<03:24,  4.54it/\u001b[A\n",
      "Training loss: 5.79e-02 lr: 3.35e-06:  93%|▉| 12925/13852 [48:25<03:24,  4.52it/\u001b[A\n",
      "Training loss: 4.28e-02 lr: 3.34e-06:  93%|▉| 12926/13852 [48:26<03:24,  4.52it/\u001b[A\n",
      "Training loss: 7.06e-02 lr: 3.34e-06:  93%|▉| 12927/13852 [48:26<03:25,  4.51it/\u001b[A\n",
      "Training loss: 5.15e-02 lr: 3.34e-06:  93%|▉| 12928/13852 [48:26<03:24,  4.51it/\u001b[A\n",
      "Training loss: 3.77e-02 lr: 3.33e-06:  93%|▉| 12929/13852 [48:26<03:25,  4.50it/\u001b[A\n",
      "Training loss: 5.74e-02 lr: 3.33e-06:  93%|▉| 12930/13852 [48:27<03:24,  4.50it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 3.32e-06:  93%|▉| 12931/13852 [48:27<03:25,  4.48it/\u001b[A\n",
      "Training loss: 3.53e-02 lr: 3.32e-06:  93%|▉| 12932/13852 [48:27<03:24,  4.50it/\u001b[A\n",
      "Training loss: 5.45e-02 lr: 3.32e-06:  93%|▉| 12933/13852 [48:27<03:23,  4.53it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 3.31e-06:  93%|▉| 12934/13852 [48:27<03:21,  4.55it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 3.31e-06:  93%|▉| 12935/13852 [48:28<03:22,  4.52it/\u001b[A\n",
      "Training loss: 3.30e-02 lr: 3.31e-06:  93%|▉| 12936/13852 [48:28<03:22,  4.52it/\u001b[A\n",
      "Training loss: 3.11e-02 lr: 3.30e-06:  93%|▉| 12937/13852 [48:28<03:23,  4.50it/\u001b[A\n",
      "Training loss: 3.19e-02 lr: 3.30e-06:  93%|▉| 12938/13852 [48:28<03:23,  4.50it/\u001b[A\n",
      "Training loss: 2.53e-02 lr: 3.30e-06:  93%|▉| 12939/13852 [48:29<03:22,  4.50it/\u001b[A\n",
      "Training loss: 5.33e-02 lr: 3.29e-06:  93%|▉| 12940/13852 [48:29<03:22,  4.50it/\u001b[A\n",
      "Training loss: 4.20e-02 lr: 3.29e-06:  93%|▉| 12941/13852 [48:29<03:22,  4.49it/\u001b[A\n",
      "Training loss: 7.08e-02 lr: 3.28e-06:  93%|▉| 12942/13852 [48:29<03:22,  4.48it/\u001b[A\n",
      "Training loss: 5.54e-02 lr: 3.28e-06:  93%|▉| 12943/13852 [48:29<03:22,  4.48it/\u001b[A\n",
      "Training loss: 5.90e-02 lr: 3.28e-06:  93%|▉| 12944/13852 [48:30<03:21,  4.51it/\u001b[A\n",
      "Training loss: 5.21e-02 lr: 3.27e-06:  93%|▉| 12945/13852 [48:30<03:20,  4.53it/\u001b[A\n",
      "Training loss: 3.81e-02 lr: 3.27e-06:  93%|▉| 12946/13852 [48:30<03:21,  4.50it/\u001b[A\n",
      "Training loss: 4.82e-02 lr: 3.27e-06:  93%|▉| 12947/13852 [48:30<03:21,  4.49it/\u001b[A\n",
      "Training loss: 8.16e-02 lr: 3.26e-06:  93%|▉| 12948/13852 [48:31<03:21,  4.49it/\u001b[A\n",
      "Training loss: 6.41e-02 lr: 3.26e-06:  93%|▉| 12949/13852 [48:31<03:21,  4.48it/\u001b[A\n",
      "Training loss: 4.68e-02 lr: 3.26e-06:  93%|▉| 12950/13852 [48:31<03:21,  4.47it/\u001b[A\n",
      "Training loss: 3.85e-02 lr: 3.25e-06:  93%|▉| 12951/13852 [48:31<03:21,  4.48it/\u001b[A\n",
      "Training loss: 2.78e-02 lr: 3.25e-06:  94%|▉| 12952/13852 [48:31<03:20,  4.48it/\u001b[A\n",
      "Training loss: 1.98e-02 lr: 3.25e-06:  94%|▉| 12953/13852 [48:32<03:20,  4.48it/\u001b[A\n",
      "Training loss: 1.76e-02 lr: 3.24e-06:  94%|▉| 12954/13852 [48:32<03:20,  4.48it/\u001b[A\n",
      "Training loss: 2.12e-02 lr: 3.24e-06:  94%|▉| 12955/13852 [48:32<03:19,  4.50it/\u001b[A\n",
      "Training loss: 3.20e-02 lr: 3.23e-06:  94%|▉| 12956/13852 [48:32<03:17,  4.53it/\u001b[A\n",
      "Training loss: 3.62e-02 lr: 3.23e-06:  94%|▉| 12957/13852 [48:33<03:16,  4.55it/\u001b[A\n",
      "Training loss: 3.46e-02 lr: 3.23e-06:  94%|▉| 12958/13852 [48:33<03:18,  4.51it/\u001b[A\n",
      "Training loss: 3.46e-02 lr: 3.22e-06:  94%|▉| 12959/13852 [48:33<03:18,  4.51it/\u001b[A\n",
      "Training loss: 3.25e-02 lr: 3.22e-06:  94%|▉| 12960/13852 [48:33<03:18,  4.50it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 3.22e-06:  94%|▉| 12961/13852 [48:33<03:18,  4.50it/\u001b[A\n",
      "Training loss: 2.74e-02 lr: 3.21e-06:  94%|▉| 12962/13852 [48:34<03:17,  4.50it/\u001b[A\n",
      "Training loss: 7.29e-02 lr: 3.21e-06:  94%|▉| 12963/13852 [48:34<03:17,  4.50it/\u001b[A\n",
      "Training loss: 7.09e-02 lr: 3.21e-06:  94%|▉| 12964/13852 [48:34<03:17,  4.49it/\u001b[A\n",
      "Training loss: 5.00e-02 lr: 3.20e-06:  94%|▉| 12965/13852 [48:34<03:17,  4.49it/\u001b[A\n",
      "Training loss: 4.82e-02 lr: 3.20e-06:  94%|▉| 12966/13852 [48:35<03:17,  4.50it/\u001b[A\n",
      "Training loss: 4.12e-02 lr: 3.19e-06:  94%|▉| 12967/13852 [48:35<03:15,  4.52it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 3.19e-06:  94%|▉| 12968/13852 [48:35<03:14,  4.54it/\u001b[A\n",
      "Training loss: 5.75e-02 lr: 3.19e-06:  94%|▉| 12969/13852 [48:35<03:13,  4.56it/\u001b[A\n",
      "Training loss: 5.22e-02 lr: 3.18e-06:  94%|▉| 12970/13852 [48:35<03:13,  4.57it/\u001b[A\n",
      "Training loss: 1.23e-01 lr: 3.18e-06:  94%|▉| 12971/13852 [48:36<03:13,  4.55it/\u001b[A\n",
      "Training loss: 8.78e-02 lr: 3.18e-06:  94%|▉| 12972/13852 [48:36<03:13,  4.54it/\u001b[A\n",
      "Training loss: 8.17e-02 lr: 3.17e-06:  94%|▉| 12973/13852 [48:36<03:13,  4.53it/\u001b[A\n",
      "Training loss: 6.03e-02 lr: 3.17e-06:  94%|▉| 12974/13852 [48:36<03:13,  4.53it/\u001b[A\n",
      "Training loss: 5.75e-02 lr: 3.17e-06:  94%|▉| 12975/13852 [48:36<03:13,  4.52it/\u001b[A\n",
      "Training loss: 4.31e-02 lr: 3.16e-06:  94%|▉| 12976/13852 [48:37<03:15,  4.49it/\u001b[A\n",
      "Training loss: 3.69e-02 lr: 3.16e-06:  94%|▉| 12977/13852 [48:37<03:15,  4.48it/\u001b[A\n",
      "Training loss: 3.06e-02 lr: 3.16e-06:  94%|▉| 12978/13852 [48:37<03:15,  4.48it/\u001b[A\n",
      "Training loss: 3.19e-02 lr: 3.15e-06:  94%|▉| 12979/13852 [48:37<03:15,  4.46it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 3.15e-06:  94%|▉| 12980/13852 [48:38<03:14,  4.48it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 3.14e-06:  94%|▉| 12981/13852 [48:38<03:13,  4.51it/\u001b[A\n",
      "Training loss: 2.78e-02 lr: 3.14e-06:  94%|▉| 12982/13852 [48:38<03:13,  4.50it/\u001b[A\n",
      "Training loss: 2.17e-02 lr: 3.14e-06:  94%|▉| 12983/13852 [48:38<03:12,  4.51it/\u001b[A\n",
      "Training loss: 2.44e-02 lr: 3.13e-06:  94%|▉| 12984/13852 [48:39<03:12,  4.51it/\u001b[A\n",
      "Training loss: 2.15e-02 lr: 3.13e-06:  94%|▉| 12985/13852 [48:39<03:11,  4.52it/\u001b[A\n",
      "Training loss: 2.57e-02 lr: 3.13e-06:  94%|▉| 12986/13852 [48:39<03:11,  4.52it/\u001b[A\n",
      "Training loss: 2.94e-02 lr: 3.12e-06:  94%|▉| 12987/13852 [48:39<03:11,  4.51it/\u001b[A\n",
      "Training loss: 2.71e-02 lr: 3.12e-06:  94%|▉| 12988/13852 [48:39<03:11,  4.50it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.14e-02 lr: 3.12e-06:  94%|▉| 12989/13852 [48:40<03:11,  4.50it/\u001b[A\n",
      "Training loss: 7.92e-02 lr: 3.11e-06:  94%|▉| 12990/13852 [48:40<03:11,  4.50it/\u001b[A\n",
      "Training loss: 5.79e-02 lr: 3.11e-06:  94%|▉| 12991/13852 [48:40<03:11,  4.50it/\u001b[A\n",
      "Training loss: 5.17e-02 lr: 3.10e-06:  94%|▉| 12992/13852 [48:40<03:10,  4.52it/\u001b[A\n",
      "Training loss: 8.12e-02 lr: 3.10e-06:  94%|▉| 12993/13852 [48:40<03:10,  4.52it/\u001b[A\n",
      "Training loss: 8.62e-02 lr: 3.10e-06:  94%|▉| 12994/13852 [48:41<03:11,  4.48it/\u001b[A\n",
      "Training loss: 6.53e-02 lr: 3.09e-06:  94%|▉| 12995/13852 [48:41<03:11,  4.47it/\u001b[A\n",
      "Training loss: 6.68e-02 lr: 3.09e-06:  94%|▉| 12996/13852 [48:41<03:10,  4.49it/\u001b[A\n",
      "Training loss: 6.27e-02 lr: 3.09e-06:  94%|▉| 12997/13852 [48:41<03:09,  4.50it/\u001b[A\n",
      "Training loss: 6.08e-02 lr: 3.08e-06:  94%|▉| 12998/13852 [48:42<03:09,  4.50it/\u001b[A\n",
      "Training loss: 8.31e-02 lr: 3.08e-06:  94%|▉| 12999/13852 [48:42<03:10,  4.49it/\u001b[A\n",
      "Training loss: 9.36e-02 lr: 3.08e-06:  94%|▉| 13000/13852 [48:42<03:09,  4.49it/\u001b[A\n",
      "Training loss: 9.28e-02 lr: 3.07e-06:  94%|▉| 13001/13852 [48:42<03:10,  4.47it/\u001b[A\n",
      "Training loss: 8.97e-02 lr: 3.07e-06:  94%|▉| 13002/13852 [48:43<03:10,  4.47it/\u001b[A\n",
      "Training loss: 1.63e-01 lr: 3.06e-06:  94%|▉| 13003/13852 [48:43<03:08,  4.50it/\u001b[A\n",
      "Training loss: 1.14e-01 lr: 3.06e-06:  94%|▉| 13004/13852 [48:43<03:07,  4.53it/\u001b[A\n",
      "Training loss: 8.18e-02 lr: 3.06e-06:  94%|▉| 13005/13852 [48:43<03:06,  4.54it/\u001b[A\n",
      "Training loss: 6.25e-02 lr: 3.05e-06:  94%|▉| 13006/13852 [48:43<03:06,  4.53it/\u001b[A\n",
      "Training loss: 5.20e-02 lr: 3.05e-06:  94%|▉| 13007/13852 [48:44<03:06,  4.53it/\u001b[A\n",
      "Training loss: 5.05e-02 lr: 3.05e-06:  94%|▉| 13008/13852 [48:44<03:06,  4.53it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 3.04e-06:  94%|▉| 13009/13852 [48:44<03:06,  4.53it/\u001b[A\n",
      "Training loss: 3.16e-02 lr: 3.04e-06:  94%|▉| 13010/13852 [48:44<03:06,  4.51it/\u001b[A\n",
      "Training loss: 2.59e-02 lr: 3.04e-06:  94%|▉| 13011/13852 [48:44<03:06,  4.51it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 3.03e-06:  94%|▉| 13012/13852 [48:45<03:06,  4.50it/\u001b[A\n",
      "Training loss: 3.29e-02 lr: 3.03e-06:  94%|▉| 13013/13852 [48:45<03:06,  4.49it/\u001b[A\n",
      "Training loss: 2.46e-02 lr: 3.03e-06:  94%|▉| 13014/13852 [48:45<03:06,  4.50it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 3.02e-06:  94%|▉| 13015/13852 [48:45<03:06,  4.50it/\u001b[A\n",
      "Training loss: 3.53e-02 lr: 3.02e-06:  94%|▉| 13016/13852 [48:46<03:04,  4.52it/\u001b[A\n",
      "Training loss: 3.00e-02 lr: 3.01e-06:  94%|▉| 13017/13852 [48:46<03:03,  4.54it/\u001b[A\n",
      "Training loss: 2.32e-02 lr: 3.01e-06:  94%|▉| 13018/13852 [48:46<03:04,  4.52it/\u001b[A\n",
      "Training loss: 6.67e-02 lr: 3.01e-06:  94%|▉| 13019/13852 [48:46<03:04,  4.52it/\u001b[A\n",
      "Training loss: 4.76e-02 lr: 3.00e-06:  94%|▉| 13020/13852 [48:46<03:04,  4.51it/\u001b[A\n",
      "Training loss: 3.88e-02 lr: 3.00e-06:  94%|▉| 13021/13852 [48:47<03:04,  4.50it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 3.00e-06:  94%|▉| 13022/13852 [48:47<03:04,  4.49it/\u001b[A\n",
      "Training loss: 3.58e-02 lr: 2.99e-06:  94%|▉| 13023/13852 [48:47<03:04,  4.49it/\u001b[A\n",
      "Training loss: 2.65e-02 lr: 2.99e-06:  94%|▉| 13024/13852 [48:47<03:04,  4.49it/\u001b[A\n",
      "Training loss: 7.03e-02 lr: 2.99e-06:  94%|▉| 13025/13852 [48:48<03:03,  4.50it/\u001b[A\n",
      "Training loss: 5.27e-02 lr: 2.98e-06:  94%|▉| 13026/13852 [48:48<03:03,  4.49it/\u001b[A\n",
      "Training loss: 4.43e-02 lr: 2.98e-06:  94%|▉| 13027/13852 [48:48<03:03,  4.50it/\u001b[A\n",
      "Training loss: 3.22e-02 lr: 2.97e-06:  94%|▉| 13028/13852 [48:48<03:02,  4.52it/\u001b[A\n",
      "Training loss: 3.13e-02 lr: 2.97e-06:  94%|▉| 13029/13852 [48:48<03:01,  4.54it/\u001b[A\n",
      "Training loss: 3.70e-02 lr: 2.97e-06:  94%|▉| 13030/13852 [48:49<03:02,  4.51it/\u001b[A\n",
      "Training loss: 3.50e-02 lr: 2.96e-06:  94%|▉| 13031/13852 [48:49<03:01,  4.52it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 2.96e-06:  94%|▉| 13032/13852 [48:49<03:01,  4.52it/\u001b[A\n",
      "Training loss: 2.80e-02 lr: 2.96e-06:  94%|▉| 13033/13852 [48:49<03:01,  4.50it/\u001b[A\n",
      "Training loss: 8.09e-02 lr: 2.95e-06:  94%|▉| 13034/13852 [48:50<03:01,  4.50it/\u001b[A\n",
      "Training loss: 6.48e-02 lr: 2.95e-06:  94%|▉| 13035/13852 [48:50<03:01,  4.50it/\u001b[A\n",
      "Training loss: 5.05e-02 lr: 2.95e-06:  94%|▉| 13036/13852 [48:50<03:01,  4.50it/\u001b[A\n",
      "Training loss: 4.22e-02 lr: 2.94e-06:  94%|▉| 13037/13852 [48:50<03:01,  4.50it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 2.94e-06:  94%|▉| 13038/13852 [48:50<03:00,  4.50it/\u001b[A\n",
      "Training loss: 2.91e-02 lr: 2.93e-06:  94%|▉| 13039/13852 [48:51<03:00,  4.51it/\u001b[A\n",
      "Training loss: 2.23e-02 lr: 2.93e-06:  94%|▉| 13040/13852 [48:51<03:00,  4.51it/\u001b[A\n",
      "Training loss: 1.69e-02 lr: 2.93e-06:  94%|▉| 13041/13852 [48:51<03:01,  4.47it/\u001b[A\n",
      "Training loss: 1.45e-02 lr: 2.92e-06:  94%|▉| 13042/13852 [48:51<03:00,  4.49it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 2.92e-06:  94%|▉| 13043/13852 [48:52<02:59,  4.50it/\u001b[A\n",
      "Training loss: 2.55e-02 lr: 2.92e-06:  94%|▉| 13044/13852 [48:52<02:59,  4.49it/\u001b[A\n",
      "Training loss: 8.46e-02 lr: 2.91e-06:  94%|▉| 13045/13852 [48:52<02:59,  4.50it/\u001b[A\n",
      "Training loss: 1.13e-01 lr: 2.91e-06:  94%|▉| 13046/13852 [48:52<02:59,  4.48it/\u001b[A\n",
      "Training loss: 8.84e-02 lr: 2.91e-06:  94%|▉| 13047/13852 [48:52<02:59,  4.49it/\u001b[A\n",
      "Training loss: 8.30e-02 lr: 2.90e-06:  94%|▉| 13048/13852 [48:53<02:58,  4.50it/\u001b[A\n",
      "Training loss: 6.33e-02 lr: 2.90e-06:  94%|▉| 13049/13852 [48:53<02:58,  4.50it/\u001b[A\n",
      "Training loss: 8.69e-02 lr: 2.90e-06:  94%|▉| 13050/13852 [48:53<02:57,  4.51it/\u001b[A\n",
      "Training loss: 8.77e-02 lr: 2.89e-06:  94%|▉| 13051/13852 [48:53<02:56,  4.53it/\u001b[A\n",
      "Training loss: 7.23e-02 lr: 2.89e-06:  94%|▉| 13052/13852 [48:54<02:55,  4.55it/\u001b[A\n",
      "Training loss: 5.39e-02 lr: 2.88e-06:  94%|▉| 13053/13852 [48:54<02:55,  4.56it/\u001b[A\n",
      "Training loss: 4.27e-02 lr: 2.88e-06:  94%|▉| 13054/13852 [48:54<03:02,  4.38it/\u001b[A\n",
      "Training loss: 5.28e-02 lr: 2.88e-06:  94%|▉| 13055/13852 [48:54<03:06,  4.28it/\u001b[A\n",
      "Training loss: 6.30e-02 lr: 2.87e-06:  94%|▉| 13056/13852 [48:55<03:08,  4.22it/\u001b[A\n",
      "Training loss: 8.08e-02 lr: 2.87e-06:  94%|▉| 13057/13852 [48:55<03:05,  4.29it/\u001b[A\n",
      "Training loss: 5.80e-02 lr: 2.87e-06:  94%|▉| 13058/13852 [48:55<03:03,  4.32it/\u001b[A\n",
      "Training loss: 4.54e-02 lr: 2.86e-06:  94%|▉| 13059/13852 [48:55<03:02,  4.35it/\u001b[A\n",
      "Training loss: 3.35e-02 lr: 2.86e-06:  94%|▉| 13060/13852 [48:55<03:05,  4.27it/\u001b[A\n",
      "Training loss: 5.06e-02 lr: 2.86e-06:  94%|▉| 13061/13852 [48:56<03:07,  4.22it/\u001b[A\n",
      "Training loss: 4.78e-02 lr: 2.85e-06:  94%|▉| 13062/13852 [48:56<03:03,  4.31it/\u001b[A\n",
      "Training loss: 4.93e-02 lr: 2.85e-06:  94%|▉| 13063/13852 [48:56<03:00,  4.36it/\u001b[A\n",
      "Training loss: 4.54e-02 lr: 2.84e-06:  94%|▉| 13064/13852 [48:56<02:59,  4.39it/\u001b[A\n",
      "Training loss: 5.14e-02 lr: 2.84e-06:  94%|▉| 13065/13852 [48:57<02:57,  4.43it/\u001b[A\n",
      "Training loss: 1.16e-01 lr: 2.84e-06:  94%|▉| 13066/13852 [48:57<02:58,  4.41it/\u001b[A\n",
      "Training loss: 8.45e-02 lr: 2.83e-06:  94%|▉| 13067/13852 [48:57<02:56,  4.45it/\u001b[A\n",
      "Training loss: 7.15e-02 lr: 2.83e-06:  94%|▉| 13068/13852 [48:57<02:54,  4.49it/\u001b[A\n",
      "Training loss: 8.80e-02 lr: 2.83e-06:  94%|▉| 13069/13852 [48:57<02:53,  4.52it/\u001b[A\n",
      "Training loss: 6.74e-02 lr: 2.82e-06:  94%|▉| 13070/13852 [48:58<02:52,  4.53it/\u001b[A\n",
      "Training loss: 8.01e-02 lr: 2.82e-06:  94%|▉| 13071/13852 [48:58<02:52,  4.53it/\u001b[A\n",
      "Training loss: 6.38e-02 lr: 2.82e-06:  94%|▉| 13072/13852 [48:58<02:52,  4.52it/\u001b[A\n",
      "Training loss: 9.75e-02 lr: 2.81e-06:  94%|▉| 13073/13852 [48:58<02:52,  4.51it/\u001b[A\n",
      "Training loss: 7.60e-02 lr: 2.81e-06:  94%|▉| 13074/13852 [48:59<02:53,  4.50it/\u001b[A\n",
      "Training loss: 5.43e-02 lr: 2.80e-06:  94%|▉| 13075/13852 [48:59<02:52,  4.50it/\u001b[A\n",
      "Training loss: 4.18e-02 lr: 2.80e-06:  94%|▉| 13076/13852 [48:59<02:52,  4.51it/\u001b[A\n",
      "Training loss: 5.84e-02 lr: 2.80e-06:  94%|▉| 13077/13852 [48:59<02:53,  4.47it/\u001b[A\n",
      "Training loss: 5.04e-02 lr: 2.79e-06:  94%|▉| 13078/13852 [48:59<02:52,  4.48it/\u001b[A\n",
      "Training loss: 7.90e-02 lr: 2.79e-06:  94%|▉| 13079/13852 [49:00<02:52,  4.48it/\u001b[A\n",
      "Training loss: 8.50e-02 lr: 2.79e-06:  94%|▉| 13080/13852 [49:00<02:51,  4.51it/\u001b[A\n",
      "Training loss: 7.54e-02 lr: 2.78e-06:  94%|▉| 13081/13852 [49:00<02:49,  4.54it/\u001b[A\n",
      "Training loss: 6.36e-02 lr: 2.78e-06:  94%|▉| 13082/13852 [49:00<02:48,  4.56it/\u001b[A\n",
      "Training loss: 7.12e-02 lr: 2.78e-06:  94%|▉| 13083/13852 [49:01<02:49,  4.53it/\u001b[A\n",
      "Training loss: 6.38e-02 lr: 2.77e-06:  94%|▉| 13084/13852 [49:01<02:50,  4.51it/\u001b[A\n",
      "Training loss: 9.49e-02 lr: 2.77e-06:  94%|▉| 13085/13852 [49:01<02:50,  4.50it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.42e-02 lr: 2.77e-06:  94%|▉| 13086/13852 [49:01<02:49,  4.51it/\u001b[A\n",
      "Training loss: 6.21e-02 lr: 2.76e-06:  94%|▉| 13087/13852 [49:01<02:50,  4.49it/\u001b[A\n",
      "Training loss: 5.02e-02 lr: 2.76e-06:  94%|▉| 13088/13852 [49:02<02:50,  4.47it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 2.75e-06:  94%|▉| 13089/13852 [49:02<02:50,  4.47it/\u001b[A\n",
      "Training loss: 2.99e-02 lr: 2.75e-06:  94%|▉| 13090/13852 [49:02<02:50,  4.47it/\u001b[A\n",
      "Training loss: 2.58e-02 lr: 2.75e-06:  95%|▉| 13091/13852 [49:02<02:49,  4.48it/\u001b[A\n",
      "Training loss: 2.68e-02 lr: 2.74e-06:  95%|▉| 13092/13852 [49:03<02:48,  4.51it/\u001b[A\n",
      "Training loss: 2.23e-02 lr: 2.74e-06:  95%|▉| 13093/13852 [49:03<02:47,  4.53it/\u001b[A\n",
      "Training loss: 1.64e-02 lr: 2.74e-06:  95%|▉| 13094/13852 [49:03<02:49,  4.47it/\u001b[A\n",
      "Training loss: 1.56e-02 lr: 2.73e-06:  95%|▉| 13095/13852 [49:03<02:49,  4.46it/\u001b[A\n",
      "Training loss: 6.18e-02 lr: 2.73e-06:  95%|▉| 13096/13852 [49:03<02:48,  4.48it/\u001b[A\n",
      "Training loss: 4.92e-02 lr: 2.73e-06:  95%|▉| 13097/13852 [49:04<02:48,  4.49it/\u001b[A\n",
      "Training loss: 4.15e-02 lr: 2.72e-06:  95%|▉| 13098/13852 [49:04<02:48,  4.48it/\u001b[A\n",
      "Training loss: 6.10e-02 lr: 2.72e-06:  95%|▉| 13099/13852 [49:04<02:47,  4.49it/\u001b[A\n",
      "Training loss: 4.57e-02 lr: 2.71e-06:  95%|▉| 13100/13852 [49:04<02:47,  4.49it/\u001b[A\n",
      "Training loss: 3.30e-02 lr: 2.71e-06:  95%|▉| 13101/13852 [49:05<02:47,  4.49it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 2.71e-06:  95%|▉| 13102/13852 [49:05<02:46,  4.49it/\u001b[A\n",
      "Training loss: 3.03e-02 lr: 2.70e-06:  95%|▉| 13103/13852 [49:05<02:45,  4.51it/\u001b[A\n",
      "Training loss: 2.66e-02 lr: 2.70e-06:  95%|▉| 13104/13852 [49:05<02:45,  4.53it/\u001b[A\n",
      "Training loss: 4.31e-02 lr: 2.70e-06:  95%|▉| 13105/13852 [49:05<02:44,  4.55it/\u001b[A\n",
      "Training loss: 3.38e-02 lr: 2.69e-06:  95%|▉| 13106/13852 [49:06<02:43,  4.55it/\u001b[A\n",
      "Training loss: 1.11e-01 lr: 2.69e-06:  95%|▉| 13107/13852 [49:06<02:44,  4.54it/\u001b[A\n",
      "Training loss: 7.92e-02 lr: 2.69e-06:  95%|▉| 13108/13852 [49:06<02:44,  4.53it/\u001b[A\n",
      "Training loss: 6.45e-02 lr: 2.68e-06:  95%|▉| 13109/13852 [49:06<02:44,  4.52it/\u001b[A\n",
      "Training loss: 7.89e-02 lr: 2.68e-06:  95%|▉| 13110/13852 [49:07<02:44,  4.51it/\u001b[A\n",
      "Training loss: 7.25e-02 lr: 2.67e-06:  95%|▉| 13111/13852 [49:07<02:46,  4.44it/\u001b[A\n",
      "Training loss: 7.86e-02 lr: 2.67e-06:  95%|▉| 13112/13852 [49:07<02:46,  4.43it/\u001b[A\n",
      "Training loss: 5.82e-02 lr: 2.67e-06:  95%|▉| 13113/13852 [49:07<02:46,  4.43it/\u001b[A\n",
      "Training loss: 6.89e-02 lr: 2.66e-06:  95%|▉| 13114/13852 [49:08<02:46,  4.43it/\u001b[A\n",
      "Training loss: 5.70e-02 lr: 2.66e-06:  95%|▉| 13115/13852 [49:08<02:45,  4.47it/\u001b[A\n",
      "Training loss: 4.15e-02 lr: 2.66e-06:  95%|▉| 13116/13852 [49:08<02:43,  4.49it/\u001b[A\n",
      "Training loss: 3.08e-02 lr: 2.65e-06:  95%|▉| 13117/13852 [49:08<02:44,  4.48it/\u001b[A\n",
      "Training loss: 3.93e-02 lr: 2.65e-06:  95%|▉| 13118/13852 [49:08<02:43,  4.49it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 2.65e-06:  95%|▉| 13119/13852 [49:09<02:43,  4.48it/\u001b[A\n",
      "Training loss: 3.04e-02 lr: 2.64e-06:  95%|▉| 13120/13852 [49:09<02:43,  4.49it/\u001b[A\n",
      "Training loss: 2.21e-02 lr: 2.64e-06:  95%|▉| 13121/13852 [49:09<02:42,  4.49it/\u001b[A\n",
      "Training loss: 3.10e-02 lr: 2.64e-06:  95%|▉| 13122/13852 [49:09<02:42,  4.49it/\u001b[A\n",
      "Training loss: 5.18e-02 lr: 2.63e-06:  95%|▉| 13123/13852 [49:10<02:42,  4.50it/\u001b[A\n",
      "Training loss: 5.28e-02 lr: 2.63e-06:  95%|▉| 13124/13852 [49:10<02:42,  4.49it/\u001b[A\n",
      "Training loss: 4.88e-02 lr: 2.62e-06:  95%|▉| 13125/13852 [49:10<02:42,  4.48it/\u001b[A\n",
      "Training loss: 8.25e-02 lr: 2.62e-06:  95%|▉| 13126/13852 [49:10<02:41,  4.50it/\u001b[A\n",
      "Training loss: 6.22e-02 lr: 2.62e-06:  95%|▉| 13127/13852 [49:10<02:41,  4.49it/\u001b[A\n",
      "Training loss: 7.14e-02 lr: 2.61e-06:  95%|▉| 13128/13852 [49:11<02:41,  4.48it/\u001b[A\n",
      "Training loss: 5.18e-02 lr: 2.61e-06:  95%|▉| 13129/13852 [49:11<02:42,  4.46it/\u001b[A\n",
      "Training loss: 6.11e-02 lr: 2.61e-06:  95%|▉| 13130/13852 [49:11<02:41,  4.47it/\u001b[A\n",
      "Training loss: 5.34e-02 lr: 2.60e-06:  95%|▉| 13131/13852 [49:11<02:41,  4.47it/\u001b[A\n",
      "Training loss: 5.58e-02 lr: 2.60e-06:  95%|▉| 13132/13852 [49:12<02:41,  4.46it/\u001b[A\n",
      "Training loss: 4.19e-02 lr: 2.60e-06:  95%|▉| 13133/13852 [49:12<02:41,  4.44it/\u001b[A\n",
      "Training loss: 3.36e-02 lr: 2.59e-06:  95%|▉| 13134/13852 [49:12<02:41,  4.45it/\u001b[A\n",
      "Training loss: 6.71e-02 lr: 2.59e-06:  95%|▉| 13135/13852 [49:12<02:40,  4.46it/\u001b[A\n",
      "Training loss: 4.94e-02 lr: 2.58e-06:  95%|▉| 13136/13852 [49:12<02:40,  4.47it/\u001b[A\n",
      "Training loss: 3.63e-02 lr: 2.58e-06:  95%|▉| 13137/13852 [49:13<02:38,  4.50it/\u001b[A\n",
      "Training loss: 3.37e-02 lr: 2.58e-06:  95%|▉| 13138/13852 [49:13<02:37,  4.52it/\u001b[A\n",
      "Training loss: 3.22e-02 lr: 2.57e-06:  95%|▉| 13139/13852 [49:13<02:38,  4.49it/\u001b[A\n",
      "Training loss: 3.05e-02 lr: 2.57e-06:  95%|▉| 13140/13852 [49:13<02:38,  4.49it/\u001b[A\n",
      "Training loss: 2.86e-02 lr: 2.57e-06:  95%|▉| 13141/13852 [49:14<02:37,  4.50it/\u001b[A\n",
      "Training loss: 2.46e-02 lr: 2.56e-06:  95%|▉| 13142/13852 [49:14<02:37,  4.51it/\u001b[A\n",
      "Training loss: 3.14e-02 lr: 2.56e-06:  95%|▉| 13143/13852 [49:14<02:37,  4.51it/\u001b[A\n",
      "Training loss: 4.09e-02 lr: 2.56e-06:  95%|▉| 13144/13852 [49:14<02:37,  4.51it/\u001b[A\n",
      "Training loss: 4.26e-02 lr: 2.55e-06:  95%|▉| 13145/13852 [49:14<02:37,  4.50it/\u001b[A\n",
      "Training loss: 5.11e-02 lr: 2.55e-06:  95%|▉| 13146/13852 [49:15<02:36,  4.50it/\u001b[A\n",
      "Training loss: 3.66e-02 lr: 2.54e-06:  95%|▉| 13147/13852 [49:15<02:36,  4.50it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 2.54e-06:  95%|▉| 13148/13852 [49:15<02:35,  4.51it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 2.54e-06:  95%|▉| 13149/13852 [49:15<02:35,  4.54it/\u001b[A\n",
      "Training loss: 2.25e-02 lr: 2.53e-06:  95%|▉| 13150/13852 [49:16<02:34,  4.55it/\u001b[A\n",
      "Training loss: 1.69e-02 lr: 2.53e-06:  95%|▉| 13151/13852 [49:16<02:34,  4.54it/\u001b[A\n",
      "Training loss: 1.31e-02 lr: 2.53e-06:  95%|▉| 13152/13852 [49:16<02:34,  4.53it/\u001b[A\n",
      "Training loss: 4.00e-02 lr: 2.52e-06:  95%|▉| 13153/13852 [49:16<02:34,  4.52it/\u001b[A\n",
      "Training loss: 2.87e-02 lr: 2.52e-06:  95%|▉| 13154/13852 [49:16<02:34,  4.51it/\u001b[A\n",
      "Training loss: 6.52e-02 lr: 2.52e-06:  95%|▉| 13155/13852 [49:17<02:34,  4.52it/\u001b[A\n",
      "Training loss: 4.69e-02 lr: 2.51e-06:  95%|▉| 13156/13852 [49:17<02:35,  4.48it/\u001b[A\n",
      "Training loss: 6.05e-02 lr: 2.51e-06:  95%|▉| 13157/13852 [49:17<02:34,  4.49it/\u001b[A\n",
      "Training loss: 6.60e-02 lr: 2.51e-06:  95%|▉| 13158/13852 [49:17<02:34,  4.49it/\u001b[A\n",
      "Training loss: 8.67e-02 lr: 2.50e-06:  95%|▉| 13159/13852 [49:18<02:34,  4.48it/\u001b[A\n",
      "Training loss: 6.73e-02 lr: 2.50e-06:  95%|▉| 13160/13852 [49:18<02:34,  4.48it/\u001b[A\n",
      "Training loss: 5.09e-02 lr: 2.49e-06:  95%|▉| 13161/13852 [49:18<02:33,  4.50it/\u001b[A\n",
      "Training loss: 3.93e-02 lr: 2.49e-06:  95%|▉| 13162/13852 [49:18<02:32,  4.52it/\u001b[A\n",
      "Training loss: 6.51e-02 lr: 2.49e-06:  95%|▉| 13163/13852 [49:18<02:32,  4.52it/\u001b[A\n",
      "Training loss: 4.77e-02 lr: 2.48e-06:  95%|▉| 13164/13852 [49:19<02:32,  4.52it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 2.48e-06:  95%|▉| 13165/13852 [49:19<02:32,  4.52it/\u001b[A\n",
      "Training loss: 2.90e-02 lr: 2.48e-06:  95%|▉| 13166/13852 [49:19<02:32,  4.51it/\u001b[A\n",
      "Training loss: 3.03e-02 lr: 2.47e-06:  95%|▉| 13167/13852 [49:19<02:32,  4.49it/\u001b[A\n",
      "Training loss: 5.35e-02 lr: 2.47e-06:  95%|▉| 13168/13852 [49:20<02:32,  4.49it/\u001b[A\n",
      "Training loss: 4.11e-02 lr: 2.47e-06:  95%|▉| 13169/13852 [49:20<02:32,  4.49it/\u001b[A\n",
      "Training loss: 3.58e-02 lr: 2.46e-06:  95%|▉| 13170/13852 [49:20<02:31,  4.49it/\u001b[A\n",
      "Training loss: 7.64e-02 lr: 2.46e-06:  95%|▉| 13171/13852 [49:20<02:31,  4.49it/\u001b[A\n",
      "Training loss: 1.05e-01 lr: 2.45e-06:  95%|▉| 13172/13852 [49:20<02:31,  4.50it/\u001b[A\n",
      "Training loss: 8.34e-02 lr: 2.45e-06:  95%|▉| 13173/13852 [49:21<02:30,  4.52it/\u001b[A\n",
      "Training loss: 7.39e-02 lr: 2.45e-06:  95%|▉| 13174/13852 [49:21<02:33,  4.41it/\u001b[A\n",
      "Training loss: 5.52e-02 lr: 2.44e-06:  95%|▉| 13175/13852 [49:21<02:37,  4.31it/\u001b[A\n",
      "Training loss: 4.95e-02 lr: 2.44e-06:  95%|▉| 13176/13852 [49:21<02:38,  4.26it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 2.44e-06:  95%|▉| 13177/13852 [49:22<02:36,  4.32it/\u001b[A\n",
      "Training loss: 2.59e-02 lr: 2.43e-06:  95%|▉| 13178/13852 [49:22<02:34,  4.36it/\u001b[A\n",
      "Training loss: 6.28e-02 lr: 2.43e-06:  95%|▉| 13179/13852 [49:22<02:32,  4.40it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 2.43e-06:  95%|▉| 13180/13852 [49:22<02:31,  4.43it/\u001b[A\n",
      "Training loss: 7.16e-02 lr: 2.42e-06:  95%|▉| 13181/13852 [49:22<02:30,  4.47it/\u001b[A\n",
      "Training loss: 7.41e-02 lr: 2.42e-06:  95%|▉| 13182/13852 [49:23<02:29,  4.50it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.98e-02 lr: 2.41e-06:  95%|▉| 13183/13852 [49:23<02:27,  4.53it/\u001b[A\n",
      "Training loss: 8.61e-02 lr: 2.41e-06:  95%|▉| 13184/13852 [49:23<02:28,  4.51it/\u001b[A\n",
      "Training loss: 7.07e-02 lr: 2.41e-06:  95%|▉| 13185/13852 [49:23<02:27,  4.51it/\u001b[A\n",
      "Training loss: 6.41e-02 lr: 2.40e-06:  95%|▉| 13186/13852 [49:24<02:27,  4.51it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 2.40e-06:  95%|▉| 13187/13852 [49:24<02:27,  4.51it/\u001b[A\n",
      "Training loss: 5.28e-02 lr: 2.40e-06:  95%|▉| 13188/13852 [49:24<02:27,  4.51it/\u001b[A\n",
      "Training loss: 4.01e-02 lr: 2.39e-06:  95%|▉| 13189/13852 [49:24<02:26,  4.51it/\u001b[A\n",
      "Training loss: 2.93e-02 lr: 2.39e-06:  95%|▉| 13190/13852 [49:24<02:26,  4.51it/\u001b[A\n",
      "Training loss: 4.09e-02 lr: 2.39e-06:  95%|▉| 13191/13852 [49:25<02:26,  4.50it/\u001b[A\n",
      "Training loss: 3.11e-02 lr: 2.38e-06:  95%|▉| 13192/13852 [49:25<02:26,  4.50it/\u001b[A\n",
      "Training loss: 4.16e-02 lr: 2.38e-06:  95%|▉| 13193/13852 [49:25<02:26,  4.50it/\u001b[A\n",
      "Training loss: 3.29e-02 lr: 2.38e-06:  95%|▉| 13194/13852 [49:25<02:25,  4.53it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 2.37e-06:  95%|▉| 13195/13852 [49:26<02:24,  4.55it/\u001b[A\n",
      "Training loss: 3.37e-02 lr: 2.37e-06:  95%|▉| 13196/13852 [49:26<02:25,  4.51it/\u001b[A\n",
      "Training loss: 3.46e-02 lr: 2.36e-06:  95%|▉| 13197/13852 [49:26<02:25,  4.51it/\u001b[A\n",
      "Training loss: 3.21e-02 lr: 2.36e-06:  95%|▉| 13198/13852 [49:26<02:24,  4.51it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 2.36e-06:  95%|▉| 13199/13852 [49:26<02:24,  4.51it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 2.35e-06:  95%|▉| 13200/13852 [49:27<02:25,  4.49it/\u001b[A\n",
      "Training loss: 4.89e-02 lr: 2.35e-06:  95%|▉| 13201/13852 [49:27<02:25,  4.48it/\u001b[A\n",
      "Training loss: 3.74e-02 lr: 2.35e-06:  95%|▉| 13202/13852 [49:27<02:24,  4.48it/\u001b[A\n",
      "Training loss: 8.12e-02 lr: 2.34e-06:  95%|▉| 13203/13852 [49:27<02:24,  4.49it/\u001b[A\n",
      "Training loss: 7.67e-02 lr: 2.34e-06:  95%|▉| 13204/13852 [49:28<02:24,  4.50it/\u001b[A\n",
      "Training loss: 6.03e-02 lr: 2.34e-06:  95%|▉| 13205/13852 [49:28<02:23,  4.52it/\u001b[A\n",
      "Training loss: 4.84e-02 lr: 2.33e-06:  95%|▉| 13206/13852 [49:28<02:22,  4.53it/\u001b[A\n",
      "Training loss: 4.02e-02 lr: 2.33e-06:  95%|▉| 13207/13852 [49:28<02:21,  4.55it/\u001b[A\n",
      "Training loss: 2.94e-02 lr: 2.32e-06:  95%|▉| 13208/13852 [49:28<02:20,  4.57it/\u001b[A\n",
      "Training loss: 2.17e-02 lr: 2.32e-06:  95%|▉| 13209/13852 [49:29<02:21,  4.55it/\u001b[A\n",
      "Training loss: 1.85e-02 lr: 2.32e-06:  95%|▉| 13210/13852 [49:29<02:22,  4.52it/\u001b[A\n",
      "Training loss: 2.87e-02 lr: 2.31e-06:  95%|▉| 13211/13852 [49:29<02:22,  4.51it/\u001b[A\n",
      "Training loss: 5.89e-02 lr: 2.31e-06:  95%|▉| 13212/13852 [49:29<02:22,  4.51it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 2.31e-06:  95%|▉| 13213/13852 [49:30<02:21,  4.50it/\u001b[A\n",
      "Training loss: 7.32e-02 lr: 2.30e-06:  95%|▉| 13214/13852 [49:30<02:21,  4.50it/\u001b[A\n",
      "Training loss: 6.39e-02 lr: 2.30e-06:  95%|▉| 13215/13852 [49:30<02:21,  4.51it/\u001b[A\n",
      "Training loss: 5.05e-02 lr: 2.30e-06:  95%|▉| 13216/13852 [49:30<02:21,  4.51it/\u001b[A\n",
      "Training loss: 7.58e-02 lr: 2.29e-06:  95%|▉| 13217/13852 [49:30<02:20,  4.51it/\u001b[A\n",
      "Training loss: 6.90e-02 lr: 2.29e-06:  95%|▉| 13218/13852 [49:31<02:20,  4.53it/\u001b[A\n",
      "Training loss: 6.40e-02 lr: 2.29e-06:  95%|▉| 13219/13852 [49:31<02:20,  4.50it/\u001b[A\n",
      "Training loss: 6.66e-02 lr: 2.28e-06:  95%|▉| 13220/13852 [49:31<02:20,  4.48it/\u001b[A\n",
      "Training loss: 5.37e-02 lr: 2.28e-06:  95%|▉| 13221/13852 [49:31<02:20,  4.49it/\u001b[A\n",
      "Training loss: 5.30e-02 lr: 2.27e-06:  95%|▉| 13222/13852 [49:32<02:20,  4.50it/\u001b[A\n",
      "Training loss: 7.39e-02 lr: 2.27e-06:  95%|▉| 13223/13852 [49:32<02:20,  4.48it/\u001b[A\n",
      "Training loss: 6.36e-02 lr: 2.27e-06:  95%|▉| 13224/13852 [49:32<02:19,  4.49it/\u001b[A\n",
      "Training loss: 5.00e-02 lr: 2.26e-06:  95%|▉| 13225/13852 [49:32<02:19,  4.49it/\u001b[A\n",
      "Training loss: 5.42e-02 lr: 2.26e-06:  95%|▉| 13226/13852 [49:32<02:19,  4.50it/\u001b[A\n",
      "Training loss: 4.08e-02 lr: 2.26e-06:  95%|▉| 13227/13852 [49:33<02:18,  4.50it/\u001b[A\n",
      "Training loss: 3.25e-02 lr: 2.25e-06:  95%|▉| 13228/13852 [49:33<02:18,  4.50it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 2.25e-06:  96%|▉| 13229/13852 [49:33<02:18,  4.51it/\u001b[A\n",
      "Training loss: 3.11e-02 lr: 2.25e-06:  96%|▉| 13230/13852 [49:33<02:17,  4.54it/\u001b[A\n",
      "Training loss: 3.59e-02 lr: 2.24e-06:  96%|▉| 13231/13852 [49:34<02:16,  4.56it/\u001b[A\n",
      "Training loss: 3.60e-02 lr: 2.24e-06:  96%|▉| 13232/13852 [49:34<02:17,  4.50it/\u001b[A\n",
      "Training loss: 2.94e-02 lr: 2.23e-06:  96%|▉| 13233/13852 [49:34<02:17,  4.51it/\u001b[A\n",
      "Training loss: 7.46e-02 lr: 2.23e-06:  96%|▉| 13234/13852 [49:34<02:25,  4.24it/\u001b[A\n",
      "Training loss: 1.02e-01 lr: 2.23e-06:  96%|▉| 13235/13852 [49:35<02:32,  4.06it/\u001b[A\n",
      "Training loss: 1.10e-01 lr: 2.22e-06:  96%|▉| 13236/13852 [49:35<02:30,  4.10it/\u001b[A\n",
      "Training loss: 8.23e-02 lr: 2.22e-06:  96%|▉| 13237/13852 [49:35<02:28,  4.14it/\u001b[A\n",
      "Training loss: 8.32e-02 lr: 2.22e-06:  96%|▉| 13238/13852 [49:35<02:27,  4.15it/\u001b[A\n",
      "Training loss: 6.34e-02 lr: 2.21e-06:  96%|▉| 13239/13852 [49:35<02:27,  4.16it/\u001b[A\n",
      "Training loss: 4.95e-02 lr: 2.21e-06:  96%|▉| 13240/13852 [49:36<02:27,  4.16it/\u001b[A\n",
      "Training loss: 4.75e-02 lr: 2.21e-06:  96%|▉| 13241/13852 [49:36<02:26,  4.16it/\u001b[A\n",
      "Training loss: 6.93e-02 lr: 2.20e-06:  96%|▉| 13242/13852 [49:36<02:26,  4.16it/\u001b[A\n",
      "Training loss: 9.16e-02 lr: 2.20e-06:  96%|▉| 13243/13852 [49:36<02:25,  4.18it/\u001b[A\n",
      "Training loss: 7.57e-02 lr: 2.19e-06:  96%|▉| 13244/13852 [49:37<02:26,  4.14it/\u001b[A\n",
      "Training loss: 7.28e-02 lr: 2.19e-06:  96%|▉| 13245/13852 [49:37<02:27,  4.12it/\u001b[A\n",
      "Training loss: 6.28e-02 lr: 2.19e-06:  96%|▉| 13246/13852 [49:37<02:27,  4.11it/\u001b[A\n",
      "Training loss: 7.14e-02 lr: 2.18e-06:  96%|▉| 13247/13852 [49:37<02:27,  4.10it/\u001b[A\n",
      "Training loss: 8.90e-02 lr: 2.18e-06:  96%|▉| 13248/13852 [49:38<02:26,  4.12it/\u001b[A\n",
      "Training loss: 1.45e-01 lr: 2.18e-06:  96%|▉| 13249/13852 [49:38<02:26,  4.11it/\u001b[A\n",
      "Training loss: 1.31e-01 lr: 2.17e-06:  96%|▉| 13250/13852 [49:38<02:25,  4.14it/\u001b[A\n",
      "Training loss: 1.01e-01 lr: 2.17e-06:  96%|▉| 13251/13852 [49:38<02:21,  4.24it/\u001b[A\n",
      "Training loss: 7.20e-02 lr: 2.17e-06:  96%|▉| 13252/13852 [49:39<02:18,  4.32it/\u001b[A\n",
      "Training loss: 5.77e-02 lr: 2.16e-06:  96%|▉| 13253/13852 [49:39<02:16,  4.38it/\u001b[A\n",
      "Training loss: 4.23e-02 lr: 2.16e-06:  96%|▉| 13254/13852 [49:39<02:15,  4.42it/\u001b[A\n",
      "Training loss: 5.43e-02 lr: 2.16e-06:  96%|▉| 13255/13852 [49:39<02:13,  4.46it/\u001b[A\n",
      "Training loss: 4.28e-02 lr: 2.15e-06:  96%|▉| 13256/13852 [49:39<02:12,  4.51it/\u001b[A\n",
      "Training loss: 3.11e-02 lr: 2.15e-06:  96%|▉| 13257/13852 [49:40<02:11,  4.54it/\u001b[A\n",
      "Training loss: 3.25e-02 lr: 2.14e-06:  96%|▉| 13258/13852 [49:40<02:12,  4.48it/\u001b[A\n",
      "Training loss: 4.60e-02 lr: 2.14e-06:  96%|▉| 13259/13852 [49:40<02:12,  4.48it/\u001b[A\n",
      "Training loss: 4.43e-02 lr: 2.14e-06:  96%|▉| 13260/13852 [49:40<02:11,  4.49it/\u001b[A\n",
      "Training loss: 5.49e-02 lr: 2.13e-06:  96%|▉| 13261/13852 [49:41<02:11,  4.50it/\u001b[A\n",
      "Training loss: 4.11e-02 lr: 2.13e-06:  96%|▉| 13262/13852 [49:41<02:11,  4.49it/\u001b[A\n",
      "Training loss: 3.57e-02 lr: 2.13e-06:  96%|▉| 13263/13852 [49:41<02:11,  4.47it/\u001b[A\n",
      "Training loss: 4.66e-02 lr: 2.12e-06:  96%|▉| 13264/13852 [49:41<02:11,  4.48it/\u001b[A\n",
      "Training loss: 3.75e-02 lr: 2.12e-06:  96%|▉| 13265/13852 [49:41<02:10,  4.49it/\u001b[A\n",
      "Training loss: 3.90e-02 lr: 2.12e-06:  96%|▉| 13266/13852 [49:42<02:10,  4.47it/\u001b[A\n",
      "Training loss: 3.19e-02 lr: 2.11e-06:  96%|▉| 13267/13852 [49:42<02:10,  4.49it/\u001b[A\n",
      "Training loss: 3.10e-02 lr: 2.11e-06:  96%|▉| 13268/13852 [49:42<02:09,  4.52it/\u001b[A\n",
      "Training loss: 2.88e-02 lr: 2.10e-06:  96%|▉| 13269/13852 [49:42<02:08,  4.54it/\u001b[A\n",
      "Training loss: 2.13e-02 lr: 2.10e-06:  96%|▉| 13270/13852 [49:43<02:09,  4.51it/\u001b[A\n",
      "Training loss: 1.56e-02 lr: 2.10e-06:  96%|▉| 13271/13852 [49:43<02:08,  4.52it/\u001b[A\n",
      "Training loss: 1.63e-02 lr: 2.09e-06:  96%|▉| 13272/13852 [49:43<02:08,  4.52it/\u001b[A\n",
      "Training loss: 1.80e-02 lr: 2.09e-06:  96%|▉| 13273/13852 [49:43<02:07,  4.53it/\u001b[A\n",
      "Training loss: 1.88e-02 lr: 2.09e-06:  96%|▉| 13274/13852 [49:43<02:07,  4.52it/\u001b[A\n",
      "Training loss: 1.71e-02 lr: 2.08e-06:  96%|▉| 13275/13852 [49:44<02:07,  4.52it/\u001b[A\n",
      "Training loss: 1.45e-02 lr: 2.08e-06:  96%|▉| 13276/13852 [49:44<02:07,  4.52it/\u001b[A\n",
      "Training loss: 1.15e-02 lr: 2.08e-06:  96%|▉| 13277/13852 [49:44<02:07,  4.52it/\u001b[A\n",
      "Training loss: 9.99e-03 lr: 2.07e-06:  96%|▉| 13278/13852 [49:44<02:07,  4.50it/\u001b[A\n",
      "Training loss: 1.03e-02 lr: 2.07e-06:  96%|▉| 13279/13852 [49:45<02:07,  4.51it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.33e-02 lr: 2.06e-06:  96%|▉| 13280/13852 [49:45<02:06,  4.53it/\u001b[A\n",
      "Training loss: 4.95e-02 lr: 2.06e-06:  96%|▉| 13281/13852 [49:45<02:05,  4.55it/\u001b[A\n",
      "Training loss: 4.46e-02 lr: 2.06e-06:  96%|▉| 13282/13852 [49:45<02:06,  4.51it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 2.05e-06:  96%|▉| 13283/13852 [49:45<02:06,  4.51it/\u001b[A\n",
      "Training loss: 3.23e-02 lr: 2.05e-06:  96%|▉| 13284/13852 [49:46<02:05,  4.51it/\u001b[A\n",
      "Training loss: 2.68e-02 lr: 2.05e-06:  96%|▉| 13285/13852 [49:46<02:05,  4.52it/\u001b[A\n",
      "Training loss: 3.19e-02 lr: 2.04e-06:  96%|▉| 13286/13852 [49:46<02:05,  4.52it/\u001b[A\n",
      "Training loss: 2.75e-02 lr: 2.04e-06:  96%|▉| 13287/13852 [49:46<02:05,  4.52it/\u001b[A\n",
      "Training loss: 2.37e-02 lr: 2.04e-06:  96%|▉| 13288/13852 [49:47<02:04,  4.51it/\u001b[A\n",
      "Training loss: 1.91e-02 lr: 2.03e-06:  96%|▉| 13289/13852 [49:47<02:05,  4.49it/\u001b[A\n",
      "Training loss: 4.80e-02 lr: 2.03e-06:  96%|▉| 13290/13852 [49:47<02:04,  4.50it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 2.03e-06:  96%|▉| 13291/13852 [49:47<02:03,  4.53it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 2.02e-06:  96%|▉| 13292/13852 [49:47<02:03,  4.55it/\u001b[A\n",
      "Training loss: 6.07e-02 lr: 2.02e-06:  96%|▉| 13293/13852 [49:48<02:02,  4.56it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 2.01e-06:  96%|▉| 13294/13852 [49:48<02:01,  4.58it/\u001b[A\n",
      "Training loss: 3.79e-02 lr: 2.01e-06:  96%|▉| 13295/13852 [49:48<02:01,  4.59it/\u001b[A\n",
      "Training loss: 3.26e-02 lr: 2.01e-06:  96%|▉| 13296/13852 [49:48<02:02,  4.55it/\u001b[A\n",
      "Training loss: 4.98e-02 lr: 2.00e-06:  96%|▉| 13297/13852 [49:49<02:01,  4.55it/\u001b[A\n",
      "Training loss: 8.13e-02 lr: 2.00e-06:  96%|▉| 13298/13852 [49:49<02:01,  4.55it/\u001b[A\n",
      "Training loss: 8.00e-02 lr: 2.00e-06:  96%|▉| 13299/13852 [49:49<02:01,  4.54it/\u001b[A\n",
      "Training loss: 9.93e-02 lr: 1.99e-06:  96%|▉| 13300/13852 [49:49<02:01,  4.54it/\u001b[A\n",
      "Training loss: 7.26e-02 lr: 1.99e-06:  96%|▉| 13301/13852 [49:49<02:01,  4.53it/\u001b[A\n",
      "Training loss: 7.24e-02 lr: 1.99e-06:  96%|▉| 13302/13852 [49:50<02:01,  4.52it/\u001b[A\n",
      "Training loss: 5.81e-02 lr: 1.98e-06:  96%|▉| 13303/13852 [49:50<02:01,  4.51it/\u001b[A\n",
      "Training loss: 4.89e-02 lr: 1.98e-06:  96%|▉| 13304/13852 [49:50<02:01,  4.51it/\u001b[A\n",
      "Training loss: 3.87e-02 lr: 1.97e-06:  96%|▉| 13305/13852 [49:50<02:00,  4.52it/\u001b[A\n",
      "Training loss: 3.57e-02 lr: 1.97e-06:  96%|▉| 13306/13852 [49:51<02:00,  4.55it/\u001b[A\n",
      "Training loss: 3.74e-02 lr: 1.97e-06:  96%|▉| 13307/13852 [49:51<01:59,  4.54it/\u001b[A\n",
      "Training loss: 1.08e-01 lr: 1.96e-06:  96%|▉| 13308/13852 [49:51<02:01,  4.47it/\u001b[A\n",
      "Training loss: 8.00e-02 lr: 1.96e-06:  96%|▉| 13309/13852 [49:51<02:00,  4.49it/\u001b[A\n",
      "Training loss: 7.44e-02 lr: 1.96e-06:  96%|▉| 13310/13852 [49:51<02:00,  4.49it/\u001b[A\n",
      "Training loss: 6.73e-02 lr: 1.95e-06:  96%|▉| 13311/13852 [49:52<02:00,  4.49it/\u001b[A\n",
      "Training loss: 5.16e-02 lr: 1.95e-06:  96%|▉| 13312/13852 [49:52<02:00,  4.49it/\u001b[A\n",
      "Training loss: 4.03e-02 lr: 1.95e-06:  96%|▉| 13313/13852 [49:52<02:00,  4.49it/\u001b[A\n",
      "Training loss: 3.95e-02 lr: 1.94e-06:  96%|▉| 13314/13852 [49:52<01:59,  4.50it/\u001b[A\n",
      "Training loss: 2.97e-02 lr: 1.94e-06:  96%|▉| 13315/13852 [49:53<01:59,  4.50it/\u001b[A\n",
      "Training loss: 4.85e-02 lr: 1.93e-06:  96%|▉| 13316/13852 [49:53<01:58,  4.50it/\u001b[A\n",
      "Training loss: 4.46e-02 lr: 1.93e-06:  96%|▉| 13317/13852 [49:53<01:58,  4.51it/\u001b[A\n",
      "Training loss: 3.40e-02 lr: 1.93e-06:  96%|▉| 13318/13852 [49:53<01:57,  4.54it/\u001b[A\n",
      "Training loss: 3.55e-02 lr: 1.92e-06:  96%|▉| 13319/13852 [49:53<01:56,  4.56it/\u001b[A\n",
      "Training loss: 5.58e-02 lr: 1.92e-06:  96%|▉| 13320/13852 [49:54<01:56,  4.58it/\u001b[A\n",
      "Training loss: 4.14e-02 lr: 1.92e-06:  96%|▉| 13321/13852 [49:54<01:56,  4.56it/\u001b[A\n",
      "Training loss: 3.44e-02 lr: 1.91e-06:  96%|▉| 13322/13852 [49:54<01:56,  4.55it/\u001b[A\n",
      "Training loss: 2.76e-02 lr: 1.91e-06:  96%|▉| 13323/13852 [49:54<01:56,  4.54it/\u001b[A\n",
      "Training loss: 2.39e-02 lr: 1.91e-06:  96%|▉| 13324/13852 [49:55<01:56,  4.53it/\u001b[A\n",
      "Training loss: 2.45e-02 lr: 1.90e-06:  96%|▉| 13325/13852 [49:55<01:56,  4.52it/\u001b[A\n",
      "Training loss: 2.60e-02 lr: 1.90e-06:  96%|▉| 13326/13852 [49:55<01:56,  4.52it/\u001b[A\n",
      "Training loss: 9.38e-02 lr: 1.90e-06:  96%|▉| 13327/13852 [49:55<01:56,  4.52it/\u001b[A\n",
      "Training loss: 6.95e-02 lr: 1.89e-06:  96%|▉| 13328/13852 [49:55<01:56,  4.51it/\u001b[A\n",
      "Training loss: 8.32e-02 lr: 1.89e-06:  96%|▉| 13329/13852 [49:56<01:56,  4.51it/\u001b[A\n",
      "Training loss: 6.05e-02 lr: 1.88e-06:  96%|▉| 13330/13852 [49:56<01:55,  4.51it/\u001b[A\n",
      "Training loss: 4.56e-02 lr: 1.88e-06:  96%|▉| 13331/13852 [49:56<01:54,  4.53it/\u001b[A\n",
      "Training loss: 3.89e-02 lr: 1.88e-06:  96%|▉| 13332/13852 [49:56<01:54,  4.55it/\u001b[A\n",
      "Training loss: 3.57e-02 lr: 1.87e-06:  96%|▉| 13333/13852 [49:56<01:54,  4.53it/\u001b[A\n",
      "Training loss: 1.42e-01 lr: 1.87e-06:  96%|▉| 13334/13852 [49:57<01:55,  4.49it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.87e-06:  96%|▉| 13335/13852 [49:57<01:54,  4.50it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.86e-06:  96%|▉| 13336/13852 [49:57<01:54,  4.50it/\u001b[A\n",
      "Training loss: 8.25e-02 lr: 1.86e-06:  96%|▉| 13337/13852 [49:57<01:54,  4.51it/\u001b[A\n",
      "Training loss: 8.67e-02 lr: 1.86e-06:  96%|▉| 13338/13852 [49:58<01:53,  4.51it/\u001b[A\n",
      "Training loss: 7.75e-02 lr: 1.85e-06:  96%|▉| 13339/13852 [49:58<01:53,  4.51it/\u001b[A\n",
      "Training loss: 7.16e-02 lr: 1.85e-06:  96%|▉| 13340/13852 [49:58<01:53,  4.51it/\u001b[A\n",
      "Training loss: 5.28e-02 lr: 1.84e-06:  96%|▉| 13341/13852 [49:58<01:53,  4.51it/\u001b[A\n",
      "Training loss: 4.11e-02 lr: 1.84e-06:  96%|▉| 13342/13852 [49:58<01:52,  4.52it/\u001b[A\n",
      "Training loss: 3.00e-02 lr: 1.84e-06:  96%|▉| 13343/13852 [49:59<01:51,  4.55it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 1.83e-06:  96%|▉| 13344/13852 [49:59<01:51,  4.56it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 1.83e-06:  96%|▉| 13345/13852 [49:59<01:52,  4.50it/\u001b[A\n",
      "Training loss: 3.32e-02 lr: 1.83e-06:  96%|▉| 13346/13852 [49:59<01:52,  4.51it/\u001b[A\n",
      "Training loss: 2.78e-02 lr: 1.82e-06:  96%|▉| 13347/13852 [50:00<01:51,  4.52it/\u001b[A\n",
      "Training loss: 4.06e-02 lr: 1.82e-06:  96%|▉| 13348/13852 [50:00<01:51,  4.52it/\u001b[A\n",
      "Training loss: 3.33e-02 lr: 1.82e-06:  96%|▉| 13349/13852 [50:00<01:51,  4.52it/\u001b[A\n",
      "Training loss: 6.96e-02 lr: 1.81e-06:  96%|▉| 13350/13852 [50:00<01:51,  4.52it/\u001b[A\n",
      "Training loss: 5.86e-02 lr: 1.81e-06:  96%|▉| 13351/13852 [50:00<01:50,  4.51it/\u001b[A\n",
      "Training loss: 5.26e-02 lr: 1.80e-06:  96%|▉| 13352/13852 [50:01<01:50,  4.51it/\u001b[A\n",
      "Training loss: 4.06e-02 lr: 1.80e-06:  96%|▉| 13353/13852 [50:01<01:51,  4.48it/\u001b[A\n",
      "Training loss: 4.90e-02 lr: 1.80e-06:  96%|▉| 13354/13852 [50:01<01:50,  4.50it/\u001b[A\n",
      "Training loss: 9.25e-02 lr: 1.79e-06:  96%|▉| 13355/13852 [50:01<01:49,  4.53it/\u001b[A\n",
      "Training loss: 7.53e-02 lr: 1.79e-06:  96%|▉| 13356/13852 [50:02<01:49,  4.55it/\u001b[A\n",
      "Training loss: 8.84e-02 lr: 1.79e-06:  96%|▉| 13357/13852 [50:02<01:48,  4.55it/\u001b[A\n",
      "Training loss: 7.66e-02 lr: 1.78e-06:  96%|▉| 13358/13852 [50:02<01:53,  4.35it/\u001b[A\n",
      "Training loss: 6.27e-02 lr: 1.78e-06:  96%|▉| 13359/13852 [50:02<01:55,  4.28it/\u001b[A\n",
      "Training loss: 5.46e-02 lr: 1.78e-06:  96%|▉| 13360/13852 [50:03<01:56,  4.22it/\u001b[A\n",
      "Training loss: 4.72e-02 lr: 1.77e-06:  96%|▉| 13361/13852 [50:03<01:54,  4.30it/\u001b[A\n",
      "Training loss: 3.85e-02 lr: 1.77e-06:  96%|▉| 13362/13852 [50:03<01:53,  4.32it/\u001b[A\n",
      "Training loss: 5.95e-02 lr: 1.77e-06:  96%|▉| 13363/13852 [50:03<01:51,  4.39it/\u001b[A\n",
      "Training loss: 5.72e-02 lr: 1.76e-06:  96%|▉| 13364/13852 [50:03<01:49,  4.46it/\u001b[A\n",
      "Training loss: 4.63e-02 lr: 1.76e-06:  96%|▉| 13365/13852 [50:04<01:49,  4.44it/\u001b[A\n",
      "Training loss: 5.31e-02 lr: 1.75e-06:  96%|▉| 13366/13852 [50:04<01:48,  4.46it/\u001b[A\n",
      "Training loss: 4.11e-02 lr: 1.75e-06:  96%|▉| 13367/13852 [50:04<01:48,  4.47it/\u001b[A\n",
      "Training loss: 4.50e-02 lr: 1.75e-06:  97%|▉| 13368/13852 [50:04<01:48,  4.48it/\u001b[A\n",
      "Training loss: 4.19e-02 lr: 1.74e-06:  97%|▉| 13369/13852 [50:05<01:47,  4.48it/\u001b[A\n",
      "Training loss: 3.15e-02 lr: 1.74e-06:  97%|▉| 13370/13852 [50:05<01:47,  4.48it/\u001b[A\n",
      "Training loss: 3.26e-02 lr: 1.74e-06:  97%|▉| 13371/13852 [50:05<01:47,  4.49it/\u001b[A\n",
      "Training loss: 2.82e-02 lr: 1.73e-06:  97%|▉| 13372/13852 [50:05<01:46,  4.49it/\u001b[A\n",
      "Training loss: 2.68e-02 lr: 1.73e-06:  97%|▉| 13373/13852 [50:05<01:46,  4.49it/\u001b[A\n",
      "Training loss: 4.93e-02 lr: 1.73e-06:  97%|▉| 13374/13852 [50:06<01:46,  4.51it/\u001b[A\n",
      "Training loss: 4.70e-02 lr: 1.72e-06:  97%|▉| 13375/13852 [50:06<01:45,  4.53it/\u001b[A\n",
      "Training loss: 7.71e-02 lr: 1.72e-06:  97%|▉| 13376/13852 [50:06<01:44,  4.55it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.94e-02 lr: 1.71e-06:  97%|▉| 13377/13852 [50:06<01:44,  4.56it/\u001b[A\n",
      "Training loss: 1.10e-01 lr: 1.71e-06:  97%|▉| 13378/13852 [50:07<01:44,  4.54it/\u001b[A\n",
      "Training loss: 7.91e-02 lr: 1.71e-06:  97%|▉| 13379/13852 [50:07<01:45,  4.49it/\u001b[A\n",
      "Training loss: 6.44e-02 lr: 1.70e-06:  97%|▉| 13380/13852 [50:07<01:45,  4.46it/\u001b[A\n",
      "Training loss: 4.61e-02 lr: 1.70e-06:  97%|▉| 13381/13852 [50:07<01:45,  4.44it/\u001b[A\n",
      "Training loss: 4.86e-02 lr: 1.70e-06:  97%|▉| 13382/13852 [50:07<01:46,  4.43it/\u001b[A\n",
      "Training loss: 7.34e-02 lr: 1.69e-06:  97%|▉| 13383/13852 [50:08<01:45,  4.45it/\u001b[A\n",
      "Training loss: 6.60e-02 lr: 1.69e-06:  97%|▉| 13384/13852 [50:08<01:44,  4.46it/\u001b[A\n",
      "Training loss: 4.81e-02 lr: 1.69e-06:  97%|▉| 13385/13852 [50:08<01:44,  4.46it/\u001b[A\n",
      "Training loss: 8.16e-02 lr: 1.68e-06:  97%|▉| 13386/13852 [50:08<01:43,  4.49it/\u001b[A\n",
      "Training loss: 1.04e-01 lr: 1.68e-06:  97%|▉| 13387/13852 [50:09<01:42,  4.52it/\u001b[A\n",
      "Training loss: 9.90e-02 lr: 1.67e-06:  97%|▉| 13388/13852 [50:09<01:42,  4.53it/\u001b[A\n",
      "Training loss: 7.12e-02 lr: 1.67e-06:  97%|▉| 13389/13852 [50:09<01:42,  4.53it/\u001b[A\n",
      "Training loss: 8.45e-02 lr: 1.67e-06:  97%|▉| 13390/13852 [50:09<01:42,  4.52it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.66e-06:  97%|▉| 13391/13852 [50:09<01:42,  4.52it/\u001b[A\n",
      "Training loss: 8.39e-02 lr: 1.66e-06:  97%|▉| 13392/13852 [50:10<01:42,  4.51it/\u001b[A\n",
      "Training loss: 6.53e-02 lr: 1.66e-06:  97%|▉| 13393/13852 [50:10<01:42,  4.47it/\u001b[A\n",
      "Training loss: 5.35e-02 lr: 1.65e-06:  97%|▉| 13394/13852 [50:10<01:42,  4.46it/\u001b[A\n",
      "Training loss: 4.82e-02 lr: 1.65e-06:  97%|▉| 13395/13852 [50:10<01:42,  4.46it/\u001b[A\n",
      "Training loss: 3.70e-02 lr: 1.65e-06:  97%|▉| 13396/13852 [50:11<01:42,  4.46it/\u001b[A\n",
      "Training loss: 3.08e-02 lr: 1.64e-06:  97%|▉| 13397/13852 [50:11<01:42,  4.46it/\u001b[A\n",
      "Training loss: 2.72e-02 lr: 1.64e-06:  97%|▉| 13398/13852 [50:11<01:41,  4.48it/\u001b[A\n",
      "Training loss: 6.38e-02 lr: 1.64e-06:  97%|▉| 13399/13852 [50:11<01:40,  4.50it/\u001b[A\n",
      "Training loss: 4.58e-02 lr: 1.63e-06:  97%|▉| 13400/13852 [50:11<01:40,  4.49it/\u001b[A\n",
      "Training loss: 3.84e-02 lr: 1.63e-06:  97%|▉| 13401/13852 [50:12<01:40,  4.47it/\u001b[A\n",
      "Training loss: 2.88e-02 lr: 1.62e-06:  97%|▉| 13402/13852 [50:12<01:40,  4.47it/\u001b[A\n",
      "Training loss: 5.39e-02 lr: 1.62e-06:  97%|▉| 13403/13852 [50:12<01:40,  4.48it/\u001b[A\n",
      "Training loss: 3.95e-02 lr: 1.62e-06:  97%|▉| 13404/13852 [50:12<01:39,  4.48it/\u001b[A\n",
      "Training loss: 3.25e-02 lr: 1.61e-06:  97%|▉| 13405/13852 [50:13<01:39,  4.49it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 1.61e-06:  97%|▉| 13406/13852 [50:13<01:39,  4.49it/\u001b[A\n",
      "Training loss: 2.53e-02 lr: 1.61e-06:  97%|▉| 13407/13852 [50:13<01:39,  4.49it/\u001b[A\n",
      "Training loss: 1.93e-02 lr: 1.60e-06:  97%|▉| 13408/13852 [50:13<01:38,  4.50it/\u001b[A\n",
      "Training loss: 2.33e-02 lr: 1.60e-06:  97%|▉| 13409/13852 [50:13<01:37,  4.52it/\u001b[A\n",
      "Training loss: 1.75e-02 lr: 1.60e-06:  97%|▉| 13410/13852 [50:14<01:37,  4.54it/\u001b[A\n",
      "Training loss: 4.65e-02 lr: 1.59e-06:  97%|▉| 13411/13852 [50:14<01:38,  4.49it/\u001b[A\n",
      "Training loss: 6.74e-02 lr: 1.59e-06:  97%|▉| 13412/13852 [50:14<01:37,  4.49it/\u001b[A\n",
      "Training loss: 9.66e-02 lr: 1.58e-06:  97%|▉| 13413/13852 [50:14<01:37,  4.50it/\u001b[A\n",
      "Training loss: 1.06e-01 lr: 1.58e-06:  97%|▉| 13414/13852 [50:15<01:37,  4.50it/\u001b[A\n",
      "Training loss: 7.80e-02 lr: 1.58e-06:  97%|▉| 13415/13852 [50:15<01:37,  4.50it/\u001b[A\n",
      "Training loss: 5.90e-02 lr: 1.57e-06:  97%|▉| 13416/13852 [50:15<01:37,  4.49it/\u001b[A\n",
      "Training loss: 4.93e-02 lr: 1.57e-06:  97%|▉| 13417/13852 [50:15<01:36,  4.49it/\u001b[A\n",
      "Training loss: 5.16e-02 lr: 1.57e-06:  97%|▉| 13418/13852 [50:15<01:36,  4.49it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 1.56e-06:  97%|▉| 13419/13852 [50:16<01:36,  4.48it/\u001b[A\n",
      "Training loss: 3.21e-02 lr: 1.56e-06:  97%|▉| 13420/13852 [50:16<01:36,  4.48it/\u001b[A\n",
      "Training loss: 2.39e-02 lr: 1.56e-06:  97%|▉| 13421/13852 [50:16<01:35,  4.50it/\u001b[A\n",
      "Training loss: 2.34e-02 lr: 1.55e-06:  97%|▉| 13422/13852 [50:16<01:35,  4.52it/\u001b[A\n",
      "Training loss: 1.70e-02 lr: 1.55e-06:  97%|▉| 13423/13852 [50:17<01:35,  4.51it/\u001b[A\n",
      "Training loss: 1.36e-02 lr: 1.55e-06:  97%|▉| 13424/13852 [50:17<01:35,  4.48it/\u001b[A\n",
      "Training loss: 2.61e-02 lr: 1.54e-06:  97%|▉| 13425/13852 [50:17<01:35,  4.49it/\u001b[A\n",
      "Training loss: 2.23e-02 lr: 1.54e-06:  97%|▉| 13426/13852 [50:17<01:34,  4.49it/\u001b[A\n",
      "Training loss: 1.71e-02 lr: 1.53e-06:  97%|▉| 13427/13852 [50:17<01:34,  4.48it/\u001b[A\n",
      "Training loss: 1.67e-02 lr: 1.53e-06:  97%|▉| 13428/13852 [50:18<01:34,  4.49it/\u001b[A\n",
      "Training loss: 1.50e-02 lr: 1.53e-06:  97%|▉| 13429/13852 [50:18<01:34,  4.49it/\u001b[A\n",
      "Training loss: 1.55e-01 lr: 1.52e-06:  97%|▉| 13430/13852 [50:18<01:34,  4.49it/\u001b[A\n",
      "Training loss: 1.18e-01 lr: 1.52e-06:  97%|▉| 13431/13852 [50:18<01:33,  4.49it/\u001b[A\n",
      "Training loss: 9.94e-02 lr: 1.52e-06:  97%|▉| 13432/13852 [50:19<01:33,  4.51it/\u001b[A\n",
      "Training loss: 9.94e-02 lr: 1.51e-06:  97%|▉| 13433/13852 [50:19<01:32,  4.54it/\u001b[A\n",
      "Training loss: 8.47e-02 lr: 1.51e-06:  97%|▉| 13434/13852 [50:19<01:31,  4.56it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 1.51e-06:  97%|▉| 13435/13852 [50:19<01:32,  4.53it/\u001b[A\n",
      "Training loss: 8.20e-02 lr: 1.50e-06:  97%|▉| 13436/13852 [50:19<01:31,  4.52it/\u001b[A\n",
      "Training loss: 7.87e-02 lr: 1.50e-06:  97%|▉| 13437/13852 [50:20<01:31,  4.52it/\u001b[A\n",
      "Training loss: 5.58e-02 lr: 1.49e-06:  97%|▉| 13438/13852 [50:20<01:31,  4.51it/\u001b[A\n",
      "Training loss: 8.87e-02 lr: 1.49e-06:  97%|▉| 13439/13852 [50:20<01:31,  4.50it/\u001b[A\n",
      "Training loss: 6.85e-02 lr: 1.49e-06:  97%|▉| 13440/13852 [50:20<01:31,  4.49it/\u001b[A\n",
      "Training loss: 5.07e-02 lr: 1.48e-06:  97%|▉| 13441/13852 [50:21<01:31,  4.49it/\u001b[A\n",
      "Training loss: 3.71e-02 lr: 1.48e-06:  97%|▉| 13442/13852 [50:21<01:31,  4.46it/\u001b[A\n",
      "Training loss: 8.54e-02 lr: 1.48e-06:  97%|▉| 13443/13852 [50:21<01:31,  4.46it/\u001b[A\n",
      "Training loss: 7.08e-02 lr: 1.47e-06:  97%|▉| 13444/13852 [50:21<01:31,  4.48it/\u001b[A\n",
      "Training loss: 6.20e-02 lr: 1.47e-06:  97%|▉| 13445/13852 [50:21<01:30,  4.51it/\u001b[A\n",
      "Training loss: 4.41e-02 lr: 1.47e-06:  97%|▉| 13446/13852 [50:22<01:31,  4.46it/\u001b[A\n",
      "Training loss: 5.83e-02 lr: 1.46e-06:  97%|▉| 13447/13852 [50:22<01:30,  4.47it/\u001b[A\n",
      "Training loss: 7.21e-02 lr: 1.46e-06:  97%|▉| 13448/13852 [50:22<01:30,  4.48it/\u001b[A\n",
      "Training loss: 8.05e-02 lr: 1.45e-06:  97%|▉| 13449/13852 [50:22<01:29,  4.48it/\u001b[A\n",
      "Training loss: 5.86e-02 lr: 1.45e-06:  97%|▉| 13450/13852 [50:23<01:29,  4.48it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 1.45e-06:  97%|▉| 13451/13852 [50:23<01:29,  4.49it/\u001b[A\n",
      "Training loss: 3.29e-02 lr: 1.44e-06:  97%|▉| 13452/13852 [50:23<01:29,  4.49it/\u001b[A\n",
      "Training loss: 5.42e-02 lr: 1.44e-06:  97%|▉| 13453/13852 [50:23<01:28,  4.49it/\u001b[A\n",
      "Training loss: 4.08e-02 lr: 1.44e-06:  97%|▉| 13454/13852 [50:23<01:28,  4.49it/\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.43e-06:  97%|▉| 13455/13852 [50:24<01:28,  4.51it/\u001b[A\n",
      "Training loss: 2.59e-02 lr: 1.43e-06:  97%|▉| 13456/13852 [50:24<01:27,  4.53it/\u001b[A\n",
      "Training loss: 3.43e-02 lr: 1.43e-06:  97%|▉| 13457/13852 [50:24<01:26,  4.54it/\u001b[A\n",
      "Training loss: 2.73e-02 lr: 1.42e-06:  97%|▉| 13458/13852 [50:24<01:27,  4.52it/\u001b[A\n",
      "Training loss: 2.22e-02 lr: 1.42e-06:  97%|▉| 13459/13852 [50:25<01:27,  4.52it/\u001b[A\n",
      "Training loss: 2.22e-02 lr: 1.42e-06:  97%|▉| 13460/13852 [50:25<01:26,  4.51it/\u001b[A\n",
      "Training loss: 3.49e-02 lr: 1.41e-06:  97%|▉| 13461/13852 [50:25<01:26,  4.50it/\u001b[A\n",
      "Training loss: 5.95e-02 lr: 1.41e-06:  97%|▉| 13462/13852 [50:25<01:26,  4.50it/\u001b[A\n",
      "Training loss: 4.97e-02 lr: 1.40e-06:  97%|▉| 13463/13852 [50:25<01:26,  4.50it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 1.40e-06:  97%|▉| 13464/13852 [50:26<01:26,  4.51it/\u001b[A\n",
      "Training loss: 3.67e-02 lr: 1.40e-06:  97%|▉| 13465/13852 [50:26<01:25,  4.50it/\u001b[A\n",
      "Training loss: 5.29e-02 lr: 1.39e-06:  97%|▉| 13466/13852 [50:26<01:25,  4.50it/\u001b[A\n",
      "Training loss: 8.45e-02 lr: 1.39e-06:  97%|▉| 13467/13852 [50:26<01:25,  4.51it/\u001b[A\n",
      "Training loss: 7.78e-02 lr: 1.39e-06:  97%|▉| 13468/13852 [50:27<01:24,  4.54it/\u001b[A\n",
      "Training loss: 5.76e-02 lr: 1.38e-06:  97%|▉| 13469/13852 [50:27<01:24,  4.52it/\u001b[A\n",
      "Training loss: 4.71e-02 lr: 1.38e-06:  97%|▉| 13470/13852 [50:27<01:24,  4.50it/\u001b[A\n",
      "Training loss: 5.29e-02 lr: 1.38e-06:  97%|▉| 13471/13852 [50:27<01:24,  4.50it/\u001b[A\n",
      "Training loss: 3.90e-02 lr: 1.37e-06:  97%|▉| 13472/13852 [50:27<01:24,  4.51it/\u001b[A\n",
      "Training loss: 3.05e-02 lr: 1.37e-06:  97%|▉| 13473/13852 [50:28<01:24,  4.51it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.61e-02 lr: 1.36e-06:  97%|▉| 13474/13852 [50:28<01:23,  4.51it/\u001b[A\n",
      "Training loss: 3.10e-02 lr: 1.36e-06:  97%|▉| 13475/13852 [50:28<01:23,  4.50it/\u001b[A\n",
      "Training loss: 6.56e-02 lr: 1.36e-06:  97%|▉| 13476/13852 [50:28<01:23,  4.51it/\u001b[A\n",
      "Training loss: 7.44e-02 lr: 1.35e-06:  97%|▉| 13477/13852 [50:29<01:23,  4.51it/\u001b[A\n",
      "Training loss: 6.35e-02 lr: 1.35e-06:  97%|▉| 13478/13852 [50:29<01:23,  4.50it/\u001b[A\n",
      "Training loss: 6.95e-02 lr: 1.35e-06:  97%|▉| 13479/13852 [50:29<01:22,  4.51it/\u001b[A\n",
      "Training loss: 5.20e-02 lr: 1.34e-06:  97%|▉| 13480/13852 [50:29<01:22,  4.53it/\u001b[A\n",
      "Training loss: 4.08e-02 lr: 1.34e-06:  97%|▉| 13481/13852 [50:29<01:21,  4.55it/\u001b[A\n",
      "Training loss: 4.21e-02 lr: 1.34e-06:  97%|▉| 13482/13852 [50:30<01:22,  4.50it/\u001b[A\n",
      "Training loss: 3.43e-02 lr: 1.33e-06:  97%|▉| 13483/13852 [50:30<01:21,  4.51it/\u001b[A\n",
      "Training loss: 2.63e-02 lr: 1.33e-06:  97%|▉| 13484/13852 [50:30<01:21,  4.51it/\u001b[A\n",
      "Training loss: 4.02e-02 lr: 1.32e-06:  97%|▉| 13485/13852 [50:30<01:21,  4.50it/\u001b[A\n",
      "Training loss: 4.14e-02 lr: 1.32e-06:  97%|▉| 13486/13852 [50:31<01:21,  4.48it/\u001b[A\n",
      "Training loss: 7.15e-02 lr: 1.32e-06:  97%|▉| 13487/13852 [50:31<01:21,  4.46it/\u001b[A\n",
      "Training loss: 5.83e-02 lr: 1.31e-06:  97%|▉| 13488/13852 [50:31<01:21,  4.47it/\u001b[A\n",
      "Training loss: 7.00e-02 lr: 1.31e-06:  97%|▉| 13489/13852 [50:31<01:21,  4.45it/\u001b[A\n",
      "Training loss: 9.14e-02 lr: 1.31e-06:  97%|▉| 13490/13852 [50:31<01:23,  4.36it/\u001b[A\n",
      "Training loss: 7.06e-02 lr: 1.30e-06:  97%|▉| 13491/13852 [50:32<01:23,  4.31it/\u001b[A\n",
      "Training loss: 5.66e-02 lr: 1.30e-06:  97%|▉| 13492/13852 [50:32<01:24,  4.27it/\u001b[A\n",
      "Training loss: 4.15e-02 lr: 1.30e-06:  97%|▉| 13493/13852 [50:32<01:22,  4.34it/\u001b[A\n",
      "Training loss: 3.50e-02 lr: 1.29e-06:  97%|▉| 13494/13852 [50:32<01:21,  4.38it/\u001b[A\n",
      "Training loss: 5.32e-02 lr: 1.29e-06:  97%|▉| 13495/13852 [50:33<01:20,  4.43it/\u001b[A\n",
      "Training loss: 4.01e-02 lr: 1.29e-06:  97%|▉| 13496/13852 [50:33<01:20,  4.45it/\u001b[A\n",
      "Training loss: 4.77e-02 lr: 1.28e-06:  97%|▉| 13497/13852 [50:33<01:19,  4.46it/\u001b[A\n",
      "Training loss: 3.63e-02 lr: 1.28e-06:  97%|▉| 13498/13852 [50:33<01:19,  4.47it/\u001b[A\n",
      "Training loss: 3.18e-02 lr: 1.27e-06:  97%|▉| 13499/13852 [50:34<01:18,  4.48it/\u001b[A\n",
      "Training loss: 2.82e-02 lr: 1.27e-06:  97%|▉| 13500/13852 [50:34<01:18,  4.50it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 1.27e-06:  97%|▉| 13501/13852 [50:34<01:17,  4.53it/\u001b[A\n",
      "Training loss: 3.48e-02 lr: 1.26e-06:  97%|▉| 13502/13852 [50:34<01:16,  4.55it/\u001b[A\n",
      "Training loss: 3.69e-02 lr: 1.26e-06:  97%|▉| 13503/13852 [50:34<01:17,  4.52it/\u001b[A\n",
      "Training loss: 8.78e-02 lr: 1.26e-06:  97%|▉| 13504/13852 [50:35<01:16,  4.52it/\u001b[A\n",
      "Training loss: 6.26e-02 lr: 1.25e-06:  97%|▉| 13505/13852 [50:35<01:16,  4.53it/\u001b[A\n",
      "Training loss: 5.10e-02 lr: 1.25e-06:  98%|▉| 13506/13852 [50:35<01:16,  4.52it/\u001b[A\n",
      "Training loss: 4.57e-02 lr: 1.25e-06:  98%|▉| 13507/13852 [50:35<01:16,  4.51it/\u001b[A\n",
      "Training loss: 3.91e-02 lr: 1.24e-06:  98%|▉| 13508/13852 [50:36<01:16,  4.51it/\u001b[A\n",
      "Training loss: 4.32e-02 lr: 1.24e-06:  98%|▉| 13509/13852 [50:36<01:16,  4.51it/\u001b[A\n",
      "Training loss: 3.26e-02 lr: 1.23e-06:  98%|▉| 13510/13852 [50:36<01:15,  4.51it/\u001b[A\n",
      "Training loss: 2.60e-02 lr: 1.23e-06:  98%|▉| 13511/13852 [50:36<01:15,  4.50it/\u001b[A\n",
      "Training loss: 8.76e-02 lr: 1.23e-06:  98%|▉| 13512/13852 [50:36<01:15,  4.52it/\u001b[A\n",
      "Training loss: 9.10e-02 lr: 1.22e-06:  98%|▉| 13513/13852 [50:37<01:14,  4.55it/\u001b[A\n",
      "Training loss: 6.45e-02 lr: 1.22e-06:  98%|▉| 13514/13852 [50:37<01:15,  4.50it/\u001b[A\n",
      "Training loss: 5.53e-02 lr: 1.22e-06:  98%|▉| 13515/13852 [50:37<01:15,  4.45it/\u001b[A\n",
      "Training loss: 5.91e-02 lr: 1.21e-06:  98%|▉| 13516/13852 [50:37<01:15,  4.42it/\u001b[A\n",
      "Training loss: 5.53e-02 lr: 1.21e-06:  98%|▉| 13517/13852 [50:38<01:15,  4.43it/\u001b[A\n",
      "Training loss: 3.96e-02 lr: 1.21e-06:  98%|▉| 13518/13852 [50:38<01:15,  4.44it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 1.20e-06:  98%|▉| 13519/13852 [50:38<01:14,  4.46it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 1.20e-06:  98%|▉| 13520/13852 [50:38<01:14,  4.47it/\u001b[A\n",
      "Training loss: 3.60e-02 lr: 1.19e-06:  98%|▉| 13521/13852 [50:38<01:14,  4.47it/\u001b[A\n",
      "Training loss: 4.66e-02 lr: 1.19e-06:  98%|▉| 13522/13852 [50:39<01:13,  4.47it/\u001b[A\n",
      "Training loss: 3.42e-02 lr: 1.19e-06:  98%|▉| 13523/13852 [50:39<01:13,  4.50it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 1.18e-06:  98%|▉| 13524/13852 [50:39<01:12,  4.52it/\u001b[A\n",
      "Training loss: 4.90e-02 lr: 1.18e-06:  98%|▉| 13525/13852 [50:39<01:12,  4.48it/\u001b[A\n",
      "Training loss: 5.23e-02 lr: 1.18e-06:  98%|▉| 13526/13852 [50:40<01:12,  4.49it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 1.17e-06:  98%|▉| 13527/13852 [50:40<01:12,  4.51it/\u001b[A\n",
      "Training loss: 5.62e-02 lr: 1.17e-06:  98%|▉| 13528/13852 [50:40<01:11,  4.51it/\u001b[A\n",
      "Training loss: 4.01e-02 lr: 1.17e-06:  98%|▉| 13529/13852 [50:40<01:11,  4.51it/\u001b[A\n",
      "Training loss: 3.09e-02 lr: 1.16e-06:  98%|▉| 13530/13852 [50:40<01:11,  4.51it/\u001b[A\n",
      "Training loss: 3.42e-02 lr: 1.16e-06:  98%|▉| 13531/13852 [50:41<01:13,  4.38it/\u001b[A\n",
      "Training loss: 2.73e-02 lr: 1.16e-06:  98%|▉| 13532/13852 [50:41<01:14,  4.29it/\u001b[A\n",
      "Training loss: 8.63e-02 lr: 1.15e-06:  98%|▉| 13533/13852 [50:41<01:13,  4.37it/\u001b[A\n",
      "Training loss: 6.39e-02 lr: 1.15e-06:  98%|▉| 13534/13852 [50:41<01:12,  4.39it/\u001b[A\n",
      "Training loss: 6.48e-02 lr: 1.14e-06:  98%|▉| 13535/13852 [50:42<01:11,  4.42it/\u001b[A\n",
      "Training loss: 4.93e-02 lr: 1.14e-06:  98%|▉| 13536/13852 [50:42<01:11,  4.43it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 1.14e-06:  98%|▉| 13537/13852 [50:42<01:10,  4.46it/\u001b[A\n",
      "Training loss: 2.98e-02 lr: 1.13e-06:  98%|▉| 13538/13852 [50:42<01:10,  4.47it/\u001b[A\n",
      "Training loss: 4.95e-02 lr: 1.13e-06:  98%|▉| 13539/13852 [50:42<01:09,  4.48it/\u001b[A\n",
      "Training loss: 4.09e-02 lr: 1.13e-06:  98%|▉| 13540/13852 [50:43<01:09,  4.50it/\u001b[A\n",
      "Training loss: 3.12e-02 lr: 1.12e-06:  98%|▉| 13541/13852 [50:43<01:09,  4.50it/\u001b[A\n",
      "Training loss: 2.88e-02 lr: 1.12e-06:  98%|▉| 13542/13852 [50:43<01:08,  4.50it/\u001b[A\n",
      "Training loss: 3.57e-02 lr: 1.12e-06:  98%|▉| 13543/13852 [50:43<01:08,  4.50it/\u001b[A\n",
      "Training loss: 4.03e-02 lr: 1.11e-06:  98%|▉| 13544/13852 [50:44<01:08,  4.52it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 1.11e-06:  98%|▉| 13545/13852 [50:44<01:07,  4.53it/\u001b[A\n",
      "Training loss: 2.64e-02 lr: 1.10e-06:  98%|▉| 13546/13852 [50:44<01:07,  4.55it/\u001b[A\n",
      "Training loss: 1.95e-02 lr: 1.10e-06:  98%|▉| 13547/13852 [50:44<01:07,  4.53it/\u001b[A\n",
      "Training loss: 5.32e-02 lr: 1.10e-06:  98%|▉| 13548/13852 [50:44<01:07,  4.53it/\u001b[A\n",
      "Training loss: 5.01e-02 lr: 1.09e-06:  98%|▉| 13549/13852 [50:45<01:06,  4.52it/\u001b[A\n",
      "Training loss: 3.99e-02 lr: 1.09e-06:  98%|▉| 13550/13852 [50:45<01:06,  4.52it/\u001b[A\n",
      "Training loss: 3.64e-02 lr: 1.09e-06:  98%|▉| 13551/13852 [50:45<01:06,  4.52it/\u001b[A\n",
      "Training loss: 3.52e-02 lr: 1.08e-06:  98%|▉| 13552/13852 [50:45<01:06,  4.52it/\u001b[A\n",
      "Training loss: 2.56e-02 lr: 1.08e-06:  98%|▉| 13553/13852 [50:46<01:06,  4.51it/\u001b[A\n",
      "Training loss: 2.19e-02 lr: 1.08e-06:  98%|▉| 13554/13852 [50:46<01:06,  4.51it/\u001b[A\n",
      "Training loss: 1.68e-02 lr: 1.07e-06:  98%|▉| 13555/13852 [50:46<01:05,  4.51it/\u001b[A\n",
      "Training loss: 3.22e-02 lr: 1.07e-06:  98%|▉| 13556/13852 [50:46<01:05,  4.50it/\u001b[A\n",
      "Training loss: 3.21e-02 lr: 1.06e-06:  98%|▉| 13557/13852 [50:46<01:05,  4.52it/\u001b[A\n",
      "Training loss: 3.55e-02 lr: 1.06e-06:  98%|▉| 13558/13852 [50:47<01:05,  4.52it/\u001b[A\n",
      "Training loss: 4.10e-02 lr: 1.06e-06:  98%|▉| 13559/13852 [50:47<01:05,  4.48it/\u001b[A\n",
      "Training loss: 3.36e-02 lr: 1.05e-06:  98%|▉| 13560/13852 [50:47<01:05,  4.49it/\u001b[A\n",
      "Training loss: 7.98e-02 lr: 1.05e-06:  98%|▉| 13561/13852 [50:47<01:04,  4.51it/\u001b[A\n",
      "Training loss: 5.79e-02 lr: 1.05e-06:  98%|▉| 13562/13852 [50:48<01:04,  4.52it/\u001b[A\n",
      "Training loss: 4.96e-02 lr: 1.04e-06:  98%|▉| 13563/13852 [50:48<01:04,  4.51it/\u001b[A\n",
      "Training loss: 4.02e-02 lr: 1.04e-06:  98%|▉| 13564/13852 [50:48<01:04,  4.49it/\u001b[A\n",
      "Training loss: 3.64e-02 lr: 1.04e-06:  98%|▉| 13565/13852 [50:48<01:03,  4.49it/\u001b[A\n",
      "Training loss: 7.63e-02 lr: 1.03e-06:  98%|▉| 13566/13852 [50:48<01:03,  4.48it/\u001b[A\n",
      "Training loss: 6.92e-02 lr: 1.03e-06:  98%|▉| 13567/13852 [50:49<01:03,  4.49it/\u001b[A\n",
      "Training loss: 5.25e-02 lr: 1.03e-06:  98%|▉| 13568/13852 [50:49<01:02,  4.52it/\u001b[A\n",
      "Training loss: 7.46e-02 lr: 1.02e-06:  98%|▉| 13569/13852 [50:49<01:02,  4.54it/\u001b[A\n",
      "Training loss: 6.22e-02 lr: 1.02e-06:  98%|▉| 13570/13852 [50:49<01:02,  4.53it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.44e-02 lr: 1.01e-06:  98%|▉| 13571/13852 [50:50<01:02,  4.50it/\u001b[A\n",
      "Training loss: 4.03e-02 lr: 1.01e-06:  98%|▉| 13572/13852 [50:50<01:02,  4.50it/\u001b[A\n",
      "Training loss: 3.57e-02 lr: 1.01e-06:  98%|▉| 13573/13852 [50:50<01:01,  4.51it/\u001b[A\n",
      "Training loss: 3.18e-02 lr: 1.00e-06:  98%|▉| 13574/13852 [50:50<01:01,  4.51it/\u001b[A\n",
      "Training loss: 3.23e-02 lr: 1.00e-06:  98%|▉| 13575/13852 [50:50<01:01,  4.50it/\u001b[A\n",
      "Training loss: 2.29e-02 lr: 9.96e-07:  98%|▉| 13576/13852 [50:51<01:01,  4.50it/\u001b[A\n",
      "Training loss: 2.52e-02 lr: 9.93e-07:  98%|▉| 13577/13852 [50:51<01:01,  4.47it/\u001b[A\n",
      "Training loss: 2.22e-02 lr: 9.89e-07:  98%|▉| 13578/13852 [50:51<01:01,  4.47it/\u001b[A\n",
      "Training loss: 1.97e-02 lr: 9.85e-07:  98%|▉| 13579/13852 [50:51<01:00,  4.48it/\u001b[A\n",
      "Training loss: 2.66e-02 lr: 9.82e-07:  98%|▉| 13580/13852 [50:52<01:02,  4.37it/\u001b[A\n",
      "Training loss: 2.31e-02 lr: 9.78e-07:  98%|▉| 13581/13852 [50:52<01:03,  4.28it/\u001b[A\n",
      "Training loss: 6.00e-02 lr: 9.75e-07:  98%|▉| 13582/13852 [50:52<01:02,  4.34it/\u001b[A\n",
      "Training loss: 6.98e-02 lr: 9.71e-07:  98%|▉| 13583/13852 [50:52<01:01,  4.40it/\u001b[A\n",
      "Training loss: 7.04e-02 lr: 9.67e-07:  98%|▉| 13584/13852 [50:52<01:00,  4.41it/\u001b[A\n",
      "Training loss: 5.67e-02 lr: 9.64e-07:  98%|▉| 13585/13852 [50:53<01:00,  4.44it/\u001b[A\n",
      "Training loss: 5.90e-02 lr: 9.60e-07:  98%|▉| 13586/13852 [50:53<00:59,  4.45it/\u001b[A\n",
      "Training loss: 5.01e-02 lr: 9.57e-07:  98%|▉| 13587/13852 [50:53<00:59,  4.47it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 9.53e-07:  98%|▉| 13588/13852 [50:53<00:58,  4.48it/\u001b[A\n",
      "Training loss: 3.46e-02 lr: 9.49e-07:  98%|▉| 13589/13852 [50:54<00:58,  4.51it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 9.46e-07:  98%|▉| 13590/13852 [50:54<00:57,  4.53it/\u001b[A\n",
      "Training loss: 2.47e-02 lr: 9.42e-07:  98%|▉| 13591/13852 [50:54<00:57,  4.54it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 9.39e-07:  98%|▉| 13592/13852 [50:54<00:57,  4.54it/\u001b[A\n",
      "Training loss: 4.64e-02 lr: 9.35e-07:  98%|▉| 13593/13852 [50:54<00:57,  4.52it/\u001b[A\n",
      "Training loss: 3.40e-02 lr: 9.31e-07:  98%|▉| 13594/13852 [50:55<00:57,  4.52it/\u001b[A\n",
      "Training loss: 2.92e-02 lr: 9.28e-07:  98%|▉| 13595/13852 [50:55<00:56,  4.52it/\u001b[A\n",
      "Training loss: 4.14e-02 lr: 9.24e-07:  98%|▉| 13596/13852 [50:55<00:56,  4.53it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 9.21e-07:  98%|▉| 13597/13852 [50:55<00:56,  4.52it/\u001b[A\n",
      "Training loss: 4.98e-02 lr: 9.17e-07:  98%|▉| 13598/13852 [50:56<00:56,  4.51it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 9.13e-07:  98%|▉| 13599/13852 [50:56<00:56,  4.52it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 9.10e-07:  98%|▉| 13600/13852 [50:56<00:55,  4.52it/\u001b[A\n",
      "Training loss: 3.08e-02 lr: 9.06e-07:  98%|▉| 13601/13852 [50:56<00:55,  4.51it/\u001b[A\n",
      "Training loss: 6.04e-02 lr: 9.02e-07:  98%|▉| 13602/13852 [50:56<00:55,  4.52it/\u001b[A\n",
      "Training loss: 4.68e-02 lr: 8.99e-07:  98%|▉| 13603/13852 [50:57<00:54,  4.53it/\u001b[A\n",
      "Training loss: 3.47e-02 lr: 8.95e-07:  98%|▉| 13604/13852 [50:57<00:54,  4.54it/\u001b[A\n",
      "Training loss: 3.26e-02 lr: 8.92e-07:  98%|▉| 13605/13852 [50:57<00:54,  4.51it/\u001b[A\n",
      "Training loss: 6.38e-02 lr: 8.88e-07:  98%|▉| 13606/13852 [50:57<00:54,  4.51it/\u001b[A\n",
      "Training loss: 6.77e-02 lr: 8.84e-07:  98%|▉| 13607/13852 [50:58<00:54,  4.51it/\u001b[A\n",
      "Training loss: 4.79e-02 lr: 8.81e-07:  98%|▉| 13608/13852 [50:58<00:54,  4.51it/\u001b[A\n",
      "Training loss: 4.41e-02 lr: 8.77e-07:  98%|▉| 13609/13852 [50:58<00:53,  4.51it/\u001b[A\n",
      "Training loss: 3.14e-02 lr: 8.74e-07:  98%|▉| 13610/13852 [50:58<00:53,  4.51it/\u001b[A\n",
      "Training loss: 2.36e-02 lr: 8.70e-07:  98%|▉| 13611/13852 [50:58<00:53,  4.51it/\u001b[A\n",
      "Training loss: 2.42e-02 lr: 8.66e-07:  98%|▉| 13612/13852 [50:59<00:53,  4.50it/\u001b[A\n",
      "Training loss: 3.95e-02 lr: 8.63e-07:  98%|▉| 13613/13852 [50:59<00:53,  4.50it/\u001b[A\n",
      "Training loss: 3.27e-02 lr: 8.59e-07:  98%|▉| 13614/13852 [50:59<00:52,  4.52it/\u001b[A\n",
      "Training loss: 3.78e-02 lr: 8.56e-07:  98%|▉| 13615/13852 [50:59<00:52,  4.54it/\u001b[A\n",
      "Training loss: 3.43e-02 lr: 8.52e-07:  98%|▉| 13616/13852 [51:00<00:51,  4.56it/\u001b[A\n",
      "Training loss: 2.47e-02 lr: 8.48e-07:  98%|▉| 13617/13852 [51:00<00:52,  4.51it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 8.45e-07:  98%|▉| 13618/13852 [51:00<00:51,  4.52it/\u001b[A\n",
      "Training loss: 3.99e-02 lr: 8.41e-07:  98%|▉| 13619/13852 [51:00<00:51,  4.52it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 8.37e-07:  98%|▉| 13620/13852 [51:00<00:51,  4.52it/\u001b[A\n",
      "Training loss: 7.12e-02 lr: 8.34e-07:  98%|▉| 13621/13852 [51:01<00:51,  4.51it/\u001b[A\n",
      "Training loss: 6.06e-02 lr: 8.30e-07:  98%|▉| 13622/13852 [51:01<00:51,  4.48it/\u001b[A\n",
      "Training loss: 6.07e-02 lr: 8.27e-07:  98%|▉| 13623/13852 [51:01<00:51,  4.49it/\u001b[A\n",
      "Training loss: 1.12e-01 lr: 8.23e-07:  98%|▉| 13624/13852 [51:01<00:50,  4.49it/\u001b[A\n",
      "Training loss: 8.68e-02 lr: 8.19e-07:  98%|▉| 13625/13852 [51:02<00:50,  4.49it/\u001b[A\n",
      "Training loss: 7.22e-02 lr: 8.16e-07:  98%|▉| 13626/13852 [51:02<00:50,  4.50it/\u001b[A\n",
      "Training loss: 5.35e-02 lr: 8.12e-07:  98%|▉| 13627/13852 [51:02<00:49,  4.52it/\u001b[A\n",
      "Training loss: 4.31e-02 lr: 8.09e-07:  98%|▉| 13628/13852 [51:02<00:49,  4.54it/\u001b[A\n",
      "Training loss: 3.40e-02 lr: 8.05e-07:  98%|▉| 13629/13852 [51:02<00:48,  4.56it/\u001b[A\n",
      "Training loss: 2.79e-02 lr: 8.01e-07:  98%|▉| 13630/13852 [51:03<00:48,  4.54it/\u001b[A\n",
      "Training loss: 3.26e-02 lr: 7.98e-07:  98%|▉| 13631/13852 [51:03<00:48,  4.53it/\u001b[A\n",
      "Training loss: 4.07e-02 lr: 7.94e-07:  98%|▉| 13632/13852 [51:03<00:48,  4.52it/\u001b[A\n",
      "Training loss: 3.00e-02 lr: 7.91e-07:  98%|▉| 13633/13852 [51:03<00:48,  4.51it/\u001b[A\n",
      "Training loss: 2.23e-02 lr: 7.87e-07:  98%|▉| 13634/13852 [51:04<00:48,  4.50it/\u001b[A\n",
      "Training loss: 2.13e-02 lr: 7.83e-07:  98%|▉| 13635/13852 [51:04<00:48,  4.50it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 7.80e-07:  98%|▉| 13636/13852 [51:04<00:47,  4.50it/\u001b[A\n",
      "Training loss: 3.64e-02 lr: 7.76e-07:  98%|▉| 13637/13852 [51:04<00:47,  4.49it/\u001b[A\n",
      "Training loss: 6.08e-02 lr: 7.73e-07:  98%|▉| 13638/13852 [51:04<00:47,  4.48it/\u001b[A\n",
      "Training loss: 4.43e-02 lr: 7.69e-07:  98%|▉| 13639/13852 [51:05<00:47,  4.50it/\u001b[A\n",
      "Training loss: 3.80e-02 lr: 7.65e-07:  98%|▉| 13640/13852 [51:05<00:46,  4.53it/\u001b[A\n",
      "Training loss: 3.51e-02 lr: 7.62e-07:  98%|▉| 13641/13852 [51:05<00:46,  4.53it/\u001b[A\n",
      "Training loss: 3.29e-02 lr: 7.58e-07:  98%|▉| 13642/13852 [51:05<00:46,  4.53it/\u001b[A\n",
      "Training loss: 2.92e-02 lr: 7.54e-07:  98%|▉| 13643/13852 [51:06<00:46,  4.53it/\u001b[A\n",
      "Training loss: 3.04e-02 lr: 7.51e-07:  98%|▉| 13644/13852 [51:06<00:46,  4.52it/\u001b[A\n",
      "Training loss: 2.49e-02 lr: 7.47e-07:  99%|▉| 13645/13852 [51:06<00:45,  4.52it/\u001b[A\n",
      "Training loss: 3.53e-02 lr: 7.44e-07:  99%|▉| 13646/13852 [51:06<00:45,  4.51it/\u001b[A\n",
      "Training loss: 2.91e-02 lr: 7.40e-07:  99%|▉| 13647/13852 [51:06<00:45,  4.51it/\u001b[A\n",
      "Training loss: 3.52e-02 lr: 7.36e-07:  99%|▉| 13648/13852 [51:07<00:45,  4.49it/\u001b[A\n",
      "Training loss: 2.86e-02 lr: 7.33e-07:  99%|▉| 13649/13852 [51:07<00:45,  4.46it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 7.29e-07:  99%|▉| 13650/13852 [51:07<00:45,  4.46it/\u001b[A\n",
      "Training loss: 2.98e-02 lr: 7.26e-07:  99%|▉| 13651/13852 [51:07<00:44,  4.49it/\u001b[A\n",
      "Training loss: 2.63e-02 lr: 7.22e-07:  99%|▉| 13652/13852 [51:08<00:44,  4.51it/\u001b[A\n",
      "Training loss: 4.20e-02 lr: 7.18e-07:  99%|▉| 13653/13852 [51:08<00:44,  4.48it/\u001b[A\n",
      "Training loss: 4.25e-02 lr: 7.15e-07:  99%|▉| 13654/13852 [51:08<00:44,  4.50it/\u001b[A\n",
      "Training loss: 4.50e-02 lr: 7.11e-07:  99%|▉| 13655/13852 [51:08<00:43,  4.51it/\u001b[A\n",
      "Training loss: 5.64e-02 lr: 7.08e-07:  99%|▉| 13656/13852 [51:08<00:43,  4.51it/\u001b[A\n",
      "Training loss: 8.13e-02 lr: 7.04e-07:  99%|▉| 13657/13852 [51:09<00:43,  4.51it/\u001b[A\n",
      "Training loss: 9.43e-02 lr: 7.00e-07:  99%|▉| 13658/13852 [51:09<00:42,  4.51it/\u001b[A\n",
      "Training loss: 6.67e-02 lr: 6.97e-07:  99%|▉| 13659/13852 [51:09<00:42,  4.51it/\u001b[A\n",
      "Training loss: 4.92e-02 lr: 6.93e-07:  99%|▉| 13660/13852 [51:09<00:42,  4.51it/\u001b[A\n",
      "Training loss: 6.31e-02 lr: 6.89e-07:  99%|▉| 13661/13852 [51:10<00:42,  4.51it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 6.86e-07:  99%|▉| 13662/13852 [51:10<00:41,  4.52it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 6.82e-07:  99%|▉| 13663/13852 [51:10<00:41,  4.55it/\u001b[A\n",
      "Training loss: 3.19e-02 lr: 6.79e-07:  99%|▉| 13664/13852 [51:10<00:41,  4.54it/\u001b[A\n",
      "Training loss: 3.41e-02 lr: 6.75e-07:  99%|▉| 13665/13852 [51:10<00:41,  4.55it/\u001b[A\n",
      "Training loss: 6.84e-02 lr: 6.71e-07:  99%|▉| 13666/13852 [51:11<00:41,  4.53it/\u001b[A\n",
      "Training loss: 7.38e-02 lr: 6.68e-07:  99%|▉| 13667/13852 [51:11<00:41,  4.50it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.17e-02 lr: 6.64e-07:  99%|▉| 13668/13852 [51:11<00:40,  4.50it/\u001b[A\n",
      "Training loss: 8.74e-02 lr: 6.61e-07:  99%|▉| 13669/13852 [51:11<00:40,  4.50it/\u001b[A\n",
      "Training loss: 7.97e-02 lr: 6.57e-07:  99%|▉| 13670/13852 [51:12<00:40,  4.47it/\u001b[A\n",
      "Training loss: 5.85e-02 lr: 6.53e-07:  99%|▉| 13671/13852 [51:12<00:40,  4.44it/\u001b[A\n",
      "Training loss: 5.47e-02 lr: 6.50e-07:  99%|▉| 13672/13852 [51:12<00:40,  4.46it/\u001b[A\n",
      "Training loss: 4.06e-02 lr: 6.46e-07:  99%|▉| 13673/13852 [51:12<00:40,  4.47it/\u001b[A\n",
      "Training loss: 3.64e-02 lr: 6.43e-07:  99%|▉| 13674/13852 [51:12<00:39,  4.49it/\u001b[A\n",
      "Training loss: 2.95e-02 lr: 6.39e-07:  99%|▉| 13675/13852 [51:13<00:39,  4.52it/\u001b[A\n",
      "Training loss: 2.39e-02 lr: 6.35e-07:  99%|▉| 13676/13852 [51:13<00:38,  4.54it/\u001b[A\n",
      "Training loss: 2.39e-02 lr: 6.32e-07:  99%|▉| 13677/13852 [51:13<00:38,  4.51it/\u001b[A\n",
      "Training loss: 1.83e-02 lr: 6.28e-07:  99%|▉| 13678/13852 [51:13<00:38,  4.52it/\u001b[A\n",
      "Training loss: 7.51e-02 lr: 6.25e-07:  99%|▉| 13679/13852 [51:14<00:38,  4.52it/\u001b[A\n",
      "Training loss: 1.15e-01 lr: 6.21e-07:  99%|▉| 13680/13852 [51:14<00:38,  4.52it/\u001b[A\n",
      "Training loss: 8.41e-02 lr: 6.17e-07:  99%|▉| 13681/13852 [51:14<00:37,  4.52it/\u001b[A\n",
      "Training loss: 1.20e-01 lr: 6.14e-07:  99%|▉| 13682/13852 [51:14<00:37,  4.51it/\u001b[A\n",
      "Training loss: 1.04e-01 lr: 6.10e-07:  99%|▉| 13683/13852 [51:14<00:38,  4.38it/\u001b[A\n",
      "Training loss: 7.57e-02 lr: 6.06e-07:  99%|▉| 13684/13852 [51:15<00:38,  4.41it/\u001b[A\n",
      "Training loss: 6.76e-02 lr: 6.03e-07:  99%|▉| 13685/13852 [51:15<00:37,  4.44it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 5.99e-07:  99%|▉| 13686/13852 [51:15<00:37,  4.48it/\u001b[A\n",
      "Training loss: 1.11e-01 lr: 5.96e-07:  99%|▉| 13687/13852 [51:15<00:36,  4.52it/\u001b[A\n",
      "Training loss: 8.62e-02 lr: 5.92e-07:  99%|▉| 13688/13852 [51:16<00:36,  4.49it/\u001b[A\n",
      "Training loss: 7.65e-02 lr: 5.88e-07:  99%|▉| 13689/13852 [51:16<00:36,  4.50it/\u001b[A\n",
      "Training loss: 6.76e-02 lr: 5.85e-07:  99%|▉| 13690/13852 [51:16<00:35,  4.51it/\u001b[A\n",
      "Training loss: 5.95e-02 lr: 5.81e-07:  99%|▉| 13691/13852 [51:16<00:35,  4.51it/\u001b[A\n",
      "Training loss: 4.68e-02 lr: 5.78e-07:  99%|▉| 13692/13852 [51:16<00:35,  4.51it/\u001b[A\n",
      "Training loss: 4.68e-02 lr: 5.74e-07:  99%|▉| 13693/13852 [51:17<00:35,  4.49it/\u001b[A\n",
      "Training loss: 6.66e-02 lr: 5.70e-07:  99%|▉| 13694/13852 [51:17<00:35,  4.46it/\u001b[A\n",
      "Training loss: 5.88e-02 lr: 5.67e-07:  99%|▉| 13695/13852 [51:17<00:35,  4.47it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 5.63e-07:  99%|▉| 13696/13852 [51:17<00:34,  4.47it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 5.60e-07:  99%|▉| 13697/13852 [51:18<00:34,  4.50it/\u001b[A\n",
      "Training loss: 2.53e-02 lr: 5.56e-07:  99%|▉| 13698/13852 [51:18<00:34,  4.53it/\u001b[A\n",
      "Training loss: 1.88e-02 lr: 5.52e-07:  99%|▉| 13699/13852 [51:18<00:33,  4.52it/\u001b[A\n",
      "Training loss: 1.85e-02 lr: 5.49e-07:  99%|▉| 13700/13852 [51:18<00:33,  4.52it/\u001b[A\n",
      "Training loss: 2.35e-02 lr: 5.45e-07:  99%|▉| 13701/13852 [51:18<00:33,  4.52it/\u001b[A\n",
      "Training loss: 2.97e-02 lr: 5.41e-07:  99%|▉| 13702/13852 [51:19<00:33,  4.53it/\u001b[A\n",
      "Training loss: 2.65e-02 lr: 5.38e-07:  99%|▉| 13703/13852 [51:19<00:32,  4.52it/\u001b[A\n",
      "Training loss: 3.72e-02 lr: 5.34e-07:  99%|▉| 13704/13852 [51:19<00:32,  4.50it/\u001b[A\n",
      "Training loss: 4.53e-02 lr: 5.31e-07:  99%|▉| 13705/13852 [51:19<00:32,  4.49it/\u001b[A\n",
      "Training loss: 5.72e-02 lr: 5.27e-07:  99%|▉| 13706/13852 [51:20<00:32,  4.49it/\u001b[A\n",
      "Training loss: 4.57e-02 lr: 5.23e-07:  99%|▉| 13707/13852 [51:20<00:32,  4.48it/\u001b[A\n",
      "Training loss: 4.17e-02 lr: 5.20e-07:  99%|▉| 13708/13852 [51:20<00:32,  4.48it/\u001b[A\n",
      "Training loss: 3.62e-02 lr: 5.16e-07:  99%|▉| 13709/13852 [51:20<00:31,  4.49it/\u001b[A\n",
      "Training loss: 5.62e-02 lr: 5.13e-07:  99%|▉| 13710/13852 [51:20<00:31,  4.52it/\u001b[A\n",
      "Training loss: 4.98e-02 lr: 5.09e-07:  99%|▉| 13711/13852 [51:21<00:31,  4.53it/\u001b[A\n",
      "Training loss: 4.33e-02 lr: 5.05e-07:  99%|▉| 13712/13852 [51:21<00:31,  4.49it/\u001b[A\n",
      "Training loss: 6.15e-02 lr: 5.02e-07:  99%|▉| 13713/13852 [51:21<00:30,  4.50it/\u001b[A\n",
      "Training loss: 4.50e-02 lr: 4.98e-07:  99%|▉| 13714/13852 [51:21<00:30,  4.50it/\u001b[A\n",
      "Training loss: 5.13e-02 lr: 4.95e-07:  99%|▉| 13715/13852 [51:22<00:30,  4.49it/\u001b[A\n",
      "Training loss: 5.05e-02 lr: 4.91e-07:  99%|▉| 13716/13852 [51:22<00:30,  4.47it/\u001b[A\n",
      "Training loss: 5.32e-02 lr: 4.87e-07:  99%|▉| 13717/13852 [51:22<00:30,  4.47it/\u001b[A\n",
      "Training loss: 5.01e-02 lr: 4.84e-07:  99%|▉| 13718/13852 [51:22<00:30,  4.47it/\u001b[A\n",
      "Training loss: 4.97e-02 lr: 4.80e-07:  99%|▉| 13719/13852 [51:22<00:29,  4.47it/\u001b[A\n",
      "Training loss: 4.74e-02 lr: 4.76e-07:  99%|▉| 13720/13852 [51:23<00:29,  4.46it/\u001b[A\n",
      "Training loss: 1.21e-01 lr: 4.73e-07:  99%|▉| 13721/13852 [51:23<00:29,  4.50it/\u001b[A\n",
      "Training loss: 8.80e-02 lr: 4.69e-07:  99%|▉| 13722/13852 [51:23<00:28,  4.53it/\u001b[A\n",
      "Training loss: 6.67e-02 lr: 4.66e-07:  99%|▉| 13723/13852 [51:23<00:28,  4.50it/\u001b[A\n",
      "Training loss: 7.59e-02 lr: 4.62e-07:  99%|▉| 13724/13852 [51:24<00:28,  4.51it/\u001b[A\n",
      "Training loss: 5.75e-02 lr: 4.58e-07:  99%|▉| 13725/13852 [51:24<00:28,  4.51it/\u001b[A\n",
      "Training loss: 4.40e-02 lr: 4.55e-07:  99%|▉| 13726/13852 [51:24<00:27,  4.51it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 4.51e-07:  99%|▉| 13727/13852 [51:24<00:27,  4.51it/\u001b[A\n",
      "Training loss: 3.22e-02 lr: 4.48e-07:  99%|▉| 13728/13852 [51:24<00:27,  4.51it/\u001b[A\n",
      "Training loss: 3.63e-02 lr: 4.44e-07:  99%|▉| 13729/13852 [51:25<00:27,  4.51it/\u001b[A\n",
      "Training loss: 5.55e-02 lr: 4.40e-07:  99%|▉| 13730/13852 [51:25<00:27,  4.51it/\u001b[A\n",
      "Training loss: 3.98e-02 lr: 4.37e-07:  99%|▉| 13731/13852 [51:25<00:26,  4.51it/\u001b[A\n",
      "Training loss: 3.66e-02 lr: 4.33e-07:  99%|▉| 13732/13852 [51:25<00:26,  4.52it/\u001b[A\n",
      "Training loss: 8.12e-02 lr: 4.30e-07:  99%|▉| 13733/13852 [51:26<00:26,  4.54it/\u001b[A\n",
      "Training loss: 6.64e-02 lr: 4.26e-07:  99%|▉| 13734/13852 [51:26<00:25,  4.56it/\u001b[A\n",
      "Training loss: 4.76e-02 lr: 4.22e-07:  99%|▉| 13735/13852 [51:26<00:25,  4.57it/\u001b[A\n",
      "Training loss: 4.29e-02 lr: 4.19e-07:  99%|▉| 13736/13852 [51:26<00:25,  4.59it/\u001b[A\n",
      "Training loss: 3.22e-02 lr: 4.15e-07:  99%|▉| 13737/13852 [51:26<00:25,  4.57it/\u001b[A\n",
      "Training loss: 2.39e-02 lr: 4.12e-07:  99%|▉| 13738/13852 [51:27<00:25,  4.55it/\u001b[A\n",
      "Training loss: 2.50e-02 lr: 4.08e-07:  99%|▉| 13739/13852 [51:27<00:25,  4.50it/\u001b[A\n",
      "Training loss: 3.04e-02 lr: 4.04e-07:  99%|▉| 13740/13852 [51:27<00:25,  4.48it/\u001b[A\n",
      "Training loss: 4.85e-02 lr: 4.01e-07:  99%|▉| 13741/13852 [51:27<00:24,  4.48it/\u001b[A\n",
      "Training loss: 5.02e-02 lr: 3.97e-07:  99%|▉| 13742/13852 [51:28<00:24,  4.49it/\u001b[A\n",
      "Training loss: 4.32e-02 lr: 3.93e-07:  99%|▉| 13743/13852 [51:28<00:24,  4.49it/\u001b[A\n",
      "Training loss: 3.22e-02 lr: 3.90e-07:  99%|▉| 13744/13852 [51:28<00:24,  4.49it/\u001b[A\n",
      "Training loss: 3.01e-02 lr: 3.86e-07:  99%|▉| 13745/13852 [51:28<00:23,  4.50it/\u001b[A\n",
      "Training loss: 3.11e-02 lr: 3.83e-07:  99%|▉| 13746/13852 [51:28<00:23,  4.52it/\u001b[A\n",
      "Training loss: 2.66e-02 lr: 3.79e-07:  99%|▉| 13747/13852 [51:29<00:23,  4.54it/\u001b[A\n",
      "Training loss: 8.12e-02 lr: 3.75e-07:  99%|▉| 13748/13852 [51:29<00:23,  4.52it/\u001b[A\n",
      "Training loss: 1.07e-01 lr: 3.72e-07:  99%|▉| 13749/13852 [51:29<00:22,  4.52it/\u001b[A\n",
      "Training loss: 8.67e-02 lr: 3.68e-07:  99%|▉| 13750/13852 [51:29<00:22,  4.52it/\u001b[A\n",
      "Training loss: 8.73e-02 lr: 3.65e-07:  99%|▉| 13751/13852 [51:30<00:22,  4.52it/\u001b[A\n",
      "Training loss: 1.31e-01 lr: 3.61e-07:  99%|▉| 13752/13852 [51:30<00:22,  4.49it/\u001b[A\n",
      "Training loss: 1.03e-01 lr: 3.57e-07:  99%|▉| 13753/13852 [51:30<00:22,  4.50it/\u001b[A\n",
      "Training loss: 9.78e-02 lr: 3.54e-07:  99%|▉| 13754/13852 [51:30<00:21,  4.50it/\u001b[A\n",
      "Training loss: 1.09e-01 lr: 3.50e-07:  99%|▉| 13755/13852 [51:30<00:21,  4.50it/\u001b[A\n",
      "Training loss: 8.90e-02 lr: 3.47e-07:  99%|▉| 13756/13852 [51:31<00:21,  4.50it/\u001b[A\n",
      "Training loss: 8.64e-02 lr: 3.43e-07:  99%|▉| 13757/13852 [51:31<00:21,  4.47it/\u001b[A\n",
      "Training loss: 8.49e-02 lr: 3.39e-07:  99%|▉| 13758/13852 [51:31<00:20,  4.50it/\u001b[A\n",
      "Training loss: 6.25e-02 lr: 3.36e-07:  99%|▉| 13759/13852 [51:31<00:20,  4.53it/\u001b[A\n",
      "Training loss: 6.26e-02 lr: 3.32e-07:  99%|▉| 13760/13852 [51:32<00:20,  4.50it/\u001b[A\n",
      "Training loss: 5.28e-02 lr: 3.28e-07:  99%|▉| 13761/13852 [51:32<00:20,  4.48it/\u001b[A\n",
      "Training loss: 5.34e-02 lr: 3.25e-07:  99%|▉| 13762/13852 [51:32<00:20,  4.50it/\u001b[A\n",
      "Training loss: 3.97e-02 lr: 3.21e-07:  99%|▉| 13763/13852 [51:32<00:19,  4.50it/\u001b[A\n",
      "Training loss: 2.86e-02 lr: 3.18e-07:  99%|▉| 13764/13852 [51:32<00:19,  4.50it/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.59e-02 lr: 3.14e-07:  99%|▉| 13765/13852 [51:33<00:19,  4.51it/\u001b[A\n",
      "Training loss: 5.09e-02 lr: 3.10e-07:  99%|▉| 13766/13852 [51:33<00:19,  4.51it/\u001b[A\n",
      "Training loss: 4.67e-02 lr: 3.07e-07:  99%|▉| 13767/13852 [51:33<00:18,  4.49it/\u001b[A\n",
      "Training loss: 3.52e-02 lr: 3.03e-07:  99%|▉| 13768/13852 [51:33<00:18,  4.49it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 3.00e-07:  99%|▉| 13769/13852 [51:34<00:18,  4.52it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 2.96e-07:  99%|▉| 13770/13852 [51:34<00:18,  4.55it/\u001b[A\n",
      "Training loss: 2.43e-02 lr: 2.92e-07:  99%|▉| 13771/13852 [51:34<00:17,  4.57it/\u001b[A\n",
      "Training loss: 2.69e-02 lr: 2.89e-07:  99%|▉| 13772/13852 [51:34<00:17,  4.52it/\u001b[A\n",
      "Training loss: 2.57e-02 lr: 2.85e-07:  99%|▉| 13773/13852 [51:34<00:17,  4.52it/\u001b[A\n",
      "Training loss: 2.39e-02 lr: 2.82e-07:  99%|▉| 13774/13852 [51:35<00:17,  4.51it/\u001b[A\n",
      "Training loss: 1.71e-02 lr: 2.78e-07:  99%|▉| 13775/13852 [51:35<00:17,  4.50it/\u001b[A\n",
      "Training loss: 2.58e-02 lr: 2.74e-07:  99%|▉| 13776/13852 [51:35<00:16,  4.50it/\u001b[A\n",
      "Training loss: 3.32e-02 lr: 2.71e-07:  99%|▉| 13777/13852 [51:35<00:16,  4.50it/\u001b[A\n",
      "Training loss: 2.77e-02 lr: 2.67e-07:  99%|▉| 13778/13852 [51:36<00:16,  4.50it/\u001b[A\n",
      "Training loss: 3.24e-02 lr: 2.64e-07:  99%|▉| 13779/13852 [51:36<00:16,  4.51it/\u001b[A\n",
      "Training loss: 3.70e-02 lr: 2.60e-07:  99%|▉| 13780/13852 [51:36<00:15,  4.51it/\u001b[A\n",
      "Training loss: 9.44e-02 lr: 2.56e-07:  99%|▉| 13781/13852 [51:36<00:15,  4.51it/\u001b[A\n",
      "Training loss: 6.66e-02 lr: 2.53e-07:  99%|▉| 13782/13852 [51:36<00:15,  4.52it/\u001b[A\n",
      "Training loss: 5.20e-02 lr: 2.49e-07: 100%|▉| 13783/13852 [51:37<00:15,  4.54it/\u001b[A\n",
      "Training loss: 4.19e-02 lr: 2.45e-07: 100%|▉| 13784/13852 [51:37<00:15,  4.53it/\u001b[A\n",
      "Training loss: 6.88e-02 lr: 2.42e-07: 100%|▉| 13785/13852 [51:37<00:14,  4.49it/\u001b[A\n",
      "Training loss: 5.59e-02 lr: 2.38e-07: 100%|▉| 13786/13852 [51:37<00:14,  4.46it/\u001b[A\n",
      "Training loss: 5.17e-02 lr: 2.35e-07: 100%|▉| 13787/13852 [51:38<00:14,  4.36it/\u001b[A\n",
      "Training loss: 3.86e-02 lr: 2.31e-07: 100%|▉| 13788/13852 [51:38<00:14,  4.39it/\u001b[A\n",
      "Training loss: 3.55e-02 lr: 2.27e-07: 100%|▉| 13789/13852 [51:38<00:14,  4.42it/\u001b[A\n",
      "Training loss: 3.00e-02 lr: 2.24e-07: 100%|▉| 13790/13852 [51:38<00:13,  4.45it/\u001b[A\n",
      "Training loss: 3.62e-02 lr: 2.20e-07: 100%|▉| 13791/13852 [51:38<00:13,  4.47it/\u001b[A\n",
      "Training loss: 3.63e-02 lr: 2.17e-07: 100%|▉| 13792/13852 [51:39<00:13,  4.50it/\u001b[A\n",
      "Training loss: 2.73e-02 lr: 2.13e-07: 100%|▉| 13793/13852 [51:39<00:13,  4.53it/\u001b[A\n",
      "Training loss: 4.50e-02 lr: 2.09e-07: 100%|▉| 13794/13852 [51:39<00:12,  4.54it/\u001b[A\n",
      "Training loss: 4.18e-02 lr: 2.06e-07: 100%|▉| 13795/13852 [51:39<00:12,  4.52it/\u001b[A\n",
      "Training loss: 3.54e-02 lr: 2.02e-07: 100%|▉| 13796/13852 [51:40<00:12,  4.52it/\u001b[A\n",
      "Training loss: 7.03e-02 lr: 1.99e-07: 100%|▉| 13797/13852 [51:40<00:12,  4.53it/\u001b[A\n",
      "Training loss: 6.33e-02 lr: 1.95e-07: 100%|▉| 13798/13852 [51:40<00:11,  4.54it/\u001b[A\n",
      "Training loss: 4.53e-02 lr: 1.91e-07: 100%|▉| 13799/13852 [51:40<00:11,  4.54it/\u001b[A\n",
      "Training loss: 3.33e-02 lr: 1.88e-07: 100%|▉| 13800/13852 [51:40<00:11,  4.53it/\u001b[A\n",
      "Training loss: 3.07e-02 lr: 1.84e-07: 100%|▉| 13801/13852 [51:41<00:11,  4.52it/\u001b[A\n",
      "Training loss: 2.36e-02 lr: 1.80e-07: 100%|▉| 13802/13852 [51:41<00:11,  4.49it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 1.77e-07: 100%|▉| 13803/13852 [51:41<00:10,  4.49it/\u001b[A\n",
      "Training loss: 2.57e-02 lr: 1.73e-07: 100%|▉| 13804/13852 [51:41<00:10,  4.51it/\u001b[A\n",
      "Training loss: 2.06e-02 lr: 1.70e-07: 100%|▉| 13805/13852 [51:42<00:10,  4.53it/\u001b[A\n",
      "Training loss: 2.30e-02 lr: 1.66e-07: 100%|▉| 13806/13852 [51:42<00:10,  4.49it/\u001b[A\n",
      "Training loss: 2.04e-02 lr: 1.62e-07: 100%|▉| 13807/13852 [51:42<00:10,  4.48it/\u001b[A\n",
      "Training loss: 3.41e-02 lr: 1.59e-07: 100%|▉| 13808/13852 [51:42<00:09,  4.50it/\u001b[A\n",
      "Training loss: 5.57e-02 lr: 1.55e-07: 100%|▉| 13809/13852 [51:42<00:09,  4.51it/\u001b[A\n",
      "Training loss: 4.14e-02 lr: 1.52e-07: 100%|▉| 13810/13852 [51:43<00:09,  4.51it/\u001b[A\n",
      "Training loss: 4.30e-02 lr: 1.48e-07: 100%|▉| 13811/13852 [51:43<00:09,  4.51it/\u001b[A\n",
      "Training loss: 3.83e-02 lr: 1.44e-07: 100%|▉| 13812/13852 [51:43<00:08,  4.51it/\u001b[A\n",
      "Training loss: 3.76e-02 lr: 1.41e-07: 100%|▉| 13813/13852 [51:43<00:08,  4.52it/\u001b[A\n",
      "Training loss: 4.68e-02 lr: 1.37e-07: 100%|▉| 13814/13852 [51:44<00:08,  4.52it/\u001b[A\n",
      "Training loss: 5.52e-02 lr: 1.34e-07: 100%|▉| 13815/13852 [51:44<00:08,  4.51it/\u001b[A\n",
      "Training loss: 4.46e-02 lr: 1.30e-07: 100%|▉| 13816/13852 [51:44<00:07,  4.53it/\u001b[A\n",
      "Training loss: 4.45e-02 lr: 1.26e-07: 100%|▉| 13817/13852 [51:44<00:07,  4.55it/\u001b[A\n",
      "Training loss: 3.31e-02 lr: 1.23e-07: 100%|▉| 13818/13852 [51:44<00:07,  4.56it/\u001b[A\n",
      "Training loss: 3.28e-02 lr: 1.19e-07: 100%|▉| 13819/13852 [51:45<00:07,  4.57it/\u001b[A\n",
      "Training loss: 3.68e-02 lr: 1.16e-07: 100%|▉| 13820/13852 [51:45<00:07,  4.55it/\u001b[A\n",
      "Training loss: 3.62e-02 lr: 1.12e-07: 100%|▉| 13821/13852 [51:45<00:06,  4.54it/\u001b[A\n",
      "Training loss: 5.50e-02 lr: 1.08e-07: 100%|▉| 13822/13852 [51:45<00:06,  4.53it/\u001b[A\n",
      "Training loss: 4.23e-02 lr: 1.05e-07: 100%|▉| 13823/13852 [51:45<00:06,  4.52it/\u001b[A\n",
      "Training loss: 6.42e-02 lr: 1.01e-07: 100%|▉| 13824/13852 [51:46<00:06,  4.51it/\u001b[A\n",
      "Training loss: 9.34e-02 lr: 9.75e-08: 100%|▉| 13825/13852 [51:46<00:05,  4.51it/\u001b[A\n",
      "Training loss: 6.93e-02 lr: 9.39e-08: 100%|▉| 13826/13852 [51:46<00:05,  4.51it/\u001b[A\n",
      "Training loss: 5.33e-02 lr: 9.02e-08: 100%|▉| 13827/13852 [51:46<00:05,  4.50it/\u001b[A\n",
      "Training loss: 6.12e-02 lr: 8.66e-08: 100%|▉| 13828/13852 [51:47<00:05,  4.50it/\u001b[A\n",
      "Training loss: 5.88e-02 lr: 8.30e-08: 100%|▉| 13829/13852 [51:47<00:05,  4.48it/\u001b[A\n",
      "Training loss: 1.08e-01 lr: 7.94e-08: 100%|▉| 13830/13852 [51:47<00:04,  4.50it/\u001b[A\n",
      "Training loss: 8.65e-02 lr: 7.58e-08: 100%|▉| 13831/13852 [51:47<00:04,  4.52it/\u001b[A\n",
      "Training loss: 7.21e-02 lr: 7.22e-08: 100%|▉| 13832/13852 [51:48<00:04,  4.50it/\u001b[A\n",
      "Training loss: 5.58e-02 lr: 6.86e-08: 100%|▉| 13833/13852 [51:48<00:04,  4.51it/\u001b[A\n",
      "Training loss: 4.62e-02 lr: 6.50e-08: 100%|▉| 13834/13852 [51:48<00:03,  4.52it/\u001b[A\n",
      "Training loss: 3.46e-02 lr: 6.14e-08: 100%|▉| 13835/13852 [51:48<00:03,  4.52it/\u001b[A\n",
      "Training loss: 2.53e-02 lr: 5.78e-08: 100%|▉| 13836/13852 [51:48<00:03,  4.52it/\u001b[A\n",
      "Training loss: 8.25e-02 lr: 5.41e-08: 100%|▉| 13837/13852 [51:49<00:03,  4.52it/\u001b[A\n",
      "Training loss: 9.01e-02 lr: 5.05e-08: 100%|▉| 13838/13852 [51:49<00:03,  4.51it/\u001b[A\n",
      "Training loss: 7.87e-02 lr: 4.69e-08: 100%|▉| 13839/13852 [51:49<00:02,  4.52it/\u001b[A\n",
      "Training loss: 9.33e-02 lr: 4.33e-08: 100%|▉| 13840/13852 [51:49<00:02,  4.50it/\u001b[A\n",
      "Training loss: 8.35e-02 lr: 3.97e-08: 100%|▉| 13841/13852 [51:49<00:02,  4.52it/\u001b[A\n",
      "Training loss: 6.01e-02 lr: 3.61e-08: 100%|▉| 13842/13852 [51:50<00:02,  4.54it/\u001b[A\n",
      "Training loss: 5.02e-02 lr: 3.25e-08: 100%|▉| 13843/13852 [51:50<00:01,  4.56it/\u001b[A\n",
      "Training loss: 8.24e-02 lr: 2.89e-08: 100%|▉| 13844/13852 [51:50<00:01,  4.57it/\u001b[A\n",
      "Training loss: 6.75e-02 lr: 2.53e-08: 100%|▉| 13845/13852 [51:50<00:01,  4.54it/\u001b[A\n",
      "Training loss: 5.21e-02 lr: 2.17e-08: 100%|▉| 13846/13852 [51:51<00:01,  4.54it/\u001b[A\n",
      "Training loss: 5.18e-02 lr: 1.80e-08: 100%|▉| 13847/13852 [51:51<00:01,  4.51it/\u001b[A\n",
      "Training loss: 5.08e-02 lr: 1.44e-08: 100%|▉| 13848/13852 [51:51<00:00,  4.51it/\u001b[A\n",
      "Training loss: 5.58e-02 lr: 1.08e-08: 100%|▉| 13849/13852 [51:51<00:00,  4.50it/\u001b[A\n",
      "Training loss: 6.29e-02 lr: 7.22e-09: 100%|▉| 13850/13852 [51:51<00:00,  4.50it/\u001b[A\n",
      "Training loss: 5.64e-02 lr: 3.61e-09: 100%|▉| 13851/13852 [51:52<00:00,  4.47it/\u001b[A\n",
      "Training loss: 4.42e-02 lr: 0.00e+00: 100%|█| 13852/13852 [51:52<00:00,  4.45it/\u001b[A\n",
      "Epoch: 100%|████████████████████████████████████| 1/1 [51:52<00:00, 3112.45s/it]\n"
     ]
    }
   ],
   "source": [
    "!python run_classifier.py \\\n",
    "--data_dir=\"data/yelp/bert_classifier_training\" \\\n",
    "--bert_model=bert-base-uncased \\\n",
    "--task_name=yelp \\\n",
    "--output_dir=\"bert_models\" \\\n",
    "--max_seq_length=70 \\\n",
    "--do_train \\\n",
    "--do_lower_case \\\n",
    "--train_batch_size=32 \\\n",
    "--num_train_epochs=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9c751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
