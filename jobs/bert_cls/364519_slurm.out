You have the following GPUs: [5]
JOB:  364519
TASK: 
HOST: rivendell.rpl

Fri Mar 10 18:01:32 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  On   | 00000000:3D:00.0 Off |                  N/A |
|ERR!   38C    P2   ERR! / 250W |      1MiB / 11019MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
03/10/2023 18:02:25 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
03/10/2023 18:02:25 - ERROR - pytorch_pretrained_bert.tokenization -   Model name 'bert-base-uncased' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt' was a path or url but couldn't find any file associated to this path or url.
03/10/2023 18:02:25 - INFO - __main__ -   Looking at /Midgard/home/martinig/transformer-drg-style-transfer/data/yelp/bert_classifier_training
03/10/2023 18:02:27 - ERROR - pytorch_pretrained_bert.modeling -   Model name 'bert-base-uncased' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz' was a path or url but couldn't find any file associated to this path or url.
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
Traceback (most recent call last):
  File "run_classifier.py", line 581, in <module>
    main()
  File "run_classifier.py", line 408, in main
    model.to(device)
AttributeError: 'NoneType' object has no attribute 'to'
